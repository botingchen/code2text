{"id": 24, "code": "func (c *ServiceDiscoveryConfig) Validate() error {\n\tfor _, cfg := range c.AzureSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in azure_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.ConsulSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in consul_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.DNSSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in dns_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.EC2SDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in ec2_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.FileSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in file_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.GCESDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in gce_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.KubernetesSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in kubernetes_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.MarathonSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in marathon_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.NerveSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in nerve_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.OpenstackSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in openstack_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.ServersetSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in serverset_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.StaticConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in static_configs\")\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// Validate validates the ServiceDiscoveryConfig.", "generated": "// Check for a missing module name and check if it exists // before calling the service discovery config function to determine whether // this is an empty configuration var newConfiguration = Service Discovery Config(ctx); return false; } func main () { try { log.Println (\"Module \" + __dirname + \"/\" ,"}
{"id": 36, "code": "func NewDiscovery(conf SDConfig, logger log.Logger) (*Discovery, error) {\n\trt, err := config_util.NewRoundTripperFromConfig(conf.HTTPClientConfig, \"marathon_sd\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif len(conf.AuthToken) > 0 {\n\t\trt, err = newAuthTokenRoundTripper(conf.AuthToken, rt)\n\t} else if len(conf.AuthTokenFile) > 0 {\n\t\trt, err = newAuthTokenFileRoundTripper(conf.AuthTokenFile, rt)\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\td := &Discovery{\n\t\tclient:     &http.Client{Transport: rt},\n\t\tservers:    conf.Servers,\n\t\tappsClient: fetchApps,\n\t}\n\td.Discovery = refresh.NewDiscovery(\n\t\tlogger,\n\t\t\"marathon\",\n\t\ttime.Duration(conf.RefreshInterval),\n\t\td.refresh,\n\t)\n\treturn d, nil\n}", "reference": "// NewDiscovery returns a new Marathon Discovery.", "generated": "// Create a Discovery session for the specified Discovery protocol and create an initial connection to it with no additional parameters or data required by this method.\n // This is done using SessionManager's init() function which returns all of its arguments as well (including any optional fields). The default value will be used when creating sessions"}
{"id": 50, "code": "func (d *Discovery) shouldWatch(name string, tags []string) bool {\n\treturn d.shouldWatchFromName(name) && d.shouldWatchFromTags(tags)\n}", "reference": "// shouldWatch returns whether the service of the given name should be watched.", "generated": "// Should watch from the specified tag list if it is not already a Discovery object and has no default value for `tag`.\n// This function will return true when an error occurs with respect to this discovery or nil otherwise.\n\n // Returns false on success in case of failure by setting Discovery's DefaultValue property as"}
{"id": 52, "code": "func (d *Discovery) getDatacenter() error {\n\t// If the datacenter was not set from clientConf, let's get it from the local Consul agent\n\t// (Consul default is to use local node's datacenter if one isn't given for a query).\n\tif d.clientDatacenter != \"\" {\n\t\treturn nil\n\t}\n\n\tinfo, err := d.client.Agent().Self()\n\tif err != nil {\n\t\tlevel.Error(d.logger).Log(\"msg\", \"Error retrieving datacenter name\", \"err\", err)\n\t\trpcFailuresCount.Inc()\n\t\treturn err\n\t}\n\n\tdc, ok := info[\"Config\"][\"Datacenter\"].(string)\n\tif !ok {\n\t\terr := errors.Errorf(\"invalid value '%v' for Config.Datacenter\", info[\"Config\"][\"Datacenter\"])\n\t\tlevel.Error(d.logger).Log(\"msg\", \"Error retrieving datacenter name\", \"err\", err)\n\t\treturn err\n\t}\n\n\td.clientDatacenter = dc\n\treturn nil\n}", "reference": "// Get the local datacenter if not specified.", "generated": "This method returns an instance of Datastore that can be used as part or in conjunction with other methods on DDS and provides access control over its data structure by querying queries against this database using SQLite3DB . The following example uses DB2-based databases such AsyncDb , which are available through Mongo"}
{"id": 64, "code": "func (ls Labels) HashForLabels(names ...string) uint64 {\n\tb := make([]byte, 0, 1024)\n\n\tfor _, v := range ls {\n\t\tfor _, n := range names {\n\t\t\tif v.Name == n {\n\t\t\t\tb = append(b, v.Name...)\n\t\t\t\tb = append(b, sep)\n\t\t\t\tb = append(b, v.Value...)\n\t\t\t\tb = append(b, sep)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn xxhash.Sum64(b)\n}", "reference": "// HashForLabels returns a hash value for the labels matching the provided names.", "generated": "This function creates a hash of the labels in an array and returns them as strings with their corresponding values for each label on that list or if they are not found by searching through all available keys to find any matching ones within it's scope using lmdir . The returned string is then passed into this method which will return"}
{"id": 117, "code": "func ParseExpr(input string) (Expr, error) {\n\tp := newParser(input)\n\n\texpr, err := p.parseExpr()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = p.typecheck(expr)\n\treturn expr, err\n}", "reference": "// ParseExpr returns the expression parsed from the input.", "generated": "Parseling expr is a simple parser that parses the input and returns an ExPr object with all of the information needed to parse it into its appropriate form. It can be used as part or in conjunction for parsing any number if necessary; see also ParserInfo#ExtractStrings().\nExample:"}
{"id": 129, "code": "func (p *parser) expectOneOf(exp1, exp2 ItemType, context string) item {\n\ttoken := p.next()\n\tif token.typ != exp1 && token.typ != exp2 {\n\t\tp.errorf(\"unexpected %s in %s, expected %s or %s\", token.desc(), context, exp1.desc(), exp2.desc())\n\t}\n\treturn token\n}", "reference": "// expectOneOf consumes the next token and guarantees it has one of the required types.", "generated": "The parser expects one of the following items to be present at a given time and returns an error if it does not match any other value for that particular type :\ntype ValueError = None , // Error handling only when there is no matching element return nil\n func parseValueError () -> Result { fmt.(*args"}
{"id": 133, "code": "func (p *parser) expectType(node Node, want ValueType, context string) {\n\tt := p.checkType(node)\n\tif t != want {\n\t\tp.errorf(\"expected type %s in %s, got %s\", documentedType(want), context, documentedType(t))\n\t}\n}", "reference": "// expectType checks the type of the node and raises an error if it\n// is not of the expected type.", "generated": "// Check if the node is a valid Type and return it as an error message for any errors encountered by this function. If not, check that there are no known types of nodes to be checked against before returning them with nil .\n// Returns true or false depending on whether we have found one at all; otherwise returns"}
{"id": 145, "code": "func New(minSize, maxSize int, factor float64, makeFunc func(int) interface{}) *Pool {\n\tif minSize < 1 {\n\t\tpanic(\"invalid minimum pool size\")\n\t}\n\tif maxSize < 1 {\n\t\tpanic(\"invalid maximum pool size\")\n\t}\n\tif factor < 1 {\n\t\tpanic(\"invalid factor\")\n\t}\n\n\tvar sizes []int\n\n\tfor s := minSize; s <= maxSize; s = int(float64(s) * factor) {\n\t\tsizes = append(sizes, s)\n\t}\n\n\tp := &Pool{\n\t\tbuckets: make([]sync.Pool, len(sizes)),\n\t\tsizes:   sizes,\n\t\tmake:    makeFunc,\n\t}\n\n\treturn p\n}", "reference": "// New returns a new Pool with size buckets for minSize to maxSize\n// increasing by the given factor.", "generated": "NewPool is a new Pool that implements the following features of its own :\n* The default implementation for all pools (including those with no other implementations).\n*/ // This feature was introduced in version 2 and 3 by Jens Stegenkamp to allow userspace-based applications using an existing API without having any"}
{"id": 165, "code": "func sendAlerts(s sender, externalURL string) rules.NotifyFunc {\n\treturn func(ctx context.Context, expr string, alerts ...*rules.Alert) {\n\t\tvar res []*notifier.Alert\n\n\t\tfor _, alert := range alerts {\n\t\t\ta := &notifier.Alert{\n\t\t\t\tStartsAt:     alert.FiredAt,\n\t\t\t\tLabels:       alert.Labels,\n\t\t\t\tAnnotations:  alert.Annotations,\n\t\t\t\tGeneratorURL: externalURL + strutil.TableLinkForExpression(expr),\n\t\t\t}\n\t\t\tif !alert.ResolvedAt.IsZero() {\n\t\t\t\ta.EndsAt = alert.ResolvedAt\n\t\t\t} else {\n\t\t\t\ta.EndsAt = alert.ValidUntil\n\t\t\t}\n\t\t\tres = append(res, a)\n\t\t}\n\n\t\tif len(alerts) > 0 {\n\t\t\ts.Send(res...)\n\t\t}\n\t}\n}", "reference": "// sendAlerts implements the rules.NotifyFunc for a Notifier.", "generated": "// Send notifications to the specified URL and return an error if no response is received from it // or returns nil otherwise returning None .\n// Returns: true for all URLs that are not sent by this method (default false).\n/**\n*/\npackage notification\nimport os import io.IOException\nimport sys."}
{"id": 166, "code": "func (g *RuleGroups) Validate() (errs []error) {\n\tset := map[string]struct{}{}\n\n\tfor _, g := range g.Groups {\n\t\tif g.Name == \"\" {\n\t\t\terrs = append(errs, errors.Errorf(\"Groupname should not be empty\"))\n\t\t}\n\n\t\tif _, ok := set[g.Name]; ok {\n\t\t\terrs = append(\n\t\t\t\terrs,\n\t\t\t\terrors.Errorf(\"groupname: \\\"%s\\\" is repeated in the same file\", g.Name),\n\t\t\t)\n\t\t}\n\n\t\tset[g.Name] = struct{}{}\n\n\t\tfor i, r := range g.Rules {\n\t\t\tfor _, err := range r.Validate() {\n\t\t\t\tvar ruleName string\n\t\t\t\tif r.Alert != \"\" {\n\t\t\t\t\truleName = r.Alert\n\t\t\t\t} else {\n\t\t\t\t\truleName = r.Record\n\t\t\t\t}\n\t\t\t\terrs = append(errs, &Error{\n\t\t\t\t\tGroup:    g.Name,\n\t\t\t\t\tRule:     i,\n\t\t\t\t\tRuleName: ruleName,\n\t\t\t\t\tErr:      err,\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t}\n\n\treturn errs\n}", "reference": "// Validate validates all rules in the rule groups.", "generated": "This function checks if a group exists and returns an error message when it does so without checking for any other members of that list or its descendants within this scope. If no member has been found by default then all groups are considered to have existed at some point during their existence as well; otherwise they will remain undefined until further"}
{"id": 182, "code": "func (r *AlertingRule) SetHealth(health RuleHealth) {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\tr.health = health\n}", "reference": "// SetHealth sets the current health of the alerting rule.", "generated": "// Sets health to the specified status, if any.\n // This is a boolean value that indicates whether or not an alert should be sent when it's reached. If true ,\nif false then this will cause all alerts to fail and send no messages at once.\n// The default setting for Health checks out of"}
{"id": 185, "code": "func (r *AlertingRule) SetEvaluationDuration(dur time.Duration) {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\tr.evaluationDuration = dur\n}", "reference": "// SetEvaluationDuration updates evaluationDuration to the duration it took to evaluate the rule on its last evaluation.", "generated": "// Sets the evaluation duration of a rule to be set by the user, using an optional value for `setEq` and `unlocks`.\n // The default is 0 seconds; if this option was specified as nil, it will not work in practice."}
{"id": 197, "code": "func (g *Group) GetEvaluationDuration() time.Duration {\n\tg.mtx.Lock()\n\tdefer g.mtx.Unlock()\n\treturn g.evaluationDuration\n}", "reference": "// GetEvaluationDuration returns the time in seconds it took to evaluate the rule group.", "generated": "This function returns the duration of the given group, in milliseconds or seconds depending on whether it is a single-element list with an element and/or multiple elements that are not part one; if so specified, this will return either None , which means no grouping at all for any particular item within its range, as defined"}
{"id": 199, "code": "func (g *Group) GetEvaluationTimestamp() time.Time {\n\tg.mtx.Lock()\n\tdefer g.mtx.Unlock()\n\treturn g.evaluationTimestamp\n}", "reference": "// GetEvaluationTimestamp returns the time the last evaluation of the rule group took place.", "generated": "This function returns the current evaluation timestamp of the group, and optionally a reference to an instance of GObject . The value returned is used as part for debugging purposes only if it has been set in this way before execution started or otherwise specified by any other method on the target object's runtime environment variable that was called with no"}
{"id": 212, "code": "func (w *WALWatcher) Start() {\n\tw.setMetrics()\n\tlevel.Info(w.logger).Log(\"msg\", \"starting WAL watcher\", \"queue\", w.name)\n\n\tgo w.loop()\n}", "reference": "// Start the WALWatcher.", "generated": "This method is called when the Watchers are started and stopped by a callback function, which will be invoked once every 10 seconds for each of these events to complete in order that they can receive notifications from their clients about changes made on this server or other servers running within its scope. The callbacks must return an object with"}
{"id": 225, "code": "func (sd *StaticProvider) Run(ctx context.Context, ch chan<- []*targetgroup.Group) {\n\t// We still have to consider that the consumer exits right away in which case\n\t// the context will be canceled.\n\tselect {\n\tcase ch <- sd.TargetGroups:\n\tcase <-ctx.Done():\n\t}\n\tclose(ch)\n}", "reference": "// Run implements the Worker interface.", "generated": "/** The Context is a wrapper around an existing target group and returns it as if by calling run() . */\n// This method can also return nil for non-nil success or failure depending on whether we are running with `run` , `catch`, etc.,\n // provided there is no other way of returning true"}
{"id": 228, "code": "func NewDiscovery(\n\tsrvs []string,\n\ttimeout time.Duration,\n\tpaths []string,\n\tlogger log.Logger,\n\tpf func(data []byte, path string) (model.LabelSet, error),\n) (*Discovery, error) {\n\tif logger == nil {\n\t\tlogger = log.NewNopLogger()\n\t}\n\n\tconn, _, err := zk.Connect(\n\t\tsrvs, timeout,\n\t\tfunc(c *zk.Conn) {\n\t\t\tc.SetLogger(treecache.NewZookeeperLogger(logger))\n\t\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tupdates := make(chan treecache.ZookeeperTreeCacheEvent)\n\tsd := &Discovery{\n\t\tconn:    conn,\n\t\tupdates: updates,\n\t\tsources: map[string]*targetgroup.Group{},\n\t\tparse:   pf,\n\t\tlogger:  logger,\n\t}\n\tfor _, path := range paths {\n\t\tsd.treeCaches = append(sd.treeCaches, treecache.NewZookeeperTreeCache(conn, path, updates, logger))\n\t}\n\treturn sd, nil\n}", "reference": "// NewDiscovery returns a new discovery along Zookeeper parses with\n// the given parse function.", "generated": "// Create a new Discovery object that will be used to create the ZOKELEPERLOGGER and LOGGING logs for each of its sources in an existing root node's Tree cache event loop. This is done by creating two separate objects named `root` with their own unique namespaces as well // provided they"}
{"id": 244, "code": "func (q *querier) Select(p *storage.SelectParams, matchers ...*labels.Matcher) (storage.SeriesSet, storage.Warnings, error) {\n\tquery, err := ToQuery(q.mint, q.maxt, matchers, p)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tremoteReadGauge := remoteReadQueries.WithLabelValues(q.client.Name())\n\tremoteReadGauge.Inc()\n\tdefer remoteReadGauge.Dec()\n\n\tres, err := q.client.Read(q.ctx, query)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn FromQueryResult(res), nil, nil\n}", "reference": "// Select implements storage.Querier and uses the given matchers to read series\n// sets from the Client.", "generated": "// Query a series of strings to select the specified string from an array or list and return it as its result if any are found in that sequence\n // The following example is used for testing purposes only; see also `quotient` below\n// This function returns all results returned by this method except those which were"}
{"id": 298, "code": "func NewRegexp(s string) (Regexp, error) {\n\tregex, err := regexp.Compile(\"^(?:\" + s + \")$\")\n\treturn Regexp{\n\t\tRegexp:   regex,\n\t\toriginal: s,\n\t}, err\n}", "reference": "// NewRegexp creates a new anchored Regexp and returns an error if the\n// passed-in regular expression does not compile.", "generated": "New rematch is a new match for the given strings and returns an empty list of matches that are valid in all cases except those where no matching pattern exists or if there was one already found by calling `new` with any other method on it to find out which matched patterns were present at runtime using its own methods from"}
{"id": 303, "code": "func (sp *scrapePool) reload(cfg *config.ScrapeConfig) error {\n\ttargetScrapePoolReloads.Inc()\n\tstart := time.Now()\n\n\tsp.mtx.Lock()\n\tdefer sp.mtx.Unlock()\n\n\tclient, err := config_util.NewClientFromConfig(cfg.HTTPClientConfig, cfg.JobName)\n\tif err != nil {\n\t\ttargetScrapePoolReloadsFailed.Inc()\n\t\treturn errors.Wrap(err, \"error creating HTTP client\")\n\t}\n\tsp.config = cfg\n\toldClient := sp.client\n\tsp.client = client\n\n\tvar (\n\t\twg              sync.WaitGroup\n\t\tinterval        = time.Duration(sp.config.ScrapeInterval)\n\t\ttimeout         = time.Duration(sp.config.ScrapeTimeout)\n\t\tlimit           = int(sp.config.SampleLimit)\n\t\thonorLabels     = sp.config.HonorLabels\n\t\thonorTimestamps = sp.config.HonorTimestamps\n\t\tmrc             = sp.config.MetricRelabelConfigs\n\t)\n\n\tfor fp, oldLoop := range sp.loops {\n\t\tvar (\n\t\t\tt       = sp.activeTargets[fp]\n\t\t\ts       = &targetScraper{Target: t, client: sp.client, timeout: timeout}\n\t\t\tnewLoop = sp.newLoop(scrapeLoopOptions{\n\t\t\t\ttarget:          t,\n\t\t\t\tscraper:         s,\n\t\t\t\tlimit:           limit,\n\t\t\t\thonorLabels:     honorLabels,\n\t\t\t\thonorTimestamps: honorTimestamps,\n\t\t\t\tmrc:             mrc,\n\t\t\t})\n\t\t)\n\t\twg.Add(1)\n\n\t\tgo func(oldLoop, newLoop loop) {\n\t\t\toldLoop.stop()\n\t\t\twg.Done()\n\n\t\t\tgo newLoop.run(interval, timeout, nil)\n\t\t}(oldLoop, newLoop)\n\n\t\tsp.loops[fp] = newLoop\n\t}\n\n\twg.Wait()\n\toldClient.CloseIdleConnections()\n\ttargetReloadIntervalLength.WithLabelValues(interval.String()).Observe(\n\t\ttime.Since(start).Seconds(),\n\t)\n\treturn nil\n}", "reference": "// reload the scrape pool with the given scrape configuration. The target state is preserved\n// but all scrape loops are restarted with the new scrape configuration.\n// This method returns after all scrape loops that were stopped have stopped scraping.", "generated": "// This function is used to check if a connection has been established and return the number of connections that have not yet started or closed in an attempt at reconnection with another server // using this method for each request made by clients on their own servers without any additional parameters; it returns true when no more requests are received from"}
{"id": 332, "code": "func NewDiscovery(conf *SDConfig, logger log.Logger) *Discovery {\n\tif logger == nil {\n\t\tlogger = log.NewNopLogger()\n\t}\n\n\tdisc := &Discovery{\n\t\tpaths:      conf.Files,\n\t\tinterval:   time.Duration(conf.RefreshInterval),\n\t\ttimestamps: make(map[string]float64),\n\t\tlogger:     logger,\n\t}\n\tfileSDTimeStamp.addDiscoverer(disc)\n\treturn disc\n}", "reference": "// NewDiscovery returns a new file discovery for the given paths.", "generated": "// Create a new Discovery instance for the specified file descriptor and logging status information in JSON format.\n // This is used to create an initial discovery of all files that are currently being created by this application (including any changes made). The name of each entry must be unique from its parent directory. If no entries exist within"}
{"id": 349, "code": "func (r *ewmaRate) tick() {\n\tnewEvents := atomic.LoadInt64(&r.newEvents)\n\tatomic.AddInt64(&r.newEvents, -newEvents)\n\tinstantRate := float64(newEvents) / r.interval.Seconds()\n\n\tr.mutex.Lock()\n\tdefer r.mutex.Unlock()\n\n\tif r.init {\n\t\tr.lastRate += r.alpha * (instantRate - r.lastRate)\n\t} else {\n\t\tr.init = true\n\t\tr.lastRate = instantRate\n\t}\n}", "reference": "// tick assumes to be called every r.interval.", "generated": "// Initializes the new events and returns an array of all existing ones that have been created by this method.\n // The initializer is a mutable object with no internal state or initialization information stored in it. It can be used to initialize any number thereof without having its own init(). This will cause\nStreamerBot to"}
{"id": 390, "code": "func (a *Args) GetBool(key string) bool {\n\tswitch b2s(a.Peek(key)) {\n\t// Support the same true cases as strconv.ParseBool\n\t// See: https://github.com/golang/go/blob/4e1b11e2c9bdb0ddea1141eed487be1a626ff5be/src/strconv/atob.go#L12\n\t// and Y and Yes versions.\n\tcase \"1\", \"t\", \"T\", \"true\", \"TRUE\", \"True\", \"y\", \"yes\", \"Y\", \"YES\", \"Yes\":\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}", "reference": "// GetBool returns boolean value for the given key.\n//\n// true is returned for \"1\", \"t\", \"T\", \"true\", \"TRUE\", \"True\", \"y\", \"yes\", \"Y\", \"YES\", \"Yes\",\n// otherwise false is returned.", "generated": "This function returns a list of strings that are returned by this method, or nil if no such result is found in any given case. The return value will be passed to an optional callback which can then either pass it back through for further processing on subsequent calls, returning null otherwise. This functions should not cause problems with Go"}
{"id": 420, "code": "func (cc *LBClient) DoTimeout(req *Request, resp *Response, timeout time.Duration) error {\n\tdeadline := time.Now().Add(timeout)\n\treturn cc.get().DoDeadline(req, resp, deadline)\n}", "reference": "// DoTimeout calculates deadline and calls DoDeadline on the least loaded client", "generated": "This method returns a new LB client that does not have any deadlines or wait times specified in the request body. It is used to check if an incoming connection has been established and then waits for it with no waiting conditions set before returning nil . The callback function will be called when all of its parameters are passed as arguments"}
{"id": 430, "code": "func (ctx *RequestCtx) TLSConnectionState() *tls.ConnectionState {\n\ttlsConn, ok := ctx.c.(connTLSer)\n\tif !ok {\n\t\treturn nil\n\t}\n\tstate := tlsConn.ConnectionState()\n\treturn &state\n}", "reference": "// TLSConnectionState returns TLS connection state.\n//\n// The function returns nil if the underlying connection isn't tls.Conn.\n//\n// The returned state may be used for verifying TLS version, client certificates,\n// etc.", "generated": "// Initializes the connection state and returns a new string representing its contents in bytes of length 0x0A00 .\n // The initial value is an array containing all strings that are to be returned by TLS for each session or buffer-local key pair used as input; this will return null if no such keys exist"}
{"id": 453, "code": "func (s *Server) Serve(ln net.Listener) error {\n\tvar lastOverflowErrorTime time.Time\n\tvar lastPerIPErrorTime time.Time\n\tvar c net.Conn\n\tvar err error\n\n\ts.mu.Lock()\n\t{\n\t\tif s.ln != nil {\n\t\t\ts.mu.Unlock()\n\t\t\treturn ErrAlreadyServing\n\t\t}\n\n\t\ts.ln = ln\n\t\ts.done = make(chan struct{})\n\t}\n\ts.mu.Unlock()\n\n\tmaxWorkersCount := s.getConcurrency()\n\ts.concurrencyCh = make(chan struct{}, maxWorkersCount)\n\twp := &workerPool{\n\t\tWorkerFunc:      s.serveConn,\n\t\tMaxWorkersCount: maxWorkersCount,\n\t\tLogAllErrors:    s.LogAllErrors,\n\t\tLogger:          s.logger(),\n\t\tconnState:       s.setState,\n\t}\n\twp.Start()\n\n\t// Count our waiting to accept a connection as an open connection.\n\t// This way we can't get into any weird state where just after accepting\n\t// a connection Shutdown is called which reads open as 0 because it isn't\n\t// incremented yet.\n\tatomic.AddInt32(&s.open, 1)\n\tdefer atomic.AddInt32(&s.open, -1)\n\n\tfor {\n\t\tif c, err = acceptConn(s, ln, &lastPerIPErrorTime); err != nil {\n\t\t\twp.Stop()\n\t\t\tif err == io.EOF {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\ts.setState(c, StateNew)\n\t\tatomic.AddInt32(&s.open, 1)\n\t\tif !wp.Serve(c) {\n\t\t\tatomic.AddInt32(&s.open, -1)\n\t\t\ts.writeFastError(c, StatusServiceUnavailable,\n\t\t\t\t\"The connection cannot be served because Server.Concurrency limit exceeded\")\n\t\t\tc.Close()\n\t\t\ts.setState(c, StateClosed)\n\t\t\tif time.Since(lastOverflowErrorTime) > time.Minute {\n\t\t\t\ts.logger().Printf(\"The incoming connection cannot be served, because %d concurrent connections are served. \"+\n\t\t\t\t\t\"Try increasing Server.Concurrency\", maxWorkersCount)\n\t\t\t\tlastOverflowErrorTime = time.Now()\n\t\t\t}\n\n\t\t\t// The current server reached concurrency limit,\n\t\t\t// so give other concurrently running servers a chance\n\t\t\t// accepting incoming connections on the same address.\n\t\t\t//\n\t\t\t// There is a hope other servers didn't reach their\n\t\t\t// concurrency limits yet :)\n\t\t\t//\n\t\t\t// See also: https://github.com/valyala/fasthttp/pull/485#discussion_r239994990\n\t\t\tif s.SleepWhenConcurrencyLimitsExceeded > 0 {\n\t\t\t\ttime.Sleep(s.SleepWhenConcurrencyLimitsExceeded)\n\t\t\t}\n\t\t}\n\t\tc = nil\n\t}\n}", "reference": "// Serve serves incoming connections from the given listener.\n//\n// Serve blocks until the given listener returns permanent error.", "generated": "This function takes two parameters and returns one of them for each parameter that was passed in by this call. It then calls its own callback method with all available arguments from both methods until either value has been returned or no values have been received at runtime. If there were multiple requests made using these functions before calling func , they"}
{"id": 480, "code": "func (req *Request) SetBodyString(body string) {\n\treq.RemoveMultipartFormFiles()\n\treq.closeBodyStream()\n\treq.bodyBuffer().SetString(body)\n}", "reference": "// SetBodyString sets request body.", "generated": "// Sets the body buffer to be closed by calling setBodybuffer .\n // Returns a String containing all of the requested files and headers, including any errors or other information that may have been received from them."}
{"id": 511, "code": "func (h *ResponseHeader) SetCookie(cookie *Cookie) {\n\th.cookies = setArgBytes(h.cookies, cookie.Key(), cookie.Cookie(), argsHasValue)\n}", "reference": "// SetCookie sets the given response cookie.\n//\n// It is save re-using the cookie after the function returns.", "generated": "Set Cookie is a wrapper around the HTTP request header and returns an object that contains all cookies in its cache for use with Cookies . The returned objects are passed to COOKIE_SETTINGS , which will be used when creating new requests from your application's web server or other applications using WebKit APIs such as GET"}
{"id": 513, "code": "func (h *ResponseHeader) DelCookie(key string) {\n\th.cookies = delAllArgs(h.cookies, key)\n}", "reference": "// DelCookie removes cookie under the given key from response header.\n//\n// Note that DelCookie doesn't remove the cookie from the client.\n// Use DelClientCookie instead.", "generated": "This method returns a Cookie object that contains the cookie information for each request and its associated parameters as well in JSON format using an optional hash function to be used when creating new requests or returning responses from existing ones . The returned cookies are then passed into this callback which is called once per response with no additional arguments required by default"}
{"id": 517, "code": "func (h *ResponseHeader) PeekBytes(key []byte) []byte {\n\th.bufKV.key = append(h.bufKV.key[:0], key...)\n\tnormalizeHeaderKey(h.bufKV.key, h.disableNormalizing)\n\treturn h.peek(h.bufKV.key)\n}", "reference": "// PeekBytes returns header value for the given key.\n//\n// Returned value is valid until the next call to ResponseHeader.\n// Do not store references to returned value. Make copies instead.", "generated": "This method is used to peek bytes of a header and return the byte value that was returned by this function in response for each request received from an HTTP server using PUT/POST requests with no additional parameters or headers than specified on-the fly at any time during processing within its scope. The following example shows how it"}
{"id": 525, "code": "func (h *RequestHeader) WriteTo(w io.Writer) (int64, error) {\n\tn, err := w.Write(h.Header())\n\treturn int64(n), err\n}", "reference": "// WriteTo writes request header to w.\n//\n// WriteTo implements io.WriterTo interface.", "generated": "This function returns a string representation of the request header and an optional message to be sent when it is received by the client or server in response to requests from clients requesting data for which there are no headers specified on this page. The returned value will contain information about whether any requested fields have been changed since receiving that field;"}
{"id": 536, "code": "func (c *Cookie) Expire() time.Time {\n\texpire := c.expire\n\tif expire.IsZero() {\n\t\texpire = CookieExpireUnlimited\n\t}\n\treturn expire\n}", "reference": "// Expire returns cookie expiration time.\n//\n// CookieExpireUnlimited is returned if cookie doesn't expire", "generated": "// Create a new cookie for the specified date and Time zone, using an existing expiration policy to ensure that it is valid until expired expires in either of those zones.\n// This method returns true if this exists or false otherwise.\n// The default value will be nil when no cookies are created by any given user agent"}
{"id": 537, "code": "func (c *Cookie) SetValue(value string) {\n\tc.value = append(c.value[:0], value...)\n}", "reference": "// SetValue sets cookie value.", "generated": "Cookie sets the values of a cookie to an array containing all cookies that have been set by Cookie . The default is nil , but can be changed with --cookie-set option in settings file or via setting options object from COOKIE_SETTING environment variable, ee :\n// Setting `cookie` will"}
{"id": 577, "code": "func (mx *Mux) Patch(pattern string, handlerFn http.HandlerFunc) {\n\tmx.handle(mPATCH, pattern, handlerFn)\n}", "reference": "// Patch adds the route `pattern` that matches a PATCH http method to\n// execute the `handlerFn` http.HandlerFunc.", "generated": "Patch is a patch function that returns an error if the given path does not match any of its parameters or nil otherwise causes it to fail with errors in response and return false . It can be used as follows for debugging purposes only :\n// Check whether there are no matching paths on this file // If so, check all"}
{"id": 579, "code": "func (mx *Mux) Put(pattern string, handlerFn http.HandlerFunc) {\n\tmx.handle(mPUT, pattern, handlerFn)\n}", "reference": "// Put adds the route `pattern` that matches a PUT http method to\n// execute the `handlerFn` http.HandlerFunc.", "generated": "This function returns a list of strings that are matched against the given URL and handlers for each match in an HTTP request or response body respectively. The returned lists can be used to create new URLs with different attributes than those provided by MIX_GET . For example if you want to use mappings from \"http://example"}
{"id": 600, "code": "func SearchArticles(w http.ResponseWriter, r *http.Request) {\n\trender.RenderList(w, r, NewArticleListResponse(articles))\n}", "reference": "// SearchArticles searches the Articles data for a matching article.\n// It's just a stub, but you get the idea.", "generated": "Search Article is a wrapper around the Request interface that provides an API for retrieving and processing content from web pages using JSON or XML data structures (e., HTTP/1.0). It implements two main methods of searching within WebKit's search engine; firstly, it returns information about what has been found in each"}
{"id": 603, "code": "func UpdateArticle(w http.ResponseWriter, r *http.Request) {\n\tarticle := r.Context().Value(\"article\").(*Article)\n\n\tdata := &ArticleRequest{Article: article}\n\tif err := render.Bind(r, data); err != nil {\n\t\trender.Render(w, r, ErrInvalidRequest(err))\n\t\treturn\n\t}\n\tarticle = data.Article\n\tdbUpdateArticle(article.ID, article)\n\n\trender.Render(w, r, NewArticleResponse(article))\n}", "reference": "// UpdateArticle updates an existing Article in our persistent store.", "generated": "// Create a new Article object with the following properties and methods to update it's content in JSON format (see below).\n // This method is called when an existing instance of this class has been created or updated by another application using `json`.\nMethods:\n*update : Called on any newly-created instances of"}
{"id": 605, "code": "func adminRouter() chi.Router {\n\tr := chi.NewRouter()\n\tr.Use(AdminOnly)\n\tr.Get(\"/\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(\"admin: index\"))\n\t})\n\tr.Get(\"/accounts\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(\"admin: list accounts..\"))\n\t})\n\tr.Get(\"/users/{userId}\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(fmt.Sprintf(\"admin: view user id %v\", chi.URLParam(r, \"userId\"))))\n\t})\n\treturn r\n}", "reference": "// A completely separate router for administrator routes", "generated": "This method returns a new RoutingContext object that contains the routing information for each route in this application and its associated routes (including any additional parameters). The returned objects are then passed to an interface which will be used by all of these methods when creating or updating their own Routes . This is useful if you want your"}
{"id": 606, "code": "func AdminOnly(next http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tisAdmin, ok := r.Context().Value(\"acl.admin\").(bool)\n\t\tif !ok || !isAdmin {\n\t\t\thttp.Error(w, http.StatusText(http.StatusForbidden), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}", "reference": "// AdminOnly middleware restricts access to just administrators.", "generated": "// This method is used to create a new admin session for the user and then return it when no more users are logged in or if there were any errors encountered during this process (e., nil). // The default value of `nil` will be returned by calling next() on all incoming requests with an error message indicating"}
{"id": 612, "code": "func DefaultCompress(next http.Handler) http.Handler {\n\treturn Compress(flate.DefaultCompression)(next)\n}", "reference": "// DefaultCompress is a middleware that compresses response\n// body of predefined content types to a data format based\n// on Accept-Encoding request header. It uses a default\n// compression level.\n// DEPRECATED", "generated": "Default compresses the current buffer to a specified size, and returns an error if it is not found in that range or otherwise fails with no response from any of its handlers (or nil for non-nil errors). The default compression method defaults on all buffers except those which are already compressed by this program; see also \""}
{"id": 623, "code": "func canonicalHostedZone(hostname string) string {\n\tfor suffix, zone := range canonicalHostedZones {\n\t\tif strings.HasSuffix(hostname, suffix) {\n\t\t\treturn zone\n\t\t}\n\t}\n\n\treturn \"\"\n}", "reference": "// canonicalHostedZone returns the matching canonical zone for a given hostname.", "generated": "This is a wrapper around the default hostnames for all zones in an existing network (see below). It uses local hosts to create new ones and then returns them as well if they exist or not at any point during their lifetime. The name of the Zone will be used when creating it from scratch; this can also include"}
{"id": 629, "code": "func InMemoryWithLogging() InMemoryOption {\n\treturn func(p *InMemoryProvider) {\n\t\tp.OnApplyChanges = func(changes *plan.Changes) {\n\t\t\tfor _, v := range changes.Create {\n\t\t\t\tlog.Infof(\"CREATE: %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.UpdateOld {\n\t\t\t\tlog.Infof(\"UPDATE (old): %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.UpdateNew {\n\t\t\t\tlog.Infof(\"UPDATE (new): %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.Delete {\n\t\t\t\tlog.Infof(\"DELETE: %v\", v)\n\t\t\t}\n\t\t}\n\t}\n}", "reference": "// InMemoryWithLogging injects logging when ApplyChanges is called", "generated": "{}: string }\n\nAddresses:[]"}
{"id": 656, "code": "func (sc *serviceSource) filterByAnnotations(services []*v1.Service) ([]*v1.Service, error) {\n\tlabelSelector, err := metav1.ParseToLabelSelector(sc.annotationFilter)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tselector, err := metav1.LabelSelectorAsSelector(labelSelector)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// empty filter returns original list\n\tif selector.Empty() {\n\t\treturn services, nil\n\t}\n\n\tfilteredList := []*v1.Service{}\n\n\tfor _, service := range services {\n\t\t// convert the service's annotations to an equivalent label selector\n\t\tannotations := labels.Set(service.Annotations)\n\n\t\t// include service if its annotations match the selector\n\t\tif selector.Matches(annotations) {\n\t\t\tfilteredList = append(filteredList, service)\n\t\t}\n\t}\n\n\treturn filteredList, nil\n}", "reference": "// filterByAnnotations filters a list of services by a given annotation selector.", "generated": "filter by annotation is a simple way of filtering out any annotated fields from within your application code and returning them as unordered lists with no additional information about their contents or metadata in order for it not be used at runtime when you need to use filters on other applications that do not support this feature yet. This allows users"}
{"id": 658, "code": "func (p *Plan) Calculate() *Plan {\n\tt := newPlanTable()\n\n\tfor _, current := range filterRecordsForPlan(p.Current) {\n\t\tt.addCurrent(current)\n\t}\n\tfor _, desired := range filterRecordsForPlan(p.Desired) {\n\t\tt.addCandidate(desired)\n\t}\n\n\tchanges := &Changes{}\n\tchanges.Create = t.getCreates()\n\tchanges.Delete = t.getDeletes()\n\tchanges.UpdateNew, changes.UpdateOld = t.getUpdates()\n\tfor _, pol := range p.Policies {\n\t\tchanges = pol.Apply(changes)\n\t}\n\n\tplan := &Plan{\n\t\tCurrent: p.Current,\n\t\tDesired: p.Desired,\n\t\tChanges: changes,\n\t}\n\n\treturn plan\n}", "reference": "// Calculate computes the actions needed to move current state towards desired\n// state. It then passes those changes to the current policy for further\n// processing. It returns a copy of Plan with the changes populated.", "generated": "// Create a list of all the possible values for this table and update it with each change to make sure that they are correct in their state when applied.\n // This function is used by filters on Plan objects as well; see FilterList(). func main():\nvar results []T[]TS {} var settings : T"}
{"id": 662, "code": "func NewTargets(target ...string) Targets {\n\tt := make(Targets, 0, len(target))\n\tt = append(t, target...)\n\treturn t\n}", "reference": "// NewTargets is a convenience method to create a new Targets object from a vararg of strings", "generated": "New Targs is a new string representation of the current targets. It contains all strings that are currently in use and any other characters (including those used by default). The name should be short for \"new\" or long for \"-\". This function returns an array containing namespaces with no spaces between them to avoid confusion when"}
{"id": 721, "code": "func NewRfc2136Provider(host string, port int, zoneName string, insecure bool, keyName string, secret string, secretAlg string, axfr bool, domainFilter DomainFilter, dryRun bool, actions rfc2136Actions) (Provider, error) {\n\tsecretAlgChecked, ok := tsigAlgs[secretAlg]\n\tif !ok && !insecure {\n\t\treturn nil, errors.Errorf(\"%s is not supported TSIG algorithm\", secretAlg)\n\t}\n\n\tr := &rfc2136Provider{\n\t\tnameserver:   net.JoinHostPort(host, strconv.Itoa(port)),\n\t\tzoneName:     dns.Fqdn(zoneName),\n\t\tinsecure:     insecure,\n\t\tdomainFilter: domainFilter,\n\t\tdryRun:       dryRun,\n\t\taxfr:         axfr,\n\t}\n\tif actions != nil {\n\t\tr.actions = actions\n\t} else {\n\t\tr.actions = r\n\t}\n\n\tif !insecure {\n\t\tr.tsigKeyName = dns.Fqdn(keyName)\n\t\tr.tsigSecret = secret\n\t\tr.tsigSecretAlg = secretAlgChecked\n\t}\n\n\tlog.Infof(\"Configured RFC2136 with zone '%s' and nameserver '%s'\", r.zoneName, r.nameserver)\n\treturn r, nil\n}", "reference": "// NewRfc2136Provider is a factory function for OpenStack rfc2136 providers", "generated": "// Initializes the new RFC2137 provider for use in a remote server using an existing client-side API to authenticate against local clients or servers on behalf of other users/groups that are connected via SSH connections from within their own network interface // This method can be used by any user who wishes access to all"}
{"id": 734, "code": "func (p *AWSSDProvider) RegisterInstance(service *sd.Service, ep *endpoint.Endpoint) error {\n\tfor _, target := range ep.Targets {\n\t\tlog.Infof(\"Registering a new instance \\\"%s\\\" for service \\\"%s\\\" (%s)\", target, *service.Name, *service.Id)\n\n\t\tattr := make(map[string]*string)\n\n\t\tif ep.RecordType == endpoint.RecordTypeCNAME {\n\t\t\tif p.isAWSLoadBalancer(target) {\n\t\t\t\tattr[sdInstanceAttrAlias] = aws.String(target)\n\t\t\t} else {\n\t\t\t\tattr[sdInstanceAttrCname] = aws.String(target)\n\t\t\t}\n\t\t} else if ep.RecordType == endpoint.RecordTypeA {\n\t\t\tattr[sdInstanceAttrIPV4] = aws.String(target)\n\t\t} else {\n\t\t\treturn fmt.Errorf(\"invalid endpoint type (%v)\", ep)\n\t\t}\n\n\t\tif !p.dryRun {\n\t\t\t_, err := p.client.RegisterInstance(&sd.RegisterInstanceInput{\n\t\t\t\tServiceId:  service.Id,\n\t\t\t\tAttributes: attr,\n\t\t\t\tInstanceId: aws.String(p.targetToInstanceID(target)),\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "reference": "// RegisterInstance creates a new instance in given service.", "generated": "// Initializes the AwssdProvider class and registers it with AWS Services API // to allow access from remote services using an authenticated user or credentials in order not expose any of // existing instances that are already registered by other providers on their own behalf.\nMethods:(NSObject *)initServices()\nParameters: ["}
{"id": 769, "code": "func canonicalizeDomainName(d string) string {\n\tif !strings.HasSuffix(d, \".\") {\n\t\td += \".\"\n\t}\n\treturn strings.ToLower(d)\n}", "reference": "// converts domain name to FQDN", "generated": "This function converts a domain name to an ASCII character (ASCII is the default). It returns either Unicode or UTF-8 if it does not exist. The following example uses this conversion for all domains in mydomainname . Note that I have used both unicode and hexadecimal as arguments; they are different"}
{"id": 772, "code": "func addEndpoint(ep *endpoint.Endpoint, recordSets map[string]*recordSet, delete bool) {\n\tkey := fmt.Sprintf(\"%s/%s\", ep.DNSName, ep.RecordType)\n\trs := recordSets[key]\n\tif rs == nil {\n\t\trs = &recordSet{\n\t\t\tdnsName:    canonicalizeDomainName(ep.DNSName),\n\t\t\trecordType: ep.RecordType,\n\t\t\tnames:      make(map[string]bool),\n\t\t}\n\t}\n\tif rs.zoneID == \"\" {\n\t\trs.zoneID = ep.Labels[designateZoneID]\n\t}\n\tif rs.recordSetID == \"\" {\n\t\trs.recordSetID = ep.Labels[designateRecordSetID]\n\t}\n\tfor _, rec := range strings.Split(ep.Labels[designateOriginalRecords], \"\\000\") {\n\t\tif _, ok := rs.names[rec]; !ok && rec != \"\" {\n\t\t\trs.names[rec] = true\n\t\t}\n\t}\n\ttargets := ep.Targets\n\tif ep.RecordType == endpoint.RecordTypeCNAME {\n\t\ttargets = canonicalizeDomainNames(targets)\n\t}\n\tfor _, t := range targets {\n\t\trs.names[t] = !delete\n\t}\n\trecordSets[key] = rs\n}", "reference": "// adds endpoint into recordset aggregation, loading original values from endpoint labels first", "generated": "// Add endpoints to the database and create a new one for each of them (see below).\n // This is done by adding an entry in db-name with name \"example\" as its first field; this will be used when creating records from existing databases or if there are no other fields available at all on"}
{"id": 787, "code": "func (ms *dedupSource) Endpoints() ([]*endpoint.Endpoint, error) {\n\tresult := []*endpoint.Endpoint{}\n\tcollected := map[string]bool{}\n\n\tendpoints, err := ms.source.Endpoints()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ep := range endpoints {\n\t\tidentifier := ep.DNSName + \" / \" + ep.Targets.String()\n\n\t\tif _, ok := collected[identifier]; ok {\n\t\t\tlog.Debugf(\"Removing duplicate endpoint %s\", ep)\n\t\t\tcontinue\n\t\t}\n\n\t\tcollected[identifier] = true\n\t\tresult = append(result, ep)\n\t}\n\n\treturn result, nil\n}", "reference": "// Endpoints collects endpoints from its wrapped source and returns them without duplicates.", "generated": "// The destination is a string containing the name of the source and an optional path to return from it if no matching strings are found in its output // This function returns all paths that have been encountered by this target for which there was not any match at least once before returning them as well as their corresponding values; see also"}
{"id": 791, "code": "func (sdr *AWSSDRegistry) ApplyChanges(changes *plan.Changes) error {\n\tfilteredChanges := &plan.Changes{\n\t\tCreate:    changes.Create,\n\t\tUpdateNew: filterOwnedRecords(sdr.ownerID, changes.UpdateNew),\n\t\tUpdateOld: filterOwnedRecords(sdr.ownerID, changes.UpdateOld),\n\t\tDelete:    filterOwnedRecords(sdr.ownerID, changes.Delete),\n\t}\n\n\tsdr.updateLabels(filteredChanges.Create)\n\tsdr.updateLabels(filteredChanges.UpdateNew)\n\tsdr.updateLabels(filteredChanges.UpdateOld)\n\tsdr.updateLabels(filteredChanges.Delete)\n\n\treturn sdr.provider.ApplyChanges(filteredChanges)\n}", "reference": "// ApplyChanges filters out records not owned the External-DNS, additionally it adds the required label\n// inserted in the AWS SD instance as a CreateID field", "generated": "awsssrgrp provides a simple and easy way to create new policy objects for AWS services using the AWSSRgrP method of an application's configuration file or database schema in order that they can be used by other applications as well without having access control over their own policies on any particular service provider . The following"}
{"id": 800, "code": "func createDiskImage(dest string, size int, r io.Reader) error {\n\t// Convert a raw image from stdin to the dest VMDK image.\n\tsizeBytes := int64(size) << 20 // usually won't fit in 32-bit int (max 2GB)\n\t// FIXME: why isn't this just using the vbm*() functions?\n\tcmd := exec.Command(vboxManageCmd, \"convertfromraw\", \"stdin\", dest,\n\t\tfmt.Sprintf(\"%d\", sizeBytes), \"--format\", \"VMDK\")\n\n\tlog.Debug(cmd)\n\n\tif os.Getenv(\"MACHINE_DEBUG\") != \"\" {\n\t\tcmd.Stdout = os.Stdout\n\t\tcmd.Stderr = os.Stderr\n\t}\n\n\tstdin, err := cmd.StdinPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Starting command\")\n\n\tif err := cmd.Start(); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Copying to stdin\")\n\n\tn, err := io.Copy(stdin, r)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Filling zeroes\")\n\n\t// The total number of bytes written to stdin must match sizeBytes, or\n\t// VBoxManage.exe on Windows will fail. Fill remaining with zeros.\n\tif left := sizeBytes - n; left > 0 {\n\t\tif err := zeroFill(stdin, left); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tlog.Debug(\"Closing STDIN\")\n\n\t// cmd won't exit until the stdin is closed.\n\tif err := stdin.Close(); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Waiting on cmd\")\n\n\treturn cmd.Wait()\n}", "reference": "// createDiskImage makes a disk image at dest with the given size in MB. If r is\n// not nil, it will be read as a raw disk image to convert from.", "generated": "Create a new disk Image and copy it into the VM's storage space for use by Disk Manager when running as an administrator at boot time without any additional configuration changes required before starting up again after installation has finished! This script creates two disks that are used during startup so you can start them both immediately upon launch if needed while"}
{"id": 802, "code": "func (n *hostOnlyNetwork) SaveIPv4(vbox VBoxManager) error {\n\tif n.IPv4.IP != nil && n.IPv4.Mask != nil {\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tlog.Warn(\"Windows might ask for the permission to configure a network adapter. Sometimes, such confirmation window is minimized in the taskbar.\")\n\t\t}\n\n\t\tif err := vbox.vbm(\"hostonlyif\", \"ipconfig\", n.Name, \"--ip\", n.IPv4.IP.String(), \"--netmask\", net.IP(n.IPv4.Mask).String()); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}", "reference": "// SaveIPv4 changes the ipv4 configuration of the host-only network.", "generated": "// This function will save ip addresses from DHCP requests and allow them on port 8080 of host only if no IPv4 address exists or otherwise fails. If this option is not specified, it defaults back-to -1 when running with --no-interfaces .\n// The default value should be 0 , which means"}
{"id": 821, "code": "func (d *Driver) Restart() error {\n\tcs := d.client()\n\t_, err := cs.RequestWithContext(context.TODO(), &egoscale.RebootVirtualMachine{\n\t\tID: d.ID,\n\t})\n\n\treturn err\n}", "reference": "// Restart reboots the existing VM instance.", "generated": "ds.Restarts() is a wrapper around the DLL that will be used to restart virtual machines when they are no longer needed by an application or service running on Windows XP/Vista and later versions of OS X 10.6 through 11 with respect for driver support in place. It provides some functionality similar from other"}
{"id": 822, "code": "func (d *Driver) Remove() error {\n\tclient := d.client()\n\n\t// Destroy the SSH key from CloudStack\n\tif d.KeyPair != \"\" {\n\t\tkey := &egoscale.SSHKeyPair{Name: d.KeyPair}\n\t\tif err := client.DeleteWithContext(context.TODO(), key); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Destroy the virtual machine\n\tif d.ID != \"\" {\n\t\tvm := &egoscale.VirtualMachine{ID: d.ID}\n\t\tif err := client.DeleteWithContext(context.TODO(), vm); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tlog.Infof(\"The Anti-Affinity group and Security group were not removed\")\n\n\treturn nil\n}", "reference": "// Remove destroys the VM instance and the associated SSH key.", "generated": "This function removes the remote hostname of a localhost, which is used to authenticate against an existing user on that server using DNS or HTTP requests for authentication purposes. The name can be changed by adding it as part \"user\" in config/ssh_config.h . This will remove all hosts with no known"}
{"id": 823, "code": "func (d *Driver) getCloudInit() ([]byte, error) {\n\tvar err error\n\tif d.UserDataFile != \"\" {\n\t\td.UserData, err = ioutil.ReadFile(d.UserDataFile)\n\t}\n\n\treturn d.UserData, err\n}", "reference": "// Build a cloud-init user data string that will install and run\n// docker.", "generated": "// Initializes the Cloud Init process to initialize all of its data files and returns a new instance for it.\n // This method is called when an application starts up with no userdata or any other information about users in progress; this will be used as initializer after initialization if necessary. The default value was 0 ."}
{"id": 834, "code": "func deviceFlowAuth(oauthCfg azure.OAuthConfig, clientID, resource string) (*azure.ServicePrincipalToken, error) {\n\tcl := oauthClient()\n\tdeviceCode, err := azure.InitiateDeviceAuth(&cl, oauthCfg, clientID, resource)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to start device auth: %v\", err)\n\t}\n\tlog.Debug(\"Retrieved device code.\", logutil.Fields{\n\t\t\"expires_in\": to.Int64(deviceCode.ExpiresIn),\n\t\t\"interval\":   to.Int64(deviceCode.Interval),\n\t})\n\n\t// Example message: \u201cTo sign in, open https://aka.ms/devicelogin and enter\n\t// the code 0000000 to authenticate.\u201d\n\tlog.Infof(\"Microsoft Azure: %s\", to.String(deviceCode.Message))\n\n\ttoken, err := azure.WaitForUserCompletion(&cl, deviceCode)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to complete device auth: %v\", err)\n\t}\n\n\tspt, err := azure.NewServicePrincipalTokenFromManualToken(oauthCfg, clientID, resource, *token)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error constructing service principal token: %v\", err)\n\t}\n\treturn spt, nil\n}", "reference": "// deviceFlowAuth prints a message to the screen for user to take action to\n// consent application on a browser and in the meanwhile the authentication\n// endpoint is polled until user gives consent, denies or the flow times out.\n// Returned token must be saved.", "generated": "/// Creates a new user account for authentication purposes using an existing username or password provided by Azur's API (Azure User Account).\n /// This method is called when you create your own app with access control over any of the following methods: // Create App --> Register Application ID - The name given as part that"}
{"id": 842, "code": "func (c *ComputeUtil) staticAddress() (string, error) {\n\t// is the address a name?\n\tisName, err := regexp.MatchString(\"[a-z]([-a-z0-9]*[a-z0-9])?\", c.address)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif !isName {\n\t\treturn c.address, nil\n\t}\n\n\t// resolve the address by name\n\texternalAddress, err := c.service.Addresses.Get(c.project, c.region(), c.address).Do()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn externalAddress.Address, nil\n}", "reference": "// staticAddress returns the external static IP address.", "generated": "Static Address provides an interface to generate addresses for use in applications that require access control over their internal network resources and are not intended as secure or private networks of any kind. It can be used with other services such AsyncCredentials , StaticHosts , etc., but it should only work on systems where you have"}
{"id": 849, "code": "func (c *ComputeUtil) startInstance() error {\n\top, err := c.service.Instances.Start(c.project, c.zone, c.instanceName).Do()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Infof(\"Waiting for instance to start.\")\n\treturn c.waitForRegionalOp(op.Name)\n}", "reference": "// startInstance starts the instance.", "generated": "This method is used when the service has started and stopped using a given project name or zone in order that it can be called from within CompileUnit . The default value of this function will return an exception if no such application exists on any system running at least one version of Java 7 , as well since all applications are"}
{"id": 867, "code": "func osDiskStorageContainerURL(account *storage.AccountProperties, vmName string) string {\n\treturn fmt.Sprintf(\"%s%s/\", to.String(account.PrimaryEndpoints.Blob), osDiskStorageContainerName(vmName))\n}", "reference": "// osDiskStorageContainerURL crafts a URL with a trailing slash pointing\n// to the full Azure Blob Container URL for given VM name.", "generated": "This method returns a container URL for the storage account that is used in an OS disk drive (or any other device). The returned URI can be either local or remote and must contain at least one of the following fields :\nname , password . This field specifies which user has access to this volume's data center on behalf"}
{"id": 892, "code": "func (d *Driver) Create() error {\n\tlog.Infof(\"Generating SSH Key\")\n\n\tif err := ssh.GenerateSSHKey(d.GetSSHKeyPath()); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Infof(\"Creating host...\")\n\n\tc, err := newComputeUtil(d)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := c.openFirewallPorts(d); err != nil {\n\t\treturn err\n\t}\n\n\tif d.UseExisting {\n\t\treturn c.configureInstance(d)\n\t}\n\treturn c.createInstance(d)\n}", "reference": "// Create creates a GCE VM instance acting as a docker host.", "generated": "// Generates a keypair for the specified port and creates an instance of that type to use as its default gateway on ports in this example // created by creating sshd-keygen with --port=0x0080 . This is used when generating keys from remote hosts using `ssh` or other similar methods; it"}
{"id": 908, "code": "func (d *Driver) Restart() error {\n\tif err := d.checkLegacyDriver(true); err != nil {\n\t\treturn err\n\t}\n\n\t// NOTE(ahmetalpbalkan) Azure will always keep the VM in Running state\n\t// during the restart operation. Hence we rely on returned async operation\n\t// polling to make sure the reboot is waited upon.\n\tc, err := d.newAzureClient()\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn c.RestartVirtualMachine(d.ResourceGroup, d.naming().VM())\n}", "reference": "// Restart reboots the virtual machine instance.", "generated": "This method returns a new virtual machine that can be used as an asynchronous backup or restore service for Windows XP and later versions of Microsoft Visual Studio 2003/2008 R2 SP1 with no additional dependencies required by any other operating system driver package installed before running this procedure. The default value was set at runtime when using DLL"}
{"id": 914, "code": "func (d *Driver) Start() error {\n\tif err := cmd(\"Hyper-V\\\\Start-VM\", d.MachineName); err != nil {\n\t\treturn err\n\t}\n\n\tip, err := d.waitForIP()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\td.IPAddress = ip\n\n\treturn nil\n}", "reference": "// Start starts an host", "generated": "// Initializes the VM to start with a default IP address and returns an empty string if it is not already initialized or null otherwise.\n // This function will return false for any errors encountered during initialization of the virtual machine in case of failure by calling this method on all instances that are still running after initializing. If"}
{"id": 921, "code": "func (d *BaseDriver) GetSSHUsername() string {\n\tif d.SSHUser == \"\" {\n\t\td.SSHUser = DefaultSSHUser\n\t}\n\treturn d.SSHUser\n}", "reference": "// GetSSHUsername returns the ssh user name, root if not specified", "generated": "// Initializes the SSID of the user to be authenticated with a password from BaseDriver, and returns it as an object in JSON format for use by other applications that want this information stored on their servers or remote systems. This method is only available if D is not already used within any application defined interfaces such ASM"}
{"id": 937, "code": "func NewDriver(machineName, storePath string) drivers.Driver {\n\tlog.Debug(\"Instantiating Rackspace driver.\", map[string]string{\"machineName\": machineName})\n\n\tinner := openstack.NewDerivedDriver(machineName, storePath)\n\tdriver := &Driver{\n\t\tDriver: inner,\n\t}\n\tinner.SetClient(&Client{\n\t\tdriver: driver,\n\t})\n\n\treturn driver\n}", "reference": "// NewDriver instantiates a Rackspace driver.", "generated": "// Create a new Driver object that will be used to create the newly created DFS instances for each of these machines in the cluster and allow them access from within their own application (using an existing database).\n // This is done by creating two objects named \"Dfs\" with names matching those specified on disk as well"}
{"id": 945, "code": "func (d *Driver) GetCreateFlags() []mcnflag.Flag {\n\treturn []mcnflag.Flag{\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_CPU_COUNT\",\n\t\t\tName:   \"vmwarevsphere-cpu-count\",\n\t\t\tUsage:  \"vSphere CPU number for docker VM\",\n\t\t\tValue:  defaultCpus,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_MEMORY_SIZE\",\n\t\t\tName:   \"vmwarevsphere-memory-size\",\n\t\t\tUsage:  \"vSphere size of memory for docker VM (in MB)\",\n\t\t\tValue:  defaultMemory,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_DISK_SIZE\",\n\t\t\tName:   \"vmwarevsphere-disk-size\",\n\t\t\tUsage:  \"vSphere size of disk for docker VM (in MB)\",\n\t\t\tValue:  defaultDiskSize,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_BOOT2DOCKER_URL\",\n\t\t\tName:   \"vmwarevsphere-boot2docker-url\",\n\t\t\tUsage:  \"vSphere URL for boot2docker image\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER\",\n\t\t\tName:   \"vmwarevsphere-vcenter\",\n\t\t\tUsage:  \"vSphere IP/hostname for vCenter\",\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER_PORT\",\n\t\t\tName:   \"vmwarevsphere-vcenter-port\",\n\t\t\tUsage:  \"vSphere Port for vCenter\",\n\t\t\tValue:  defaultSDKPort,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_USERNAME\",\n\t\t\tName:   \"vmwarevsphere-username\",\n\t\t\tUsage:  \"vSphere username\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_PASSWORD\",\n\t\t\tName:   \"vmwarevsphere-password\",\n\t\t\tUsage:  \"vSphere password\",\n\t\t},\n\t\tmcnflag.StringSliceFlag{\n\t\t\tEnvVar: \"VSPHERE_NETWORK\",\n\t\t\tName:   \"vmwarevsphere-network\",\n\t\t\tUsage:  \"vSphere network where the docker VM will be attached\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATASTORE\",\n\t\t\tName:   \"vmwarevsphere-datastore\",\n\t\t\tUsage:  \"vSphere datastore for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATACENTER\",\n\t\t\tName:   \"vmwarevsphere-datacenter\",\n\t\t\tUsage:  \"vSphere datacenter for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_FOLDER\",\n\t\t\tName:   \"vmwarevsphere-folder\",\n\t\t\tUsage:  \"vSphere folder for the docker VM. This folder must already exist in the datacenter.\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_POOL\",\n\t\t\tName:   \"vmwarevsphere-pool\",\n\t\t\tUsage:  \"vSphere resource pool for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_HOSTSYSTEM\",\n\t\t\tName:   \"vmwarevsphere-hostsystem\",\n\t\t\tUsage:  \"vSphere compute resource where the docker VM will be instantiated. This can be omitted if using a cluster with DRS.\",\n\t\t},\n\t\tmcnflag.StringSliceFlag{\n\t\t\tEnvVar: \"VSPHERE_CFGPARAM\",\n\t\t\tName:   \"vmwarevsphere-cfgparam\",\n\t\t\tUsage:  \"vSphere vm configuration parameters (used for guestinfo)\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_CLOUDINIT\",\n\t\t\tName:   \"vmwarevsphere-cloudinit\",\n\t\t\tUsage:  \"vSphere cloud-init file or url to set in the guestinfo\",\n\t\t},\n\t}\n}", "reference": "// GetCreateFlags registers the flags this driver adds to\n// \"docker-machine create\"", "generated": "Code:\nfunc (d *Driver) GetCreateFlags() []mcnflag.Flag {\n\treturn []mcnflag.Flag{\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_CPU_COUNT\",\n\t\t\tName:   \"vmwarevsphere-cpu-count\",\n\t\t\tUsage:  \"vSphere CPU number for docker VM\",\n\t\t\tValue:  defaultCpus,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_MEMORY_SIZE\",\n\t\t\tName:   \"vmwarevsphere-memory-size\",\n\t\t\tUsage:  \"vSphere size of memory for docker VM (in MB)\",\n\t\t\tValue:  defaultMemory,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_DISK_SIZE\",\n\t\t\tName:   \"vmwarevsphere-disk-size\",\n\t\t\tUsage:  \"vSphere size of disk for docker VM (in MB)\",\n\t\t\tValue:  defaultDiskSize,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_BOOT2DOCKER_URL\",\n\t\t\tName:   \"vmwarevsphere-boot2docker-url\",\n\t\t\tUsage:  \"vSphere URL for boot2docker image\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER\",\n\t\t\tName:   \"vmwarevsphere-vcenter\",\n\t\t\tUsage:  \"vSphere IP/hostname for vCenter\",\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER_PORT\",\n\t\t\tName:   \"vmwarevsphere-vcenter-port\",\n\t\t\tUsage:  \"vSphere Port for vCenter\",\n\t\t\tValue:  defaultSDKPort,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_USERNAME\",\n\t\t\tName:   \"vmwarevsphere-username\",\n\t\t\tUsage:  \"vSphere username\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_PASSWORD\",\n\t\t\tName:   \"vmwarevsphere-password\",\n\t\t\tUsage:  \"vSphere password\",\n\t\t},\n\t\tmcnflag.StringSliceFlag{\n\t\t\tEnvVar: \"VSPHERE_NETWORK\",\n\t\t\tName:   \"vmwarevsphere-network\",\n\t\t\tUsage:  \"vSphere network where the docker VM will be attached\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATASTORE\",\n\t\t\tName:   \"vmwarevsphere-datastore\",\n\t\t\tUsage:  \"vSphere datastore for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATACENTER\",\n\t\t\tName:   \"vmwarevsphere-datacenter\",\n\t\t\tUsage:  \"vSphere datacenter for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_FOLDER\",\n\t\t\tName:   \"vmwarevsphere-folder\",\n\t\t\tUsage:  \"vSphere folder for the docker VM. This folder must already exist in the datacenter.\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_POOL\",\n\t\t\tName:   \"vmwarevsphere-pool\",\n\t\t\tUsage:  \"vSphere resource pool for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_HOSTSYSTEM\",\n\t\t\tName:   \"vmwarevsphere-hostsystem\",\n\t\t\tUsage:  \"h"}
{"id": 963, "code": "func (v *View) Data() interface{} {\n\tv.dataLock.RLock()\n\tdefer v.dataLock.RUnlock()\n\treturn v.data\n}", "reference": "// Data returns the most-recently-received data from Consul for this View.", "generated": "// This method is called when the data lock has been locked by a user, and returns nil if no locks have been unlocked for that time.\n// The default value of this function will be used to initialize all available keys in an array with zero or more key-value pairs at once; otherwise it defaults back into"}
{"id": 1020, "code": "func NewKVListQuery(s string) (*KVListQuery, error) {\n\tif s != \"\" && !KVListQueryRe.MatchString(s) {\n\t\treturn nil, fmt.Errorf(\"kv.list: invalid format: %q\", s)\n\t}\n\n\tm := regexpMatch(KVListQueryRe, s)\n\treturn &KVListQuery{\n\t\tstopCh: make(chan struct{}, 1),\n\t\tdc:     m[\"dc\"],\n\t\tprefix: m[\"prefix\"],\n\t}, nil\n}", "reference": "// NewKVListQuery parses a string into a dependency.", "generated": "// kvv is a list query that returns an array of strings with the given name and length (in bytes). The returned value will be used to match any existing KVM-specific data structures in this context for all other queries within it.\n // This function can also return null if no matching elements are found or"}
{"id": 1021, "code": "func NewDedupManager(config *config.DedupConfig, clients *dep.ClientSet, brain *template.Brain, templates []*template.Template) (*DedupManager, error) {\n\td := &DedupManager{\n\t\tconfig:    config,\n\t\tclients:   clients,\n\t\tbrain:     brain,\n\t\ttemplates: templates,\n\t\tleader:    make(map[*template.Template]<-chan struct{}),\n\t\tlastWrite: make(map[*template.Template]uint64),\n\t\tupdateCh:  make(chan struct{}, 1),\n\t\tstopCh:    make(chan struct{}),\n\t}\n\treturn d, nil\n}", "reference": "// NewDedupManager creates a new Dedup manager", "generated": "New DEDUP Manager is a new interface for the builtin client set and brains template functions that are used to create an instance of this class in order not only from scratch but also as part or after initialization (see below). It provides two methods which can be called on any given object by calling init() . The"}
{"id": 1045, "code": "func NewVaultReadQuery(s string) (*VaultReadQuery, error) {\n\ts = strings.TrimSpace(s)\n\ts = strings.Trim(s, \"/\")\n\tif s == \"\" {\n\t\treturn nil, fmt.Errorf(\"vault.read: invalid format: %q\", s)\n\t}\n\n\tsecretURL, err := url.Parse(s)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &VaultReadQuery{\n\t\tstopCh:      make(chan struct{}, 1),\n\t\trawPath:     secretURL.Path,\n\t\tqueryValues: secretURL.Query(),\n\t}, nil\n}", "reference": "// NewVaultReadQuery creates a new datacenter dependency.", "generated": "// This function reads the contents of the vault read query and returns a new VACUUM_READ_QUERY object with an optional hash value for each key in it. The default is to return null if no keys are found or false otherwise.\n // It also checks that all vaults have been opened before"}
{"id": 1057, "code": "func (c *Child) Kill() {\n\tlog.Printf(\"[INFO] (child) killing process\")\n\tc.Lock()\n\tdefer c.Unlock()\n\tc.kill()\n}", "reference": "// Kill sends the kill signal to the child process and waits for successful\n// termination. If no kill signal is defined, the process is killed with the\n// most aggressive kill signal. If the process does not gracefully stop within\n// the provided KillTimeout, the process is force-killed. If a splay was\n// provided, this function will sleep for a random period of time between 0 and\n// the provided splay value to reduce the thundering herd problem. This function\n// does not return any errors because it guarantees the process will be dead by\n// the return of the function call.", "generated": "This function is called when a child processes an object, and returns the value of that instance's lock state if it was killed or not by another thread in its own looping chain. It also calls kill on any other threads who are waiting for this to happen before calling terminate(). The name \"kill\" refers only specifically"}
{"id": 1064, "code": "func NewRunner(config *config.Config, dry, once bool) (*Runner, error) {\n\tlog.Printf(\"[INFO] (runner) creating new runner (dry: %v, once: %v)\", dry, once)\n\n\trunner := &Runner{\n\t\tconfig: config,\n\t\tdry:    dry,\n\t\tonce:   once,\n\t}\n\n\tif err := runner.init(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn runner, nil\n}", "reference": "// NewRunner accepts a slice of TemplateConfigs and returns a pointer to the new\n// Runner and any error that occurred during creation.", "generated": "New Runner creates a new runner and returns it as an object with the following properties :\n// The name of the running process to run from if no other processes exist in this directory // If not specified, then all existing runners will be created by default for each instance that is spawned on one or more instances named \"run"}
{"id": 1102, "code": "func base64URLDecode(s string) (string, error) {\n\tv, err := base64.URLEncoding.DecodeString(s)\n\tif err != nil {\n\t\treturn \"\", errors.Wrap(err, \"base64URLDecode\")\n\t}\n\treturn string(v), nil\n}", "reference": "// base64URLDecode decodes the given string as a URL-safe base64 string.", "generated": "// Base32 decoding of URL decoded strings is done using the standard encoding scheme for URLs and URLS in RFC 6455-1.\n // This method uses a simple wrapper function to encode an encoded URI into bytes that can be read by any user or other application with no need on top thereof.\n// The"}
{"id": 1107, "code": "func in(l, v interface{}) (bool, error) {\n\tlv := reflect.ValueOf(l)\n\tvv := reflect.ValueOf(v)\n\n\tswitch lv.Kind() {\n\tcase reflect.Array, reflect.Slice:\n\t\t// if the slice contains 'interface' elements, then the element needs to be extracted directly to examine its type,\n\t\t// otherwise it will just resolve to 'interface'.\n\t\tvar interfaceSlice []interface{}\n\t\tif reflect.TypeOf(l).Elem().Kind() == reflect.Interface {\n\t\t\tinterfaceSlice = l.([]interface{})\n\t\t}\n\n\t\tfor i := 0; i < lv.Len(); i++ {\n\t\t\tvar lvv reflect.Value\n\t\t\tif interfaceSlice != nil {\n\t\t\t\tlvv = reflect.ValueOf(interfaceSlice[i])\n\t\t\t} else {\n\t\t\t\tlvv = lv.Index(i)\n\t\t\t}\n\n\t\t\tswitch lvv.Kind() {\n\t\t\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\t\t\tswitch vv.Kind() {\n\t\t\t\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\t\t\t\tif vv.Int() == lvv.Int() {\n\t\t\t\t\t\treturn true, nil\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase reflect.Float32, reflect.Float64:\n\t\t\t\tswitch vv.Kind() {\n\t\t\t\tcase reflect.Float32, reflect.Float64:\n\t\t\t\t\tif vv.Float() == lvv.Float() {\n\t\t\t\t\t\treturn true, nil\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase reflect.String:\n\t\t\t\tif vv.Type() == lvv.Type() && vv.String() == lvv.String() {\n\t\t\t\t\treturn true, nil\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tcase reflect.String:\n\t\tif vv.Type() == lv.Type() && strings.Contains(lv.String(), vv.String()) {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\n\treturn false, nil\n}", "reference": "// in searches for a given value in a given interface.", "generated": "This function returns true when a string is found that matches an existing value of this object and does not contain any additional information about what was added or removed from the original array by reference. The returned boolean indicates whether there are no more values for these objects than were specified before calling return . If so , all other arguments must"}
{"id": 1110, "code": "func parseBool(s string) (bool, error) {\n\tif s == \"\" {\n\t\treturn false, nil\n\t}\n\n\tresult, err := strconv.ParseBool(s)\n\tif err != nil {\n\t\treturn false, errors.Wrap(err, \"parseBool\")\n\t}\n\treturn result, nil\n}", "reference": "// parseBool parses a string into a boolean", "generated": "// This function parses a list of strings and returns an array containing the parsed values for each element in the range specified by this method. The returned value is then passed to `strconv` as its argument when parsing or returning from `parse`.\n // Note that if you are using StrConvert::fromChar"}
{"id": 1111, "code": "func parseFloat(s string) (float64, error) {\n\tif s == \"\" {\n\t\treturn 0.0, nil\n\t}\n\n\tresult, err := strconv.ParseFloat(s, 10)\n\tif err != nil {\n\t\treturn 0, errors.Wrap(err, \"parseFloat\")\n\t}\n\treturn result, nil\n}", "reference": "// parseFloat parses a string into a base 10 float", "generated": "// This function parses the float64 and returns a value of type int32 . The return values are returned as an array with all fields in their respective order from left to right inclusive.\n // Note that this is not guaranteed to work for any other types or arrays; it's possible to use multiple functions if you"}
{"id": 1132, "code": "func (c *cache) Delete(k string) {\n\tc.mu.Lock()\n\tv, evicted := c.delete(k)\n\tc.mu.Unlock()\n\tif evicted {\n\t\tc.onEvicted(k, v)\n\t}\n}", "reference": "// Delete an item from the cache. Does nothing if the key is not in the cache.", "generated": "// This function deletes the cache object from memory and returns it to the caller if no other caches exist or are available for use in a future call stack.\n// The delete method is called by calling this with an empty buffer containing zero bytes of data that can be deleted at any time without affecting performance on subsequent calls"}
{"id": 1133, "code": "func (c *cache) DeleteExpired() {\n\tvar evictedItems []keyAndValue\n\tnow := time.Now().UnixNano()\n\tc.mu.Lock()\n\tfor k, v := range c.items {\n\t\t// \"Inlining\" of expired\n\t\tif v.Expiration > 0 && now > v.Expiration {\n\t\t\tov, evicted := c.delete(k)\n\t\t\tif evicted {\n\t\t\t\tevictedItems = append(evictedItems, keyAndValue{k, ov})\n\t\t\t}\n\t\t}\n\t}\n\tc.mu.Unlock()\n\tfor _, v := range evictedItems {\n\t\tc.onEvicted(v.key, v.value)\n\t}\n}", "reference": "// Delete all expired items from the cache.", "generated": "This function deletes the items from cache and returns them to the caller for future use. The delete function is used in conjunction with a lock method on an object that can be called by any other callable or non-callables within this scope. This allows you access to deleted objects without having to write code using locks"}
{"id": 1137, "code": "func djb33(seed uint32, k string) uint32 {\n\tvar (\n\t\tl = uint32(len(k))\n\t\td = 5381 + seed + l\n\t\ti = uint32(0)\n\t)\n\t// Why is all this 5x faster than a for loop?\n\tif l >= 4 {\n\t\tfor i < l-4 {\n\t\t\td = (d * 33) ^ uint32(k[i])\n\t\t\td = (d * 33) ^ uint32(k[i+1])\n\t\t\td = (d * 33) ^ uint32(k[i+2])\n\t\t\td = (d * 33) ^ uint32(k[i+3])\n\t\t\ti += 4\n\t\t}\n\t}\n\tswitch l - i {\n\tcase 1:\n\tcase 2:\n\t\td = (d * 33) ^ uint32(k[i])\n\tcase 3:\n\t\td = (d * 33) ^ uint32(k[i])\n\t\td = (d * 33) ^ uint32(k[i+1])\n\tcase 4:\n\t\td = (d * 33) ^ uint32(k[i])\n\t\td = (d * 33) ^ uint32(k[i+1])\n\t\td = (d * 33) ^ uint32(k[i+2])\n\t}\n\treturn d ^ (d >> 16)\n}", "reference": "// djb2 with better shuffling. 5x faster than FNV with the hash.Hash overhead.", "generated": "djB34() returns the number of bytes in an array. The first byte represents one or more elements that are not part and/or contain no data at any time during execution. If there were multiple arrays with different values then each element would be represented by its own value as if it had been written to memory using"}
{"id": 1143, "code": "func (m *MockTaskEngine) MarshalJSON() ([]byte, error) {\n\tret := m.ctrl.Call(m, \"MarshalJSON\")\n\tret0, _ := ret[0].([]byte)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// MarshalJSON mocks base method", "generated": "The marshaled JSON object is a collection of strings representing the serialized data in Mocks and its associated fields as well an array containing all field names that are valid for use with Mock Task Engine's API or any other application which uses it to generate mock tasks using Java EE APIs such As JUnit 2 . The returned"}
{"id": 1149, "code": "func (mr *MockImageManagerMockRecorder) AddAllImageStates(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"AddAllImageStates\", reflect.TypeOf((*MockImageManager)(nil).AddAllImageStates), arg0)\n}", "reference": "// AddAllImageStates indicates an expected call of AddAllImageStates", "generated": "This method returns a mutable array of image states that are added to the Mocks collection by calling addAllImages() . The returned state is then passed as an argument to all images in the list and can be used for adding or removing any existing ones from the queue at once if desired. This implementation does not support"}
{"id": 1150, "code": "func (m *MockImageManager) GetImageStateFromImageName(arg0 string) (*image.ImageState, bool) {\n\tret := m.ctrl.Call(m, \"GetImageStateFromImageName\", arg0)\n\tret0, _ := ret[0].(*image.ImageState)\n\tret1, _ := ret[1].(bool)\n\treturn ret0, ret1\n}", "reference": "// GetImageStateFromImageName mocks base method", "generated": "This method returns the image state from a specified ImageState object and optionally an optional flag to indicate whether it should be returned by this call. The flags are as follows :\n*default-flags - indicates that no images can currently exist in the current buffer or if they do not yet have any available buffers for use with"}
{"id": 1181, "code": "func (mr *MockContainerMetadataResolverMockRecorder) ResolveContainer(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"ResolveContainer\", reflect.TypeOf((*MockContainerMetadataResolver)(nil).ResolveContainer), arg0)\n}", "reference": "// ResolveContainer indicates an expected call of ResolveContainer", "generated": "// This method returns a mutable container metadata resolver for the specified MocksController .\n// The returned value is an immutable array of all associated fields and methods that are used to resolve containers in this controller's context.\n// Note that if you want to use multiple instances or return different values from one instance then"}
{"id": 1183, "code": "func NewTaskResponse(taskARN string,\n\tstate dockerstate.TaskEngineState,\n\tecsClient api.ECSClient,\n\tcluster string,\n\taz string,\n\tcontainerInstanceArn string,\n\tpropagateTags bool) (*TaskResponse, error) {\n\ttask, ok := state.TaskByArn(taskARN)\n\tif !ok {\n\t\treturn nil, errors.Errorf(\"v2 task response: unable to find task '%s'\", taskARN)\n\t}\n\n\tresp := &TaskResponse{\n\t\tCluster:          cluster,\n\t\tTaskARN:          task.Arn,\n\t\tFamily:           task.Family,\n\t\tRevision:         task.Version,\n\t\tDesiredStatus:    task.GetDesiredStatus().String(),\n\t\tKnownStatus:      task.GetKnownStatus().String(),\n\t\tAvailabilityZone: az,\n\t}\n\n\ttaskCPU := task.CPU\n\ttaskMemory := task.Memory\n\tif taskCPU != 0 || taskMemory != 0 {\n\t\ttaskLimits := &LimitsResponse{}\n\t\tif taskCPU != 0 {\n\t\t\ttaskLimits.CPU = &taskCPU\n\t\t}\n\t\tif taskMemory != 0 {\n\t\t\ttaskLimits.Memory = &taskMemory\n\t\t}\n\t\tresp.Limits = taskLimits\n\t}\n\n\tif timestamp := task.GetPullStartedAt(); !timestamp.IsZero() {\n\t\tresp.PullStartedAt = aws.Time(timestamp.UTC())\n\t}\n\tif timestamp := task.GetPullStoppedAt(); !timestamp.IsZero() {\n\t\tresp.PullStoppedAt = aws.Time(timestamp.UTC())\n\t}\n\tif timestamp := task.GetExecutionStoppedAt(); !timestamp.IsZero() {\n\t\tresp.ExecutionStoppedAt = aws.Time(timestamp.UTC())\n\t}\n\tcontainerNameToDockerContainer, ok := state.ContainerMapByArn(task.Arn)\n\tif !ok {\n\t\tseelog.Warnf(\"V2 task response: unable to get container name mapping for task '%s'\",\n\t\t\ttask.Arn)\n\t\treturn resp, nil\n\t}\n\n\teni := task.GetTaskENI()\n\tfor _, dockerContainer := range containerNameToDockerContainer {\n\t\tcontainerResponse := newContainerResponse(dockerContainer, eni, state)\n\t\tresp.Containers = append(resp.Containers, containerResponse)\n\t}\n\n\tif propagateTags {\n\t\tpropagateTagsToMetadata(state, ecsClient, containerInstanceArn, taskARN, resp)\n\t}\n\n\treturn resp, nil\n}", "reference": "// NewTaskResponse creates a new response object for the task", "generated": "// Task Response is a wrapper around the Docker API and provides an interface that allows you access to all of its properties (including metadata). // This implementation uses only one parameter in order not interfere with other implementations using it; this can be used as part or sole method invocation if desired. func main () { var args []"}
{"id": 1195, "code": "func (m *MockTime) After(arg0 time.Duration) <-chan time.Time {\n\tret := m.ctrl.Call(m, \"After\", arg0)\n\tret0, _ := ret[0].(<-chan time.Time)\n\treturn ret0\n}", "reference": "// After mocks base method", "generated": "This method returns a mutable object that can be used to create new threads and execute commands on the specified thread or command line using any of its parameters as described in RFC 6455 . The following example uses this implementation for creating an asynchronous task with two goroutines running concurrently at once :\n\n```curl -"}
{"id": 1200, "code": "func (mr *MockTimeMockRecorder) Sleep(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Sleep\", reflect.TypeOf((*MockTime)(nil).Sleep), arg0)\n}", "reference": "// Sleep indicates an expected call of Sleep", "generated": "// This method is called when the Mocks are idle and can be used to sleep or wake up a thread in an asynchronous manner using `sleep` as its default parameter.\n// The callback will return nil if no such call was made by this caller before calling it with any parameters other than those specified here."}
{"id": 1205, "code": "func (mr *MockTimerMockRecorder) Stop() *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Stop\", reflect.TypeOf((*MockTimer)(nil).Stop))\n}", "reference": "// Stop indicates an expected call of Stop", "generated": "// Returns true for all methods in the"}
{"id": 1216, "code": "func (imageState *ImageState) AddImageName(imageName string) {\n\timageState.lock.Lock()\n\tdefer imageState.lock.Unlock()\n\tif !imageState.HasImageName(imageName) {\n\t\tseelog.Infof(\"Adding image name- %v to Image state- %v\", imageName, imageState.Image.ImageID)\n\t\timageState.Image.Names = append(imageState.Image.Names, imageName)\n\t}\n}", "reference": "// AddImageName adds image name to image state", "generated": "This function creates a new instance of Image State and locks the lock on that newly created object with an associated ID value for each element in the array containing images from this class as well As described above it also provides access by default to all other instances within its scope which are not currently locked upon creation or modification without any additional"}
{"id": 1254, "code": "func copyMetricsMetadata(metadata *ecstcs.MetricsMetadata, fin bool) *ecstcs.MetricsMetadata {\n\treturn &ecstcs.MetricsMetadata{\n\t\tCluster:           aws.String(*metadata.Cluster),\n\t\tContainerInstance: aws.String(*metadata.ContainerInstance),\n\t\tIdle:              aws.Bool(*metadata.Idle),\n\t\tMessageId:         aws.String(*metadata.MessageId),\n\t\tFin:               aws.Bool(fin),\n\t}\n}", "reference": "// copyMetricsMetadata creates a new MetricsMetadata object from a given MetricsMetadata object.\n// It copies all the fields from the source object to the new object and sets the 'Fin' field\n// as specified by the argument.", "generated": "// Copy metadata from the cluster to the specified bucket and return it as a string if no matching data is found in that block of records // or otherwise fails with an error message when attempting this method on any other node within its own chain. This can be used for creating new instances at runtime without having accesses into existing"}
{"id": 1285, "code": "func (cgroup *CgroupResource) Create() error {\n\terr := cgroup.setupTaskCgroup()\n\tif err != nil {\n\t\tseelog.Criticalf(\"Cgroup resource [%s]: unable to setup cgroup root: %v\", cgroup.taskARN, err)\n\t\treturn err\n\t}\n\treturn nil\n}", "reference": "// Create creates cgroup root for the task", "generated": "// Creates a task that will create the CGroup Resource and initialize it with its own init method for each of these tasks. The Task is created by creating an instance of this class in order from all available resources on disk into one single thread within which they can be used as threads without having to call any other methods"}
{"id": 1293, "code": "func NewECRFactory(acceptInsecureCert bool) ECRFactory {\n\treturn &ecrFactory{\n\t\thttpClient: httpclient.New(roundtripTimeout, acceptInsecureCert),\n\t}\n}", "reference": "// NewECRFactory returns an ECRFactory capable of producing ECRSDK clients", "generated": "This method creates a new ECRI instance and returns the newly created certificate from it with an optional timeout of 1 second to allow for verification before returning any certificates that have been verified by other users or are being used in connection with this service (e-mail). The default value is 0 seconds . This can be changed using"}
{"id": 1313, "code": "func (err CannotStopContainerError) IsRetriableError() bool {\n\tif _, ok := err.FromError.(NoSuchContainerError); ok {\n\t\treturn false\n\t}\n\n\treturn true\n}", "reference": "// IsRetriableError returns a boolean indicating whether the call that\n// generated the error can be retried.\n// When stopping a container, most errors that we can get should be\n// considered retriable. However, in the case where the container is\n// already stopped or doesn't exist at all, there's no sense in\n// retrying.", "generated": "// This function is called when the container fails to stop or if it does not return an error message // and returns a nil value for this exception type in case of failure; otherwise we call Stop().\n// The default behavior should be that all containers fail once they are stopped by their own process before returning any status information"}
{"id": 1327, "code": "func (m *MockEC2MetadataClient) DefaultCredentials() (*ec2.RoleCredentials, error) {\n\tret := m.ctrl.Call(m, \"DefaultCredentials\")\n\tret0, _ := ret[0].(*ec2.RoleCredentials)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// DefaultCredentials mocks base method", "generated": "// Initializes the credentials for a specific role and returns an instance of Mocks::defaultCreditations .\n // Returns nil if no credential is provided or return false otherwise.\n func (credential *MockingContext ) GetCreds () string { ctx []string{\n\u0019return ctx"}
{"id": 1340, "code": "func (mr *MockClientSDKMockRecorder) DescribeTags(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"DescribeTags\", reflect.TypeOf((*MockClientSDK)(nil).DescribeTags), arg0)\n}", "reference": "// DescribeTags indicates an expected call of DescribeTags", "generated": "This method returns a list of tags that describe the current state of the MocksDB and its associated metadata collection in JSON format. The tag is an array containing all fields from which to retrieve information about this data set including name, description string, date, time, location etc.. This can be used as a way for"}
{"id": 1352, "code": "func (agent *ecsAgent) setClusterInConfig(previousCluster string) error {\n\t// TODO Handle default cluster in a sane and unified way across the codebase\n\tconfiguredCluster := agent.cfg.Cluster\n\tif configuredCluster == \"\" {\n\t\tseelog.Debug(\"Setting cluster to default; none configured\")\n\t\tconfiguredCluster = config.DefaultClusterName\n\t}\n\tif previousCluster != configuredCluster {\n\t\terr := clusterMismatchError{\n\t\t\tfmt.Errorf(clusterMismatchErrorFormat, previousCluster, configuredCluster),\n\t\t}\n\t\tseelog.Criticalf(\"%v\", err)\n\t\treturn err\n\t}\n\tagent.cfg.Cluster = previousCluster\n\tseelog.Infof(\"Restored cluster '%s'\", agent.cfg.Cluster)\n\n\treturn nil\n}", "reference": "// setClusterInConfig sets the cluster name in the config object based on\n// previous state. It returns an error if there's a mismatch between the\n// the current cluster name with what's restored from the cluster state", "generated": "This method sets up an initial configuration of all nodes on each node that are not already connected by using clusterManager . This is done so as to avoid any unnecessary network traffic between different clients or servers when running multiple instances of this service at once with no need for additional connections from other services such like SSH/TLS"}
{"id": 1377, "code": "func handleInvalidParamException(err error, events *list.List, eventToSubmit *list.Element) {\n\tif utils.IsAWSErrorCodeEqual(err, ecs.ErrCodeInvalidParameterException) {\n\t\tevent := eventToSubmit.Value.(*sendableEvent)\n\t\tseelog.Warnf(\"TaskHandler: Event is sent with invalid parameters; just removing: %s\", event.toString())\n\t\tevents.Remove(eventToSubmit)\n\t}\n}", "reference": "// handleInvalidParamException removes the event from event queue when its parameters are\n// invalid to reduce redundant API call", "generated": "// Handle an exception that occurs when the user attempts to submit a request for data from another application or service using SendableContext .\n // This method returns nil if no response was received and return false otherwise.\n// Returns true in case of errors (see below). If this fails, it will be returned as null"}
{"id": 1402, "code": "func NewJitteredTicker(ctx context.Context, start, end time.Duration) <-chan time.Time {\n\tticker := make(chan time.Time, 1)\n\n\tgo func() {\n\t\tdefer close(ticker)\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tdefault:\n\t\t\t\ttime.Sleep(randomDuration(start, end))\n\t\t\t\tsendNow(ticker)\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn ticker\n}", "reference": "// NewJitteredTicker works like a time.Ticker except with randomly distributed ticks\n// between start and end duration.", "generated": "New Jitter Tickers is a wrapper around the new jitted-out tiddler format and provides an interface to create custom widgets for each of its fields in order from most recently created (or previously added) objects into existing ones using either JSON or XML data structures as well . The default widget type used by this implementation"}
{"id": 1411, "code": "func (m *MockECSClient) GetResourceTags(arg0 string) ([]*ecs.Tag, error) {\n\tret := m.ctrl.Call(m, \"GetResourceTags\", arg0)\n\tret0, _ := ret[0].([]*ecs.Tag)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// GetResourceTags mocks base method", "generated": "The Mocksocket API provides a simple way to retrieve and return the tags of an ECNS client using C# code that is not yet available in Java 8 or later versions; it does this by calling getResourcesTags() . The tag returned from these calls will be used as part for future use with other clients such"}
{"id": 1417, "code": "func (m *MockSaveableOption) AddSaveable(arg0 string, arg1 statemanager.Saveable) statemanager.Option {\n\tret := m.ctrl.Call(m, \"AddSaveable\", arg0, arg1)\n\tret0, _ := ret[0].(statemanager.Option)\n\treturn ret0\n}", "reference": "// AddSaveable mocks base method", "generated": "This method returns a new Saveable option that can be used to save the current saved file or any other data in an existing directory on disk with no additional parameters and without saving it as part of another script call from Mocksave.\nExample:\n\n```var fs = NewFile(\"/tmp/my_"}
{"id": 1440, "code": "func (state *DockerTaskEngineState) TaskByArn(arn string) (*apitask.Task, bool) {\n\tstate.lock.RLock()\n\tdefer state.lock.RUnlock()\n\n\treturn state.taskByArn(arn)\n}", "reference": "// TaskByArn returns a task for a given ARN", "generated": "// This task is a lock-free container for the Docker runtime and can be used to create new locks in any of its dependencies or as an alternative way around locking down other containers that are not locked by default // with this method callbacks from within Docker's own init process. The main purpose here is simply to"}
{"id": 1448, "code": "func (state *DockerTaskEngineState) AddTaskIPAddress(addr string, taskARN string) {\n\tstate.lock.Lock()\n\tdefer state.lock.Unlock()\n\n\tstate.ipToTask[addr] = taskARN\n}", "reference": "// AddTaskIPAddress adds ip adddress for a task arn into the state", "generated": "// This is a Task Engine State that will be used to lock the specified address in order for it not being locked by other processes or services on this machine. // The default value of `dock` and `task ARNs are set when running as root if they exist; otherwise nil .\n// Note : If"}
{"id": 1457, "code": "func (c *Container) GetKnownStatus() apicontainerstatus.ContainerStatus {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.KnownStatusUnsafe\n}", "reference": "// GetKnownStatus returns the known status of the container", "generated": "// Returns the status of a container if it is known to be safe, or nil otherwise.\n // This method returns true for all containers that are not currently in use and false for any other ones. If an exception occurs while attempting this, then\nbool has been called with no error message returned by `Cancel"}
{"id": 1458, "code": "func (c *Container) SetKnownStatus(status apicontainerstatus.ContainerStatus) {\n\tc.lock.Lock()\n\tdefer c.lock.Unlock()\n\n\tc.KnownStatusUnsafe = status\n\tc.updateAppliedStatusUnsafe(status)\n}", "reference": "// SetKnownStatus sets the known status of the container and update the container\n// applied status", "generated": "// Initializes the container and locks it in a safe state, returning an error if no known Status is available for that application or nil otherwise.\n// This method returns true when all pending applications are closed by default.\n // The lock will be updated with new information about any existing issues before closing them; this can"}
{"id": 1466, "code": "func (c *Container) ShouldPullWithExecutionRole() bool {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.RegistryAuthentication != nil &&\n\t\tc.RegistryAuthentication.Type == AuthTypeECR &&\n\t\tc.RegistryAuthentication.ECRAuthData != nil &&\n\t\tc.RegistryAuthentication.ECRAuthData.UseExecutionRole\n}", "reference": "// ShouldPullWithExecutionRole returns whether this container has its own ECR credentials", "generated": "// Check if the execution role is authorized by a user or not, and return true for authorization purposes\n // If false then check whether it's an authenticated session with no users in its scope to determine which one should be used as the default login handler\nif C.UserAccounts[C._user] == null"}
{"id": 1497, "code": "func (c *Container) GetV3EndpointID() string {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.V3EndpointID\n}", "reference": "// GetV3EndpointID returns the v3 endpoint id of container", "generated": "// Returns the end point ID of the container, if any.\n // The value is a pointer to the V2 endpoint that was created by the user in this case and not nullptr or nil. If no such object exists,\nif it has been initialized with an empty array then return false. This function returns"}
{"id": 1507, "code": "func (secret *ASMSecretResource) retrieveASMSecretValue(apiSecret apicontainer.Secret, iamCredentials credentials.IAMRoleCredentials, wg *sync.WaitGroup, errorEvents chan error) {\n\tdefer wg.Done()\n\n\tasmClient := secret.asmClientCreator.NewASMClient(apiSecret.Region, iamCredentials)\n\tseelog.Infof(\"ASM secret resource: retrieving resource for secret %v in region %s for task: [%s]\", apiSecret.ValueFrom, apiSecret.Region, secret.taskARN)\n\t//for asm secret, ValueFrom can be arn or name\n\tsecretValue, err := asm.GetSecretFromASM(apiSecret.ValueFrom, asmClient)\n\tif err != nil {\n\t\terrorEvents <- fmt.Errorf(\"fetching secret data from AWS Secrets Manager in region %s: %v\", apiSecret.Region, err)\n\t\treturn\n\t}\n\n\tsecret.lock.Lock()\n\tdefer secret.lock.Unlock()\n\n\t// put secret value in secretData\n\tsecretKey := apiSecret.GetSecretResourceCacheKey()\n\tsecret.secretData[secretKey] = secretValue\n}", "reference": "// retrieveASMSecretValue reads secret value from cache first, if not exists, call GetSecretFromASM to retrieve value\n// AWS secrets Manager", "generated": "/** Returns the ASMX key of an authenticated session and returns a new Secret object with all associated metadata including its id/value pairs that are unique to this user's account.*\n*/ // This method is deprecated by default because it does not work well when using `asms` API methods on remote users who have no"}
{"id": 1516, "code": "func handleInactivityTimeout(reader io.ReadCloser, timeout time.Duration, cancelRequest func(), canceled *uint32) (io.ReadCloser, chan<- struct{}) {\n\tdone := make(chan struct{})\n\tproxyReader := &proxyReader{ReadCloser: reader}\n\tgo func() {\n\t\tvar lastCallCount uint64\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-time.After(timeout):\n\t\t\tcase <-done:\n\t\t\t\treturn\n\t\t\t}\n\t\t\tcurCallCount := proxyReader.callCount()\n\t\t\tif curCallCount == lastCallCount {\n\t\t\t\tatomic.AddUint32(canceled, 1)\n\t\t\t\tcancelRequest()\n\t\t\t\treturn\n\t\t\t}\n\t\t\tlastCallCount = curCallCount\n\t\t}\n\t}()\n\treturn proxyReader, done\n}", "reference": "// When pulling an image, the docker api will pull and then subsequently unzip the downloaded artifacts. Docker does\n// not separate the \"pull\" from the \"unpack\" step. What this means is that this timeout doesn't 'tick' while unpacking\n// the downloaded files. This only causes noticeable impact with large files, but we should investigate improving this.", "generated": "// HandleInactiveTimeout is a method that returns an asynchronous status code for the given callback and cancellation request respectively. It can be used to return true if there was no response or false otherwise. // This function will only work on nonblocking goroutines with concurrent threads in use. The default value of this option may"}
{"id": 1519, "code": "func (imageManager *dockerImageManager) RemoveContainerReferenceFromImageState(container *apicontainer.Container) error {\n\t// the image state has been updated, save the new state\n\tdefer imageManager.saver.ForceSave()\n\t// this lock is for reading image states and finding the one that the container belongs to\n\timageManager.updateLock.RLock()\n\tdefer imageManager.updateLock.RUnlock()\n\tif container.ImageID == \"\" {\n\t\treturn fmt.Errorf(\"Invalid container reference: Empty image id\")\n\t}\n\n\t// Find image state that this container is part of, and remove the reference\n\timageState, ok := imageManager.getImageState(container.ImageID)\n\tif !ok {\n\t\treturn fmt.Errorf(\"Cannot find image state for the container to be removed\")\n\t}\n\t// Found matching ImageState\n\treturn imageState.RemoveContainerReference(container)\n}", "reference": "// RemoveContainerReferenceFromImageState removes container reference from the corresponding imageState object", "generated": "This function removes the current storage from the Docker imageserver by using a Lock operation on an object created with dockerImages . The locks are used in order not only to prevent any changes made during execution but also as security checks against future updates or other malicious code which may cause problems if they were executed before being applied after initial"}
{"id": 1540, "code": "func (td *TransitionDependenciesMap) UnmarshalJSON(b []byte) error {\n\tdepMap := make(map[apicontainerstatus.ContainerStatus]TransitionDependencySet)\n\terr := json.Unmarshal(b, &depMap)\n\tif err == nil {\n\t\t*td = depMap\n\t\treturn nil\n\t}\n\tseelog.Debugf(\"Unmarshal 'TransitionDependencySet': %s, not a map: %v\", string(b), err)\n\t// Unmarshal to deprecated 'TransitionDependencySet' and then convert to a map\n\ttdSet := TransitionDependencySet{}\n\tif err := json.Unmarshal(b, &tdSet); err != nil {\n\t\treturn errors.Wrapf(err,\n\t\t\t\"Unmarshal 'TransitionDependencySet': does not comply with any of the dependency types\")\n\t}\n\tfor _, dep := range tdSet.ContainerDependencies {\n\t\tdependentStatus := dep.DependentStatus\n\t\t// no need for DependentStatus field anymore, since it becomes the map's key\n\t\tdep.DependentStatus = 0\n\t\tif _, ok := depMap[dependentStatus]; !ok {\n\t\t\tdepMap[dependentStatus] = TransitionDependencySet{}\n\t\t}\n\t\tdeps := depMap[dependentStatus]\n\t\tdeps.ContainerDependencies = append(deps.ContainerDependencies, dep)\n\t\tdepMap[dependentStatus] = deps\n\t}\n\t*td = depMap\n\treturn nil\n}", "reference": "// UnmarshalJSON decodes the TransitionDependencySet tag in the JSON encoded string\n// into the TransitionDependenciesMap object", "generated": "The `transitionddependents` mapping is used by Transitions in order that they can be converted into maps using their dependencies as keys or values instead thereof. The default value will always return an empty list if there are more than one dependent status fields on this interface; otherwise all dependants must have been added before"}
{"id": 1543, "code": "func NewMockCgroup(ctrl *gomock.Controller) *MockCgroup {\n\tmock := &MockCgroup{ctrl: ctrl}\n\tmock.recorder = &MockCgroupMockRecorder{mock}\n\treturn mock\n}", "reference": "// NewMockCgroup creates a new mock instance", "generated": "NewMutex is a mutable, immutable object that can be used to create new Mutecks and other objects from existing Mocks or Cgroups . It provides the following methods for creating an instance of this class :\n\n```mutex::newMutExchange()```, `mutcgmt::create"}
{"id": 1579, "code": "func (m *MockSecretsManagerAPI) DeleteResourcePolicyWithContext(arg0 aws.Context, arg1 *secretsmanager.DeleteResourcePolicyInput, arg2 ...request.Option) (*secretsmanager.DeleteResourcePolicyOutput, error) {\n\tvarargs := []interface{}{arg0, arg1}\n\tfor _, a := range arg2 {\n\t\tvarargs = append(varargs, a)\n\t}\n\tret := m.ctrl.Call(m, \"DeleteResourcePolicyWithContext\", varargs...)\n\tret0, _ := ret[0].(*secretsmanager.DeleteResourcePolicyOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// DeleteResourcePolicyWithContext mocks base method", "generated": "delete resource policy with context and return nil if no action is taken to delete it from the cache or otherwise remove any existing resources that are not in use by this service provider for which there is an active request handler on callbacks of MocksMutex . The returned value will be used as part-of_cache operations"}
{"id": 1595, "code": "func (m *MockSecretsManagerAPI) ListSecretVersionIds(arg0 *secretsmanager.ListSecretVersionIdsInput) (*secretsmanager.ListSecretVersionIdsOutput, error) {\n\tret := m.ctrl.Call(m, \"ListSecretVersionIds\", arg0)\n\tret0, _ := ret[0].(*secretsmanager.ListSecretVersionIdsOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// ListSecretVersionIds mocks base method", "generated": "// Returns a list of secret versions that are available for use in the security manager API and optionally contains information about their key-value pairs to be used by other services or applications when they need access to them from within an application's system context.\n// This function is only useful if you want to provide additional functionality such"}
{"id": 1612, "code": "func (m *MockSecretsManagerAPI) RotateSecret(arg0 *secretsmanager.RotateSecretInput) (*secretsmanager.RotateSecretOutput, error) {\n\tret := m.ctrl.Call(m, \"RotateSecret\", arg0)\n\tret0, _ := ret[0].(*secretsmanager.RotateSecretOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// RotateSecret mocks base method", "generated": "// This function rotates the secret into a random number generator and returns an output of 0 if it is not found or nil otherwise.\n func () bool { return false } // Returns true for all keys in the keychain that are already generated by this method. If no such string exists, then only one value will"}
{"id": 1616, "code": "func (m *MockSecretsManagerAPI) TagResourceRequest(arg0 *secretsmanager.TagResourceInput) (*request.Request, *secretsmanager.TagResourceOutput) {\n\tret := m.ctrl.Call(m, \"TagResourceRequest\", arg0)\n\tret0, _ := ret[0].(*request.Request)\n\tret1, _ := ret[1].(*secretsmanager.TagResourceOutput)\n\treturn ret0, ret1\n}", "reference": "// TagResourceRequest mocks base method", "generated": "// This method returns a string of the requested resource information and an array of tag resources to be used for processing in order that it can return more than one response from the request object if needed.\n// The returned value is either nil or null depending on whether this parameter was passed as part by calling MocksMutex"}
{"id": 1628, "code": "func (manager *metadataManager) parseMetadataAtContainerCreate(task *apitask.Task, containerName string) Metadata {\n\treturn Metadata{\n\t\tcluster: manager.cluster,\n\t\ttaskMetadata: TaskMetadata{\n\t\t\tcontainerName:          containerName,\n\t\t\ttaskARN:                task.Arn,\n\t\t\ttaskDefinitionFamily:   task.Family,\n\t\t\ttaskDefinitionRevision: task.Version,\n\t\t},\n\t\tcontainerInstanceARN:  manager.containerInstanceARN,\n\t\tmetadataStatus:        MetadataInitial,\n\t\tavailabilityZone:      manager.availabilityZone,\n\t\thostPublicIPv4Address: manager.hostPublicIPv4Address,\n\t}\n}", "reference": "// parseMetadataAtContainerCreate gathers metadata from task and cluster configurations\n// then packages it for JSON Marshaling. We use this version to get data\n// available prior to container creation\n// Since we accept incomplete metadata fields, we should not return\n// errors here and handle them at this or the above stage.", "generated": "// This is a metadata creation service that creates and stores the following data in an array of containers for use with other services or as part to create new instances on disk if needed. // The name will be used when creating this class; it should not contain any special characters such like \"*\" unless specified otherwise. func"}
{"id": 1649, "code": "func (m *MockTaskResource) Cleanup() error {\n\tret := m.ctrl.Call(m, \"Cleanup\")\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// Cleanup mocks base method", "generated": "This method cleans up the task resource and returns a new Task object with an empty value for each of its arguments. The returned objects are then used to perform cleanup on any errors that occur during execution. This is useful when you want your tasks to be run in parallel or if they have different names than their parent's resources"}
{"id": 1669, "code": "func (f *factory) GetClient(version dockerclient.DockerVersion) (sdkclient.Client, error) {\n\tfor _, v := range getWindowsReplaceableVersions() {\n\t\tif v == version {\n\t\t\tversion = minDockerAPIVersion\n\t\t\tbreak\n\t\t}\n\t}\n\treturn f.getClient(version)\n}", "reference": "// GetClient will replace some versions of Docker on Windows. We need this because\n// agent assumes that it can always call older versions of the docker API.", "generated": "This function returns a client that is the current Windows registry key and can be used to create new clients for Docker containers using Microsoft's Registry API or other similar APIs in order to perform additional operations on existing applications running within an application container environment such as SQL Server 2008 R2 SP1/R3 etc.. This functionality was"}
{"id": 1739, "code": "func (task *Task) GetExecutionCredentialsID() string {\n\ttask.lock.RLock()\n\tdefer task.lock.RUnlock()\n\n\treturn task.ExecutionCredentialsID\n}", "reference": "// GetExecutionCredentialsID gets the credentials ID for the task", "generated": "This method returns a list of credentials that are associated with the specified execution context, and optionally an optional callback function to be called when executing this credential on behalf or from another process in order for it not being blocked by any other processes running within its scope. The default value is nil . This callbacks will only return true"}
{"id": 1757, "code": "func (task *Task) RecordExecutionStoppedAt(container *apicontainer.Container) {\n\tif !container.Essential {\n\t\treturn\n\t}\n\tif container.GetKnownStatus() != apicontainerstatus.ContainerStopped {\n\t\treturn\n\t}\n\t// If the essential container is stopped, set the ExecutionStoppedAt timestamp\n\tnow := time.Now()\n\tok := task.SetExecutionStoppedAt(now)\n\tif !ok {\n\t\t// ExecutionStoppedAt was already recorded. Nothing to left to do here\n\t\treturn\n\t}\n\tseelog.Infof(\"Task [%s]: recording execution stopped time. Essential container [%s] stopped at: %s\",\n\t\ttask.Arn, container.Name, now.String())\n}", "reference": "// RecordExecutionStoppedAt checks if this is an essential container stopped\n// and set the task executionStoppedAt timestamps", "generated": "This method creates a new Task that will be executed when an application stops executing on its own and then executes it again after all of those tasks have been completed successfully in order for them notto fail or crash during runtime. The default behavior can be changed by setting this option as follows :\n\n```\nvar main ="}
{"id": 1767, "code": "func (task *Task) getPIDMode() string {\n\ttask.lock.RLock()\n\tdefer task.lock.RUnlock()\n\n\treturn task.PIDMode\n}", "reference": "// Retrieves a Task's PIDMode", "generated": "This method is called when the Task object has been created and locked by a thread, or if it was not already set to lock before calling this methods on an instance of the class that implements PIDsession . The default value for these calls are nil , which means they do nothing except return true in case any other call"}
{"id": 1793, "code": "func (healthStatus *ContainerHealthStatus) UnmarshalJSON(b []byte) error {\n\t*healthStatus = ContainerHealthUnknown\n\n\tif strings.ToLower(string(b)) == \"null\" {\n\t\treturn nil\n\t}\n\tif b[0] != '\"' || b[len(b)-1] != '\"' {\n\t\treturn errors.New(\"container health status unmarshal: status must be a string or null; Got \" + string(b))\n\t}\n\n\tstrStatus := string(b[1 : len(b)-1])\n\tswitch strStatus {\n\tcase \"UNKNOWN\":\n\t// The health status is already set to ContainerHealthUnknown initially\n\tcase \"HEALTHY\":\n\t\t*healthStatus = ContainerHealthy\n\tcase \"UNHEALTHY\":\n\t\t*healthStatus = ContainerUnhealthy\n\tdefault:\n\t\treturn errors.New(\"container health status unmarshal: unrecognized status: \" + string(b))\n\t}\n\treturn nil\n}", "reference": "// UnmarshalJSON overrides the logic for parsing the JSON-encoded container health data", "generated": "This method returns an unmodified JSON object that contains the Health Status of all containers in the container, and its associated values for each type as well Async , Await . It also provides methods such like GetAllDependencies() which will return any dependencies on those types if they are not present at runtime when calling"}
{"id": 1797, "code": "func (m *MockDockerClient) APIVersion() (dockerclient.DockerVersion, error) {\n\tret := m.ctrl.Call(m, \"APIVersion\")\n\tret0, _ := ret[0].(dockerclient.DockerVersion)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// APIVersion mocks base method", "generated": "This method returns an object that contains the Docker container's version number and a list of all versions in use at timeof execution for each docker client running on this instance as well as any changes made to it by other clients or containers during its lifetime with no change required from them when they are run again using new-version"}
{"id": 1807, "code": "func (m *MockDockerClient) ListContainers(arg0 context.Context, arg1 bool, arg2 time.Duration) dockerapi.ListContainersResponse {\n\tret := m.ctrl.Call(m, \"ListContainers\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(dockerapi.ListContainersResponse)\n\treturn ret0\n}", "reference": "// ListContainers mocks base method", "generated": "List Contains a list of containers that are currently running in the Docker container manager and can be used to create new instances for each one by calling ls -l . The default is nil , but you may specify more options with --help or use `ls` as an option if your application does not support it yet."}
{"id": 1823, "code": "func (mtask *managedTask) waitForHostResources() {\n\tif mtask.StartSequenceNumber == 0 {\n\t\t// This is the first transition on this host. No need to wait\n\t\treturn\n\t}\n\tif mtask.GetDesiredStatus().Terminal() {\n\t\t// Task's desired status is STOPPED. No need to wait in this case either\n\t\treturn\n\t}\n\n\tseelog.Infof(\"Managed task [%s]: waiting for any previous stops to complete. Sequence number: %d\",\n\t\tmtask.Arn, mtask.StartSequenceNumber)\n\n\tothersStoppedCtx, cancel := context.WithCancel(mtask.ctx)\n\tdefer cancel()\n\n\tgo func() {\n\t\tmtask.taskStopWG.Wait(mtask.StartSequenceNumber)\n\t\tcancel()\n\t}()\n\n\tfor !mtask.waitEvent(othersStoppedCtx.Done()) {\n\t\tif mtask.GetDesiredStatus().Terminal() {\n\t\t\t// If we end up here, that means we received a start then stop for this\n\t\t\t// task before a task that was expected to stop before it could\n\t\t\t// actually stop\n\t\t\tbreak\n\t\t}\n\t}\n\tseelog.Infof(\"Managed task [%s]: wait over; ready to move towards status: %s\",\n\t\tmtask.Arn, mtask.GetDesiredStatus().String())\n}", "reference": "// waitForHostResources waits for host resources to become available to start\n// the task. This involves waiting for previous stops to complete so the\n// resources become free.", "generated": "/**\n* Wait until an event has occurred and return if there are no pending tasks or nil otherwise.\n*/ // Called when all scheduled events have been completed by default. The callback will be called once every 10 seconds with each new request being processed asynchronously. It should not take more than one call per second"}
{"id": 1857, "code": "func (m *MockWebsocketConn) ReadMessage() (int, []byte, error) {\n\tret := m.ctrl.Call(m, \"ReadMessage\")\n\tret0, _ := ret[0].(int)\n\tret1, _ := ret[1].([]byte)\n\tret2, _ := ret[2].(error)\n\treturn ret0, ret1, ret2\n}", "reference": "// ReadMessage mocks base method", "generated": "This method reads a message from the socket and returns an int or error if it is not found in response to any of the following conditions:\n\nA string containing information about what was sent; A byte indicating whether this received data for that purpose has been returned by another process on its own server with no connection issues caused by"}
{"id": 1890, "code": "func (engine *DockerTaskEngine) isTaskManaged(arn string) bool {\n\tengine.tasksLock.RLock()\n\tdefer engine.tasksLock.RUnlock()\n\t_, ok := engine.managedTasks[arn]\n\treturn ok\n}", "reference": "// isTaskManaged checks if task for the corresponding arn is present", "generated": "// This task manager will lock the locks of all tasks in a container and allow them to be executed by any other process running on it // without locking themselves out from execution or using their own threading mechanism for synchronization purposes.\n/**\n* A Task Manager can also use its LockManager interface as an alternative method that"}
{"id": 1896, "code": "func (engine *DockerTaskEngine) sweepTask(task *apitask.Task) {\n\tfor _, cont := range task.Containers {\n\t\terr := engine.removeContainer(task, cont)\n\t\tif err != nil {\n\t\t\tseelog.Debugf(\"Task engine [%s]: unable to remove old container [%s]: %v\",\n\t\t\t\ttask.Arn, cont.Name, err)\n\t\t}\n\t\t// Internal container(created by ecs-agent) state isn't recorded\n\t\tif cont.IsInternal() {\n\t\t\tcontinue\n\t\t}\n\t\terr = engine.imageManager.RemoveContainerReferenceFromImageState(cont)\n\t\tif err != nil {\n\t\t\tseelog.Errorf(\"Task engine [%s]: Unable to remove container [%s] reference from image state: %v\",\n\t\t\t\ttask.Arn, cont.Name, err)\n\t\t}\n\t}\n\n\t// Clean metadata directory for task\n\tif engine.cfg.ContainerMetadataEnabled {\n\t\terr := engine.metadataManager.Clean(task.Arn)\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Task engine [%s]: clean task metadata failed: %v\", task.Arn, err)\n\t\t}\n\t}\n\tengine.saver.Save()\n}", "reference": "// sweepTask deletes all the containers associated with a task", "generated": "The following code snippet is a simple wrapper around the Docker Task Engine API and provides an easy way of cleaning up existing tasks in order that they can be reused without having any additional dependencies on other containers or services running within it. The example below uses this functionality as well; however if you are using another service such one like"}
{"id": 1906, "code": "func (engine *DockerTaskEngine) updateTaskUnsafe(task *apitask.Task, update *apitask.Task) {\n\tmanagedTask, ok := engine.managedTasks[task.Arn]\n\tif !ok {\n\t\tseelog.Criticalf(\"Task engine [%s]: ACS message for a task we thought we managed, but don't!  Aborting.\",\n\t\t\ttask.Arn)\n\t\treturn\n\t}\n\t// Keep the lock because sequence numbers cannot be correct unless they are\n\t// also read in the order addtask was called\n\t// This does block the engine's ability to ingest any new events (including\n\t// stops for past tasks, ack!), but this is necessary for correctness\n\tupdateDesiredStatus := update.GetDesiredStatus()\n\tseelog.Debugf(\"Task engine [%s]: putting update on the acs channel: [%s] with seqnum [%d]\",\n\t\ttask.Arn, updateDesiredStatus.String(), update.StopSequenceNumber)\n\tmanagedTask.emitACSTransition(acsTransition{\n\t\tdesiredStatus: updateDesiredStatus,\n\t\tseqnum:        update.StopSequenceNumber,\n\t})\n\tseelog.Debugf(\"Task engine [%s]: update taken off the acs channel: [%s] with seqnum [%d]\",\n\t\ttask.Arn, updateDesiredStatus.String(), update.StopSequenceNumber)\n}", "reference": "// updateTaskUnsafe determines if a new transition needs to be applied to the\n// referenced task, and if needed applies it. It should not be called anywhere\n// but from 'AddTask' and is protected by the tasksLock lock there.", "generated": "This function updates the ACS queue of an event that has been scheduled by another thread and returns it asynchronously if no other threads have started or stopped processing its pending state at once. The callback will return nil when all previous queued states were exhausted; otherwise, only one current active session can receive information about what"}
{"id": 1918, "code": "func (m *MockFileSystem) Copy(arg0 io.Writer, arg1 io.Reader) (int64, error) {\n\tret := m.ctrl.Call(m, \"Copy\", arg0, arg1)\n\tret0, _ := ret[0].(int64)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// Copy mocks base method", "generated": "copy() copies the contents of a file to an arbitrary location in the specified buffer and returns it as its result if any errors occurred while copying or writing data from that point on up until execution time has elapsed. It is useful for debugging purposes only when there are no other options available at runtime such use with respect not just"}
{"id": 1919, "code": "func (m *MockFileSystem) Exit(arg0 int) {\n\tm.ctrl.Call(m, \"Exit\", arg0)\n}", "reference": "// Exit mocks base method", "generated": "// This function exits the MOCKFILE system process and returns a list of exit status codes for all processes that exited from it in this case. The default is 0 if no such exception was encountered or 1 otherwise.\n // Note that these are not necessarily fatal errors; they may be caused by an error message sent to"}
{"id": 1920, "code": "func (m *MockFileSystem) MkdirAll(arg0 string, arg1 os.FileMode) error {\n\tret := m.ctrl.Call(m, \"MkdirAll\", arg0, arg1)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// MkdirAll mocks base method", "generated": "This function returns a list of all the files in the specified directory and its contents if any are found or not included by calling mkdirall() . The default is nil , but can be overridden with --no-mkdirs option to avoid confusion when using this method for directories that do exist as well; see"}
{"id": 1937, "code": "func (m *MockTaskEngineState) AllTasks() []*task.Task {\n\tret := m.ctrl.Call(m, \"AllTasks\")\n\tret0, _ := ret[0].([]*task.Task)\n\treturn ret0\n}", "reference": "// AllTasks mocks base method", "generated": "This method returns a Task object that implements the Mocking API of the task manager and provides an interface to all tasks in its scope for each thread on which it is running or waiting for execution by calling this methods with no arguments other than nil . The default implementation will be used when using any asynchronous operations such as callbacks"}
{"id": 1948, "code": "func (containerType ContainerType) String() string {\n\tfor str, contType := range stringToContainerType {\n\t\tif contType == containerType {\n\t\t\treturn str\n\t\t}\n\t}\n\n\treturn \"NORMAL\"\n}", "reference": "// String converts the container type enum to a string", "generated": "// This method returns a list of strings. The first element is the name and last one is the type used to represent it. It can be any number or an array with no parameters as long that includes all elements in the same order they are returned from. // Example usage for creating lists using this example var List ="}
{"id": 1959, "code": "func (f *factory) GetClient(version dockerclient.DockerVersion) (sdkclient.Client, error) {\n\treturn f.getClient(version)\n}", "reference": "// GetClient on linux will simply return the cached client from the map", "generated": "This function returns the version of the Docker client that is running on a given host and optionally provides an optional service name to be used by it for its services in order notifying clients about changes made during deployment or when they are no longer needed due as such from any other source code available at runtime with respect backends like"}
{"id": 2002, "code": "func (engine *DockerStatsEngine) removeContainer(dockerID string) {\n\tengine.lock.Lock()\n\tdefer engine.lock.Unlock()\n\n\t// Make sure that this container belongs to a task.\n\ttask, err := engine.resolver.ResolveTask(dockerID)\n\tif err != nil {\n\t\tseelog.Debugf(\"Could not map container to task, ignoring, err: %v, id: %s\", err, dockerID)\n\t\treturn\n\t}\n\n\t_, taskExists := engine.tasksToContainers[task.Arn]\n\tif !taskExists {\n\t\tseelog.Debugf(\"Container not being watched, id: %s\", dockerID)\n\t\treturn\n\t}\n\n\t// task arn exists in map.\n\tcontainer, containerExists := engine.tasksToContainers[task.Arn][dockerID]\n\tif !containerExists {\n\t\t// container arn does not exist in map.\n\t\tseelog.Debugf(\"Container not being watched, id: %s\", dockerID)\n\t\treturn\n\t}\n\n\tengine.doRemoveContainerUnsafe(container, task.Arn)\n}", "reference": "// removeContainer deletes the container from the map of containers being watched.\n// It also stops the periodic usage data collection for the container.", "generated": "This function removes the containers from the list of tasks created by Docker Stats Engine and returns them as an array with all their associated metadata removed or returned for each new batch run on it. The following example shows how to do so using DockerStatsService::removeAllItems(). This is useful when you want your database queries"}
{"id": 2004, "code": "func (engine *DockerStatsEngine) taskContainerMetricsUnsafe(taskArn string) ([]*ecstcs.ContainerMetric, error) {\n\tcontainerMap, taskExists := engine.tasksToContainers[taskArn]\n\tif !taskExists {\n\t\treturn nil, fmt.Errorf(\"Task not found\")\n\t}\n\n\tvar containerMetrics []*ecstcs.ContainerMetric\n\tfor _, container := range containerMap {\n\t\tdockerID := container.containerMetadata.DockerID\n\t\t// Check if the container is terminal. If it is, make sure that it is\n\t\t// cleaned up properly. We might sometimes miss events from docker task\n\t\t// engine and this helps in reconciling the state. The tcs client's\n\t\t// GetInstanceMetrics probe is used as the trigger for this.\n\t\tif engine.stopTrackingContainerUnsafe(container, taskArn) {\n\t\t\tcontinue\n\t\t}\n\n\t\tif !container.statsQueue.enoughDatapointsInBuffer() &&\n\t\t\t!container.statsQueue.resetThresholdElapsed(queueResetThreshold) {\n\t\t\tseelog.Debugf(\"Stats not ready for container %s\", dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Container is not terminal. Get CPU stats set.\n\t\tcpuStatsSet, err := container.statsQueue.GetCPUStatsSet()\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Error getting cpu stats, err: %v, container: %v\", err, dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Get memory stats set.\n\t\tmemoryStatsSet, err := container.statsQueue.GetMemoryStatsSet()\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Error getting memory stats, err: %v, container: %v\", err, dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\tcontainerMetrics = append(containerMetrics, &ecstcs.ContainerMetric{\n\t\t\tCpuStatsSet:    cpuStatsSet,\n\t\t\tMemoryStatsSet: memoryStatsSet,\n\t\t})\n\n\t}\n\n\treturn containerMetrics, nil\n}", "reference": "// taskContainerMetricsUnsafe gets all container metrics for a task arn.", "generated": "This function creates a new Docker statistics queue with an initial number of metrics to be collected by DSCS on each run-in time frame after which all other containers are stopped at their current checkpoint status or removed altogether when they have been started again using disk space available elsewhere within storage devices such AsyncStorage . This allows"}
{"id": 2025, "code": "func NewNamedError(err error) *DefaultNamedError {\n\tif namedErr, ok := err.(NamedError); ok {\n\t\treturn &DefaultNamedError{Err: namedErr.Error(), Name: namedErr.ErrorName()}\n\t}\n\treturn &DefaultNamedError{Err: err.Error()}\n}", "reference": "// NewNamedError creates a NamedError.", "generated": "New Naming Error is a new method that returns an error if the name of the given object has been changed or otherwise not specified in its default state (see below). It can be used to return errors from any other methods defined by this class and may also provide additional information about what was previously provided for those instances when"}
{"id": 2037, "code": "func (r *eventLogReceiver) ReceiveMessage(message string, level seelog.LogLevel, context seelog.LogContextInterface) error {\n\tswitch level {\n\tcase seelog.DebugLvl, seelog.InfoLvl:\n\t\treturn eventLog.Info(eventLogID, message)\n\tcase seelog.WarnLvl:\n\t\treturn eventLog.Warning(eventLogID, message)\n\tcase seelog.ErrorLvl, seelog.CriticalLvl:\n\t\treturn eventLog.Error(eventLogID, message)\n\t}\n\treturn nil\n}", "reference": "// ReceiveMessage receives a log line from seelog and emits it to the Windows event log", "generated": "// EventLogReceived messages are sent to the log handler and received by a logging process when they have been logged in. The logger is responsible for sending an exception if it has not yet encountered any errors or otherwise failed with its response status code of 0x0F00 . // This method returns true on success ,"}
{"id": 2051, "code": "func (m *MockIOUtil) WriteFile(arg0 string, arg1 []byte, arg2 os.FileMode) error {\n\tret := m.ctrl.Call(m, \"WriteFile\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// WriteFile mocks base method", "generated": "This function writes a file to the specified directory and returns an object with all of the information about that particular path or filename in its format set by Mocking IOUtil . The default is nil , but you can specify any other option for your own convenience if desired; see below on how this works here. Note that"}
{"id": 2052, "code": "func (mr *MockIOUtilMockRecorder) WriteFile(arg0, arg1, arg2 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"WriteFile\", reflect.TypeOf((*MockIOUtil)(nil).WriteFile), arg0, arg1, arg2)\n}", "reference": "// WriteFile indicates an expected call of WriteFile", "generated": "This function writes a file to the console using MOCK IOSTOCALLS and returns an error if it does not exist or is unable to write any data at all in its current state before writing this command line argument list of arguments for that operation on disk with no other options available except one -f option which will"}
{"id": 2060, "code": "func NewVolumesResponse(dockerContainer *apicontainer.DockerContainer) []VolumeResponse {\n\tcontainer := dockerContainer.Container\n\tvar resp []VolumeResponse\n\n\tvolumes := container.GetVolumes()\n\n\tfor _, volume := range volumes {\n\t\tvolResp := VolumeResponse{\n\t\t\tDockerName:  volume.Name,\n\t\t\tSource:      volume.Source,\n\t\t\tDestination: volume.Destination,\n\t\t}\n\n\t\tresp = append(resp, volResp)\n\t}\n\treturn resp\n}", "reference": "// NewVolumesResponse creates VolumeResponse for a container", "generated": "New VolumeResponse is a new Docker Container that provides the following functionality to create and manage containers in an environment with minimal configuration (e-mailing or using SSH):"}
{"id": 2062, "code": "func NewPublishMetricsRequest(metadata *MetricsMetadata, taskMetrics []*TaskMetric) *PublishMetricsRequest {\n\treturn &PublishMetricsRequest{\n\t\tMetadata:    metadata,\n\t\tTaskMetrics: taskMetrics,\n\t\tTimestamp:   aws.Time(time.Now()),\n\t}\n}", "reference": "// NewPublishMetricsRequest creates a PublishMetricsRequest object.", "generated": "NewMetaService is a service that provides the Metronet API for publishing metrics to clients and servers using JSON or XML format (e.,g.: http://metronetservice/api). It uses an HTTP request body as its first parameter; it returns true if this response was received by any of these services"}
{"id": 2092, "code": "func (m *MockCNI) AddNetworkList(arg0 *libcni.NetworkConfigList, arg1 *libcni.RuntimeConf) (types.Result, error) {\n\tret := m.ctrl.Call(m, \"AddNetworkList\", arg0, arg1)\n\tret0, _ := ret[0].(types.Result)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// AddNetworkList mocks base method", "generated": "addnetworklist is a wrapper around the NetworkConfigList interface that provides an array of network configuration options for each type and its associated types in order to provide additional information about how networks are configured on their own or with other applications using it as part-of/partitioning data structures such by default. It also allows"}
{"id": 2094, "code": "func (mr *MockCNIMockRecorder) DelNetwork(arg0, arg1 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"DelNetwork\", reflect.TypeOf((*MockCNI)(nil).DelNetwork), arg0, arg1)\n}", "reference": "// DelNetwork indicates an expected call of DelNetwork", "generated": "This method returns a record call with the specified parameters and an optional return value for each parameter in its context. The returned records are then passed to the caller's callback function as well as their associated metadata type if any is provided by Mocks::Dispatch . Parameters:\nparameter Description string Return Value of Record Call Method"}
{"id": 2114, "code": "func (v *StackSwitcher) native() *C.GtkStackSwitcher {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkStackSwitcher(p)\n}", "reference": "// native returns a pointer to the underlying GtkStackSwitcher.", "generated": "// This method is a wrapper around the Gdk.Builder class, which provides an interface for creating and manipulating StackSwitches in Swift.\n // The methods are implemented as follows:\n\n#[inline]\nfn new () -> bool { return true } #[inline][stringify]( func NewInstance () string"}
{"id": 2116, "code": "func (v *ComboBoxText) native() *C.GtkComboBoxText {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkComboBoxText(p)\n}", "reference": "// native returns a pointer to the underlying GtkComboBoxText.", "generated": "This is a wrapper around the GdkCombox library, which provides an interface to create and manipulate text strings in various ways including asynchronously or synchronous mode using gdb . The main purpose of this implementation is for creating new string objects that can be used by other programs with different types of input/output"}
{"id": 2124, "code": "func (v *Variant) GetString() string {\n\tvar len C.gsize\n\tgc := C.g_variant_get_string(v.native(), &len)\n\tdefer C.g_free(C.gpointer(gc))\n\treturn C.GoStringN((*C.char)(gc), (C.int)(len))\n}", "reference": "// GetString returns the string value of the variant.", "generated": "This function returns a Go String object that contains the strings of an array, and is used to store information about arrays in memory for later use by other programs or applications using this library. It also provides access control over how it stores data on disk when no such storage exists at all; see Section 4 below under \"Access"}
{"id": 2143, "code": "func (v *StyleContext) native() *C.GtkStyleContext {\n\tif v == nil || v.Object == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkStyleContext(p)\n}", "reference": "// native returns a pointer to the underlying GtkStyleContext.", "generated": "// This method is used to create a new style context for the current layout, and returns an object that implements this interface with its own methods // provided by Gtk::Builder(). The default implementation of these interfaces will be implemented in gtk_stylecontext .\n// Note that if you want to use any other type"}
{"id": 2148, "code": "func (m *Matrix) InitRotate(radians float64) {\n\tC.cairo_matrix_init_rotate(m.native(), C.double(radians))\n}", "reference": "// InitRotate initializes a matrix with the given rotation", "generated": "Initializes a matrix with the rotation of radians in degrees and returns an array containing all rotations that have been performed on it, including those for which no other vector is available to compute or return true . The returned arrays are then used as vectors by Matrix::InitRotates() , where each element has its own"}
{"id": 2165, "code": "func NewSurface(s uintptr, needsRef bool) *Surface {\n\tsurface := WrapSurface(s)\n\tif needsRef {\n\t\tsurface.reference()\n\t}\n\truntime.SetFinalizer(surface, (*Surface).destroy)\n\treturn surface\n}", "reference": "// NewSurface creates a gotk3 cairo Surface from a pointer to a\n// C cairo_surface_t.  This is primarily designed for use with other\n// gotk3 packages and should be avoided by applications.", "generated": "// Create a new Surface object that implements the interface of the current Surfaces struct and returns it as an instanceof Interface{}, which is used to create interfaces for all existing instances in the system's memory pool (see below), including those created by calling methods on this class or passing them through its constructor method; see"}
{"id": 2167, "code": "func AddFont(fontPath string) {\n\tpath := (*C.uchar)(unsafe.Pointer(C.CString(fontPath)))\n\tC.addFont(path)\n}", "reference": "// AddFont adds the font to the configuration.", "generated": "Add Font is a wrapper around the C++ standard library's font class, which provides support for all of its features and functions (including those provided by default). It can be used to create custom fonts or customize existing ones using any other method on your system that you wish. The following example creates an image with two different"}
{"id": 2168, "code": "func (v *Label) native() *C.GtkLabel {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkLabel(p)\n}", "reference": "// native returns a pointer to the underlying GtkLabel.", "generated": "// This is a wrapper around the GtkFrame class, which implements an interface for creating and manipulating widgets in Objective-F using ObjBuilder .\n // The implementation of this method can be found at http://www/gtkgui_interface#methods.html , or by calling gkwidget::createWidget"}
{"id": 2182, "code": "func (v *ActionGroup) ChangeActionState(actionName string, value *Variant) {\n\tC.g_action_group_change_action_state(v.native(), (*C.gchar)(C.CString(actionName)), value.native())\n}", "reference": "// ChangeActionState is a wrapper around g_action_group_change_action_state", "generated": "Changes the action state of a group to change its name and type in ActionGroup . The changes are applied asynchronously by calling CMakeUpdate() on each new instance of this class or object that is created with it at runtime using an asynchronous callback method called update(). This will cause all actions within these groups not"}
{"id": 2186, "code": "func (v *GLArea) native() *C.GtkGLArea {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkGLArea(p)\n}", "reference": "// native returns a pointer to the underlying GtkGLArea.", "generated": "This function returns a new GL Area object that contains the current location of the GdkContext and its associated objects, as well any references to it by reference or otherwise provided in connection with this call. The returned value is an array containing all locations within which these entities are located; if there were no such entity at present"}
{"id": 2188, "code": "func (v *TreeView) SetSearchEqualSubstringMatch() {\n\tC.gtk_tree_view_set_search_equal_func(\n\t\tv.native(),\n\t\t(C.GtkTreeViewSearchEqualFunc)(unsafe.Pointer(C.substring_match_equal_func)),\n\t\tnil,\n\t\tnil)\n}", "reference": "// SetSearchEqualSubstringMatch sets TreeView to search by substring match.", "generated": "// Sets the search match for a tree view to equal the string matched by the specified filter in the TreeView's native mode.\n // The default is nil if no matching matches are found and false otherwise. If true , returns an error message indicating that all strings were not included as part of this selection."}
{"id": 2202, "code": "func (v *ShortcutsShortcut) native() *C.GtkShortcutsShortcut {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkShortcutsShortcut(p)\n}", "reference": "// native returns a pointer to the underlying GtkShortcutsShortcut.", "generated": "This is a short-cut implementation of the GK Shortcuts interface, which implements both gkshortcuts and ktintext . The main purpose for this extension was to provide an easy way in case you need more than one shortcut on your system or want multiple shortcuts available at once without having to worry about dupl"}
{"id": 2203, "code": "func SimpleActionGroupNew() *SimpleActionGroup {\n\tc := C.g_simple_action_group_new()\n\tif c == nil {\n\t\treturn nil\n\t}\n\treturn wrapSimpleActionGroup(wrapObject(unsafe.Pointer(c)))\n}", "reference": "// SimpleActionGroupNew is a wrapper around g_simple_action_group_new", "generated": "This function creates a new group of actions for the specified action groups, and returns an ActionGroup object that contains all associated Actions in its context (including those from which it was created). The default is to create one Group with each activity defined as follows :\n\n```\n// Create two Groups using `C`. //"}
{"id": 2208, "code": "func (v *Action) GetParameterType() *VariantType {\n\tc := C.g_action_get_parameter_type(v.native())\n\tif c == nil {\n\t\treturn nil\n\t}\n\treturn newVariantType((*C.GVariantType)(c))\n}", "reference": "// GetParameterType is a wrapper around g_action_get_parameter_type", "generated": "This method returns a string representation of the parameter type, which is used to determine whether or not an action should be performed on this object by calling its getParamter function with no parameters specified in return value . The returned paramters are passed as arguments and can either contain any values that have been set for use within Action"}
{"id": 2218, "code": "func (v *Bin) native() *C.GtkBin {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkBin(p)\n}", "reference": "// native returns a pointer to the underlying GtkBin.", "generated": "This function is a wrapper around the GdkContext and provides an interface to create new objects from existing ones, which can be used as arguments for other functions in this context. The following example uses it with two different methods of creating newly created BINs using one method instead; they are both called by calling gdb"}
{"id": 2221, "code": "func (v *CellRendererSpinner) native() *C.GtkCellRendererSpinner {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkCellRendererSpinner(p)\n}", "reference": "// native returns a pointer to the underlying GtkCellRendererSpinner.", "generated": "// This method is used to create a new cell from the GdkContext and return it as an object with no parameters or methods, which can be passed in by calling this method on any of its children if they are not already created using // existing cells provided for that purpose. The returned value will contain all information about"}
{"id": 2247, "code": "func (v *FileChooserDialog) native() *C.GtkFileChooserDialog {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkFileChooserDialog(p)\n}", "reference": "// native returns a pointer to the underlying GtkFileChooserDialog.", "generated": "This is a wrapper for the Gdk.Gobject interface, which provides an object-oriented way to create and manipulate objects in your application's codebase using methods such as Object , FileChoosingOptions . The method returns either true or false if it succeeds; otherwise, error messages are displayed when attempting access through this"}
{"id": 2267, "code": "func (v *Paned) native() *C.GtkPaned {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkPaned(p)\n}", "reference": "// native returns a pointer to the underlying GtkPaned.", "generated": "This function returns a Panized object that is an instance of Panizable . It can be used to create new instances, or it may return the same objects as previously created by calling this method on any existing paned class and returning them in their original form when called with no arguments other than its name. The default value"}
{"id": 2303, "code": "func (v *TreePath) GetIndices() []int {\n\tvar depth C.gint\n\tvar goindices []int\n\tvar ginthelp C.gint\n\tindices := uintptr(unsafe.Pointer(C.gtk_tree_path_get_indices_with_depth(v.native(), &depth)))\n\tsize := unsafe.Sizeof(ginthelp)\n\tfor i := 0; i < int(depth); i++ {\n\t\tgoind := int(*((*C.gint)(unsafe.Pointer(indices))))\n\t\tgoindices = append(goindices, goind)\n\t\tindices += size\n\t}\n\treturn goindices\n}", "reference": "// GetIndices is a wrapper around gtk_tree_path_get_indices_with_depth", "generated": "This function returns a list of indices for the tree path specified by the root node in the current directory and its descendants as well with all branches removed from it at once if any are found to be missing or incomplete nodes within that branch set up correctly without removing them altogether when traversing through those trees again using this method instead"}
{"id": 2313, "code": "func (v *Window) native() *C.GtkWindow {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkWindow(p)\n}", "reference": "// native returns a pointer to the underlying GtkWindow.", "generated": "This is a wrapper around the GdkWindow interface, which provides an API for creating and manipulating window objects in order to create new windows or add/remove existing ones from within it. The implementation of this method takes advantage that there are no special methods required by any other package; instead, all you need to do with"}
{"id": 2348, "code": "func hideConsoleWindowOnWindows() {\n\tpid, err := getCurrentProcessId()\n\tif err != nil {\n\t\t// Ignore errors because:\n\t\t// 1. It is not critical if the console can't be hid.\n\t\t// 2. There is nothing to do when errors happen.\n\t\treturn\n\t}\n\tw, err := getConsoleWindow()\n\tif err != nil {\n\t\t// Ignore errors\n\t\treturn\n\t}\n\t// Get the process ID of the console's creator.\n\tcpid, err := getWindowThreadProcessId(w)\n\tif err != nil {\n\t\t// Ignore errors\n\t\treturn\n\t}\n\tif pid == cpid {\n\t\t// The current process created its own console. Hide this.\n\t\tshowWindowAsync(w, windows.SW_HIDE)\n\t}\n}", "reference": "// hideConsoleWindowOnWindows will hide the console window that is showing when\n// compiling on Windows without specifying the '-ldflags \"-Hwindowsgui\"' flag.", "generated": "/** * Display a window on Windows that hides all processes in it and displays them as an error message for those who are unable or unwilling (or have no way out). */ func main (){ // Create new thread with PID=0x0080c5f8d9e4a6b7fd3"}
{"id": 2349, "code": "func DepthMask(flag bool) {\n\tC.glowDepthMask(gpDepthMask, (C.GLboolean)(boolToInt(flag)))\n}", "reference": "// enable or disable writing into the depth buffer", "generated": "Depth mask is a boolean value that indicates whether the depth of the buffer should be used to determine if an image has been created or not. The default values are false and true . If this option is set to False , then no images will ever have their original depths calculated by using any other method on it than gl_"}
{"id": 2354, "code": "func scaleUpdater() {\n\tfor {\n\t\ts := getscale(0, 0)\n\t\tatomic.StoreUint64(&cachedScale, math.Float64bits(s))\n\t\ttime.Sleep(cacheUpdateWait)\n\t}\n}", "reference": "// run as goroutine. Will keep the desktop scale up to date.\n// This can be removed once the scale change event is implemented in GLFW 3.3", "generated": "// Scale up dater to a specified number of bytes in the cache and store it as an unsigned int for use with time.sleep(1).\n // The default is 1 byte (inclusive), but can be changed by setting this option on each iteration."}
{"id": 2359, "code": "func (b *Board) Draw(boardImage *ebiten.Image) {\n\tboardImage.Fill(frameColor)\n\tfor j := 0; j < b.size; j++ {\n\t\tfor i := 0; i < b.size; i++ {\n\t\t\tv := 0\n\t\t\top := &ebiten.DrawImageOptions{}\n\t\t\tx := i*tileSize + (i+1)*tileMargin\n\t\t\ty := j*tileSize + (j+1)*tileMargin\n\t\t\top.GeoM.Translate(float64(x), float64(y))\n\t\t\tr, g, b, a := colorToScale(tileBackgroundColor(v))\n\t\t\top.ColorM.Scale(r, g, b, a)\n\t\t\tboardImage.DrawImage(tileImage, op)\n\t\t}\n\t}\n\tanimatingTiles := map[*Tile]struct{}{}\n\tnonAnimatingTiles := map[*Tile]struct{}{}\n\tfor t := range b.tiles {\n\t\tif t.IsMoving() {\n\t\t\tanimatingTiles[t] = struct{}{}\n\t\t} else {\n\t\t\tnonAnimatingTiles[t] = struct{}{}\n\t\t}\n\t}\n\tfor t := range nonAnimatingTiles {\n\t\tt.Draw(boardImage)\n\t}\n\tfor t := range animatingTiles {\n\t\tt.Draw(boardImage)\n\t}\n}", "reference": "// Draw draws the board to the given boardImage.", "generated": "// Initializes the board image and draws it to the screen using draw(). // The drawing method is called when an animation has finished or stopped for each frame in time.\n/**\n/* This function creates new animations based on current position of selected tile at start of game loop */ func (a *Board){ var x"}
{"id": 2441, "code": "func (i *Image) makeStale() {\n\ti.basePixels = nil\n\ti.drawTrianglesHistory = nil\n\ti.stale = true\n\n\t// Don't have to call makeStale recursively here.\n\t// Restoring is done after topological sorting is done.\n\t// If an image depends on another stale image, this means that\n\t// the former image can be restored from the latest state of the latter image.\n}", "reference": "// makeStale makes the image stale.", "generated": "/// Creates a new Stalagmite instance for each element in the collection and returns it as its base pixel value if no other elements exist or are not present. /// Returns `nil` when there's nothing left over at all times by default.\n func main([] string{\"image\", \"old\", \""}
{"id": 2498, "code": "func (u *UserInterface) setScreenSize(width, height int, scale float64, fullscreen bool, vsync bool) bool {\n\tif u.width == width && u.height == height && u.scale == scale && u.isFullscreen() == fullscreen && u.vsync == vsync {\n\t\treturn false\n\t}\n\tu.forceSetScreenSize(width, height, scale, fullscreen, vsync)\n\treturn true\n}", "reference": "// setScreenSize must be called from the main thread.", "generated": "// Set screen size to the specified value of UUID and VSCode for each user interface element in a UIKit application.\n // The default is 0xFFFFFFF .\n// This method returns True if all elements are fully-loaded or False otherwise.\n// Note that this implementation does not support setting"}
{"id": 2504, "code": "func (q *commandQueue) Flush() {\n\tif q.err != nil {\n\t\treturn\n\t}\n\n\tes := q.indices\n\tvs := q.vertices\n\tif recordLog() {\n\t\tfmt.Println(\"--\")\n\t}\n\n\ttheGraphicsDriver.Begin()\n\tfor len(q.commands) > 0 {\n\t\tnv := 0\n\t\tne := 0\n\t\tnc := 0\n\t\tfor _, c := range q.commands {\n\t\t\tif c.NumIndices() > graphics.IndicesNum {\n\t\t\t\tpanic(fmt.Sprintf(\"graphicscommand: c.NumIndices() must be <= graphics.IndicesNum but not at Flush: c.NumIndices(): %d, graphics.IndicesNum: %d\", c.NumIndices(), graphics.IndicesNum))\n\t\t\t}\n\t\t\tif ne+c.NumIndices() > graphics.IndicesNum {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tnv += c.NumVertices()\n\t\t\tne += c.NumIndices()\n\t\t\tnc++\n\t\t}\n\t\tif 0 < ne {\n\t\t\ttheGraphicsDriver.SetVertices(vs[:nv], es[:ne])\n\t\t\tes = es[ne:]\n\t\t\tvs = vs[nv:]\n\t\t}\n\t\tindexOffset := 0\n\t\tfor _, c := range q.commands[:nc] {\n\t\t\tif err := c.Exec(indexOffset); err != nil {\n\t\t\t\tq.err = err\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif recordLog() {\n\t\t\t\tfmt.Printf(\"%s\\n\", c)\n\t\t\t}\n\t\t\t// TODO: indexOffset should be reset if the command type is different\n\t\t\t// from the previous one. This fix is needed when another drawing command is\n\t\t\t// introduced than drawTrianglesCommand.\n\t\t\tindexOffset += c.NumIndices()\n\t\t}\n\t\tif 0 < nc {\n\t\t\t// Call glFlush to prevent black flicking (especially on Android (#226) and iOS).\n\t\t\ttheGraphicsDriver.Flush()\n\t\t}\n\t\tq.commands = q.commands[nc:]\n\t}\n\ttheGraphicsDriver.End()\n\tq.commands = nil\n\tq.nvertices = 0\n\tq.nindices = 0\n\tq.tmpNumIndices = 0\n\tq.nextIndex = 0\n}", "reference": "// Flush flushes the command queue.", "generated": "The following code snippet creates a new file called \"drawtriangle-cluster\" in order for it's vertex data to appear as an array of vertices that can then have their indices updated by calling fsync(). The resulting image will look like this with all its edges set up correctly using FNV_FULL"}
{"id": 2534, "code": "func flattenClusterHostGroup(d *schema.ResourceData, obj *types.ClusterHostGroup) error {\n\tvar hostIDs []string\n\tfor _, v := range obj.Host {\n\t\thostIDs = append(hostIDs, v.Value)\n\t}\n\n\treturn structure.SetBatch(d, map[string]interface{}{\n\t\t\"host_system_ids\": hostIDs,\n\t})\n}", "reference": "// flattenClusterHostGroup saves a ClusterHostGroup into the supplied ResourceData.", "generated": "This function creates a cluster of hosts for the specified resource data type and returns an array of all clusters that are connected to it in this way. The returned list is then sorted by number (inclusive) from 0-65535 inclusive using d's default sorting algorithm based on its size as described above. This method can"}
{"id": 2535, "code": "func resourceVSphereComputeClusterHostGroupFlattenID(cluster *object.ClusterComputeResource, name string) (string, error) {\n\tclusterID := cluster.Reference().Value\n\treturn strings.Join([]string{clusterID, name}, \":\"), nil\n}", "reference": "// resourceVSphereComputeClusterHostGroupFlattenID makes an ID for the\n// vsphere_cluster_host_group resource.", "generated": "The Cluster Host Group Flattens the ID of a group that is configured to be used by this VM in order for it not only accesses resources from other hosts but also provides them with an additional identifier and/or hostname as well if necessary or otherwise required on behalf thereof; see below under Configuring Clusters"}
{"id": 2590, "code": "func MoveToFolder(client *govmomi.Client, vm *object.VirtualMachine, relative string) error {\n\tlog.Printf(\"[DEBUG] Moving virtual %q to VM path %q\", vm.InventoryPath, relative)\n\tf, err := folder.VirtualMachineFolderFromObject(client, vm, relative)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn folder.MoveObjectTo(vm.Reference(), f)\n}", "reference": "// MoveToFolder moves a virtual machine to the specified folder.", "generated": "// Moves the Virtual Machine from the current location in the inventory of the client and returns a list containing all items that have been moved since this point (excluding any changes made by clients).\n // This function is called when an item has changed its position or if it was previously placed on the same level as another object within"}
{"id": 2611, "code": "func FromPath(client *govmomi.Client, name string, dc *object.Datacenter) (*object.VirtualApp, error) {\n\tfinder := find.NewFinder(client.Client, false)\n\n\tctx, cancel := context.WithTimeout(context.Background(), provider.DefaultAPITimeout)\n\tdefer cancel()\n\tif dc != nil {\n\t\tfinder.SetDatacenter(dc)\n\t}\n\treturn finder.VirtualApp(ctx, name)\n}", "reference": "// FromPath returns a VirtualApp via its supplied path.", "generated": "This method returns a virtual app that is created by the client and passed to its constructor as an argument in order for it not be terminated with an exception thrown from within this call (see below). The default value of This method will return null if no such instance exists or undefined otherwise. Parameters : Client - Name of application"}
{"id": 2643, "code": "func resourceVSphereComputeClusterApplyCreate(d *schema.ResourceData, meta interface{}) (*object.ClusterComputeResource, error) {\n\tlog.Printf(\"[DEBUG] %s: Processing compute cluster creation\", resourceVSphereComputeClusterIDString(d))\n\tclient, err := resourceVSphereComputeClusterClient(meta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdc, err := datacenterFromID(client, d.Get(\"datacenter_id\").(string))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot locate datacenter: %s\", err)\n\t}\n\n\t// Find the folder based off the path to the datacenter. This is where we\n\t// create the datastore cluster.\n\tf, err := folder.FromPath(client, d.Get(\"folder\").(string), folder.VSphereFolderTypeHost, dc)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot locate folder: %s\", err)\n\t}\n\n\t// Create the cluster. We use an empty config spec so that we can move the\n\t// necessary hosts into the cluster *before* we send the full configuration,\n\t// ensuring that any host-dependent configuration does not break.\n\tcluster, err := clustercomputeresource.Create(f, d.Get(\"name\").(string), types.ClusterConfigSpecEx{})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error creating cluster: %s\", err)\n\t}\n\n\t// Set the ID now before proceeding any further. Any other operation past\n\t// this point is recoverable.\n\td.SetId(cluster.Reference().Value)\n\n\treturn cluster, nil\n}", "reference": "// resourceVSphereComputeClusterApplyCreate processes the creation part of\n// resourceVSphereComputeClusterCreate.", "generated": "The Cluster Compute Clusters (CCC) API provides a simple way of defining and managing clusters in C# using resources from within your application or project codebase as described above. The APIs are designed for developers who want to build applications with high performance computing capabilities but do have limited experience building large scale distributed systems such"}
{"id": 2650, "code": "func resourceVSphereComputeClusterSaveDatacenter(\n\td *schema.ResourceData,\n\tmeta interface{},\n\tcluster *object.ClusterComputeResource,\n) error {\n\tlog.Printf(\"[DEBUG] %s: Saving datacenter\", resourceVSphereComputeClusterIDString(d))\n\tclient, err := resourceVSphereComputeClusterClient(meta)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tp, err := folder.RootPathParticleHost.SplitDatacenter(cluster.InventoryPath)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error parsing datacenter path from cluster: %s\", err)\n\t}\n\n\tdc, err := getDatacenter(client, p)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error fetching datacenter for cluster: %s\", err)\n\t}\n\n\treturn d.Set(\"datacenter_id\", dc.Reference().Value)\n}", "reference": "// resourceVSphereComputeClusterSaveDatacenter saves the datacenter that the\n// cluster is a member of for correctness on imports.", "generated": "// Resource Data is a collection of Datacodes and Clusters that are used to store the data in an array or CSV file (see below). The following example uses this dataset as its base class with no additional dependencies on other datasets; it does not require any special configuration at all!\n// This method returns true"}
{"id": 2677, "code": "func expandClusterDrsConfigInfo(d *schema.ResourceData) *types.ClusterDrsConfigInfo {\n\tobj := &types.ClusterDrsConfigInfo{\n\t\tDefaultVmBehavior:         types.DrsBehavior(d.Get(\"drs_automation_level\").(string)),\n\t\tEnabled:                   structure.GetBool(d, \"drs_enabled\"),\n\t\tEnableVmBehaviorOverrides: structure.GetBool(d, \"drs_enable_vm_overrides\"),\n\t\tVmotionRate:               int32(d.Get(\"drs_migration_threshold\").(int)),\n\t\tOption:                    expandResourceVSphereComputeClusterDrsAdvancedOptions(d),\n\t}\n\n\treturn obj\n}", "reference": "// expandClusterDrsConfigInfo reads certain ResourceData keys and returns a\n// ClusterDrsConfigInfo.", "generated": "// Initializes the cluster DRS configuration information for a given schema and provides an initial list of options to use in configuring it // with additional parameters that can be used later on when creating new clusters or adding features from existing ones.\n func initScheme(d []Schemas[]) (name string ) (*"}
{"id": 2689, "code": "func Rename(pod *object.StoragePod, name string) error {\n\tlog.Printf(\"[DEBUG] Renaming storage pod %q to %s\", pod.InventoryPath, name)\n\tctx, cancel := context.WithTimeout(context.Background(), provider.DefaultAPITimeout)\n\tdefer cancel()\n\ttask, err := pod.Rename(ctx, name)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn task.Wait(ctx)\n}", "reference": "// Rename renames a StoragePod.", "generated": "// Initialize the Pod object and initialize it with a new instance of StoragePods .\n // This is done by calling init().init(); for each item in this list, create an empty array containing all items that have been created since creation. The default value is None , which will be used when creating objects from"}
{"id": 2727, "code": "func createHardDisk(client *govmomi.Client, size int, diskPath string, diskType string, adapterType string, dc string) error {\n\tvar vDiskType string\n\tswitch diskType {\n\tcase \"thin\":\n\t\tvDiskType = \"thin\"\n\tcase \"eagerZeroedThick\":\n\t\tvDiskType = \"eagerZeroedThick\"\n\tcase \"lazy\":\n\t\tvDiskType = \"preallocated\"\n\t}\n\n\tvirtualDiskManager := object.NewVirtualDiskManager(client.Client)\n\tspec := &types.FileBackedVirtualDiskSpec{\n\t\tVirtualDiskSpec: types.VirtualDiskSpec{\n\t\t\tAdapterType: adapterType,\n\t\t\tDiskType:    vDiskType,\n\t\t},\n\t\tCapacityKb: int64(1024 * 1024 * size),\n\t}\n\tdatacenter, err := getDatacenter(client, dc)\n\tif err != nil {\n\t\treturn err\n\t}\n\tlog.Printf(\"[DEBUG] Disk spec: %v\", spec)\n\n\ttask, err := virtualDiskManager.CreateVirtualDisk(context.TODO(), diskPath, datacenter, spec)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = task.WaitForResult(context.TODO(), nil)\n\tif err != nil {\n\t\tlog.Printf(\"[INFO] Failed to create disk:  %v\", err)\n\t\treturn err\n\t}\n\tlog.Printf(\"[INFO] Created disk.\")\n\n\treturn nil\n}", "reference": "// createHardDisk creates a new Hard Disk.", "generated": "// Create a harddisk with the following parameters and an optional storage type for it // in order that we can use as our primary drive (for example, if you have multiple disks).\n#define DEFAULT-DATASETTYPE 0x0020 # define DATASECONDS 1 uint32_"}
{"id": 2729, "code": "func (p *nasDatastoreMountProcessor) processMountOperations() (*object.Datastore, error) {\n\thosts := p.diffNewOld()\n\tif len(hosts) < 1 {\n\t\t// Nothing to do\n\t\treturn p.ds, nil\n\t}\n\t// Validate we are vCenter if we are working with multiple hosts\n\tif len(hosts) > 1 {\n\t\tif err := viapi.ValidateVirtualCenter(p.client); err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"cannot mount on multiple hosts: %s\", err)\n\t\t}\n\t}\n\tfor _, hsID := range hosts {\n\t\tdss, err := hostDatastoreSystemFromHostSystemID(p.client, hsID)\n\t\tif err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\t\tdefer cancel()\n\t\tds, err := dss.CreateNasDatastore(ctx, *p.volSpec)\n\t\tif err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t\tif err := p.validateDatastore(ds); err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"datastore validation error on host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t}\n\treturn p.ds, nil\n}", "reference": "// processMountOperations processes all pending mount operations by diffing old\n// and new and adding any hosts that were not found in old. The datastore is\n// returned, along with any error.", "generated": "This function checks whether the datagram is mounted using a virtual network address or an existing one and returns true for each of those addresses in order that they can be used as mounts by other applications when needed. The return value should not exceed 0 otherwise it will fail because no valid data was found at any given time during this"}
{"id": 2733, "code": "func tagByName(client *tags.RestClient, name, categoryID string) (string, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\ttags, err := client.GetTagByNameForCategory(ctx, name, categoryID)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"could not get tag for name %q: %s\", name, err)\n\t}\n\n\tif len(tags) < 1 {\n\t\treturn \"\", fmt.Errorf(\"tag name %q not found in category ID %q\", name, categoryID)\n\t}\n\tif len(tags) > 1 {\n\t\t// This situation is very similar to the one in tagCategoryByName. The API\n\t\t// docs even say that tags need to be unique in categories, yet\n\t\t// GetTagByNameForCategory still returns multiple results.\n\t\treturn \"\", fmt.Errorf(vSphereTagSearchErrMultiple, name)\n\t}\n\n\treturn tags[0].ID, nil\n}", "reference": "// tagByName locates a tag by it supplied name and category ID. Use\n// tagCategoryByName to get the tag category ID if require the category ID as\n// well.", "generated": "This method creates a new Tag by Name object and assigns it to an existing CategoryId . It then calls Cancel on all of its children with no return value or null if none were returned from this call. If any are encountered during cancellation , they will either fail to create Tags as described above or continue execution without being canceled"}
{"id": 2752, "code": "func expandVMwareDVSConfigSpec(d *schema.ResourceData) *types.VMwareDVSConfigSpec {\n\tobj := &types.VMwareDVSConfigSpec{\n\t\tDVSConfigSpec: types.DVSConfigSpec{\n\t\t\tName:                                d.Get(\"name\").(string),\n\t\t\tConfigVersion:                       d.Get(\"config_version\").(string),\n\t\t\tDefaultPortConfig:                   expandVMwareDVSPortSetting(d),\n\t\t\tHost:                                expandSliceOfDistributedVirtualSwitchHostMemberConfigSpec(d),\n\t\t\tDescription:                         d.Get(\"description\").(string),\n\t\t\tContact:                             expandDVSContactInfo(d),\n\t\t\tSwitchIpAddress:                     d.Get(\"ipv4_address\").(string),\n\t\t\tInfrastructureTrafficResourceConfig: expandSliceOfDvsHostInfrastructureTrafficResource(d),\n\t\t\tNetworkResourceControlVersion:       d.Get(\"network_resource_control_version\").(string),\n\t\t\tUplinkPortPolicy:                    expandDVSNameArrayUplinkPortPolicy(d),\n\t\t},\n\t\tMaxMtu:                      int32(d.Get(\"max_mtu\").(int)),\n\t\tLinkDiscoveryProtocolConfig: expandLinkDiscoveryProtocolConfig(d),\n\t\tIpfixConfig:                 expandVMwareIpfixConfig(d),\n\t\tLacpApiVersion:              d.Get(\"lacp_api_version\").(string),\n\t\tMulticastFilteringMode:      d.Get(\"multicast_filtering_mode\").(string),\n\t}\n\treturn obj\n}", "reference": "// expandVMwareDVSConfigSpec reads certain ResourceData keys and\n// returns a VMwareDVSConfigSpec.", "generated": "// This module provides a way to specify the number of virtual machines that should be allocated in an application, and how many are needed for each VM (in bytes).\ntype vmwndvmwntm = struct vmxalloc; // The default is 1 if there's no more than one instance per host or"}
{"id": 2765, "code": "func expandVirtualMachineResourceAllocation(d *schema.ResourceData, key string) *types.ResourceAllocationInfo {\n\tshareLevelKey := fmt.Sprintf(\"%s_share_level\", key)\n\tshareCountKey := fmt.Sprintf(\"%s_share_count\", key)\n\tlimitKey := fmt.Sprintf(\"%s_limit\", key)\n\treservationKey := fmt.Sprintf(\"%s_reservation\", key)\n\n\tobj := &types.ResourceAllocationInfo{\n\t\tLimit:       structure.GetInt64PtrEmptyZero(d, limitKey),\n\t\tReservation: structure.GetInt64PtrEmptyZero(d, reservationKey),\n\t}\n\tshares := &types.SharesInfo{\n\t\tLevel:  types.SharesLevel(d.Get(shareLevelKey).(string)),\n\t\tShares: int32(d.Get(shareCountKey).(int)),\n\t}\n\tobj.Shares = shares\n\treturn obj\n}", "reference": "// expandVirtualMachineResourceAllocation reads the VM resource allocation\n// resource data keys for the type supplied by key and returns an appropriate\n// types.ResourceAllocationInfo reference.", "generated": "The virtual machine resource allocation function expands the allocated resources to a list of shared objects and returns an object with allocating them in order from most recently created (or at least previously-created) instances. The returned value is then used as a reference for subsequent allocations by calling allocate() . This method also allows you access control"}
{"id": 2781, "code": "func expandClusterDasVMConfigInfo(\n\td *schema.ResourceData,\n\tmeta interface{},\n\tvm *object.VirtualMachine,\n) (*types.ClusterDasVmConfigInfo, error) {\n\tclient, err := resourceVSphereHAVMOverrideClient(meta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tversion := viapi.ParseVersionFromClient(client)\n\n\tobj := &types.ClusterDasVmConfigInfo{\n\t\tDasSettings: expandClusterDasVMSettings(d, version),\n\t\tKey:         vm.Reference(),\n\t}\n\n\t// Expand ha_vm_monitoring_use_cluster_defaults here as it's not included in\n\t// the base vsphere_compute_cluster resource.\n\tobj.DasSettings.VmToolsMonitoringSettings.ClusterSettings = structure.GetBool(d, \"ha_vm_monitoring_use_cluster_defaults\")\n\n\treturn obj, nil\n}", "reference": "// expandClusterDasVMConfigInfo reads certain ResourceData keys and returns a\n// ClusterDasVmConfigInfo.", "generated": "This module provides a new HAProxy configuration for VMs that uses cluster default settings to monitor and manage their virtual machines (vms). The following sections describe how this is done using an existing Hadoop VM with no additional features or functionality added by adding support for other types of hw-based configurations such at runtime"}
{"id": 2819, "code": "func expandVmwareUplinkPortTeamingPolicy(d *schema.ResourceData) *types.VmwareUplinkPortTeamingPolicy {\n\tobj := &types.VmwareUplinkPortTeamingPolicy{\n\t\tPolicy:          structure.GetStringPolicy(d, \"teaming_policy\"),\n\t\tNotifySwitches:  structure.GetBoolPolicy(d, \"notify_switches\"),\n\t\tRollingOrder:    structure.GetBoolPolicyReverse(d, \"failback\"),\n\t\tFailureCriteria: expandDVSFailureCriteria(d),\n\t\tUplinkPortOrder: expandVMwareUplinkPortOrderPolicy(d),\n\t}\n\n\tif structure.AllFieldsEmpty(obj) {\n\t\treturn nil\n\t}\n\treturn obj\n}", "reference": "// expandVmwareUplinkPortTeamingPolicy reads certain ResourceData keys and\n// returns a VmwareUplinkPortTeamingPolicy.", "generated": "// Expand the port to which this protocol is sent and send it back if there are no ports available for that type of transport in a given context.\n // This allows you access to all types (including UDP/IPv4).\ntype VMWareUportTransports struct {} func main() string { return"}
{"id": 2824, "code": "func flattenVMwareUplinkLacpPolicy(d *schema.ResourceData, obj *types.VMwareUplinkLacpPolicy) error {\n\tif obj == nil {\n\t\treturn nil\n\t}\n\n\tstructure.SetBoolPolicy(d, \"lacp_enabled\", obj.Enable)\n\tstructure.SetStringPolicy(d, \"lacp_mode\", obj.Mode)\n\treturn nil\n}", "reference": "// flattenVMwareUplinkLacpPolicy reads various fields from a\n// VMwareUplinkLacpPolicy into the passed in ResourceData.", "generated": "// This policy is used to create a new VMwareUppolicy for the current user and allows it access to all of its resources in one go (see below).\n // The default value is enabled if no policies are specified or disabled otherwise. If an exception occurs while this Policy exists, then any additional settings that"}
{"id": 2841, "code": "func (r *CdromSubresource) ValidateDiff() error {\n\tlog.Printf(\"[DEBUG] %s: Beginning CDROM configuration validation\", r)\n\tdsID := r.Get(\"datastore_id\").(string)\n\tpath := r.Get(\"path\").(string)\n\tclientDevice := r.Get(\"client_device\").(bool)\n\tswitch {\n\tcase clientDevice && (dsID != \"\" || path != \"\"):\n\t\treturn fmt.Errorf(\"Cannot have both client_device parameter and ISO file parameters (datastore_id, path) set\")\n\tcase !clientDevice && (dsID == \"\" || path == \"\"):\n\t\treturn fmt.Errorf(\"Either client_device or datastore_id and path must be set\")\n\t}\n\tlog.Printf(\"[DEBUG] %s: Config validation complete\", r)\n\treturn nil\n}", "reference": "// ValidateDiff performs any complex validation of an individual\n// cdrom sub-resource that can't be done in schema alone.", "generated": "This function checks if the specified CDSD is valid for a given directory in an existing DLL that has been created by another process running on it's own system with no other dependencies installed at all to ensure compatibility between processes within its scope. The check can also return true otherwise false . If this fails, then any"}
{"id": 2848, "code": "func verifyVAppCdromIso(d *schema.ResourceData, device *types.VirtualCdrom, l object.VirtualDeviceList, c *govmomi.Client) (bool, error) {\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: Checking if CDROM is using a vApp ISO\")\n\t// If the CDROM is using VirtualCdromIsoBackingInfo and matches the ISO\n\t// naming pattern, it has been used as a vApp CDROM, and we can move on to\n\t// checking if the parent VM supports ISO transport.\n\tif backing, ok := device.Backing.(*types.VirtualCdromIsoBackingInfo); ok {\n\t\tdp := &object.DatastorePath{}\n\t\tif ok := dp.FromString(backing.FileName); !ok {\n\t\t\t// If the ISO path can not be read, we can't tell if a vApp ISO is\n\t\t\t// connected.\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: Cannot read ISO path, cannot determine if CDROM is used for vApp\")\n\t\t\treturn false, nil\n\t\t}\n\t\t// The pattern used for vApp ISO naming is\n\t\t// \"<vmname>/_ovfenv-<vmname>.iso\"\n\t\tre := regexp.MustCompile(\".*/_ovfenv-.*.iso\")\n\t\tif !re.MatchString(dp.Path) {\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: ISO is name does not match vApp ISO naming pattern (<vmname>/_ovfenv-<vmname>.iso): %s\", dp.Path)\n\t\t\treturn false, nil\n\t\t}\n\t} else {\n\t\t// vApp CDROMs must be backed by an ISO.\n\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: CDROM is not backed by an ISO\")\n\t\treturn false, nil\n\t}\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: CDROM has a vApp ISO inserted\")\n\t// Set the vApp transport methods\n\ttm := d.Get(\"vapp_transport\").([]interface{})\n\tfor _, t := range tm {\n\t\tif t.(string) == \"iso\" {\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: vApp ISO transport is supported\")\n\t\t\treturn true, nil\n\t\t}\n\t}\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: vApp ISO transport is not required\")\n\treturn false, nil\n}", "reference": "// verifyVAppCdromIso takes VirtualCdrom and determines if it is needed for\n// vApp ISO transport. It does this by first checking if it has an ISO inserted\n// that matches the vApp ISO naming pattern. If it does, then the next step is\n// to see if vApp ISO transport is supported on the VM. If both of those\n// conditions are met, then the CDROM is considered in use for vApp transport.", "generated": "The VDVM provides support of virtualization protocols that are compatible with Windows XP/7 operating systems including Microsoft Exchange Server 2003 SP1 or later versions; however, there may be some limitations in certain implementations which require additional hardware components such at least one USB port per host machine when running from disk space rather than physical memory"}
{"id": 2853, "code": "func soapFault(err error) (*soap.Fault, bool) {\n\tif soap.IsSoapFault(err) {\n\t\treturn soap.ToSoapFault(err), true\n\t}\n\treturn nil, false\n}", "reference": "// soapFault extracts the SOAP fault from an error fault, if it exists. Check\n// the returned boolean value to see if you have a SoapFault.", "generated": "// This function is called when a new instance of the class has been created and it was not initialized with an initializer or initialization method that returns None .\n // The constructor will be invoked once every time this call occurs in order to initialize all instances before calling any methods on them (see below). It should return no"}
{"id": 2860, "code": "func isConcurrentAccessError(err error) bool {\n\t// ConcurrentAccess comes from a task more than it usually does from a direct\n\t// SOAP call, so we need to handle both here.\n\tvar f types.AnyType\n\tvar ok bool\n\tf, ok = vimSoapFault(err)\n\tif !ok {\n\t\tf, ok = taskFault(err)\n\t}\n\tif ok {\n\t\tswitch f.(type) {\n\t\tcase types.ConcurrentAccess, *types.ConcurrentAccess:\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "reference": "// isConcurrentAccessError checks an error to see if it's of the\n// ConcurrentAccess type.", "generated": "/** Returns the current state of an access request if no connection has been established with this context or nil otherwise. */\npackage main import ( \"fmt\" \"log\" ) func () { // Initialize logging log := new Log()\n// Create and initialize logger for each session in which there are currently logged sessions"}
{"id": 2882, "code": "func validateCloneSnapshots(props *mo.VirtualMachine) error {\n\tif props.Snapshot == nil {\n\t\treturn fmt.Errorf(\"virtual machine or template %s must have a snapshot to be used as a linked clone\", props.Config.Uuid)\n\t}\n\t// Root snapshot list can only have a singular element\n\tif len(props.Snapshot.RootSnapshotList) != 1 {\n\t\treturn fmt.Errorf(\"virtual machine or template %s must have exactly one root snapshot (has: %d)\", props.Config.Uuid, len(props.Snapshot.RootSnapshotList))\n\t}\n\t// Check to make sure the root snapshot has no children\n\tif len(props.Snapshot.RootSnapshotList[0].ChildSnapshotList) > 0 {\n\t\treturn fmt.Errorf(\"virtual machine or template %s's root snapshot must not have children\", props.Config.Uuid)\n\t}\n\t// Current snapshot must match root snapshot (this should be the case anyway)\n\tif props.Snapshot.CurrentSnapshot.Value != props.Snapshot.RootSnapshotList[0].Snapshot.Value {\n\t\treturn fmt.Errorf(\"virtual machine or template %s's current snapshot must match root snapshot\", props.Config.Uuid)\n\t}\n\treturn nil\n}", "reference": "// validateCloneSnapshots checks a VM to make sure it has a single snapshot\n// with no children, to make sure there is no ambiguity when selecting a\n// snapshot for linked clones.", "generated": "This method checks for all of its child snapshots in the virtual machines and returns an empty string if it does so without any parenthesis at runtime. It also provides some helper methods that allow you access from within your own VM by using this wrapper function instead; see below on how these are implemented here. The following example is"}
{"id": 2893, "code": "func dvsProperties(dvs *object.VmwareDistributedVirtualSwitch) (*mo.VmwareDistributedVirtualSwitch, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\tvar props mo.VmwareDistributedVirtualSwitch\n\tif err := dvs.Properties(ctx, dvs.Reference(), nil, &props); err != nil {\n\t\treturn nil, err\n\t}\n\treturn &props, nil\n}", "reference": "// dvsProperties is a convenience method that wraps fetching the DVS MO from\n// its higher-level object.", "generated": "// AVAILABLE TO"}
{"id": 2907, "code": "func (r *Subresource) Hash() int {\n\thf := schema.HashResource(&schema.Resource{Schema: r.schema})\n\treturn hf(r.data)\n}", "reference": "// Hash calculates a set hash for the current data. If you want a hash for\n// error reporting a device address, it's probably a good idea to run this at\n// the beginning of a run as any set calls will change the value this\n// ultimately calculates.", "generated": "This method returns the hash of a subresource that contains an array of hashes, and optionally one or more fields for each field in its data structure to be returned by this function. The return value is passed as nil if no other parameters are provided; otherwise, it will contain all values from any given resource type except those"}
{"id": 2919, "code": "func createSCSIController(l *object.VirtualDeviceList, ct string, st string) ([]types.BaseVirtualDeviceConfigSpec, error) {\n\tnc, err := l.CreateSCSIController(ct)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnc.(types.BaseVirtualSCSIController).GetVirtualSCSIController().SharedBus = types.VirtualSCSISharing(st)\n\tcspec, err := object.VirtualDeviceList{nc}.ConfigSpec(types.VirtualDeviceConfigSpecOperationAdd)\n\t*l = applyDeviceChange(*l, cspec)\n\treturn cspec, err\n}", "reference": "// createSCSIController creates a new SCSI controller of the specified type and\n// sharing mode.", "generated": "// Create a virtual device for the specified type and its associated configuration settings in an SCSI controller interface to be used by this application when creating new devices from scratch using scsi-controller interfaces or other methods of initialization/deinitialization with no additional parameters required // This method is called on each invocation after initializing all"}
{"id": 2933, "code": "func resourceVSphereComputeClusterVMDependencyRuleFetchObjects(\n\tmeta interface{},\n\tclusterID string,\n\tkey int32,\n) (*object.ClusterComputeResource, int32, error) {\n\tclient, err := resourceVSphereComputeClusterVMDependencyRuleClient(meta)\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\n\tcluster, err := clustercomputeresource.FromID(client, clusterID)\n\tif err != nil {\n\t\treturn nil, 0, fmt.Errorf(\"cannot locate cluster: %s\", err)\n\t}\n\n\treturn cluster, key, nil\n}", "reference": "// resourceVSphereComputeClusterVMDependencyRuleFetchObjects fetches the \"objects\"\n// for a cluster rule. This is currently just the cluster object as the rule\n// key a static value and a pass-through - this is to keep its workflow\n// consistent with other cluster-dependent resources that derive from\n// ArrayUpdateSpec that have managed object as keys, such as VM and host\n// overrides.", "generated": "The resources vCenter Server Compute Cluster VMDependent Rule Fuzzy Clusters are used to compute the dependency rule for a given client and server in an application that is running on VMware ESXi host machines (VMware Hyper-viseen). The rules can be applied using any of the following methods or functions"}
{"id": 2938, "code": "func resourceVSphereDatastoreClusterReadCustomAttributes(d *schema.ResourceData, meta interface{}, pod *object.StoragePod) error {\n\tclient := meta.(*VSphereClient).vimClient\n\t// Read custom attributes\n\tif customattribute.IsSupported(client) {\n\t\tlog.Printf(\"[DEBUG] %s: Reading custom attributes\", resourceVSphereDatastoreClusterIDString(d))\n\t\tprops, err := storagepod.Properties(pod)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcustomattribute.ReadFromResource(client, props.Entity(), d)\n\t} else {\n\t\tlog.Printf(\"[DEBUG] %s: Custom attributes unsupported on this connection, skipping\", resourceVSphereDatastoreClusterIDString(d))\n\t}\n\n\treturn nil\n}", "reference": "// resourceVSphereDatastoreClusterReadCustomAttributes reads the custom\n// attributes for vsphere_datastore_cluster.", "generated": "The VCSD Datasource provides a datatype for the data structure of an object that is used to store and retrieve information about its state in memory or disk space (or any other form), as well at runtime by calling vcsd_datacenter() . The default value is null if no such"}
{"id": 2958, "code": "func flattenStorageDrsOptionSpec(d *schema.ResourceData, opts []types.BaseOptionValue) error {\n\tm := make(map[string]interface{})\n\tfor _, opt := range opts {\n\t\tm[opt.GetOptionValue().Key] = opt.GetOptionValue().Value\n\t}\n\n\treturn d.Set(\"sdrs_advanced_options\", m)\n}", "reference": "// flattenStorageDrsOptionSpec saves a StorageDrsOptionSpec into the supplied\n// ResourceData.", "generated": "This function creates a new storage option spec for the schema and returns an optional value if it is not present in the options list or nil otherwise. The default implementation of this method will return true when no additional information has been provided to create that feature (i.,e.: \"no extra data\" ). This can be useful"}
{"id": 2965, "code": "func diskApplyOperationDelete(\n\tindex int,\n\toldData map[string]interface{},\n\tnewDataSet []interface{},\n\tc *govmomi.Client,\n\td *schema.ResourceData,\n\tl *object.VirtualDeviceList,\n\tspec *[]types.BaseVirtualDeviceConfigSpec,\n) error {\n\tdidx := -1\n\tfor ni, ne := range newDataSet {\n\t\tnewData := ne.(map[string]interface{})\n\t\tvar name string\n\t\tvar err error\n\t\tif name, err = diskLabelOrName(newData); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif (name == diskDeletedName || name == diskDetachedName) && oldData[\"uuid\"] == newData[\"uuid\"] {\n\t\t\tdidx = ni\n\t\t\tbreak\n\t\t}\n\t}\n\tif didx < 0 {\n\t\t// Deleted entry not found\n\t\treturn nil\n\t}\n\tr := NewDiskSubresource(c, d, oldData, nil, index)\n\tdspec, err := r.Delete(*l)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"%s: %s\", r.Addr(), err)\n\t}\n\t*l = applyDeviceChange(*l, dspec)\n\t*spec = append(*spec, dspec...)\n\treturn nil\n}", "reference": "// diskApplyOperationDelete is an inner-loop helper for disk deletion\n// operations.", "generated": "diskApply Operation Delete is a method that deletes the specified data set from an existing virtual device list and returns it to its caller for use in future operations on other devices or applications using this interface. It can be used as part of any operation performed by DiskScanner with no additional parameters required except those provided explicitly when"}
{"id": 2974, "code": "func (r *DiskSubresource) Delete(l object.VirtualDeviceList) ([]types.BaseVirtualDeviceConfigSpec, error) {\n\tlog.Printf(\"[DEBUG] %s: Beginning delete\", r)\n\tdisk, err := r.findVirtualDisk(l, false)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot find disk device: %s\", err)\n\t}\n\tdeleteSpec, err := object.VirtualDeviceList{disk}.ConfigSpec(types.VirtualDeviceConfigSpecOperationRemove)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(deleteSpec) != 1 {\n\t\treturn nil, fmt.Errorf(\"incorrect number of config spec items returned - expected 1, got %d\", len(deleteSpec))\n\t}\n\tif r.Get(\"keep_on_remove\").(bool) || r.Get(\"attach\").(bool) {\n\t\t// Clear file operation so that the disk is kept on remove.\n\t\tdeleteSpec[0].GetVirtualDeviceConfigSpec().FileOperation = \"\"\n\t}\n\tlog.Printf(\"[DEBUG] %s: Device config operations from update: %s\", r, DeviceChangeString(deleteSpec))\n\tlog.Printf(\"[DEBUG] %s: Delete completed\", r)\n\treturn deleteSpec, nil\n}", "reference": "// Delete deletes a vsphere_virtual_machine disk sub-resource.", "generated": "This function deletes a virtual device and returns an empty list if it exists or not. If no Virtualdevice was found in this process, then all devices are deleted with the exception for those created by deleting Spec objects as well; otherwise they will be removed using append() . The return value should contain only one argument to"}
{"id": 2979, "code": "func (r *DiskSubresource) String() string {\n\tp := diskPathOrName(r.data)\n\tif p == \"\" {\n\t\tp = \"<unknown>\"\n\t}\n\treturn fmt.Sprintf(\"%s (%s)\", r.Subresource.String(), p)\n}", "reference": "// String prints out the disk sub-resource's information including the ID at\n// time of instantiation, the path of the disk, and the current device\n// key and address.", "generated": "// This method returns a new instance of the DiskSubResource class, which is used to create and store subdirectories for each partition in the filesystem hierarchy that contains all files on this system's hard drive or other physical device with no partitions available at any time during boot. The name parameter specifies how many disks are created"}
{"id": 2993, "code": "func hostNetworkSystemFromHostSystem(hs *object.HostSystem) (*object.HostNetworkSystem, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\treturn hs.ConfigManager().NetworkSystem(ctx)\n}", "reference": "// hostNetworkSystemFromHostSystem locates a HostNetworkSystem from a specified\n// HostSystem.", "generated": "This method returns a network system from the specified HostSystem object that is connected to the server and can be used as an interface for networking purposes (see below). The name of this class will depend on whether it has been created by another application or not. This implementation uses two methods in order; one calls connectToServer"}
{"id": 3011, "code": "func (b *EnvironmentBrowser) QueryConfigOptionDescriptor(ctx context.Context) ([]types.VirtualMachineConfigOptionDescriptor, error) {\n\treq := types.QueryConfigOptionDescriptor{\n\t\tThis: b.Reference(),\n\t}\n\tres, err := methods.QueryConfigOptionDescriptor(ctx, b.Client(), &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn res.Returnval, nil\n}", "reference": "// QueryConfigOptionDescriptor returns a list the list of ConfigOption keys\n// available on the environment that this browser targets. The keys can be used\n// as query options for DefaultDevices and other functions, facilitating the\n// specification of results specific to a certain VM version.", "generated": "// This query option descriptor is a virtual machine configurable by the user and can be used to specify an optional parameter for querying options in Virtual Machine Config.\n // The default value of this method will return true if no parameters are specified or false otherwise. If any paramter returns null , it defaults back-to"}
{"id": 3033, "code": "func lookupAddrs(svc *compute.Service, project, zone, tag string) ([]string, error) {\n\tvar addrs []string\n\tf := func(page *compute.InstanceList) error {\n\t\tfor _, v := range page.Items {\n\t\t\tif len(v.NetworkInterfaces) == 0 || v.NetworkInterfaces[0].NetworkIP == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor _, t := range v.Tags.Items {\n\t\t\t\tif t == tag {\n\t\t\t\t\taddrs = append(addrs, v.NetworkInterfaces[0].NetworkIP)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tcall := svc.Instances.List(project, zone)\n\tif err := call.Pages(oauth2.NoContext, f); err != nil {\n\t\treturn nil, err\n\t}\n\treturn addrs, nil\n}", "reference": "// lookupAddrs retrieves the private ip addresses of all instances in a given\n// project and zone which have a matching tag value.", "generated": "The following example creates a new instance of the Compute class and adds an additional layer to its interface by adding tags for each element in it that is not already present on this list or has been added previously as part \"in\" another context with no other information about them available at all; if there are any changes made"}
{"id": 3055, "code": "func virtualMachinesForTag(ctx context.Context, client *vSphereClient, id string) ([]*object.VirtualMachine, error) {\n\tlogger.Printf(\"[DEBUG] Locating all virtual machines under tag ID %q\", id)\n\n\tvar vms []*object.VirtualMachine\n\n\tobjs, err := client.TagsClient.ListAttachedObjects(ctx, id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor i, obj := range objs {\n\t\tswitch {\n\t\tcase obj.Type == nil || obj.ID == nil:\n\t\t\tlogger.Printf(\"[WARN] Discovered object at index %d has either no ID or type\", i)\n\t\t\tcontinue\n\t\tcase *obj.Type != \"VirtualMachine\":\n\t\t\tlogger.Printf(\"[DEBUG] Discovered object ID %q is not a virutal machine\", *obj.ID)\n\t\t\tcontinue\n\t\t}\n\t\tvm, err := virtualMachineFromMOID(ctx, client.VimClient, *obj.ID)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error locating virtual machine with ID %q: %s\", *obj.ID, err)\n\t\t}\n\t\tvms = append(vms, vm)\n\t}\n\n\tlogger.Printf(\"[DEBUG] Discovered virtual machines: %s\", virtualMachineNames(vms))\n\treturn vms, nil\n}", "reference": "// virtualMachinesForTag discovers all of the virtual machines that match a\n// specific tag ID and returns their higher level helper objects.", "generated": "virtual Machines for Tag and Virtual Machine are used to create new objects that can be attached by the VM's hostname in order of priority from most recently created tags into newest ones using an interface called VVMName . The name must match any given identifier on both hosts as well if it exists within this namespace; otherwise there"}
{"id": 3071, "code": "func (ctx *Context) RemoteAddr() string {\n\taddr := ctx.Req.Header.Get(\"X-Real-IP\")\n\tif len(addr) == 0 {\n\t\taddr = ctx.Req.Header.Get(\"X-Forwarded-For\")\n\t\tif addr == \"\" {\n\t\t\taddr = ctx.Req.RemoteAddr\n\t\t\tif i := strings.LastIndex(addr, \":\"); i > -1 {\n\t\t\t\taddr = addr[:i]\n\t\t\t}\n\t\t}\n\t}\n\treturn addr\n}", "reference": "// RemoteAddr returns more real IP address.", "generated": "// This function returns a remote address that is the same as an existing X server's IP and can be used to connect from any other client or host in your network using this method.\n // The name of the localhost parameter must match its value if it exists; otherwise, use `remoteaddrs` instead."}
{"id": 3085, "code": "func (ctx *Context) GetCookie(name string) string {\n\tcookie, err := ctx.Req.Cookie(name)\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\tval, _ := url.QueryUnescape(cookie.Value)\n\treturn val\n}", "reference": "// GetCookie returns given cookie value from request header.", "generated": "// Returns a cookie that contains the name of the user specified in CookieName and returns an error if it is not found or returned by COOKIE_ERRORS() .\n // This method can be used to check for errors when returning from cookies using HTTP/1.0 with no parameters provided as well as return"}
{"id": 3090, "code": "func (ctx *Context) GetSecureCookie(key string) (string, bool) {\n\treturn ctx.GetSuperSecureCookie(defaultCookieSecret, key)\n}", "reference": "// GetSecureCookie returns given cookie value from request header with default secret string.", "generated": "This method returns a Secure Cookie object that contains the keys and values of an encrypted session cookie for use in secure-caching applications or other contexts where it is needed to store data on behalf from which users can access their private information without having to decrypt them manually by using AES encryption algorithms such as RSA Key Derivation Function"}
{"id": 3092, "code": "func (ctx *Context) GetSuperSecureCookie(secret, name string) (string, bool) {\n\tval := ctx.GetCookie(name)\n\tif val == \"\" {\n\t\treturn \"\", false\n\t}\n\n\ttext, err := hex.DecodeString(val)\n\tif err != nil {\n\t\treturn \"\", false\n\t}\n\n\tkey := pbkdf2.Key([]byte(secret), []byte(secret), 1000, 16, sha256.New)\n\ttext, err = com.AESGCMDecrypt(key, text)\n\treturn string(text), err == nil\n}", "reference": "// GetSuperSecureCookie returns given cookie value from request header with secret string.", "generated": "// This function is used to decrypt the key and return it as a byte array of bytes in order for us // to use AES-CBC encryption on our keys if we have one or more cipher suites available at this time. The following code uses an implementation that supports both CBC/SHA1 decryption with no additional steps"}
{"id": 3127, "code": "func (app *App) ReloadConfig() error {\n\tapp.Lock()\n\tdefer app.Unlock()\n\n\tvar err error\n\tif err = app.configure(); err != nil {\n\t\treturn err\n\t}\n\n\truntime.GOMAXPROCS(app.Config.Common.MaxCPU)\n\n\tapp.Cache.SetMaxSize(app.Config.Cache.MaxSize)\n\tapp.Cache.SetWriteStrategy(app.Config.Cache.WriteStrategy)\n\tapp.Cache.SetTagsEnabled(app.Config.Tags.Enabled)\n\n\tif app.Persister != nil {\n\t\tapp.Persister.Stop()\n\t\tapp.Persister = nil\n\t}\n\n\tif app.Tags != nil {\n\t\tapp.Tags.Stop()\n\t\tapp.Tags = nil\n\t}\n\n\tapp.startPersister()\n\n\tif app.Collector != nil {\n\t\tapp.Collector.Stop()\n\t\tapp.Collector = nil\n\t}\n\n\tapp.Collector = NewCollector(app)\n\n\treturn nil\n}", "reference": "// ReloadConfig reloads some settings from config", "generated": "// Initializes a new App object and returns the current state of the application, including all pending changes to it // in order for this method callbacks from previous methods into // future calls to collectors to be executed on subsequent invocations.\nMethods:"}
{"id": 3133, "code": "func (d *Duration) UnmarshalText(text []byte) error {\n\tvar err error\n\td.Duration, err = time.ParseDuration(string(text))\n\treturn err\n}", "reference": "// UnmarshalText from TOML", "generated": "This method is used to unify the text of a string into an array and return it as if by using its length or len() methods on each element in that list . The returned value will be passed along to all subsequent calls with this function which returns nil for any errors encountered during execution when attempting such operations without returning"}
{"id": 3147, "code": "func (p *Points) Eq(other *Points) bool {\n\tif other == nil {\n\t\treturn false\n\t}\n\tif p.Metric != other.Metric {\n\t\treturn false\n\t}\n\tif p.Data == nil && other.Data == nil {\n\t\treturn true\n\t}\n\tif (p.Data == nil || other.Data == nil) && (p.Data != nil || other.Data != nil) {\n\t\treturn false\n\t}\n\tif len(p.Data) != len(other.Data) {\n\t\treturn false\n\t}\n\tfor i := 0; i < len(p.Data); i++ {\n\t\tif p.Data[i].Value != other.Data[i].Value {\n\t\t\treturn false\n\t\t}\n\t\tif p.Data[i].Timestamp != other.Data[i].Timestamp {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}", "reference": "// Eq points check", "generated": "// Returns the number of points in a given field, if any are missing or not present at all and returns an error when no fields have been filled out for that value.\n // This function is used to check whether there are more than one Field with this type available on each line before returning it as null . func"}
{"id": 3152, "code": "func (app *App) Restore(storeFunc func(*points.Points), path string, rps int) {\n\tif rps > 0 {\n\t\tticker := persister.NewThrottleTicker(rps)\n\t\tdefer ticker.Stop()\n\n\t\tthrottledStoreFunc := func(p *points.Points) {\n\t\t\tfor i := 0; i < len(p.Data); i++ {\n\t\t\t\t<-ticker.C\n\t\t\t}\n\t\t\tstoreFunc(p)\n\t\t}\n\n\t\tapp.RestoreFromDir(path, throttledStoreFunc)\n\t} else {\n\t\tapp.RestoreFromDir(path, storeFunc)\n\t}\n}", "reference": "// Restore from dump.path", "generated": "This method restores the state of a stored procedure from its previous execution to an earlier one that is not affected by this change. The restore process will be called once every 10 seconds for each step in the restoration cycle and then resumed when no further steps are needed or if any other changes have been made since it was last executed"}
{"id": 3183, "code": "func (client *Client) CreateComment(handle, message string) (*Comment, error) {\n\tvar out reqComment\n\tcomment := Comment{Message: String(message)}\n\tif len(handle) > 0 {\n\t\tcomment.Handle = String(handle)\n\t}\n\tif err := client.doJsonRequest(\"POST\", \"/v1/comments\", &comment, &out); err != nil {\n\t\treturn nil, err\n\t}\n\treturn out.Comment, nil\n}", "reference": "// CreateComment adds a new comment to the system.", "generated": "// Creates a new comment in the log file and returns it as an object with no parameters or return values for any of its attributes.\n // This method is called by creating comments from existing logs to create them into one-line statements that are not executed when they're finished being created.\n func main() {}"}
{"id": 3185, "code": "func (client *Client) EditComment(id int, handle, message string) error {\n\tcomment := Comment{Message: String(message)}\n\tif len(handle) > 0 {\n\t\tcomment.Handle = String(handle)\n\t}\n\treturn client.doJsonRequest(\"PUT\", fmt.Sprintf(\"/v1/comments/%d\", id),\n\t\t&comment, nil)\n}", "reference": "// EditComment changes the message and possibly handle of a particular comment.", "generated": "// Create a new comment with the following content and return it as an object of type Error :\n// Example 1 // Creating a New Comment in JSON format using `json` method to create comments from json data types for each input field name or description fields that are not specified by default; use this function instead if you"}
{"id": 3254, "code": "func (c *Check) GetTimestampOk() (string, bool) {\n\tif c == nil || c.Timestamp == nil {\n\t\treturn \"\", false\n\t}\n\treturn *c.Timestamp, true\n}", "reference": "// GetTimestampOk returns a tuple with the Timestamp field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Check if the timestamp is correct and return it to check for errors in a future call.\n // This function returns an error message when no valid timestamps are found or returned from this method. If there was one then all of the checks will fail with an exception thrown by\n practitionecef(C"}
{"id": 3256, "code": "func (c *Comment) GetRelatedId() int {\n\tif c == nil || c.RelatedId == nil {\n\t\treturn 0\n\t}\n\treturn *c.RelatedId\n}", "reference": "// GetRelatedId returns the RelatedId field if non-nil, zero value otherwise.", "generated": "// Returns the number of related id's in a given context, or null if no associated ID exists for that particular user/group name and not an existing one // otherwise returns None ."}
{"id": 3292, "code": "func (d *Downtime) GetRecurrence() Recurrence {\n\tif d == nil || d.Recurrence == nil {\n\t\treturn Recurrence{}\n\t}\n\treturn *d.Recurrence\n}", "reference": "// GetRecurrence returns the Recurrence field if non-nil, zero value otherwise.", "generated": "// Returns a recurrences list of all occurrences in the specified time period, with an optional delay between each occurrence and return value for any given interval or duration if no such intervals are available to be returned by Downtimes.\n\n\n// Example:\nvar n = 0; // N is 1-9 seconds"}
{"id": 3293, "code": "func (d *Downtime) GetRecurrenceOk() (Recurrence, bool) {\n\tif d == nil || d.Recurrence == nil {\n\t\treturn Recurrence{}, false\n\t}\n\treturn *d.Recurrence, true\n}", "reference": "// GetRecurrenceOk returns a tuple with the Recurrence field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns the number of occurrences in a given period that are not recurred by this service or any other services on an interval specified as `None`. The default is None if no such occurrence occurs and returns False otherwise.\n// This function takes two arguments to specify which periods should be returned for each time-period defined"}
{"id": 3310, "code": "func (g *Graph) GetDefinition() GraphDefinition {\n\tif g == nil || g.Definition == nil {\n\t\treturn GraphDefinition{}\n\t}\n\treturn *g.Definition\n}", "reference": "// GetDefinition returns the Definition field if non-nil, zero value otherwise.", "generated": "G provides a function to retrieve the definition of an object, and returns it as if by calling GGetDefinition(g). The return value is returned in JSON format with no additional information about its type or any other parameters that may be passed through for further processing. It also allows you access via methods such Async ,"}
{"id": 3320, "code": "func (g *GraphDefinitionMarker) GetValOk() (json.Number, bool) {\n\tif g == nil || g.Val == nil {\n\t\treturn \"\", false\n\t}\n\treturn *g.Val, true\n}", "reference": "// GetValOk returns a tuple with the Val field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// This function returns a GraphDefinitionMarkers object that contains the values of all valid JSON objects in its context and provides an error message if any are not found or returned by this method.\n // The value is passed to this function as part for each validation failure on subsequent calls. If no errors were encountered during these"}
{"id": 3325, "code": "func (g *GraphDefinitionRequest) GetStacked() bool {\n\tif g == nil || g.Stacked == nil {\n\t\treturn false\n\t}\n\treturn *g.Stacked\n}", "reference": "// GetStacked returns the Stacked field if non-nil, zero value otherwise.", "generated": "// Returns a GraphDefinitionRequest object that contains the requested data and returns an error if it is not found in any of its fields or otherwise fails to return true for some reason.\n// This method can be used with either GDB::GetErrorResponse, which will cause errors when returning null , or as described above"}
{"id": 3343, "code": "func (h *HostActionMute) GetEndTime() string {\n\tif h == nil || h.EndTime == nil {\n\t\treturn \"\"\n\t}\n\treturn *h.EndTime\n}", "reference": "// GetEndTime returns the EndTime field if non-nil, zero value otherwise.", "generated": "// This method returns the time in milliseconds, or 0 if no end-time is specified and 1 otherwise.\n // The default value of this function will be returned as a number between zero and one inclusive of two digits from the start to finish line.\n\n\n/** Returns an array containing all known values for `host"}
{"id": 3366, "code": "func (i *IntegrationGCPCreateRequest) GetClientX509CertURL() string {\n\tif i == nil || i.ClientX509CertURL == nil {\n\t\treturn \"\"\n\t}\n\treturn *i.ClientX509CertURL\n}", "reference": "// GetClientX509CertURL returns the ClientX509CertURL field if non-nil, zero value otherwise.", "generated": "// Initializes the client certificate URL to be used for authentication purposes.\n // This is a simple HTTP request, and should not require any additional parameters or configuration changes in\n/// code execution.\n// The initialization of the server certificates can take several steps depending on how many requests are made by\n#{"}
{"id": 3375, "code": "func (i *IntegrationGCPCreateRequest) HasPrivateKeyID() bool {\n\tif i != nil && i.PrivateKeyID != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasPrivateKeyID returns a boolean if a field has been set.", "generated": "// Initializes the private key ID for integration GCPCREATE request, returns if it is not null or a non-null value and otherwise sets its public key to that of an existing implementation's own unique identifier // provided by this method. If no such instance exists in any other context, return undefined .\n//"}
{"id": 3394, "code": "func (m *MetricMetadata) HasStatsdInterval() bool {\n\tif m != nil && m.StatsdInterval != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasStatsdInterval returns a boolean if a field has been set.", "generated": "// Metrics are used to determine the number of times a metric is needed for an operation, and how many seconds it takes before that time expires or when its value will be reset in future operations. The default values include 0 , 1 . // This function returns True if no metrics have been requested by any user at all"}
{"id": 3423, "code": "func (o *Options) GetLockedOk() (bool, bool) {\n\tif o == nil || o.Locked == nil {\n\t\treturn false, false\n\t}\n\treturn *o.Locked, true\n}", "reference": "// GetLockedOk returns a tuple with the Locked field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns the lock state of an object if it is locked or not in use by a user agent and returns either None or LockState .\n // The default value for this method should be null , otherwise return Nothing\n// This function will only check that all locks are available to any given application when using `Lock`"}
{"id": 3431, "code": "func (o *Options) GetQueryConfig() QueryConfig {\n\tif o == nil || o.QueryConfig == nil {\n\t\treturn QueryConfig{}\n\t}\n\treturn *o.QueryConfig\n}", "reference": "// GetQueryConfig returns the QueryConfig field if non-nil, zero value otherwise.", "generated": "// This method returns the query config for a given option, and optionally provides an optional default value if it is not provided by any of its options.\n // The defaults are specified in this example as follows :\n// Option Description Default Value Type Required to be used with all queries returned from Options . New(options)"}
{"id": 3444, "code": "func (o *Options) GetThresholdWindowsOk() (ThresholdWindows, bool) {\n\tif o == nil || o.ThresholdWindows == nil {\n\t\treturn ThresholdWindows{}, false\n\t}\n\treturn *o.ThresholdWindows, true\n}", "reference": "// GetThresholdWindowsOk returns a tuple with the ThresholdWindows field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns the threshold Windows ok value for a given window if it is not already set to 0 or greater than this specified level of thresholds in `options`.\n // This can be used as a shorthand way around setting an existing minimum and maximum windows on which we want to run tests with minimal overhead from testing our own code"}
{"id": 3465, "code": "func (r *Recurrence) GetUntilDateOk() (int, bool) {\n\tif r == nil || r.UntilDate == nil {\n\t\treturn 0, false\n\t}\n\treturn *r.UntilDate, true\n}", "reference": "// GetUntilDateOk returns a tuple with the UntilDate field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns the date of the occurrence in a string that is not an integer or non-negative number and returns None if no occurrences occurred within this range.\n // This function takes two arguments to specify which dates are returned by recursively searching for them with each iteration returning zero results until all matches have been found."}
{"id": 3475, "code": "func (r *reqComment) HasComment() bool {\n\tif r != nil && r.Comment != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasComment returns a boolean if a field has been set.", "generated": "// Returns a string that contains the comment's name, and optionally an optional description of what it should be used for in comments.\n // This is useful when you want to specify which text will appear on your page after each line or if there are no lines left before any one at all. It also returns information about"}
{"id": 3483, "code": "func (r *reqGetTags) GetTagsOk() (TagMap, bool) {\n\tif r == nil || r.Tags == nil {\n\t\treturn TagMap{}, false\n\t}\n\treturn *r.Tags, true\n}", "reference": "// GetTagsOk returns a tuple with the Tags field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// This method returns a tag that is not tagged by the user or any other tags in this context. It does NOT return an error if no such tagging exists for some reason.\n// The default value of \"tag\" will be returned as follows:\n // If there are multiple users and one has been added to"}
{"id": 3485, "code": "func (r *Rule) GetThreshold() json.Number {\n\tif r == nil || r.Threshold == nil {\n\t\treturn \"\"\n\t}\n\treturn *r.Threshold\n}", "reference": "// GetThreshold returns the Threshold field if non-nil, zero value otherwise.", "generated": "// Returns the threshold value for a rule, or null if it is not specified in an array of rules and returns false otherwise // return true .\n// Example:\n// Check that all entries are equal to zero by checking whether they have been entered as \"zero\" , then check their entry status with `CheckEntry"}
{"id": 3492, "code": "func (s *Screenboard) GetSharedOk() (bool, bool) {\n\tif s == nil || s.Shared == nil {\n\t\treturn false, false\n\t}\n\treturn *s.Shared, true\n}", "reference": "// GetSharedOk returns a tuple with the Shared field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns the shared ok value of a screenboard if it is not already available in an existing buffer or has been created by another user with no previous access to that pool's buffers and/or other resources on its behalf.\n // This function returns null for non-nil error messages when there are multiple pools open at"}
{"id": 3495, "code": "func (s *Series) GetAggrOk() (string, bool) {\n\tif s == nil || s.Aggr == nil {\n\t\treturn \"\", false\n\t}\n\treturn *s.Aggr, true\n}", "reference": "// GetAggrOk returns a tuple with the Aggr field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns a list of all the Aggregators that have been added to Series since its creation.\n // The first is an array containing each entry in the series and contains any entries from it as well;\n/**\n* Each Entry has at least one value for this Value which must be set by default on every"}
{"id": 3518, "code": "func (s *SyntheticsDevice) GetIsMobileOk() (bool, bool) {\n\tif s == nil || s.IsMobile == nil {\n\t\treturn false, false\n\t}\n\treturn *s.IsMobile, true\n}", "reference": "// GetIsMobileOk returns a tuple with the IsMobile field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns the mobile device ID of a SYNTHESIS Device if it is not available in an existing network connection or otherwise unavailable to users on that interface.\n // This function returns True for all devices and False for any other interfaces with which this functionality does NOT exist.\n\n\n/*** Gets MobileOk("}
{"id": 3522, "code": "func (s *SyntheticsDevice) HasUserAgent() bool {\n\tif s != nil && s.UserAgent != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasUserAgent returns a boolean if a field has been set.", "generated": "// This function returns the user agent for this device if it is not already present in a remote system or has been created by another process, and does nothing else when called with an error message indicating that there was no connection to any other application on which they were connected at all.\n// The default value of False indicates"}
{"id": 3534, "code": "func (s *SyntheticsOptions) HasMinLocationFailed() bool {\n\tif s != nil && s.MinLocationFailed != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasMinLocationFailed returns a boolean if a field has been set.", "generated": "// Returns the minimum location for a SyntheticOption to be used in an application that does not have any options available, or if it is already specified as such by default.\n // This option can only occur when using Options::minLocationFails().\n// The minlocationfailing method returns True .\n//"}
{"id": 3541, "code": "func (s *SyntheticsRequest) GetMethod() string {\n\tif s == nil || s.Method == nil {\n\t\treturn \"\"\n\t}\n\treturn *s.Method\n}", "reference": "// GetMethod returns the Method field if non-nil, zero value otherwise.", "generated": "// This method returns a list of methods that are available to the user for use in SyntheticRequest().\n // The following is an example, using only one syntax request and two parameters :\n\n#[inline]\n// Example usage from http://www-api/syntaxrequest.com/getmethod(params"}
{"id": 3548, "code": "func (s *SyntheticsTest) GetConfigOk() (SyntheticsConfig, bool) {\n\tif s == nil || s.Config == nil {\n\t\treturn SyntheticsConfig{}, false\n\t}\n\treturn *s.Config, true\n}", "reference": "// GetConfigOk returns a tuple with the Config field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// This method returns the ConfigOK value if it is not set to a boolean or an error occurs when attempting this test with no config options available for that type of configuration option in scope.\n // The default setting will be used by all tests except those where there are multiple configurations and/or settings being tested at once"}
{"id": 3551, "code": "func (s *SyntheticsTest) GetDeletedAtOk() (string, bool) {\n\tif s == nil || s.DeletedAt == nil {\n\t\treturn \"\", false\n\t}\n\treturn *s.DeletedAt, true\n}", "reference": "// GetDeletedAtOk returns a tuple with the DeletedAt field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Check if the deleted object is a new instance of SyntheticTest . If it's not, return an error message and exit with no result.\n // This method returns True for all instances that are created by SynthesisTest , False for those which have been destroyed or removed from the system after being added to its"}
{"id": 3577, "code": "func (t *ThresholdCount) GetTimeAggregator() string {\n\tif t == nil || t.TimeAggregator == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.TimeAggregator\n}", "reference": "// GetTimeAggregator returns the TimeAggregator field if non-nil, zero value otherwise.", "generated": "// This method returns the time interval between two consecutive ticks of a given threshold count, or 0 if no tick is specified and 1 otherwise.\n // The default value for this function will be used to determine how long it takes to complete an operation before returning true when all operations are completed successfully."}
{"id": 3579, "code": "func (t *ThresholdCount) HasTimeAggregator() bool {\n\tif t != nil && t.TimeAggregator != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasTimeAggregator returns a boolean if a field has been set.", "generated": "// This method returns the number of ticks in a tick interval, if any // are left over from previous iterations or otherwise not returned by this function. If no time intervals have been specified for an `T` to be considered as \"tick\", // it will return 0 and continue with its execution until all remaining values remain"}
{"id": 3582, "code": "func (t *ThresholdCount) HasUnknown() bool {\n\tif t != nil && t.Unknown != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasUnknown returns a boolean if a field has been set.", "generated": "// This function returns the number of ticks that have been ticked in a given time interval, and if it is not zero then no further actions are performed on this value until all other values returned by ThreshReturnTicksInRange(tick) or TickSetTimeout().\n // If T is an integer with one"}
{"id": 3583, "code": "func (t *ThresholdCount) GetWarning() json.Number {\n\tif t == nil || t.Warning == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.Warning\n}", "reference": "// GetWarning returns the Warning field if non-nil, zero value otherwise.", "generated": "// This method returns a list of warnings for the specified threshold. The warning is an array containing all known errors and any other information that might be needed to resolve them, including if there are no such exceptions in this case.\n// Note that it does not return true or false when calling ThrowsWithError(T"}
{"id": 3589, "code": "func (t *ThresholdWindows) GetRecoveryWindow() string {\n\tif t == nil || t.RecoveryWindow == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.RecoveryWindow\n}", "reference": "// GetRecoveryWindow returns the RecoveryWindow field if non-nil, zero value otherwise.", "generated": "// This method returns a list of windows that are currently recovering from the Windows recovery process, and optionally an error message if there is no such window in this registry entry.\n// The returned value should be either \"None\" or \"No Recovery Window\".\n// If it's not specified, return None .\n//"}
{"id": 3597, "code": "func (t *TileDefRequest) HasQueryType() bool {\n\tif t != nil && t.QueryType != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasQueryType returns a boolean if a field has been set.", "generated": "// This method returns the type of a Tile object if it is not an instance of Tiles, or null otherwise. If this does NOT return any value for that tile, then no query will be performed on its data structure until all queries are completed and returned to caller.\n// Returns None when none of these methods"}
{"id": 3598, "code": "func (t *TileDefRequest) GetTextFilter() string {\n\tif t == nil || t.TextFilter == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.TextFilter\n}", "reference": "// GetTextFilter returns the TextFilter field if non-nil, zero value otherwise.", "generated": "// This method returns a text filter that will return the specified value of TextFilter if it is not found in an existing tile cache or has been deleted by another application, and also provides access to other tiles for which this function was called with no arguments passed as parameters.\nMethods:\n\n\n// Returns true when T"}
{"id": 3604, "code": "func (t *TimeRange) GetLive() bool {\n\tif t == nil || t.Live == nil {\n\t\treturn false\n\t}\n\treturn *t.Live\n}", "reference": "// GetLive returns the Live field if non-nil, zero value otherwise.", "generated": "// Returns the live time range for a given interval, if it is not already set to zero or more than one hour ago.\n // This can be used as an alias of TimeZone::GetCurrentDuration().\n// The default value will return true when no current duration has been reached and False otherwise."}
{"id": 3606, "code": "func (t *TimeRange) HasLive() bool {\n\tif t != nil && t.Live != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasLive returns a boolean if a field has been set.", "generated": "// Returns the live time range for a given date and hour, if it is not already known to be in use by an application or has been updated with new information about that location within its current scope.\n// This function returns True when no changes have occurred on this target since last call of `Has Live` ."}
{"id": 3613, "code": "func (t *TimeseriesRequestStyle) GetLineType() string {\n\tif t == nil || t.LineType == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.LineType\n}", "reference": "// GetLineType returns the LineType field if non-nil, zero value otherwise.", "generated": "// Returns the line type of a request, or null if it is not found in an array and returned as None .\n// This method returns true for all requests that return strings with no content to be parsed by T , false for any other queries where there are none available at runtime."}
{"id": 3626, "code": "func (t *TraceServiceDefinition) GetShowBreakdownOk() (bool, bool) {\n\tif t == nil || t.ShowBreakdown == nil {\n\t\treturn false, false\n\t}\n\treturn *t.ShowBreakdown, true\n}", "reference": "// GetShowBreakdownOk returns a tuple with the ShowBreakdown field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Find out if the breakpoint is set to a value of None or not and return it as an error message when no values are found in this context.\n// This function returns True for all exceptions that occur while searching through Traces service definitions with respect only to non-default settings such as \"no\" ."}
{"id": 3631, "code": "func (t *TraceServiceDefinition) GetShowErrors() bool {\n\tif t == nil || t.ShowErrors == nil {\n\t\treturn false\n\t}\n\treturn *t.ShowErrors\n}", "reference": "// GetShowErrors returns the ShowErrors field if non-nil, zero value otherwise.", "generated": "// This function returns a list of errors that should be reported to the Tracert service for each trace event, and optionally an error message if there is one or more missing events in it.\n// The default value is None .\n// If this does not return true , then no tracing will occur until all traces"}
{"id": 3702, "code": "func (w *Widget) HasMustShowHits() bool {\n\tif w != nil && w.MustShowHits != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasMustShowHits returns a boolean if a field has been set.", "generated": "// Returns the number of hits that must be displayed in a widget if it is not currently being used by an application or has been disabled for any reason.\n // This function returns True when no widgets are present, False otherwise. If this value was set to None , then all hit counts will return 0 . Example :"}
{"id": 3703, "code": "func (w *Widget) GetMustShowLatency() bool {\n\tif w == nil || w.MustShowLatency == nil {\n\t\treturn false\n\t}\n\treturn *w.MustShowLatency\n}", "reference": "// GetMustShowLatency returns the MustShowLatency field if non-nil, zero value otherwise.", "generated": "// Returns true if the widget is in a Latent state, or False otherwise for all other widgets that are not currently displayed on screen. If this option is set to True , it returns an error message when no current display of any type exists and none of its children have been selected by default.\n// This method"}
{"id": 3726, "code": "func (w *Widget) HasTileDef() bool {\n\tif w != nil && w.TileDef != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasTileDef returns a boolean if a field has been set.", "generated": "// This method returns the tile def if it is not a TileDef object, otherwise returns None .\n// The default value of this function should be null , but can also be set to any other non-nullable type in an array or string by calling SetTiles(WIDTH_TYPE). Default values"}
{"id": 3747, "code": "func (w *WidgetConditionalFormat) HasImageUrl() bool {\n\tif w != nil && w.ImageUrl != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasImageUrl returns a boolean if a field has been set.", "generated": "// Returns the image url of the widget if it is a URL, otherwise returns None.\n // The default value for this method should be \"none\".\n// This can also return an error message when no images are found in its cache or after some time has passed since returning from `widget`. If not specified,"}
{"id": 3762, "code": "func (t *templateData) addArrayType(x *ast.ArrayType, receiverType, fieldName string) {\n\t// TODO: should we make this dynamic? Could handle more cases than string only\n\tvar eltType string\n\tswitch elt := x.Elt.(type) {\n\tcase *ast.Ident:\n\t\teltType = elt.String()\n\tdefault:\n\t\tlogf(\"addArrayType: type %q, field %q: unknown element type: %T %+v; skipping.\", receiverType, fieldName, elt, elt)\n\t\treturn\n\t}\n\n\tt.Accessors = append(t.Accessors, newAccessor(receiverType, fieldName, \"[]\"+eltType, \"nil\"))\n}", "reference": "// addArrayType adds an accessor for a array type for a given receiver and field", "generated": "This function adds an array of types to the template data structure and returns a list containing all elements in that set as strings or arrays with no fields specified by default. The returned lists are then passed through the callbacks for each method on which they were added using `append` . This is useful when you want to return"}
{"id": 3764, "code": "func (client *Client) UpdateDowntime(downtime *Downtime) error {\n\treturn client.doJsonRequest(\"PUT\", fmt.Sprintf(\"/v1/downtime/%d\", *downtime.Id),\n\t\tdowntime, nil)\n}", "reference": "// UpdateDowntime takes a downtime that was previously retrieved through some method\n// and sends it back to the server.", "generated": "This method updates the time of a request to reflect changes in server status and returns an updated dt-time object that is used for future requests when needed. The returned DTS will be stored asynchronously on disk or synchronized with other clients using this API if necessary before any new data can reach its destination address at"}
{"id": 3768, "code": "func (k *APIKey) UnmarshalJSON(data []byte) error {\n\ttype Alias APIKey\n\taux := &struct {\n\t\tCreated *string `json:\"created,omitempty\"`\n\t\t*Alias\n\t}{\n\t\tAlias: (*Alias)(k),\n\t}\n\tif err := json.Unmarshal(data, &aux); err != nil {\n\t\treturn err\n\t}\n\n\tif created, err := time.Parse(createdTimeLayout, *aux.Created); err != nil {\n\t\treturn err\n\t} else {\n\t\tk.Created = &created\n\t}\n\n\treturn nil\n}", "reference": "// UnmarshalJSON is a custom method for handling datetime unmarshalling", "generated": "// This function creates a new JSON object with the name of the key in its field and returns an array containing all keys that have been added to it by this method. The returned string is then used as part for subsequent calls on other methods or functions within the same class if necessary.\n // Note: If you are"}
{"id": 3770, "code": "func (client *Client) GetAPIKey(key string) (*APIKey, error) {\n\tvar out reqAPIKey\n\tif err := client.doJsonRequest(\"GET\", fmt.Sprintf(\"/v1/api_key/%s\", key), nil, &out); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn out.APIKey, nil\n}", "reference": "// GetAPIKey returns a single API key or error on failure", "generated": "// This method returns an API Key object that can be used to retrieve the requested information from a request or response stream using JSON and XML APIs. The returned value is either \"nil\" if no data was received by this endpoint in any of its fields; or \"null\". // Note that it's possible for some requests"}
{"id": 3791, "code": "func (t *bufferedObjectStream) WriteObject(obj interface{}) error {\n\tt.mu.Lock()\n\tdefer t.mu.Unlock()\n\tif err := t.codec.WriteObject(t.w, obj); err != nil {\n\t\treturn err\n\t}\n\treturn t.w.Flush()\n}", "reference": "// WriteObject implements ObjectStream.", "generated": "This function writes a buffer to the specified stream and returns an object that contains all of the information about it in its state when called with no arguments or if any other options are provided by this method. The callback is invoked once for each message received from the given string representation as well; otherwise, only one call will be"}
{"id": 3794, "code": "func (r *Request) SetMeta(v interface{}) error {\n\tb, err := json.Marshal(v)\n\tif err != nil {\n\t\treturn err\n\t}\n\tr.Meta = (*json.RawMessage)(&b)\n\treturn nil\n}", "reference": "// SetMeta sets r.Meta to the JSON representation of v. If JSON\n// marshaling fails, it returns an error.", "generated": "// Initializes a new Meta object with the following properties and returns an empty string if it is not already created or null otherwise.\n // The default value of this property will be set to false for all subsequent calls to `setMeta`.\n// This method can also optionally return true when no other methods are called on"}
{"id": 3795, "code": "func (r *Response) SetResult(v interface{}) error {\n\tb, err := json.Marshal(v)\n\tif err != nil {\n\t\treturn err\n\t}\n\tr.Result = (*json.RawMessage)(&b)\n\treturn nil\n}", "reference": "// SetResult sets r.Result to the JSON representation of v. If JSON\n// marshaling fails, it returns an error.", "generated": "// Sets the result of a JSON response to be sent as an object with no parameters or return values in this case.\n // This method is used for sending messages from one API endpoint and returning them back when they are received by another api endpoint."}
{"id": 3804, "code": "func PickID(id ID) CallOption {\n\treturn callOptionFunc(func(r *Request) error {\n\t\tr.ID = id\n\t\treturn nil\n\t})\n}", "reference": "// PickID returns a call option which sets the ID on a request. Care must be\n// taken to ensure there are no conflicts with any previously picked ID, nor\n// with the default sequence ID.", "generated": "This method returns an Option object that contains the name of the requested option, and a list containing all options for this user (including any associated fields). The returned value is then passed to the caller's callback function as follows :\n\npackage com.googleapiservices . api ;\n// Create new API calls with"}
{"id": 3863, "code": "func (c *Cursor) Backspace() {\n\ta := c.input\n\ti := c.Position\n\tif i == 0 {\n\t\t// Shrug\n\t\treturn\n\t}\n\tif i == len(a) {\n\t\tc.input = a[:i-1]\n\t} else {\n\t\tc.input = append(a[:i-1], a[i:]...)\n\t}\n\t// now it's pointing to the i+1th element\n\tc.Move(-1)\n}", "reference": "// Backspace removes the rune that precedes the cursor\n//\n// It handles being at the beginning or end of the row, and moves the cursor to\n// the appropriate position.", "generated": ""}
{"id": 3870, "code": "func (p *Package) Type(name string) (t *Type) {\n\tt, _ = p.Members[name].(*Type)\n\treturn\n}", "reference": "// Type returns the package-level type of the specified name,\n// or nil if not found.\n//", "generated": "type is a type that can be used to represent any package name or class of the specified types and classes in an interface with no special syntax restrictions applied by default. It may also contain other packages as well; see Package Types for more information. The following examples show how it works using this method on some common interfaces such"}
{"id": 3892, "code": "func (b *builder) switchStmt(fn *Function, s *ast.SwitchStmt, label *lblock) {\n\t// We treat SwitchStmt like a sequential if-else chain.\n\t// Multiway dispatch can be recovered later by ssautil.Switches()\n\t// to those cases that are free of side effects.\n\tif s.Init != nil {\n\t\tb.stmt(fn, s.Init)\n\t}\n\tvar tag Value = vTrue\n\tif s.Tag != nil {\n\t\ttag = b.expr(fn, s.Tag)\n\t}\n\tdone := fn.newBasicBlock(\"switch.done\")\n\tif label != nil {\n\t\tlabel._break = done\n\t}\n\t// We pull the default case (if present) down to the end.\n\t// But each fallthrough label must point to the next\n\t// body block in source order, so we preallocate a\n\t// body block (fallthru) for the next case.\n\t// Unfortunately this makes for a confusing block order.\n\tvar dfltBody *[]ast.Stmt\n\tvar dfltFallthrough *BasicBlock\n\tvar fallthru, dfltBlock *BasicBlock\n\tncases := len(s.Body.List)\n\tfor i, clause := range s.Body.List {\n\t\tbody := fallthru\n\t\tif body == nil {\n\t\t\tbody = fn.newBasicBlock(\"switch.body\") // first case only\n\t\t}\n\n\t\t// Preallocate body block for the next case.\n\t\tfallthru = done\n\t\tif i+1 < ncases {\n\t\t\tfallthru = fn.newBasicBlock(\"switch.body\")\n\t\t}\n\n\t\tcc := clause.(*ast.CaseClause)\n\t\tif cc.List == nil {\n\t\t\t// Default case.\n\t\t\tdfltBody = &cc.Body\n\t\t\tdfltFallthrough = fallthru\n\t\t\tdfltBlock = body\n\t\t\tcontinue\n\t\t}\n\n\t\tvar nextCond *BasicBlock\n\t\tfor _, cond := range cc.List {\n\t\t\tnextCond = fn.newBasicBlock(\"switch.next\")\n\t\t\t// TODO(adonovan): opt: when tag==vTrue, we'd\n\t\t\t// get better code if we use b.cond(cond)\n\t\t\t// instead of BinOp(EQL, tag, b.expr(cond))\n\t\t\t// followed by If.  Don't forget conversions\n\t\t\t// though.\n\t\t\tcond := emitCompare(fn, token.EQL, tag, b.expr(fn, cond), cond.Pos())\n\t\t\temitIf(fn, cond, body, nextCond)\n\t\t\tfn.currentBlock = nextCond\n\t\t}\n\t\tfn.currentBlock = body\n\t\tfn.targets = &targets{\n\t\t\ttail:         fn.targets,\n\t\t\t_break:       done,\n\t\t\t_fallthrough: fallthru,\n\t\t}\n\t\tb.stmtList(fn, cc.Body)\n\t\tfn.targets = fn.targets.tail\n\t\temitJump(fn, done)\n\t\tfn.currentBlock = nextCond\n\t}\n\tif dfltBlock != nil {\n\t\temitJump(fn, dfltBlock)\n\t\tfn.currentBlock = dfltBlock\n\t\tfn.targets = &targets{\n\t\t\ttail:         fn.targets,\n\t\t\t_break:       done,\n\t\t\t_fallthrough: dfltFallthrough,\n\t\t}\n\t\tb.stmtList(fn, *dfltBody)\n\t\tfn.targets = fn.targets.tail\n\t}\n\temitJump(fn, done)\n\tfn.currentBlock = done\n}", "reference": "// switchStmt emits to fn code for the switch statement s, optionally\n// labelled by label.\n//", "generated": "The following example creates an empty list with all its elements and returns it as one element without any additional information about what is contained within them or how they were created/removed from their original state; otherwise, there would be no way to know which items have been removed because none existed at runtime before being added into the"}
{"id": 3913, "code": "func yaml_emitter_flush(emitter *yaml_emitter_t) bool {\n\tif emitter.write_handler == nil {\n\t\tpanic(\"write handler not set\")\n\t}\n\n\t// Check if the buffer is empty.\n\tif emitter.buffer_pos == 0 {\n\t\treturn true\n\t}\n\n\tif err := emitter.write_handler(emitter, emitter.buffer[:emitter.buffer_pos]); err != nil {\n\t\treturn yaml_emitter_set_writer_error(emitter, \"write error: \"+err.Error())\n\t}\n\temitter.buffer_pos = 0\n\treturn true\n}", "reference": "// Flush the output buffer.", "generated": "YAML emitters are used to write messages from a file descriptor (or stream of files). They can be written in any format that supports writing and/ or reading streams; they may also contain an optional callback function which will return false for failure when no such message was received by this process. The following example uses"}
{"id": 3930, "code": "func TCPDialCheck(addr string, timeout time.Duration) Check {\n\treturn func() error {\n\t\tconn, err := net.DialTimeout(\"tcp\", addr, timeout)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn conn.Close()\n\t}\n}", "reference": "// TCPDialCheck returns a Check that checks TCP connectivity to the provided\n// endpoint.", "generated": "TCP checks the connection to a local server and returns an HTTP status code of 200 or 404 if it is successful. If not provided with any response headers (e., \"Content-Type\" , for example), TCP will return 403 . The default value in this case is 302 but can be changed by setting its own"}
{"id": 3934, "code": "func NewMetricsHandler(registry prometheus.Registerer, namespace string) Handler {\n\treturn &metricsHandler{\n\t\thandler:   NewHandler(),\n\t\tregistry:  registry,\n\t\tnamespace: namespace,\n\t}\n}", "reference": "// NewMetricsHandler returns a healthcheck Handler that also exposes metrics\n// into the provided Prometheus registry.", "generated": "New MetricHandler is a new handler for the metrics daemon that will be used to generate and display statistics on Prometheus's servers (and other services). It provides an interface similar in functionality as its peers but with more granular control over how it handles requests from clients or their own server-side APIs. The API also"}
{"id": 3938, "code": "func (p *Pinger) AddIP(ipaddr string) error {\n\taddr := net.ParseIP(ipaddr)\n\tif addr == nil {\n\t\treturn fmt.Errorf(\"%s is not a valid textual representation of an IP address\", ipaddr)\n\t}\n\tp.mu.Lock()\n\tp.addrs[addr.String()] = &net.IPAddr{IP: addr}\n\tif isIPv4(addr) {\n\t\tp.hasIPv4 = true\n\t} else if isIPv6(addr) {\n\t\tp.hasIPv6 = true\n\t}\n\tp.mu.Unlock()\n\treturn nil\n}", "reference": "// AddIP adds an IP address to Pinger. ipaddr arg should be a string like\n// \"192.0.2.1\".", "generated": "// This function adds an IPv4-based packet to the Pinger interface, which can be used for authentication purposes only.\n // The default value will return false when no packets are received from this endpoint and returns true in all cases where it's possible that there was one or more incoming connections on any given port."}
{"id": 3943, "code": "func Substitute(s string, sub map[string]string) (buf string) {\n\tbuf = s\n\tvar keys []string\n\tfor k := range sub {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)\n\n\tfor _, key := range keys {\n\t\tbuf = strings.Replace(buf, key, sub[key], -1)\n\t}\n\treturn\n}", "reference": "// Substitute returns string with superseded all substrings from\n// provided substitution map. Substitution map will be applied in alphabetic\n// order. Many passes, on one substitution another one could apply.", "generated": "This function replaces the current buffer with a new one and returns an empty list of all buffers that have been replaced by this replacement method. The returned lists are sorted according to their size in bytes before returning nil . If no such array exists then it is assumed that there was not any previous replacements for each element within its original"}
{"id": 3945, "code": "func Parse() error {\n\targs := os.Args\n\tif len(args) == 1 {\n\t\treturn nil\n\t}\n\n\t// Global flags.\n\tfset := flag.CommandLine\n\tfset.Usage = Usage\n\tout := fsetOutput(fset)\n\n\tif err := fset.Parse(args[1:]); err != nil {\n\t\treturn err\n\t}\n\n\t// Handle version request.\n\tif f := fset.Lookup(VersionBoolFlag); f != nil {\n\t\tif v, ok := f.Value.(flag.Getter); ok {\n\t\t\t// All values implemented by the flag package implement the flag.Getter interface.\n\t\t\tif b, ok := v.Get().(bool); ok && b {\n\t\t\t\t// The flag was defined as a bool and is set.\n\t\t\t\tprogram := programName(args[0])\n\t\t\t\tfmt.Fprintf(out, \"%s version %s %s/%s\\n\",\n\t\t\t\t\tprogram, buildinfo(),\n\t\t\t\t\truntime.GOOS, runtime.GOARCH)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n\n\t// No cmdflag.\n\tif fset.NArg() == 0 {\n\t\treturn nil\n\t}\n\n\t// Subcommand.\n\tidx := len(args) - fset.NArg()\n\ts := args[idx]\n\targs = args[idx+1:]\n\tfor _, sub := range subs {\n\t\tif sub.name != s {\n\t\t\tcontinue\n\t\t}\n\n\t\tfs, handler := sub.init(out)\n\t\tif err := fs.Parse(args); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn handler(args[len(args)-fs.NArg():]...)\n\t}\n\n\treturn fmt.Errorf(\"%s is not a valid cmdflag\", s)\n}", "reference": "// Parse parses the command line arguments including the global flags and, if any, the cmdflag and its flags.\n//\n// If the VersionBoolFlag is defined as a global boolean flag, then the program version is displayed and the program stops.", "generated": "This function returns an array of strings that contains all commands to be executed in one command line (i.,e.: \"cmd\", or any other string). It also provides some information about how this script works; see Command Line Options for more details. This method can optionally return null if no arguments are given but it does"}
{"id": 3946, "code": "func (xxh XXHZero) Sum(b []byte) []byte {\n\th32 := xxh.Sum32()\n\treturn append(b, byte(h32), byte(h32>>8), byte(h32>>16), byte(h32>>24))\n}", "reference": "// Sum appends the current hash to b and returns the resulting slice.\n// It does not change the underlying hash state.", "generated": "XXI Zero is a zero-based hash function that returns an integer representation of the given hexadecimal value in binary form with no return values or nil . The returned string can be used to represent any number as long and short , respectively; it also has two optional parameters which are passed through for each element within"}
{"id": 3949, "code": "func (xxh *XXHZero) Sum32() uint32 {\n\th32 := uint32(xxh.totalLen)\n\tif h32 >= 16 {\n\t\th32 += rol1(xxh.v1) + rol7(xxh.v2) + rol12(xxh.v3) + rol18(xxh.v4)\n\t} else {\n\t\th32 += prime32_5\n\t}\n\n\tp := 0\n\tn := xxh.bufused\n\tbuf := xxh.buf\n\tfor n := n - 4; p <= n; p += 4 {\n\t\th32 += binary.LittleEndian.Uint32(buf[p:p+4]) * prime32_3\n\t\th32 = rol17(h32) * prime32_4\n\t}\n\tfor ; p < n; p++ {\n\t\th32 += uint32(buf[p]) * prime32_5\n\t\th32 = rol11(h32) * prime32_1\n\t}\n\n\th32 ^= h32 >> 15\n\th32 *= prime32_2\n\th32 ^= h32 >> 13\n\th32 *= prime32_3\n\th32 ^= h32 >> 16\n\n\treturn h32\n}", "reference": "// Sum32 returns the 32 bits Hash value.", "generated": "This function returns the number of bytes in the buffer, and then compares it against a string representation to determine if there is any difference between them or not at all. The result can be used as an input for other functions that return more than one byte value from the same data structure such like this:"}
{"id": 3956, "code": "func (z *Writer) Write(buf []byte) (int, error) {\n\tif !z.Header.done {\n\t\tif err := z.writeHeader(); err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t}\n\tif debugFlag {\n\t\tdebug(\"input buffer len=%d index=%d\", len(buf), z.idx)\n\t}\n\n\tzn := len(z.data)\n\tvar n int\n\tfor len(buf) > 0 {\n\t\tif z.idx == 0 && len(buf) >= zn {\n\t\t\t// Avoid a copy as there is enough data for a block.\n\t\t\tif err := z.compressBlock(buf[:zn]); err != nil {\n\t\t\t\treturn n, err\n\t\t\t}\n\t\t\tn += zn\n\t\t\tbuf = buf[zn:]\n\t\t\tcontinue\n\t\t}\n\t\t// Accumulate the data to be compressed.\n\t\tm := copy(z.data[z.idx:], buf)\n\t\tn += m\n\t\tz.idx += m\n\t\tbuf = buf[m:]\n\t\tif debugFlag {\n\t\t\tdebug(\"%d bytes copied to buf, current index %d\", n, z.idx)\n\t\t}\n\n\t\tif z.idx < len(z.data) {\n\t\t\t// Buffer not filled.\n\t\t\tif debugFlag {\n\t\t\t\tdebug(\"need more data for compression\")\n\t\t\t}\n\t\t\treturn n, nil\n\t\t}\n\n\t\t// Buffer full.\n\t\tif err := z.compressBlock(z.data); err != nil {\n\t\t\treturn n, err\n\t\t}\n\t\tz.idx = 0\n\t}\n\n\treturn n, nil\n}", "reference": "// Write compresses data from the supplied buffer into the underlying io.Writer.\n// Write does not return until the data has been written.", "generated": "This function creates and compresses an array of byte arrays into one or more chunks that are then decompressed using write() . The resulting chunk can contain any number of elements in its original size which will eventually become uncompiled if it has been used up by another process before being processed again with read(). This method also allows"}
{"id": 3959, "code": "func (z *Writer) Close() error {\n\tif !z.Header.done {\n\t\tif err := z.writeHeader(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := z.Flush(); err != nil {\n\t\treturn err\n\t}\n\n\tif debugFlag {\n\t\tdebug(\"writing last empty block\")\n\t}\n\tif err := z.writeUint32(0); err != nil {\n\t\treturn err\n\t}\n\tif !z.NoChecksum {\n\t\tchecksum := z.checksum.Sum32()\n\t\tif debugFlag {\n\t\t\tdebug(\"stream checksum %x\", checksum)\n\t\t}\n\t\tif err := z.writeUint32(checksum); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// Close closes the Writer, flushing any unwritten data to the underlying io.Writer, but does not close the underlying io.Writer.", "generated": "// Write a new buffer to the specified file descriptor, and return it as an object with no errors or warnings if there are any // non-zero bytes in that stream at all.\n/**\n* This method is called when writing buffers from stdin into another thread's main process using `Zend` . It"}
{"id": 4014, "code": "func (d *FileSelectDialog) detectPath() {\n\tp := d.currPath\n\tif p == \"\" {\n\t\td.currPath, _ = os.Getwd()\n\t\treturn\n\t}\n\n\tp = filepath.Clean(p)\n\tfor {\n\t\t_, err := os.Stat(p)\n\t\tif err == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tdirUp := filepath.Dir(p)\n\t\tif dirUp == p {\n\t\t\tp, _ = os.Getwd()\n\t\t\tbreak\n\t\t}\n\n\t\tp = dirUp\n\t}\n\td.currPath = p\n}", "reference": "// Tries to find the best fit for the given path.\n// It goes up until it gets into the existing directory.\n// If all fails it returns working directory.", "generated": "// Detects the path to a directory that is not in an existing list of directories and returns true if it exists or false otherwise return false for each entry on the current line.\n/**\n* This function will be called when all entries are found by default with no errors encountered during this process.\n*/ // Initial"}
{"id": 4018, "code": "func (d *dbCache) preload(firstRow, rowCount int) {\n\tif firstRow == d.firstRow && rowCount == d.rowCount {\n\t\t// fast path: view area is the same, return immediately\n\t\treturn\n\t}\n\n\t// slow path: refill cache\n\tfNames := []string{\"Jack\", \"Alisa\", \"Richard\", \"Paul\", \"Nicole\", \"Steven\", \"Jane\"}\n\tlNames := []string{\"Smith\", \"Catcher\", \"Stone\", \"White\", \"Black\"}\n\tposts := []string{\"Engineer\", \"Manager\", \"Janitor\", \"Driver\"}\n\tdeps := []string{\"IT\", \"Financial\", \"Support\"}\n\tsalary := []int{40000, 38000, 41000, 32000}\n\n\td.data = make([][]string, rowCount, rowCount)\n\tfor i := 0; i < rowCount; i++ {\n\t\tabsIndex := firstRow + i\n\t\td.data[i] = make([]string, columnInTable, columnInTable)\n\t\td.data[i][0] = fNames[absIndex%len(fNames)]\n\t\td.data[i][1] = lNames[absIndex%len(lNames)]\n\t\td.data[i][2] = fmt.Sprintf(\"%08d\", 100+absIndex)\n\t\td.data[i][3] = posts[absIndex%len(posts)]\n\t\td.data[i][4] = deps[absIndex%len(deps)]\n\t\td.data[i][5] = fmt.Sprintf(\"%d k/year\", salary[absIndex%len(salary)]/1000)\n\t}\n\n\t// do not forget to save the last values\n\td.firstRow = firstRow\n\td.rowCount = rowCount\n}", "reference": "// cache data from a new row span\n// It imitates a random data by selecting values from predefined arrays. Sizes\n// of all arrays should be different to make TableView data look more random", "generated": "This function takes a list of rows and returns an array containing all those records that were stored in this database at one time or another by default. The following example shows how it works with SQLite's built-in indexes for each record type as well :"}
{"id": 4037, "code": "func PopClip() {\n\tif len(canvas.clipStack) == 0 {\n\t\treturn\n\t}\n\tc := canvas.clipStack[len(canvas.clipStack)-1]\n\tcanvas.clipStack = canvas.clipStack[:len(canvas.clipStack)-1]\n\tSetClipRect(c.x, c.y, c.w, c.h)\n}", "reference": "// PopClip restores saved with PushClip clipping window", "generated": "// Create a clip stack for the current frame of an image buffer and return it to its parent container if necessary.\n// This method is called when drawing from one or more frames in memory (i.,e.: draw(), resize(), etc.). It returns nil otherwise unless there are no other buffers available at the time this"}
{"id": 4038, "code": "func InClipRect(x, y int) bool {\n\treturn x >= canvas.clipX && y >= canvas.clipY &&\n\t\tx < canvas.clipX+canvas.clipW &&\n\t\ty < canvas.clipY+canvas.clipH\n}", "reference": "// InClipRect returns true if x and y position is inside current clipping\n// rectangle", "generated": "// This function returns true if the clip is in the specified range and false otherwise // for any other reason. If a value of nil or an error occurs while this function was called, // it will return false to indicate that no clipping has occurred (if there were none). Returns :true , // default: False ."}
{"id": 4049, "code": "func FillRect(x, y, w, h int, r rune) {\n\tx, y, w, h = clip(x, y, w, h)\n\tif w < 1 || y < -1 {\n\t\treturn\n\t}\n\n\tfor yy := y; yy < y+h; yy++ {\n\t\tfor xx := x; xx < x+w; xx++ {\n\t\t\tputCharUnsafe(xx, yy, r)\n\t\t}\n\t}\n}", "reference": "// FillRect paints the area with r character using the current colors", "generated": "// Create a new rectangle with the width and height of the current screen. The resulting rectangles are drawn to be used as an input for drawing on top or bottom screens in any order desired.\n // This function is called when creating multiple drawable objects from one buffer using two buffers at once (see below)."}
{"id": 4058, "code": "func (l *ListBox) SelectedItemText() string {\n\tif l.currSelection == -1 {\n\t\treturn \"\"\n\t}\n\n\treturn l.items[l.currSelection]\n}", "reference": "// SelectedItemText returns text of currently selected item or empty sting if nothing is\n// selected or ListBox is empty.", "generated": "// Selects a selected item from the list of items in Listbox, and returns it to the user for further processing.\n // This method is called once every 10 seconds on an unselected or unexported object with no selection history at all. It does not return nil if any selections have been made by this process"}
{"id": 4070, "code": "func ColorToString(attr term.Attribute) string {\n\tvar out string\n\n\trawClr := attr & 15\n\tif rawClr < 8 {\n\t\tfor k, v := range colorMap {\n\t\t\tif v == rawClr {\n\t\t\t\tout += k + \" \"\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tif attr&term.AttrBold != 0 {\n\t\tout += \"bold \"\n\t}\n\tif attr&term.AttrUnderline != 0 {\n\t\tout += \"underline \"\n\t}\n\tif attr&term.AttrReverse != 0 {\n\t\tout += \"reverse \"\n\t}\n\n\treturn strings.TrimSpace(out)\n}", "reference": "// ColorToString returns string representation of the attribute", "generated": "// This method is used to create a new String object that can be passed as an argument in the constructor of this class. It returns all attributes and methods from the current instance (including any associated fields).\n // The name must match `name` or `string`. If it does not, then no attribute will ever"}
{"id": 4074, "code": "func DeactivateControls(parent Control) {\n\tfor _, ctrl := range parent.Children() {\n\t\tif ctrl.Active() {\n\t\t\tctrl.SetActive(false)\n\t\t\tctrl.ProcessEvent(Event{Type: EventActivate, X: 0})\n\t\t}\n\n\t\tDeactivateControls(ctrl)\n\t}\n}", "reference": "// DeactivateControls makes all children of parent inactive", "generated": "// This function deactivates control handlers for the specified child controllers and sets them to active if they are not already activated by default in a given context.\n // The handler is used when an event occurs that will be triggered on any of these children (e., events with no associated controls). It also allows you access"}
{"id": 4089, "code": "func (c *CheckBox) SetAllow3State(enable bool) {\n\tif !enable && c.state == 2 {\n\t\tc.state = 0\n\t}\n\tc.allow3state = enable\n}", "reference": "// SetAllow3State sets if ComboBox should use 3 states. If the current\n// state is unknown and one disables Allow3State option then the current\n// value resets to off", "generated": "// Checkbox checks whether the state of a box is set to 3 or not, if it's true and false, then returns an error message when no change has occurred in that condition.\n// Note that this method does nothing for any other boxes which are already checked by checkboxes() . If there was one such"}
{"id": 4109, "code": "func (b *ProgressBar) SecondaryColors() (term.Attribute, term.Attribute) {\n\treturn b.emptyFg, b.emptyBg\n}", "reference": "// SecondaryColors returns text and background colors for empty\n// part of the ProgressBar", "generated": "// Initializes the secondary color scheme for progress bar and displays it in a window with an empty background of black or white to indicate that there is no current statusbar on screen.\n// This method returns true if this gradient was applied before any other methods have been called; false otherwise will return nil.\n\n // Returns"}
{"id": 4219, "code": "func NewMemoryKeyCacher(maxKeyAge time.Duration, maxCacheSize int) KeyCacher {\n\treturn &memoryKeyCacher{\n\t\tentries:      map[string]keyCacherEntry{},\n\t\tmaxKeyAge:    maxKeyAge,\n\t\tmaxCacheSize: maxCacheSize,\n\t}\n}", "reference": "// NewMemoryKeyCacher creates a new Keycacher interface with option\n// to set max age of cached keys and max size of the cache.", "generated": "New Memory key cache is a new memory caching system that uses the same keys as existing ones and caches them in different locations on disk for each session (see below). It also provides an additional level of security to ensure users can't access any other data stored within it without being exposed to unauthorized use. The default value will"}
{"id": 4226, "code": "func validColor(c string) bool {\n\tvalid := false\n\tif validColors[c] {\n\t\tvalid = true\n\t}\n\treturn valid\n}", "reference": "// validColor will make sure the given color is actually allowed", "generated": "// This function is used to validate the color of a given c. It returns an error if it does not match any other values in the array, or nil otherwise.\n// The default value for this method will be \"nil\". If no matching colors are found then all whitespace must have been removed from the resulting"}
{"id": 4230, "code": "func (s *Spinner) Reverse() {\n\ts.lock.Lock()\n\tdefer s.lock.Unlock()\n\tfor i, j := 0, len(s.chars)-1; i < j; i, j = i+1, j-1 {\n\t\ts.chars[i], s.chars[j] = s.chars[j], s.chars[i]\n\t}\n}", "reference": "// Reverse will reverse the order of the slice assigned to the indicator", "generated": "// This function is called when the string has been decrypted and a new key was created for it to be used in an encrypted session. It returns nil if no keys were found or null otherwise.\n// The default value of this method will return false unless there are any errors encountered during encryption operations on strings that have"}
{"id": 4237, "code": "func NewMultiplex(con net.Conn, initiator bool) *Multiplex {\n\tmp := &Multiplex{\n\t\tcon:       con,\n\t\tinitiator: initiator,\n\t\tbuf:       bufio.NewReader(con),\n\t\tchannels:  make(map[streamID]*Stream),\n\t\tclosed:    make(chan struct{}),\n\t\tshutdown:  make(chan struct{}),\n\t\twrTkn:     make(chan struct{}, 1),\n\t\tnstreams:  make(chan *Stream, 16),\n\t}\n\n\tgo mp.handleIncoming()\n\n\tmp.wrTkn <- struct{}{}\n\n\treturn mp\n}", "reference": "// NewMultiplex creates a new multiplexer session.", "generated": "The new stream is a single-byte buffer containing the name of an existing Stream object and its channel ID (if any). The channels are specified in bytes as follows:\n//Channel Name Channel Id Description string[] int [] charBuffer [ 8 ] //channel id number String[] byteBuffer [ 9 ], uint64_"}
{"id": 4242, "code": "func (b Box) Round() (lat, lng float64) {\n\tx := maxDecimalPower(b.MaxLat - b.MinLat)\n\tlat = math.Ceil(b.MinLat/x) * x\n\tx = maxDecimalPower(b.MaxLng - b.MinLng)\n\tlng = math.Ceil(b.MinLng/x) * x\n\treturn\n}", "reference": "// Round returns a point inside the box, making an effort to round to minimal\n// precision.", "generated": "Round is a method that returns the number of degrees to be rounded in an integer range from 0-255 inclusive for all inputs and negative values if no input or positive value has been specified by default. It also provides some useful properties such as rounding time based on current rotation speed; it can return either zero at any given"}
{"id": 4327, "code": "func (c *Client) DeleteCheckoutKey(account, repo, fingerprint string) error {\n\treturn c.request(\"DELETE\", fmt.Sprintf(\"project/%s/%s/checkout-key/%s\", account, repo, fingerprint), nil, nil, nil)\n}", "reference": "// DeleteCheckoutKey fetches the checkout key for the given project by fingerprint", "generated": "delete checks out key and returns a new checkouts list with the following properties :\nCursorPos := CursorPos + 1 if cursorPos > 0;\nCursorPos > -1 elseif cursorPosition < 2 ;\n\n\n// Check for duplicate keys in repository or branch history of project to be deleted from"}
{"id": 4332, "code": "func (c *Client) Timing(bucket string, value interface{}) {\n\tif c.skip() {\n\t\treturn\n\t}\n\tc.conn.metric(c.prefix, bucket, value, \"ms\", c.rate, c.tags)\n}", "reference": "// Timing sends a timing value to a bucket.", "generated": "// This method is called when the client sends a request to an endpoint and returns true if it succeeds or false otherwise.\n// The callback will be invoked once every 10 seconds for each tick of time elapsed since receiving this response.\n// If no success was returned by that timeout, then return nil .\n// Returns"}
{"id": 4333, "code": "func (t Timing) Send(bucket string) {\n\tt.c.Timing(bucket, int(t.Duration()/time.Millisecond))\n}", "reference": "// Send sends the time elapsed since the creation of the Timing.", "generated": "// This method sends a message to the bucket and returns an object with timestamps for each time interval in seconds that elapsed since receiving it from its caller. The returned objects are then passed along asynchronously back to their respective threads when they return or receive new messages after returning them; this is called synchronous sending"}
{"id": 4348, "code": "func SpatialEntropy(match match.Match, turns int, shiftCount int) float64 {\n\tvar s, d float64\n\tif match.DictionaryName == \"qwerty\" || match.DictionaryName == \"dvorak\" {\n\t\t//todo: verify qwerty and dvorak have the same length and degree\n\t\ts = float64(len(adjacency.BuildQwerty().Graph))\n\t\td = adjacency.BuildQwerty().CalculateAvgDegree()\n\t} else {\n\t\ts = float64(keyPadStartingPositions)\n\t\td = keyPadAvgDegree\n\t}\n\n\tpossibilities := float64(0)\n\n\tlength := float64(len(match.Token))\n\n\t//TODO: Should this be <= or just < ?\n\t//Estimate the number of possible patterns w/ length L or less with t turns or less\n\tfor i := float64(2); i <= length+1; i++ {\n\t\tpossibleTurns := math.Min(float64(turns), i-1)\n\t\tfor j := float64(1); j <= possibleTurns+1; j++ {\n\t\t\tx := zxcvbnmath.NChoseK(i-1, j-1) * s * math.Pow(d, j)\n\t\t\tpossibilities += x\n\t\t}\n\t}\n\n\tentropy := math.Log2(possibilities)\n\t//add extra entropu for shifted keys. ( % instead of 5 A instead of a)\n\t//Math is similar to extra entropy for uppercase letters in dictionary matches.\n\n\tif S := float64(shiftCount); S > float64(0) {\n\t\tpossibilities = float64(0)\n\t\tU := length - S\n\n\t\tfor i := float64(0); i < math.Min(S, U)+1; i++ {\n\t\t\tpossibilities += zxcvbnmath.NChoseK(S+U, i)\n\t\t}\n\n\t\tentropy += math.Log2(possibilities)\n\t}\n\n\treturn entropy\n}", "reference": "// SpatialEntropy calculates the entropy for spatial matches", "generated": "The following example uses an algorithm that can generate random numbers from any given string as long it has at least one character set equal by 1 byte per line on each side of its first occurrence within range 0 through 255 inclusive characters using two different strings representing all occurrences between zero bytes beginning after their initial position inside ranges 100000 up"}
{"id": 4354, "code": "func Null(in []byte, pos int) (int, error) {\n\tswitch in[pos] {\n\tcase 'n':\n\t\treturn expect(in, pos, n...)\n\t\treturn pos + 4, nil\n\tdefault:\n\t\treturn 0, errUnexpectedValue\n\t}\n}", "reference": "// Null verifies the contents of bytes provided is a null starting as pos", "generated": "// This function returns an array of bytes. The first byte is the number that was returned by this method and the second byte is the value from a string representation to be used as the initializer for subsequent calls. If no strings are provided then it defaults back into its original state with zero or more values remaining after calling"}
{"id": 4404, "code": "func (b *Base64) SetBSON(raw bson.Raw) error {\n\tvar m bson.M\n\tif err := raw.Unmarshal(&m); err != nil {\n\t\treturn err\n\t}\n\n\tif data, ok := m[\"data\"].(string); ok {\n\t\t*b = Base64(data)\n\t\treturn nil\n\t}\n\n\treturn errors.New(\"couldn't unmarshal bson raw value as Base64\")\n}", "reference": "// SetBSON sets the Base64 from raw bson data", "generated": "// Initializes the base64 encoding for a string and returns it if any of its elements are not null or non-null .\n// Returns an array containing all values in that range with their corresponding bytes encoded to be used by BSONs on strings , including those from other sources suchas arrays stored within them."}
{"id": 4413, "code": "func (e *Email) UnmarshalEasyJSON(in *jlexer.Lexer) {\n\tif data := in.String(); in.Ok() {\n\t\t*e = Email(data)\n\t}\n}", "reference": "// UnmarshalEasyJSON sets the Email from a easyjson.Lexer", "generated": "This method is a wrapper around the JSON API, which provides an easy way to create and retrieve email addresses from any URL that you specify as part of your application's request body. It also allows for customizing how it handles requests with respect not only their content but its headers too. The following example shows what this can"}
{"id": 4422, "code": "func (u *IPv6) DeepCopy() *IPv6 {\n\tif u == nil {\n\t\treturn nil\n\t}\n\tout := new(IPv6)\n\tu.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new IPv6.", "generated": "// This function is a wrapper around the IPv4 deepcopy method, which returns an int64 encoded string that can be used to encode any number of bytes in memory at once for use with IPv6 addresses and other protocols such as UDP or TCP/UDP connections. The implementation uses this encoding scheme so it does"}
{"id": 4452, "code": "func (h *HexColor) DeepCopy() *HexColor {\n\tif h == nil {\n\t\treturn nil\n\t}\n\tout := new(HexColor)\n\th.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new HexColor.", "generated": "// This function is a wrapper around the HEX color scheme, which can be used to create an array of hexadecimal colors for use in other programs or as input into any program that uses it // by calling this method on its own instance of HexColor().\n// The following code snippet creates two arrays with"}
{"id": 4466, "code": "func (t DateTime) MarshalJSON() ([]byte, error) {\n\tvar w jwriter.Writer\n\tt.MarshalEasyJSON(&w)\n\treturn w.BuildBytes()\n}", "reference": "// MarshalJSON returns the DateTime as JSON", "generated": "// This method returns a JSON object that can be used to build the serialized string from an array of strings and return it as raw data in time format for use with Serialization::Serialize().\n// The returned json is then converted into bytecode using TimeFormatUtils . ConvertToBytecode(time."}
{"id": 4474, "code": "func (d *Duration) Scan(raw interface{}) error {\n\tswitch v := raw.(type) {\n\t// TODO: case []byte: // ?\n\tcase int64:\n\t\t*d = Duration(v)\n\tcase float64:\n\t\t*d = Duration(int64(v))\n\tcase nil:\n\t\t*d = Duration(0)\n\tdefault:\n\t\treturn fmt.Errorf(\"cannot sql.Scan() strfmt.Duration from: %#v\", v)\n\t}\n\n\treturn nil\n}", "reference": "// Scan reads a Duration value from database driver type.", "generated": "This method scans the string to determine if a given type is valid and returns an object of that kind, or null for any other types in this context. The returned objects are then passed along as arguments into the scan function which will be called when it finds all possible values on each element within its range with no errors encountered"}
{"id": 4491, "code": "func (d *Date) DeepCopy() *Date {\n\tif d == nil {\n\t\treturn nil\n\t}\n\tout := new(Date)\n\td.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new Date.", "generated": "// This function is a wrapper around the DBCL, which provides an interface to deepcopy and returns true if it succeeds or false otherwise; in other words for any error encountered by this method that does not return True .\n// The implementation of these functions can be found at http://www-dbl/deep"}
{"id": 4522, "code": "func GrepNot(r string) Filter {\n\tre, err := regexp.Compile(r)\n\tif err != nil {\n\t\treturn FilterFunc(func(Arg) error { return err })\n\t}\n\treturn If(func(s string) bool { return !re.MatchString(s) })\n}", "reference": "// GrepNot emits every input x that does not match the regular expression r.", "generated": "GprFilter is a filter that returns the results of an unary search for strings in r . It can be used to perform any sort or reverse lookup on all occurrences within it (including those from which no matching match was found). The default value is false if there are not enough matches and true otherwise. This function"}
{"id": 4537, "code": "func FetchVersion(v discovery.ServerVersionInterface) (ret ServerVersion, err error) {\n\tversion, err := v.ServerVersion()\n\tif err != nil {\n\t\treturn ServerVersion{}, err\n\t}\n\treturn ParseVersion(version)\n}", "reference": "// FetchVersion fetches version information from discovery client, and parses", "generated": "Fuzzy version checking is performed on the server and returns a list of versions that are available for testing purposes in order to verify compatibility with other servers or applications running under it. The default value will be 0 if no tests have been run against this particular client/server instance since its initial release date; 1 otherwise means"}
{"id": 4543, "code": "func (n ImageName) RegistryRepoName() string {\n\trepo := n.Repository\n\tif repo == \"\" {\n\t\trepo = \"library\"\n\t}\n\treturn fmt.Sprintf(\"%s/%s\", repo, n.Name)\n}", "reference": "// RegistryRepoName returns the \"repository\" as used in the registry URL", "generated": "This function returns a registry reposession object that contains the name of the repository to which it is returned from. It can be used as an alias for any other named repositories in your application or by calling this method on all instances where you want them stored and then returning nil . The default value will return None if no"}
{"id": 4556, "code": "func MarkdownHelper(body string, help HelperContext) (template.HTML, error) {\n\tvar err error\n\tif help.HasBlock() {\n\t\tbody, err = help.Block()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\tb := github_flavored_markdown.Markdown([]byte(body))\n\treturn template.HTML(b), err\n}", "reference": "// Markdown converts the string into HTML using GitHub flavored markdown.", "generated": "// This helper is a wrapper around the HTML helpers provided by markdown and provides an interface to generate markup for your code in plain text format using inline-block syntax // with no special formatting or other restrictions on how it can be used as input/output; this implementation does not support any of these features yet but will"}
{"id": 4565, "code": "func (t *Template) Exec(ctx hctx.Context) (string, error) {\n\terr := t.Parse()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tev := compiler{\n\t\tctx:     ctx,\n\t\tprogram: t.program,\n\t}\n\n\ts, err := ev.compile()\n\treturn s, err\n}", "reference": "// Exec the template using the content and return the results", "generated": "// Compiles a template to the specified language and returns an output string if it is found in that locale or not.\n // The default value of `c++` will be used for all templates created with this function.\n/**\n* This method creates new instances from existing ones using TemplateBuilder::newInstance()."}
{"id": 4576, "code": "func hasPathPrefix(p string, s map[string]string) bool {\n\tfor prefix := range s {\n\t\tif strings.HasPrefix(p, prefix+\"/\") {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "reference": "// hasPathPrefix returns true if any of s is the prefix of p.", "generated": "// Returns the path to a file that contains all of its contents in one go (or nil if no files exist).\n // This is useful for debugging purposes only and should not be used as an alternative to `path` or `map`. It returns either \"true\", or null .\n\n func main() {}"}
{"id": 4588, "code": "func (a *Args) similar(r *Args, similar Similarity) bool {\n\tif a.Elided != r.Elided || len(a.Values) != len(r.Values) {\n\t\treturn false\n\t}\n\tif similar == AnyValue {\n\t\treturn true\n\t}\n\tfor i, l := range a.Values {\n\t\tswitch similar {\n\t\tcase ExactFlags, ExactLines:\n\t\t\tif l != r.Values[i] {\n\t\t\t\treturn false\n\t\t\t}\n\t\tdefault:\n\t\t\tif l.IsPtr() != r.Values[i].IsPtr() || (!l.IsPtr() && l != r.Values[i]) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\treturn true\n}", "reference": "// similar returns true if the two Args are equal or almost but not quite\n// equal.", "generated": "The returned values can be any of these options :\n// Returns True for all elements that match or none , otherwise Return Nothing // to prevent duplicate matches from occurring on"}
{"id": 4597, "code": "func (s *Stack) merge(r *Stack) *Stack {\n\t// Assumes similar stacks have the same length.\n\tout := &Stack{\n\t\tCalls:  make([]Call, len(s.Calls)),\n\t\tElided: s.Elided,\n\t}\n\tfor i := range s.Calls {\n\t\tout.Calls[i] = s.Calls[i].merge(&r.Calls[i])\n\t}\n\treturn out\n}", "reference": "// merge merges two similar Stack, zapping out differences.", "generated": "This function merges a stack of two different types and returns an array containing all elements in that type's list as well with no additional information about which element is being merged or whether it has been removed from the original collection by calling this method on each iteration. The resulting arrays are then sorted into ascending order based upon their"}
{"id": 4624, "code": "func (b *base57) stringToNum(s string) (string, error) {\n\tn := big.NewInt(0)\n\n\tfor i := len(s) - 1; i >= 0; i-- {\n\t\tn.Mul(n, big.NewInt(b.alphabet.Length()))\n\n\t\tindex, err := b.alphabet.Index(string(s[i]))\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\n\t\tn.Add(n, big.NewInt(index))\n\t}\n\n\tx := fmt.Sprintf(\"%x\", n)\n\n\tif len(x) < 32 {\n\t\t// Pad the most significant bit (MSG) with 0 (zero) if the string is too short.\n\t\tx = strings.Repeat(\"0\", 32-len(x)) + x\n\t} else if len(x) > 32 {\n\t\treturn \"\", fmt.Errorf(\"UUID length overflow for %q\", s)\n\t}\n\n\treturn fmt.Sprintf(\"%s-%s-%s-%s-%s\", x[0:8], x[8:12], x[12:16], x[16:20], x[20:32]), nil\n}", "reference": "// stringToNum converts a string a number using the given alpabet.", "generated": "This function returns a new int representing the number of characters in the current buffer and an integer representation of its size that represents the total amount of bytes to be written by this character at each iteration. The resulting value can be used as a starting point or any other suitable data structure such which may provide additional information about how long"}
{"id": 4644, "code": "func (geoIndex *geoIndex) AddEntryAt(point Point) interface{} {\n\tsquare := cellOf(point, geoIndex.resolution)\n\n\tif _, ok := geoIndex.index[square]; !ok {\n\t\tgeoIndex.index[square] = geoIndex.newEntry()\n\t}\n\n\treturn geoIndex.index[square]\n}", "reference": "// AddEntryAt adds an entry if missing, returns the entry at specific position.", "generated": "Add entry at point to the map of geocodes and add a new node for each location in the list that contains an address field or index value from within this mapping object's scope. The returned nodes are added as part \"add\" entries into the array containing coordinates between points on which they were previously located by adding"}
{"id": 4662, "code": "func BearingTo(p1, p2 Point) float64 {\n\tdLon := toRadians(p2.Lon() - p1.Lon())\n\n\tlat1 := toRadians(p1.Lat())\n\tlat2 := toRadians(p2.Lat())\n\n\ty := math.Sin(dLon) * math.Cos(lat2)\n\tx := math.Cos(lat1)*math.Sin(lat2) -\n\t\tmath.Sin(lat1)*math.Cos(lat2)*math.Cos(dLon)\n\tbrng := toDegrees(math.Atan2(y, x))\n\n\treturn brng\n}", "reference": "// BearingTo returns the bearing from p1 to p2", "generated": "The bearing method is a simple and efficient way of calculating the angle between two points in an array using radian coordinates (or any other coordinate system). The following example shows how to compute this by simply dividing both angles into degrees or fractions with radius 1/3 . This will give you some useful results for your application when"}
{"id": 4720, "code": "func AddRelayTransport(ctx context.Context, h host.Host, upgrader *tptu.Upgrader, opts ...RelayOpt) error {\n\tn, ok := h.Network().(tpt.Network)\n\tif !ok {\n\t\treturn fmt.Errorf(\"%v is not a transport network\", h.Network())\n\t}\n\n\tr, err := NewRelay(ctx, h, upgrader, opts...)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// There's no nice way to handle these errors as we have no way to tear\n\t// down the relay.\n\t// TODO\n\tif err := n.AddTransport(r.Transport()); err != nil {\n\t\tlog.Error(\"failed to add relay transport:\", err)\n\t} else if err := n.Listen(r.Listener().Multiaddr()); err != nil {\n\t\tlog.Error(\"failed to listen on relay transport:\", err)\n\t}\n\treturn nil\n}", "reference": "// AddRelayTransport constructs a relay and adds it as a transport to the host network.", "generated": "This function adds an additional relaying service that will be used for each of its clients and servers in order create new connections between them using UDP or TCP/IP protocols (see below). The client must provide some information about their connection status before it can connect with any other server; this info may include whether they are connected"}
{"id": 4731, "code": "func NewServer() http.Handler {\n\tr := mux.NewRouter()\n\tr.Path(\"/hello\").Methods(\"GET\").HandlerFunc(handleHello)\n\treturn r\n}", "reference": "// NewServer makes a new example server.", "generated": "This method returns a new server instance that implements the protocol described in RFC 6455, and provides access to all of its methods (including those defined by this class). The interface is provided as follows:\n\n```\n// This implementation uses MIXER's `newserver` for routing requests from an existing router into"}
{"id": 4742, "code": "func StringFindBetween(s, start, stop string) (between, remainder string, found bool) {\n\tbegin := strings.Index(s, start)\n\tif begin == -1 {\n\t\treturn \"\", s, false\n\t}\n\tbetween = s[begin+len(start):]\n\tend := strings.Index(between, stop)\n\tif end == -1 {\n\t\treturn \"\", s, false\n\t}\n\treturn between[:end], s[begin+len(start)+end+len(stop):], true\n}", "reference": "// StringFindBetween returns the string between the first occurrences of the tokens start and stop.\n// The remainder of the string after the stop token will be returned if found.\n// If the tokens couldn't be found, then the whole string will be returned as remainder.", "generated": "String FindBetween returns a list of the elements in an array that are separated by commas and terminated with . The resulting result is returned as follows :\n\npackage main import ( \"fmt\" )\nimport os\nimport sys , strconv\ndef __init__ ( self ): \"\"\"Initialize Strconv\"\"\""}
{"id": 4755, "code": "func HTTPPostJSON(url string, data interface{}) error {\n\tb, err := json.MarshalIndent(data, \"\", \"  \")\n\tif err != nil {\n\t\treturn err\n\t}\n\tresponse, err := http.Post(url, \"application/json\", bytes.NewBuffer(b))\n\tif err == nil && (response.StatusCode < 200 || response.StatusCode > 299) {\n\t\terr = errors.New(response.Status)\n\t}\n\treturn err\n}", "reference": "// HTTPPostJSON marshalles data as JSON\n// and sends it as HTTP POST request to url.\n// If the response status code is not 200 OK,\n// then the status is returned as an error.", "generated": "HTTP POST JSON is a simple and efficient way to send an object of type String or any other format that can be used as the first parameter for sending messages in your application's web server environment. It provides two main advantages over standard methods such Async , which are not supported by most browsers but may work well with some"}
{"id": 4764, "code": "func FileSize(filename string) int64 {\r\n\tinfo, err := os.Stat(filename)\r\n\tif err != nil {\r\n\t\treturn 0\r\n\t}\r\n\treturn info.Size()\r\n}", "reference": "// FileSize returns the size of a file or zero in case of an error.", "generated": "This function returns the size of a file in bytes (in this case 32-bit). The default is 64 bits for Windows and 128 bits if not specified otherwise. This can be used to specify an arbitrary number of files or directories that are large enough to fit into one directory on your system without having to worry about overw"}
{"id": 4781, "code": "func LoadTOMLBytes(conf interface{}, src []byte) error {\n\treturn loadConfigBytes(conf, src, nil, toml.Unmarshal)\n}", "reference": "// LoadTOMLBytes loads TOML bytes", "generated": "This function loads the byte[] from a config file and returns it as an array of bytes in binary format (binary-encoded). The returned string is then converted into ASCII by calling init() . This will return all values that are present on this module's stack when loaded with Init(). If no value was found for"}
{"id": 4787, "code": "func Crop(img image.Image, c Config) (image.Image, error) {\n\tmaxBounds := c.maxBounds(img.Bounds())\n\tsize := c.computeSize(maxBounds, image.Point{c.Width, c.Height})\n\tcr := c.computedCropArea(img.Bounds(), size)\n\tcr = img.Bounds().Intersect(cr)\n\n\tif c.Options&Copy == Copy {\n\t\treturn cropWithCopy(img, cr)\n\t}\n\tif dImg, ok := img.(subImageSupported); ok {\n\t\treturn dImg.SubImage(cr), nil\n\t}\n\treturn cropWithCopy(img, cr)\n}", "reference": "// Crop retrieves an image that is a\n// cropped copy of the original img.\n//\n// The crop is made given the informations provided in config.", "generated": "// Create a new Image with the specified width and height as parameters to create an alternate cropped area for each pixel in the selected rectangle of the canvas that is not already included by this method. // This will be used when creating additional images from existing PNG files or if there are no other options available on your system such methods"}
{"id": 4788, "code": "func (c Config) computeSize(bounds image.Rectangle, ratio image.Point) (p image.Point) {\n\tif c.Options&Ratio == Ratio {\n\t\t// Ratio option is on, so we take the biggest size available that fit the given ratio.\n\t\tif float64(ratio.X)/float64(bounds.Dx()) > float64(ratio.Y)/float64(bounds.Dy()) {\n\t\t\tp = image.Point{bounds.Dx(), (bounds.Dx() / ratio.X) * ratio.Y}\n\t\t} else {\n\t\t\tp = image.Point{(bounds.Dy() / ratio.Y) * ratio.X, bounds.Dy()}\n\t\t}\n\t} else {\n\t\tp = image.Point{ratio.X, ratio.Y}\n\t}\n\treturn\n}", "reference": "// computeSize retrieve the effective size of the cropped image.\n// It is defined by Height, Width, and Ratio option.", "generated": "The following example calculates a scaled-down version of an ImageView with respect to its dimensions and widths in order for it's scaling properties such as height and depth not affected by any other aspect of this Scale property or scaleFactor . The resulting view will be displayed at 640 x 480 pixels per inch when used within Windows"}
{"id": 4790, "code": "func NewThen(command string, args ...string) Then {\n\treturn &gitCmd{command: command, args: args}\n}", "reference": "// NewThen creates a new Then command.", "generated": "NewThen is a new GitCommand that creates an instance of the Command object. It returns nil if it does not exist or contains no arguments and has only one argument to be passed as its first parameter. The default value for this function is \"nil\". If there is any other option available in your configuration file (e"}
{"id": 4792, "code": "func (g *gitCmd) Command() string {\n\treturn g.command + \" \" + strings.Join(g.args, \" \")\n}", "reference": "// Command returns the full command as configured in Caddyfile.", "generated": "Command returns a command object that contains the specified arguments and optionally an optional argument to be passed as parameters for commands in which they are defined or used by GitCommands . Commands can also contain any of several other options such like :set , :delete_all , etc., but these will not work with all versions except"}
{"id": 4812, "code": "func (r *Repo) pull() error {\n\n\t// if not pulled, perform clone\n\tif !r.pulled {\n\t\treturn r.clone()\n\t}\n\n\t// if latest tag config is set\n\tif r.Branch == latestTag {\n\t\treturn r.checkoutLatestTag()\n\t}\n\n\tparams := append([]string{\"pull\"}, append(r.PullArgs, \"origin\", r.Branch)...)\n\tvar err error\n\tif err = r.gitCmd(params, r.Path); err == nil {\n\t\tr.pulled = true\n\t\tr.lastPull = time.Now()\n\t\tLogger().Printf(\"%v pulled.\\n\", r.URL)\n\t\tr.lastCommit, err = r.mostRecentCommit()\n\t}\n\treturn err\n}", "reference": "// pull performs git pull, or git clone if repository does not exist.", "generated": "/// Returns the current branch of a repo that has been merged with another repository in this directory.\n# Examples include ```github.com/rust-lang/\u200bRust/tree/master`` and `githubusercontent.*/*/***.md5`.cplusplus.org`` #\nfn main (){ // check"}
{"id": 4815, "code": "func (r *Repo) Prepare() error {\n\t// check if directory exists or is empty\n\t// if not, create directory\n\tfs, err := gos.ReadDir(r.Path)\n\tif err != nil || len(fs) == 0 {\n\t\treturn gos.MkdirAll(r.Path, os.FileMode(0755))\n\t}\n\n\t// validate git repo\n\tisGit := false\n\tfor _, f := range fs {\n\t\tif f.IsDir() && f.Name() == \".git\" {\n\t\t\tisGit = true\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif isGit {\n\t\t// check if same repository\n\t\tvar repoURL string\n\t\tif repoURL, err = r.originURL(); err == nil {\n\t\t\tif strings.TrimSuffix(repoURL, \".git\") == strings.TrimSuffix(r.URL.Val(), \".git\") {\n\t\t\t\tr.pulled = true\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"cannot retrieve repo url for %v Error: %v\", r.Path, err)\n\t\t}\n\t\treturn fmt.Errorf(\"another git repo '%v' exists at %v\", repoURL, r.Path)\n\t}\n\treturn fmt.Errorf(\"cannot git clone into %v, directory not empty\", r.Path)\n}", "reference": "// Prepare prepares for a git pull\n// and validates the configured directory", "generated": "This function checks whether the given path contains a Git subdirectory and returns an output of \"C:\\Program Files\\Microsoft Visual Studio 2010 R2\". The returned result will be used to generate new files in your project that you can use as repositories on Windows XP/Vista with no additional configuration required by Microsoft's documentation"}
{"id": 4819, "code": "func (g *gitCmd) Stdin(stdin io.Reader) {\n\tg.Cmd.Stdin = stdin\n}", "reference": "// Stdin sets the process's standard input.", "generated": "// This function returns a string containing the current buffer and its contents, if any.\n // The returned value is an array of strings with length 0xFFFFFFF .\nreturn g{}, nil , [] }"}
{"id": 4831, "code": "func (t TravisHook) handleSignature(r *http.Request, secret string) error {\n\tsignature := r.Header.Get(\"Authorization\")\n\tif signature == \"\" {\n\t\treturn errors.New(\"request sent no authorization signature\")\n\t}\n\tif secret == \"\" {\n\t\tLogger().Print(\"Unable to verify request signature. Secret not set in caddyfile!\\n\")\n\t\treturn nil\n\t}\n\n\tcontent := r.Header.Get(\"Travis-Repo-Slug\") + secret\n\thash := sha256.Sum256([]byte(content))\n\texpectedMac := hex.EncodeToString(hash[:])\n\tif signature != expectedMac {\n\t\tfmt.Println(signature, expectedMac)\n\t\treturn errors.New(\"Invalid authorization header\")\n\t}\n\treturn nil\n}", "reference": "// Check for an authorization signature in the request. Reject if not present. If validation required, check the sha", "generated": "// Handle the signing of a signed certificate using an authorized key and/or hash from http://www1.example.com/. The following example uses https for authentication purposes only; it is intended as general purpose code execution by users who are familiar with this protocol or its implementation details but do not wish their certificates compromised due"}
{"id": 4833, "code": "func hookName(h hookHandler) string {\n\tfor name, handler := range handlers {\n\t\tif handler == h {\n\t\t\treturn name\n\t\t}\n\t}\n\treturn \"\"\n}", "reference": "// hookName returns the name of the hookHanlder h.", "generated": "hookNames is a wrapper around the Hooks interface. It provides an API for creating and retrieving hooks from any given URL or url type (e., \"http://example.\"). The default implementation of hooknames uses JSON as its primary data source; it does not provide support for other types of methods such that you can"}
{"id": 4861, "code": "func (u *URL) Short() string {\n\tif u.Scheme == \"\" {\n\t\treturn \"\"\n\t}\n\n\ts := schemeMap[u.Scheme].Aliases[0]\n\n\tif u.Scheme == \"odbc\" || u.Scheme == \"oleodbc\" {\n\t\tn := u.Proto\n\t\tif v, ok := schemeMap[n]; ok {\n\t\t\tn = v.Aliases[0]\n\t\t}\n\t\ts += \"+\" + n\n\t} else if u.Proto != \"tcp\" {\n\t\ts += \"+\" + u.Proto\n\t}\n\n\ts += \":\"\n\n\tif u.User != nil {\n\t\tif un := u.User.Username(); un != \"\" {\n\t\t\ts += un + \"@\"\n\t\t}\n\t}\n\n\tif u.Host != \"\" {\n\t\ts += u.Host\n\t}\n\n\tif u.Path != \"\" && u.Path != \"/\" {\n\t\ts += u.Path\n\t}\n\n\tif u.Opaque != \"\" {\n\t\ts += u.Opaque\n\t}\n\n\treturn s\n}", "reference": "// Short provides a short description of the user, host, and database.", "generated": "// This function returns a list of strings that are the same as their names in this case. The first two bytes should be empty and must not contain any characters other than whitespace or capital letters; otherwise they will return an error message when encountered with no matching character set to match them. // Returns true for all sequences"}
{"id": 4873, "code": "func (e *hdbError) Error() string {\n\tif e.stmtNo != -1 {\n\t\treturn fmt.Sprintf(\"SQL %s %d - %s (statement no: %d)\", e.errorLevel, e.errorCode, e.errorText, e.stmtNo)\n\t}\n\treturn fmt.Sprintf(\"SQL %s %d - %s\", e.errorLevel, e.errorCode, e.errorText)\n}", "reference": "// Error implements the Error interface.", "generated": "This function returns a SQL statement that contains the error message and an exception status code for the specified condition or exceptions thrown by this method of execution. The result is returned as JSON formatted strings with all errors in their respective fields set to nil . If there are any missing values from the query field it will be converted into null"}
{"id": 4883, "code": "func StringSize(s string) int {\n\tn := 0\n\tfor _, r := range s {\n\t\tn += RuneLen(r)\n\t}\n\treturn n\n}", "reference": "// StringSize is like Size with a string as parameter.", "generated": "String size() returns the number of bytes in a given length. The default is 32 bits for strings with no characters or numbers and 64 bit integers are supported as well. It can be used to specify an arbitrary value by passing it into the function's constructor method (see below). This will return either 1 byte if there"}
{"id": 4887, "code": "func On() bool {\n\ttracer.mu.RLock()\n\ton := tracer.on\n\ttracer.mu.RUnlock()\n\treturn on\n}", "reference": "// On returns if tracing methods output is active.", "generated": "// This method is called when the lock has been unlocked and no other locks are available to perform a task, such as calling an unlock operation or performing another action in progress. The // default value of this function will be set by Tracer's implementation if it was not defined before (see below).\n// Note that"}
{"id": 4913, "code": "func (r *Reader) ReadUint32() uint32 {\n\tif r.err != nil {\n\t\treturn 0\n\t}\n\tvar n int\n\tn, r.err = io.ReadFull(r.rd, r.b[:4])\n\tr.cnt += n\n\tif r.err != nil {\n\t\treturn 0\n\t}\n\treturn binary.LittleEndian.Uint32(r.b[:4])\n}", "reference": "// ReadUint32 reads and returns an uint32.", "generated": "// This function reads the full string from a buffer and returns an unsigned integer if it is not found in the current read stream. The returned value of this method should be either zero or one-half as long for non-zero bytes to match any given length on disk space with no errors encountered during reading operations such that"}
{"id": 4918, "code": "func (r *Reader) ReadCesu8(size int) []byte {\n\tif r.err != nil {\n\t\treturn nil\n\t}\n\tp := make([]byte, size)\n\tvar n int\n\tn, r.err = io.ReadFull(r.rd, p)\n\tr.cnt += n\n\tif r.err != nil {\n\t\treturn nil\n\t}\n\tr.tr.Reset()\n\tif n, _, r.err = r.tr.Transform(p, p, true); r.err != nil { // inplace transformation\n\t\treturn nil\n\t}\n\treturn p[:n]\n}", "reference": "// ReadCesu8 reads a size CESU-8 encoded byte sequence and returns an UTF-8 byte slice.", "generated": "// This function is used to create a new buffer and store the contents of the current file into it for later use by calling this method on an existing one or more buffers that are already created with `new` methods such as read(), write(). The return value will be returned from each call if there were no previous calls"}
{"id": 4923, "code": "func (w *Writer) Write(p []byte) {\n\tif w.err != nil {\n\t\treturn\n\t}\n\tw.wr.Write(p)\n}", "reference": "// Write writes the contents of p.", "generated": "// This function is used to write a string of bytes, and returns the result if it succeeds. It also checks for errors in its output buffer before returning.\n // The return value should be an integer or float that represents how many times this process has failed with no error message returned by fmt.Errorf."}
{"id": 4938, "code": "func (c *Connector) Locale() string {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\treturn c.locale\n}", "reference": "// Locale returns the locale of the connector.", "generated": "This method is used to lock the connection of a given module or class, and returns an error if it does not exist in that context for any reason other than being unable access its local storage space by calling this methods on all modules/classes with which they are associated at runtime. The returned value will be null . If"}
{"id": 4942, "code": "func (c *Connector) SetTLSConfig(tlsConfig *tls.Config) error {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.tlsConfig = tlsConfig\n\treturn nil\n}", "reference": "// SetTLSConfig sets the TLS configuration of the connector.", "generated": "This method sets TLS configuration to the specified TSL config file, and returns a new connection object for each session that is connected with it. The default value of this function will be set by calling connect(). This callback should only occur once per client request or if there are multiple sessions in an existing network context using TCP/"}
{"id": 4958, "code": "func Slice(arr []byte, count int) [][]byte {\n\n\tsliceCount := len(arr) / count\n\tresult := make([][]byte, sliceCount)\n\n\tfor i := 0; i < sliceCount; i++ {\n\t\tstart := i * count\n\t\tend := i*count + count\n\n\t\tresult[i] = arr[start:end]\n\t}\n\n\treturn result\n}", "reference": "// Slice is splitting input byte array into slice of subarrays. Each of count length.", "generated": "Slices are a type of Array. The following example creates an array with the same length as its first element and returns it to the caller for each iteration in which this is done (as opposed \"slice\"): // create an empty string from start to end using `[]` var strArray : String\nDescription"}
{"id": 4965, "code": "func Decode(data string) ([]byte,error) {\n\tdata = strings.Replace(data, \"-\", \"+\", -1) // 62nd char of encoding\n\tdata = strings.Replace(data, \"_\", \"/\", -1) // 63rd char of encoding\n\t\n\tswitch(len(data) % 4) { // Pad with trailing '='s\n\t\tcase 0:             // no padding\n\t\tcase 2: data+=\"==\"  // 2 pad chars\n\t\tcase 3:\tdata+=\"=\"   // 1 pad char\t\t\n\t}\n\t\t\n\treturn base64.StdEncoding.DecodeString(data)\n}", "reference": "// Decode decodes base64url string to byte array", "generated": "This function decodes a byte array containing the encoded text and returns an error if it fails to decode or not at all in case there is any missing characters that need to be converted back into ASCII code for decoding purposes. The resulting character set can then be used as input by other programs using this method on their own program"}
{"id": 4969, "code": "func DerivePBKDF2(password, salt []byte, iterationCount, keyBitLength int, h hash.Hash) []byte {\n\n\tprf := hmac.New(func() hash.Hash { return h }, password)\n\thLen := prf.Size()\n\tdkLen := keyBitLength >> 3 //size of derived key in bytes\n\n\tl := int(math.Ceil(float64(dkLen) / float64(hLen))) // l = CEIL (dkLen / hLen)\n\tr := dkLen - (l-1)*hLen\n\n\t// 1. If dkLen > (2^32 - 1) * hLen, output \"derived key too long\" and stop.\n\tif dkLen > MaxInt {\n\t\tpanic(fmt.Sprintf(\"kdf.DerivePBKDF2: expects derived key size to be not more that (2^32-1) bits, but was requested %v bits.\", keyBitLength))\n\t}\n\n\tdk := make([]byte, 0, dkLen)\n\n\tfor i := 0; i < l; i++ {\n\n\t\tt := f(salt, iterationCount, i+1, prf) // T_l = F (P, S, c, l)\n\n\t\tif i == (l - 1) {\n\t\t\tt = t[:r]\n\t\t} // truncate last block to r bits\n\n\t\tdk = append(dk, t...) // DK = T_1 || T_2 ||  ...  || T_l<0..r-1>\n\t}\n\n\treturn dk\n}", "reference": "// DerivePBKDF2 implements Password Based Key Derivation Function 2, RFC 2898. Derives key of keyBitLength size, given password, salt, iteration count and hash function", "generated": "The function derive PBKEF2 returns a new byte pair with the same length as its original value if it is an integer or unsigned char . The returned string must contain at least one character from either side except for characters which are nonzero when used on strings containing zero digits after their initial digitization time period , where"}
{"id": 4970, "code": "func ReadPrivate(raw []byte) (key *ecdsa.PrivateKey,err error) {\n\tvar encoded *pem.Block\n\n\tif encoded, _ = pem.Decode(raw); encoded == nil {\n\t\treturn nil, errors.New(\"Ecc.ReadPrivate(): Key must be PEM encoded PKCS1 or PKCS8 EC private key\")\n\t}\n\n\tvar parsedKey interface{}\n\n\tif parsedKey,err=x509.ParseECPrivateKey(encoded.Bytes);err!=nil {\n\t\tif parsedKey, err = x509.ParsePKCS8PrivateKey(encoded.Bytes);err!=nil {\n\t\t\treturn nil,err\n\t\t}\n\t}\n\n\tvar ok bool\n\t\t\n\tif key,ok=parsedKey.(*ecdsa.PrivateKey);!ok {\n\t\treturn nil, errors.New(\"Ecc.ReadPrivate(): Key is not valid *ecdsa.PrivateKey\")\n\t}\n\t\n\treturn key,nil\n}", "reference": "// ReadPrivate loads ecdsa.PrivateKey from given PKCS1 or PKCS8 blobs", "generated": "// This function reads the public keys of a given encrypted file and returns an array containing all bytes in that data set to 0 for each byte on which it was read from this buffer // The returned hash will contain information about how many bits are needed before we can write any further code here if necessary\n// If no other"}
{"id": 4978, "code": "func (c *Consumer) TailingLogs(appGuid, authToken string) (<-chan *events.LogMessage, <-chan error) {\n\treturn c.tailingLogs(appGuid, authToken, true)\n}", "reference": "// TailingLogs listens indefinitely for log messages only; other event types\n// are dropped.\n// Whenever an error is encountered, the error will be sent down the error\n// channel and TailingLogs will attempt to reconnect up to 5 times.  After\n// five failed reconnection attempts, TailingLogs will give up and close the\n// error and LogMessage channels.\n//\n// If c is closed, the returned channels will both be closed.\n//\n// Errors must be drained from the returned error channel for it to continue\n// retrying; if they are not drained, the connection attempts will hang.", "generated": "Tails logs a log message to the specified user's account and returns an event that is logged on by default for each of those users in connection with this application. The logging messages are sent asynchronously from one or more threads running concurrently at once using threadpool API calls such AsyncTaskQueue . This method provides"}
{"id": 4980, "code": "func (c *Consumer) Stream(appGuid string, authToken string) (outputChan <-chan *events.Envelope, errorChan <-chan error) {\n\treturn c.runStream(appGuid, authToken, true)\n}", "reference": "// Stream listens indefinitely for all log and event messages.\n//\n// Messages are presented in the order received from the loggregator server.\n// Chronological or other ordering is not guaranteed. It is the responsibility\n// of the consumer of these channels to provide any desired sorting mechanism.\n//\n// Whenever an error is encountered, the error will be sent down the error\n// channel and Stream will attempt to reconnect indefinitely.", "generated": "This stream is a wrapper around the consumer interface of Consumer . It provides an API for creating and receiving streams from user-defined APIs using std::stream , which can be used to create or receive messages in any order you wish; it also supports sending/receiving data as well as serialization via JSON format strings"}
{"id": 5001, "code": "func (d *Dataset) Snapshot(name string, recursive bool) (*Dataset, error) {\n\targs := make([]string, 1, 4)\n\targs[0] = \"snapshot\"\n\tif recursive {\n\t\targs = append(args, \"-r\")\n\t}\n\tsnapName := fmt.Sprintf(\"%s@%s\", d.Name, name)\n\targs = append(args, snapName)\n\t_, err := zfs(args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn GetDataset(snapName)\n}", "reference": "// Snapshot creates a new ZFS snapshot of the receiving dataset, using the\n// specified name.  Optionally, the snapshot can be taken recursively, creating\n// snapshots of all descendent filesystems in a single, atomic operation.", "generated": "// This function returns a Datastore that is used to create the snapshot of an existing datatype and then creates new snapshots for each type in its dataset using DFSSnapshot() .\n// The default implementation uses this method only if there are no other methods available on disk or otherwise unavailable by any means at"}
{"id": 5017, "code": "func DialWithTimeout(url string, timeout time.Duration) (*Session, error) {\n\tinfo, err := ParseURL(url)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tinfo.Timeout = timeout\n\treturn DialWithInfo(info)\n}", "reference": "// DialWithTimeout works like Dial, but uses timeout as the amount of time to\n// wait for a server to respond when first connecting and also on follow up\n// operations in the session. If timeout is zero, the call may block\n// forever waiting for a connection to be made.\n//\n// See SetSyncTimeout for customizing the timeout for the session.", "generated": "// This function returns a new instance of the Session object and provides an interface to call upon it when called with no parameters or return values in this case.\n // The callback is invoked by calling func() { if not self .session.isConnected (){ log.Fatal(\"Connection failed\") } else {}"}
{"id": 5025, "code": "func (s *Session) LogoutAll() {\n\ts.m.Lock()\n\tfor _, cred := range s.creds {\n\t\tif s.masterSocket != nil {\n\t\t\ts.masterSocket.Logout(cred.Source)\n\t\t}\n\t\tif s.slaveSocket != nil {\n\t\t\ts.slaveSocket.Logout(cred.Source)\n\t\t}\n\t}\n\ts.creds = s.creds[0:0]\n\ts.m.Unlock()\n}", "reference": "// LogoutAll removes all established authentication credentials for the session.", "generated": "// This method is used to log out all sessions from the specified session and lock them in a locked state for each of their associated credentials if they are not already logged out by default.\n// The following example logs an authenticated user into one of two different accounts that have been configured as \"Master\" or otherwise set up"}
{"id": 5048, "code": "func (q *Query) LogReplay() *Query {\n\tq.m.Lock()\n\tq.op.flags |= flagLogReplay\n\tq.m.Unlock()\n\treturn q\n}", "reference": "// LogReplay enables an option that optimizes queries that are typically\n// made on the MongoDB oplog for replaying it. This is an internal\n// implementation aspect and most likely uninteresting for other uses.\n// It has seen at least one use case, though, so it's exposed via the API.", "generated": "// This function is used to lock the replay server and allow it access to all of its data in a single call, without requiring any additional parameters or calling log(Q). // The callback must be called with no arguments other than Q's own key-value pairs; otherwise this will return nil ."}
{"id": 5071, "code": "func tokenFor(t *transaction) token {\n\tnonce := t.Nonce\n\tif nonce == \"\" {\n\t\tnonce = newNonce()\n\t}\n\treturn token(t.Id.Hex() + \"_\" + nonce)\n}", "reference": "// tokenFor returns a unique transaction token that\n// is composed by t's id and a nonce. If t already has\n// a nonce assigned to it, it will be used, otherwise\n// a new nonce will be generated.", "generated": "token for isToken, token for isTransaction, and tokens are used to create a transaction that will be sent from the server using an address of \":\" . The following example creates two transactions with different addresses in each case (the first one being created by sending it through RPC):\n\n\n// Create Transaction $tx"}
{"id": 5073, "code": "func (r *Runner) Run(ops []Op, id bson.ObjectId, info interface{}) (err error) {\n\tconst efmt = \"error in transaction op %d: %s\"\n\tfor i := range ops {\n\t\top := &ops[i]\n\t\tif op.C == \"\" || op.Id == nil {\n\t\t\treturn fmt.Errorf(efmt, i, \"C or Id missing\")\n\t\t}\n\t\tchanges := 0\n\t\tif op.Insert != nil {\n\t\t\tchanges++\n\t\t}\n\t\tif op.Update != nil {\n\t\t\tchanges++\n\t\t}\n\t\tif op.Remove {\n\t\t\tchanges++\n\t\t}\n\t\tif changes > 1 {\n\t\t\treturn fmt.Errorf(efmt, i, \"more than one of Insert/Update/Remove set\")\n\t\t}\n\t\tif changes == 0 && op.Assert == nil {\n\t\t\treturn fmt.Errorf(efmt, i, \"none of Assert/Insert/Update/Remove set\")\n\t\t}\n\t}\n\tif id == \"\" {\n\t\tid = bson.NewObjectId()\n\t}\n\n\t// Insert transaction sooner rather than later, to stay on the safer side.\n\tt := transaction{\n\t\tId:    id,\n\t\tOps:   ops,\n\t\tState: tpreparing,\n\t\tInfo:  info,\n\t}\n\tif err = r.tc.Insert(&t); err != nil {\n\t\treturn err\n\t}\n\tif err = flush(r, &t); err != nil {\n\t\treturn err\n\t}\n\tif t.State == taborted {\n\t\treturn ErrAborted\n\t} else if t.State != tapplied {\n\t\tpanic(fmt.Errorf(\"invalid state for %s after flush: %q\", &t, t.State))\n\t}\n\treturn nil\n}", "reference": "// Run creates a new transaction with ops and runs it immediately.\n// The id parameter specifies the transaction id, and may be written\n// down ahead of time to later verify the success of the change and\n// resume it, when the procedure is interrupted for any reason. If\n// empty, a random id will be generated.\n// The info parameter, if not nil, is included under the \"i\"\n// field of the transaction document.\n//\n// Operations across documents are not atomically applied, but are\n// guaranteed to be eventually all applied in the order provided or\n// all aborted, as long as the affected documents are only modified\n// through transactions. If documents are simultaneously modified\n// by transactions and out of transactions the behavior is undefined.\n//\n// If Run returns no errors, all operations were applied successfully.\n// If it returns ErrAborted, one or more operations can't be applied\n// and the transaction was entirely aborted with no changes performed.\n// Otherwise, if the transaction is interrupted while running for any\n// reason, it may be resumed explicitly or by attempting to apply\n// another transaction on any of the documents targeted by ops, as\n// long as the interruption was made after the transaction document\n// itself was inserted. Run Resume with the obtained transaction id\n// to confirm whether the transaction was applied or not.\n//\n// Any number of transactions may be run concurrently, with one\n// runner or many.", "generated": "/** Initializes a new Transaction object with an ID and its associated data structure as specified by `tx` at runtime. The tx is then inserted into the current buffer using insert(). Returns true when no transactions have been added since this point. */ func initTransaction () string { return os.UnsafeFunc(tx"}
{"id": 5076, "code": "func SetChaos(c Chaos) {\n\tchaosSetting = c\n\tchaosEnabled = c.KillChance > 0 || c.SlowdownChance > 0\n}", "reference": "// SetChaos sets the failure injection parameters to c.", "generated": "// Sets the chaos setting to true if a player is in control of this chasm, and false otherwise.\n // This will cause all players within that channel (including those who are not currently on Channels or have no current channels available for them), regardless whether they were killed by an enemy champion with their own abilities"}
{"id": 5099, "code": "func NewObjectIdWithTime(t time.Time) ObjectId {\n\tvar b [12]byte\n\tbinary.BigEndian.PutUint32(b[:4], uint32(t.Unix()))\n\treturn ObjectId(string(b[:]))\n}", "reference": "// NewObjectIdWithTime returns a dummy ObjectId with the timestamp part filled\n// with the provided number of seconds from epoch UTC, and all other parts\n// filled with zeroes. It's not safe to insert a document with an id generated\n// by this method, it is useful only for queries to find documents with ids\n// generated before or after the specified timestamp.", "generated": "NewObjIdWith Time is a new object ID that can be used to create an instance of the class, or any other subclass with which it has been created (such as Java's java-class). It uses two methods for creating and returning objects; first one returns the current id from the constructor in addition notifying"}
{"id": 5102, "code": "func (id ObjectId) Time() time.Time {\n\t// First 4 bytes of ObjectId is 32-bit big-endian seconds from epoch.\n\tsecs := int64(binary.BigEndian.Uint32(id.byteSlice(0, 4)))\n\treturn time.Unix(secs, 0)\n}", "reference": "// Time returns the timestamp part of the id.\n// It's a runtime error to call this method with an invalid id.", "generated": "This method returns the first byte in the string that was passed to this function as a parameter and then passes it back through its own implementation for each iteration until all values are returned by calling return .\nExample:\n\npackage main import ( \"fmt\" ) func () {\nrawdownload // Initialize an instance with id"}
{"id": 5107, "code": "func hasMinOf(top interface{}, current interface{}, field interface{}, param string) bool {\n\n\treturn isGte(top, current, field, param)\n}", "reference": "// min tests whether a variable value is larger or equal to a given\n// number. For number types, it's a simple lesser-than test; for\n// strings it tests the number of characters whereas for maps\n// and slices it tests the number of items.", "generated": "This method returns true if the top of a given fields or parameter list contains an integer value. If no such element exists in that array, then this function will return false . Otherwise it'll throw any error encountered by calling func() on all elements within its range (including those with non-zero length). The returned values"}
{"id": 5109, "code": "func Connect() {\n\turi := os.Getenv(\"MONGODB_URL\")\n\n\tif len(uri) == 0 {\n\t\turi = MongoDBUrl\n\t}\n\n\tmongo, err := mgo.ParseURL(uri)\n\ts, err := mgo.Dial(uri)\n\tif err != nil {\n\t\tfmt.Printf(\"Can't connect to mongo, go error %v\\n\", err)\n\t\tpanic(err.Error())\n\t}\n\ts.SetSafe(&mgo.Safe{})\n\tfmt.Println(\"Connected to\", uri)\n\tSession = s\n\tMongo = mongo\n}", "reference": "// Connect connects to mongodb", "generated": "// This function is used for connecting and de-connecting a session from the Mongodb server using an HTTP connection (or any other method). It returns true if there was no such request or false otherwise.\n // The default value of this parameter will be set by ``discover`. If it's"}
{"id": 5112, "code": "func (file *GridFile) SetChunkSize(bytes int) {\n\tfile.assertMode(gfsWriting)\n\tdebugf(\"GridFile %p: setting chunk size to %d\", file, bytes)\n\tfile.m.Lock()\n\tfile.doc.ChunkSize = bytes\n\tfile.m.Unlock()\n}", "reference": "// SetChunkSize sets size of saved chunks.  Once the file is written to, it\n// will be split in blocks of that size and each block saved into an\n// independent chunk document.  The default chunk size is 256kb.\n//\n// It is a runtime error to call this function once the file has started\n// being written to.", "generated": "// Sets the chunksize of a buffer in GBFS using gfsWrite(). This is used for writing and locking buffers on disk or by calling fsRead(), which will write all data from one location into another if necessary.\n// Note that this method does not lock any files with non-zero length; it only"}
{"id": 5120, "code": "func (file *GridFile) Read(b []byte) (n int, err error) {\n\tfile.assertMode(gfsReading)\n\tfile.m.Lock()\n\tdebugf(\"GridFile %p: reading at offset %d into buffer of length %d\", file, file.offset, len(b))\n\tdefer file.m.Unlock()\n\tif file.offset == file.doc.Length {\n\t\treturn 0, io.EOF\n\t}\n\tfor err == nil {\n\t\ti := copy(b, file.rbuf)\n\t\tn += i\n\t\tfile.offset += int64(i)\n\t\tfile.rbuf = file.rbuf[i:]\n\t\tif i == len(b) || file.offset == file.doc.Length {\n\t\t\tbreak\n\t\t}\n\t\tb = b[i:]\n\t\tfile.rbuf, err = file.getChunk()\n\t}\n\treturn n, err\n}", "reference": "// Read reads into b the next available data from the file and\n// returns the number of bytes written and an error in case\n// something wrong happened.  At the end of the file, n will\n// be zero and err will be set to os.EOF.\n//\n// The parameters and behavior of this function turn the file\n// into an io.Reader.", "generated": "// Initializes a new Grid File with the specified size and encoding as an argument to read(). The default is 32 bytes for byte-based reads in this case. // This can be changed by setting it up using gfsReadSize(), or changing its value via GFSWriteBytesToString(); if you want more"}
{"id": 5123, "code": "func invertAttributes(windowsMode uint16) uint16 {\n\treturn (COMMON_LVB_MASK & windowsMode) | ((FOREGROUND_MASK & windowsMode) << 4) | ((BACKGROUND_MASK & windowsMode) >> 4)\n}", "reference": "// invertAttributes inverts the foreground and background colors of a Windows attributes value", "generated": "This function returns the value of the underlying Windows mode. The default is to return a string containing all attributes that are specified by this method, and no additional information about them will be provided for subsequent calls on it or its associated methods. This can also include any other attribute values defined as well. It does not provide an"}
{"id": 5157, "code": "func (s *SegmentStack) Peek() int64 {\n\tif s.Len() == 0 {\n\t\treturn rootSegment\n\t}\n\treturn s.s[s.Len()-1]\n}", "reference": "// Peek returns id from the top of the stack. It returns rootSegment if the stack is empty.", "generated": "// This method is used to peek at the current segment of the stack, and return a new one if it's not found in any other way.\n// The following example uses this technique for checking that an existing chunk has been created by calling peck().\n// Note that there are two ways to check whether or"}
{"id": 5171, "code": "func (t *tx) StartExternal(host, name string) error {\n\tt.mtx.Lock()\n\tdefer t.mtx.Unlock()\n\n\tid, err := t.Tracer.BeginExternalSegment(t.id, t.ss.Peek(), host, name)\n\tif err != nil {\n\t\treturn err\n\t}\n\tt.ss.Push(id)\n\treturn nil\n}", "reference": "// StartExternal starts an external segment.", "generated": "Start external segmentation for the specified Host and Name . The start of this internal loop is a single byte sequence that starts at 0 , ends with an empty line after it, then returns to its initial state as follows:\n// Initialize local file descriptor in /var/run/local/.tsc or create new"}
{"id": 5186, "code": "func NewClusterWithHost(hosts ...*URI) *Cluster {\n\tcluster := DefaultCluster()\n\tfor _, host := range hosts {\n\t\tcluster.AddHost(host)\n\t}\n\treturn cluster\n}", "reference": "// NewClusterWithHost returns a cluster with the given URIs.", "generated": "This is a new Cluster with Host and ServerName set to the same name as default clusters in this example (defaulting \"DefaultClustering\"). It will be used for all of the following purposes only if you want it to work on your own servers or other applications that use Cluster . The servername must"}
{"id": 5206, "code": "func (idx *Index) BatchQuery(queries ...PQLQuery) *PQLBatchQuery {\n\tstringQueries := make([]string, 0, len(queries))\n\thasKeys := false\n\tfor _, query := range queries {\n\t\tserializedQuery := query.Serialize()\n\t\thasKeys = hasKeys || serializedQuery.HasWriteKeys()\n\t\tstringQueries = append(stringQueries, serializedQuery.String())\n\t}\n\treturn &PQLBatchQuery{\n\t\tindex:   idx,\n\t\tqueries: stringQueries,\n\t\thasKeys: hasKeys,\n\t}\n}", "reference": "// BatchQuery creates a batch query with the given queries.", "generated": "// This function returns a list of all the queryset keys in an array with index and length that match any given key or value pair for which this is true if not specified otherwise.\n // The returned values are then passed to PLSQLError as follows:\nvar queries : [ \"SELECT"}
{"id": 5218, "code": "func OptFieldTypeMutex(cacheType CacheType, cacheSize int) FieldOption {\n\treturn func(options *FieldOptions) {\n\t\toptions.fieldType = FieldTypeMutex\n\t\toptions.cacheType = cacheType\n\t\toptions.cacheSize = cacheSize\n\t}\n}", "reference": "// OptFieldTypeMutex adds a mutex field.", "generated": "This method returns a field type mutable with the following fields and methods that are available to all of its members in this context:\n\nA Type Mutate is an instance of Option , which provides access for any value within it (including those provided by other types). A Value can be either None or Either . The default"}
{"id": 5230, "code": "func (f *Field) Rows() *PQLRowsQuery {\n\ttext := fmt.Sprintf(\"Rows(field='%s')\", f.name)\n\treturn NewPQLRowsQuery(text, f.index, nil)\n}", "reference": "// Rows creates a Rows query with defaults", "generated": "This method returns a new PLS query object with the fields and indexes of all rows returned by this function as well its corresponding values for each field in it's list . The return value is an array containing one or more columns that are not part-of-the original data set but which may be used to store additional"}
{"id": 5261, "code": "func OptClientConnectTimeout(timeout time.Duration) ClientOption {\n\treturn func(options *ClientOptions) error {\n\t\toptions.ConnectTimeout = timeout\n\t\treturn nil\n\t}\n}", "reference": "// OptClientConnectTimeout is the maximum time to connect in nanoseconds.", "generated": "This method is used to connect a client with the specified protocol and wait for it to complete before sending an HTTP request, or if no connection has been established by that server (e., \"no response\") then return false . The default value of this option will be returned when all connections have completed successfully in order from most"}
{"id": 5271, "code": "func OptImportThreadCount(count int) ImportOption {\n\treturn func(options *ImportOptions) error {\n\t\toptions.threadCount = count\n\t\treturn nil\n\t}\n}", "reference": "// OptImportThreadCount is the number of goroutines allocated for import.", "generated": "This method imports a thread from the specified options list and returns an Option object that is used to import threads into your application using optimport() . The default value of this option will be None if no other methods are available, or False otherwise for all supported platforms (including Windows). This can also be useful when you want"}
{"id": 5282, "code": "func NewValueIterator(format Format, reader io.Reader) *Iterator {\n\treturn NewIterator(reader, FieldValueUnmarshaller(format))\n}", "reference": "// NewValueIterator creates a new iterator for value data.", "generated": "New Value Iterator is a new iterator that implements the format interface of fmt . The formatting method returns an error if it does not implement this type or nil otherwise and will return null in case any errors are encountered during processing (e., for example when using `new` to create multiple values). It also provides support on"}
{"id": 5287, "code": "func elementsFromLine(config *Config, line string) []interface{} {\n\tseparated := strings.Split(line, config.Delim)\n\telements := make([]interface{}, len(separated))\n\tfor i, field := range separated {\n\t\tvalue := field\n\t\tif !config.NoTrim {\n\t\t\tvalue = strings.TrimSpace(field)\n\t\t}\n\n\t\t// Apply the empty value, if configured.\n\t\tif value == \"\" && config.Empty != \"\" {\n\t\t\tvalue = config.Empty\n\t\t}\n\t\telements[i] = value\n\t}\n\treturn elements\n}", "reference": "// elementsFromLine returns a list of elements, each representing a single\n// item which will belong to a column of output.", "generated": "This function creates a new element from an existing list of lines and returns it as its first argument to this method. The initializer is called with two arguments (the name of the current file or directory), which are passed in by default when creating any other files that have been created using these methods. It also provides some"}
{"id": 5306, "code": "func postEOFCheck(c *Cmp, r io.Reader, buf []byte) bool {\n\ttmpLR, isLR := r.(*io.LimitedReader)\n\tif isLR {\n\t\t// If the limit wasn't reached, then we don't need to check for\n\t\t// more data after the EOF\n\t\tif tmpLR.N > 0 {\n\t\t\treturn true\n\t\t}\n\n\t\t// Use the internal Reader for checking for more data\n\t\tr = tmpLR.R\n\t} else {\n\t\tc.debugf(\"compareReader: A type assertion of LimitedReader unexpectedly failed\\n\")\n\t}\n\n\t// Attempt to read more bytes from the original readers, to determine\n\t// if we should return an error for exceeding the MaxSize read limit.\n\tn, _ := readPartial(c, r, buf, 0, len(buf))\n\treturn n == 0\n}", "reference": "// postEOFCheck returns false if there is more data in a LimitedReader after\n// hitting EOF", "generated": "This function checks whether a given buffer contains at least one byte in length and returns false otherwise (see below). The default value is nil . This can be used as follows : // Check that there are no errors or exceptions on this line before returning any results; see above code snippet #1#check_maxsize()"}
{"id": 5311, "code": "func exist(file string) (bool, error) {\n\t_, err := os.Stat(file)\n\tif err != nil {\n\t\tif err == os.ErrNotExist {\n\t\t\treturn false, nil\n\t\t}\n\t\treturn false, err\n\t}\n\treturn true, nil\n}", "reference": "// exist checks if the file exists.", "generated": "// Create a new file with the name of the current directory and its contents in it.\n // This is called create() .\n// The default value for this function will be created when creating an existing one or more files from\n#existing directories using fsck-create().\n// Note that if you want to"}
{"id": 5340, "code": "func (e *edit) Comment(reLine []string) error {\n\tallReSearch := make([]*regexp.Regexp, len(reLine))\n\n\tfor i, v := range reLine {\n\t\tif re, err := regexp.Compile(v); err != nil {\n\t\t\treturn err\n\t\t} else {\n\t\t\tallReSearch[i] = re\n\t\t}\n\t}\n\n\tif _, err := e.file.Seek(0, os.SEEK_SET); err != nil {\n\t\treturn err\n\t}\n\n\tchar := []byte(e.CommentChar + \" \")\n\tisNew := false\n\tbuf := new(bytes.Buffer)\n\n\t// Check every line.\n\tfor {\n\t\tline, err := e.buf.ReadBytes('\\n')\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\n\t\tfor _, v := range allReSearch {\n\t\t\tif v.Match(line) {\n\t\t\t\tline = append(char, line...)\n\n\t\t\t\tif !isNew {\n\t\t\t\t\tisNew = true\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif _, err = buf.Write(line); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif isNew {\n\t\treturn e.rewrite(buf.Bytes())\n\t}\n\treturn nil\n}", "reference": "// Comment inserts the comment character in lines that mach any regular expression\n// in reLine.", "generated": "This function returns a string that contains the text of an input character and its corresponding comment characters in order to determine if it matches any given entry or block element's content type for which this method has been called on each file descriptor specified by ESRB::FileDescriptor . The following example shows how these functions can"}
{"id": 5384, "code": "func Run(command string) (output []byte, err error) {\n\toutput, _, err = RunWithMatch(command)\n\treturn\n}", "reference": "// Run executes external commands just like RunWithMatch, but does not return\n// the boolean `match`.", "generated": "Runs a command. The output is the same as if it were run with an input buffer of bytes and errors are returned for each line in that file or by calling its completion function on any other lines within this program's current directory structure . It returns nil when no matching files exist at all , otherwise runs without exception"}
{"id": 5387, "code": "func (i *info) GroupHas(p ...perm) bool {\n\tmode := i.fi.Mode()\n\n\tfor _, v := range p {\n\t\tswitch v {\n\t\tcase R:\n\t\t\tif mode&modeRGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase W:\n\t\t\tif mode&modeWGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase X:\n\t\t\tif mode&modeXGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\treturn true\n}", "reference": "// GroupHas reports whether the group has all given permissions.", "generated": "// Groups are defined as a group of the specified type and can be used to define any number or multiple groups in an array with no parameters at all. The default is nil for non-nil members which means that they cannot have more than one member per element within their scope. // This allows grouping by name only if"}
{"id": 5393, "code": "func ChPasswd(user string, key []byte) error {\n\tshadow, err := LookupShadow(user)\n\tif err != nil {\n\t\treturn err\n\t}\n\tshadow.Passwd(key)\n\n\treturn edit(user, shadow)\n}", "reference": "// == Change passwd\n// ChPasswd updates passwd.\n// The passwd must be supplied in clear-text.", "generated": "Chpassw (chpasswd) is a wrapper around chpasswd to create an alias for the user specified in this method. It can be used as follows:\n// Create aliases of users and keys using `chan` or `Chan`. // The first two are optional but may not work if you don't"}
{"id": 5399, "code": "func parseGroup(row string) (*Group, error) {\n\tfields := strings.Split(row, \":\")\n\tif len(fields) != 4 {\n\t\treturn nil, rowError{_GROUP_FILE, row}\n\t}\n\n\tgid, err := strconv.Atoi(fields[2])\n\tif err != nil {\n\t\treturn nil, atoiError{_GROUP_FILE, row, \"GID\"}\n\t}\n\n\treturn &Group{\n\t\tName:     fields[0],\n\t\tpassword: fields[1],\n\t\tGID:      gid,\n\t\tUserList: strings.Split(fields[3], \",\"),\n\t}, nil\n}", "reference": "// parseGroup parses the row of a group.", "generated": "// Generate a group of groups for the specified user and password to use in an application that uses Group objects as their default settings (see below).\n // This is used by many applications which want to store passwords or other information about users on disk but do not have access control over them from outside sources such data storage"}
{"id": 5450, "code": "func (c *CallService) Create(ctx context.Context, data url.Values) (*Call, error) {\n\tcall := new(Call)\n\terr := c.client.CreateResource(ctx, callsPathPart, data, call)\n\treturn call, err\n}", "reference": "// Initiate a new Call.", "generated": "This method creates a Call service and returns an instance of the Service object that implements its methods as described in this section. The returned resource is created by calling C.create() . This function also provides access to resources from other services provided through callback functions or with parameters passed directly into it via returnValue , which can be"}
{"id": 5453, "code": "func (c *CallService) GetNextCallsInRange(start time.Time, end time.Time, nextPageURI string) CallPageIterator {\n\tif nextPageURI == \"\" {\n\t\tpanic(\"nextpageuri is empty\")\n\t}\n\titer := NewNextPageIterator(c.client, callsPathPart)\n\titer.SetNextPageURI(types.NullString{Valid: true, String: nextPageURI})\n\treturn &callDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetNextCallsInRange retrieves the page at the nextPageURI and continues\n// retrieving pages until any results are found in the range given by start or\n// end, or we determine there are no more records to be found in that range.\n//\n// If CallPage is non-nil, it will have at least one result.", "generated": "// Create a new call to the callback function and return it as an array of strings with all elements in range for each element returned by this method.\n // The first argument must be one or more arguments that are passed through from within C# code using methods such AsyncTask , TaskResult , etc., respectively;"}
{"id": 5455, "code": "func (c *CallService) GetRecordingsIterator(callSid string, data url.Values) *RecordingPageIterator {\n\tif data == nil {\n\t\tdata = url.Values{}\n\t}\n\t// Cheat - hit the Recordings list view with a filter instead of\n\t// GET /calls/CA123/Recordings. The former is probably more reliable\n\tdata.Set(\"CallSid\", callSid)\n\treturn c.client.Recordings.GetPageIterator(data)\n}", "reference": "// GetRecordings returns an iterator of recording pages for this Call.\n// Note there may be more than one Page of results.", "generated": "This method returns an iterator that iterates over all records in CallServices and then performs some operations on them to return results from it. It also provides methods for returning values or other information about record types such as ID , name , etc., which are not available through this API at present. This implementation does not provide any"}
{"id": 5461, "code": "func (r *KeyService) Delete(ctx context.Context, sid string) error {\n\treturn r.client.DeleteResource(ctx, keyPathPart, sid)\n}", "reference": "// Delete the Key with the given sid. If the Key has already been\n// deleted, or does not exist, Delete returns nil. If another error or a\n// timeout occurs, the error is returned.", "generated": "delete returns a new resource that is deleted from the client's cache and returned to the server for further processing by calling delete . It also deletes all of its associated resources in order to return them back as an object with no additional information about their contents or state at any time during this process. The following example uses it"}
{"id": 5462, "code": "func (a *AlertService) GetAlertsInRange(start time.Time, end time.Time, data url.Values) AlertPageIterator {\n\tif start.After(end) {\n\t\tpanic(\"start date is after end date\")\n\t}\n\td := url.Values{}\n\tif data != nil {\n\t\tfor k, v := range data {\n\t\t\td[k] = v\n\t\t}\n\t}\n\td.Del(\"Page\") // just in case\n\tif start != Epoch {\n\t\tstartFormat := start.UTC().Format(time.RFC3339)\n\t\td.Set(\"StartDate\", startFormat)\n\t}\n\tif end != HeatDeath {\n\t\t// If you specify \"StartTime<=YYYY-MM-DD\", the *latest* result returned\n\t\t// will be midnight (the earliest possible second) on DD. We want all\n\t\t// of the results for DD so we need to specify DD+1 in the API.\n\t\t//\n\t\t// TODO validate midnight-instant math more closely, since I don't think\n\t\t// Twilio returns the correct results for that instant.\n\t\tendFormat := end.UTC().Format(time.RFC3339)\n\t\td.Set(\"EndDate\", endFormat)\n\t}\n\titer := NewPageIterator(a.client, d, alertPathPart)\n\treturn &alertDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetAlertsInRange gets an Iterator containing conferences in the range\n// [start, end), optionally further filtered by data. GetAlertsInRange\n// panics if start is not before end. Any date filters provided in data will\n// be ignored. If you have an end, but don't want to specify a start, use\n// twilio.Epoch for start. If you have a start, but don't want to specify an\n// end, use twilio.HeatDeath for end.\n//\n// Assumes that Twilio returns resources in chronological order, latest\n// first. If this assumption is incorrect, your results will not be correct.\n//\n// Returned AlertPages will have at most PageSize results, but may have fewer,\n// based on filtering.", "generated": "This function takes a string and sets it as an array with values from 0 through 9 inclusive using `new` method which creates new page objects based upon each value being set by this callback . The first element must have at least one key or hash associated; if not specified then only those elements are created when called once per"}
{"id": 5466, "code": "func (d Direction) Friendly() string {\n\tswitch d {\n\tcase DirectionOutboundReply:\n\t\treturn \"Reply\"\n\tcase DirectionOutboundCall:\n\t\treturn \"Outgoing (from call)\"\n\tcase DirectionOutboundAPI:\n\t\treturn \"Outgoing (from API)\"\n\tcase DirectionInbound:\n\t\treturn \"Incoming\"\n\tcase DirectionOutboundDial:\n\t\treturn \"Outgoing (via Dial)\"\n\tcase DirectionTrunkingTerminating:\n\t\treturn \"Trunking (terminating)\"\n\tcase DirectionTrunkingOriginating:\n\t\treturn \"Trunking (originating)\"\n\tdefault:\n\t\treturn string(d)\n\t}\n}", "reference": "// Friendly prints out a friendly version of the Direction, following the\n// example shown in the Twilio Dashboard.", "generated": "// This function is used to send a message from the client. It returns nil if it doesn't exist, or an error code of 0 otherwise and return nil for any errors encountered in this case // as well on subsequent calls.\nfunc SendMessageToClient () string{\n\nif err := Client.GetResponseFrom"}
{"id": 5468, "code": "func (m *MessageService) GetPage(ctx context.Context, data url.Values) (*MessagePage, error) {\n\titer := m.GetPageIterator(data)\n\treturn iter.Next(ctx)\n}", "reference": "// GetPage returns a single page of resources. To retrieve multiple pages, use\n// GetPageIterator.", "generated": "This method returns a new MessageService instance that implements the following methods and provides an interface to getPage() :\nMethods Description GET Page Return Response A message containing information about this page's content or status of success . POST Page Return Response A response object with details on how it was received by other users in connection for sending"}
{"id": 5470, "code": "func (c *MessageService) GetNextMessagesInRange(start time.Time, end time.Time, nextPageURI string) MessagePageIterator {\n\tif nextPageURI == \"\" {\n\t\tpanic(\"nextpageuri is empty\")\n\t}\n\titer := NewNextPageIterator(c.client, messagesPathPart)\n\titer.SetNextPageURI(types.NullString{Valid: true, String: nextPageURI})\n\treturn &messageDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetNextMessagesInRange retrieves the page at the nextPageURI and continues\n// retrieving pages until any results are found in the range given by start or\n// end, or we determine there are no more records to be found in that range.\n//\n// If MessagePage is non-nil, it will have at least one result.", "generated": "// This method returns a new message for the current page URI and an iterator of all pending requests to this URL in range 0 to 1 inclusive.\n // The returned value should be nil if no response was received from any given request or null otherwise return None .\n\n\n/**\n* Returns `nil` when there are"}
{"id": 5486, "code": "func (r *ApplicationService) Delete(ctx context.Context, sid string) error {\n\treturn r.client.DeleteResource(ctx, applicationPathPart, sid)\n}", "reference": "// Delete the Application with the given sid. If the Application has already been\n// deleted, or does not exist, Delete returns nil. If another error or a\n// timeout occurs, the error is returned.", "generated": "delete returns a new Resource object that contains the specified resource and its associated ID number in hexadecimal format for use with applications running on Windows Server 2008 R2 or later operating systems using Microsoft SQLite 3.0+ . The returned value is an array of all resources to be deleted from this service by default when"}
{"id": 5490, "code": "func (ipn *IncomingNumberService) BuyNumber(phoneNumber string) (*IncomingPhoneNumber, error) {\n\tdata := url.Values{\"PhoneNumber\": []string{phoneNumber}}\n\treturn ipn.NumberPurchasingService.Create(context.Background(), data)\n}", "reference": "// BuyNumber attempts to buy the provided phoneNumber and returns it if\n// successful.", "generated": "This method creates a new Ingoing Number Service that will be used to purchase the phone number from an incoming call or outgoing message sent by any of its clients and returns it as nil if no such service exists for this client in order not return false . The returned value is then passed back to caller's callback function which calls"}
{"id": 5517, "code": "func (m *Messenger) DeleteGetStartedButton() error {\n\tresult, err := m.changeThreadSettings(http.MethodDelete, &threadSettings{\n\t\tType:  settingTypeCallToActions,\n\t\tState: threadStateNew,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\tif result.Result != \"Successfully deleted all new_thread's CTAs\" {\n\t\treturn fmt.Errorf(\"Error occured while deleting get started button, invalid result: %s\", result.Result)\n\t}\n\treturn nil\n}", "reference": "// DeleteGetStartedButton delets a button set by SetGetStartedButton", "generated": "// This method deletes the current queue of threads that are currently waiting for a message to be sent from an applet or other process in order notifying them about changes made by this class and returning it as soon after receiving one if any pending messages have been received at some point during its lifetime.\n/**\n*"}
{"id": 5523, "code": "func pushNumberValue(L *lua.State, a interface{}, t1, t2 reflect.Type) {\n\tv := reflect.ValueOf(a)\n\tisComplex := unsizedKind(v) == reflect.Complex128\n\tmt := cNumberMeta\n\tif isComplex {\n\t\tmt = cComplexMeta\n\t}\n\tif t1 == t2 || isPredeclaredType(t2) {\n\t\tmakeValueProxy(L, v.Convert(t1), mt)\n\t} else if isPredeclaredType(t1) {\n\t\tmakeValueProxy(L, v.Convert(t2), mt)\n\t} else if isComplex {\n\t\tcomplexType := reflect.TypeOf(0i)\n\t\tmakeValueProxy(L, v.Convert(complexType), cComplexMeta)\n\t} else {\n\t\tL.PushNumber(valueToNumber(L, v))\n\t}\n}", "reference": "// pushNumberValue pushes the number resulting from an arithmetic operation.\n//\n// At least one operand must be a proxy for this function to be called. See the\n// main documentation for the conversion rules.", "generated": "push Number Value represents the number of elements in a string representation (or an array). It can be used to represent multiple strings or arrays with different values and sizes depending on which type of value you want it represented as; for example, \"abc\" would have two numbers representing one element while other characters are written using numeric"}
{"id": 5556, "code": "func (d *digest) Sum(in []byte) []byte {\n\ts := d.Sum64()\n\tin = append(in, byte(s))\n\tin = append(in, byte(s>>8))\n\tin = append(in, byte(s>>16))\n\tin = append(in, byte(s>>24))\n\tin = append(in, byte(s>>32))\n\tin = append(in, byte(s>>40))\n\tin = append(in, byte(s>>48))\n\tin = append(in, byte(s>>56))\n\treturn in\n}", "reference": "// Encode in little endian", "generated": "sum is a function that returns the sum of all bytes from an input string to its destination output string and then compares it against any other strings returned by this method on each iteration until the result matches or exceeds one specified value for which there are no known values at compile time. It also provides some useful information about how many"}
{"id": 5562, "code": "func FindPerformancePrice(productPackage datatypes.Product_Package, priceCategory string) (datatypes.Product_Item_Price, error) {\n\tfor _, item := range productPackage.Items {\n\t\tfor _, price := range item.Prices {\n\t\t\t// Only collect prices from valid location groups.\n\t\t\tif price.LocationGroupId != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif !hasCategory(price.Categories, priceCategory) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn price, nil\n\t\t}\n\t}\n\treturn datatypes.Product_Item_Price{}, bosherr.Error(\"Unable to find price for performance storage\")\n}", "reference": "// Find the price in the given package that has the specified category", "generated": "This function returns a list of all the available pricing information in an order that is consistent with its default value and provides some sort or other indication as to whether it should be collected by this method. The following example shows how one might use these options if they are not provided explicitly on each line:\n\npackage com.github"}
{"id": 5571, "code": "func (o *OrderVMByFilterParams) WithBody(body *models.VMFilter) *OrderVMByFilterParams {\n\to.SetBody(body)\n\treturn o\n}", "reference": "// WithBody adds the body to the order Vm by filter params", "generated": "This method returns a new Order VM by filter parameters, which is used to create the order of all models in the model list and then return it as an object with its own setOf() function that can be called from any other methods or functions within this class without having to call directly for each parameter's value type ."}
{"id": 5572, "code": "func (c *FakeClient) Delete(instanceID string) error {\n\tc.DeleteCalled = true\n\treturn c.DeleteErr\n}", "reference": "// Delete deletes the instance settings for a given instance ID.", "generated": "deleteCalls the client to delete a specified instance ID from the database, returning an object that contains all of its associated data and returns information about it in JSON format as well with no additional parameters or return values for any other method callbacks on this class if necessary. The returned objects are then passed back through the callback"}
{"id": 5599, "code": "func (o *UpdateVMWithStateParams) WithBody(body *models.VMState) *UpdateVMWithStateParams {\n\to.SetBody(body)\n\treturn o\n}", "reference": "// WithBody adds the body to the update Vm with state params", "generated": "This method returns a new VMState object that contains the state of the current model and its associated body, as well any changes made to it by this update operation or other operations performed on it in future updates from UpdateVM with StateParameters . The value returned is an array containing all states for which there are no"}
{"id": 5601, "code": "func (o *AddVMParams) WithTimeout(timeout time.Duration) *AddVMParams {\n\to.SetTimeout(timeout)\n\treturn o\n}", "reference": "// WithTimeout adds the timeout to the add Vm params", "generated": "// Add VMPars to the queue, and return a new list of vmparamets for each callbacks in this loop.\n // This is useful if you want to use multiple queues at once or have different priorities when calling other methods on them."}
{"id": 5606, "code": "func (o *ListVMParams) WithContext(ctx context.Context) *ListVMParams {\n\to.SetContext(ctx)\n\treturn o\n}", "reference": "// WithContext adds the context to the list Vm params", "generated": "This method returns a list of VML parameters that are used to create the vmparsession object for each VM in the specified scope, and optionally an array containing all available values from this collection as well if necessary. The returned value is then passed along with any additional information about how it was created or updated by calling"}
{"id": 5626, "code": "func (pk PrivKeyLedgerSecp256k1) getPubKey() (key PubKey, err error) {\n\tdev, err := getLedger()\n\tif err != nil {\n\t\treturn key, fmt.Errorf(\"cannot connect to Ledger device - error: %v\", err)\n\t}\n\tkey, err = pubkeyLedgerSecp256k1(dev, pk.Path)\n\tif err != nil {\n\t\treturn key, fmt.Errorf(\"please open Cosmos app on the Ledger device - error: %v\", err)\n\t}\n\treturn key, err\n}", "reference": "// getPubKey reads the pubkey the ledger itself\n// since this involves IO, it may return an error, which is not exposed\n// in the PubKey interface, so this function allows better error handling", "generated": "// Get a private Key and an encrypted Private Keys for this session using CryptoNote's public keys as their primary encryption scheme // This is used by all crypto-currencies including Bitcoin in order not only to protect against attacks from malicious users but also allow them access via secure channels such that they can use it with other cryptocurrencies"}
{"id": 5656, "code": "func (kb dbKeybase) ImportPubKey(name string, armor string) (err error) {\n\tbz := kb.db.Get(infoKey(name))\n\tif len(bz) > 0 {\n\t\treturn errors.New(\"Cannot overwrite data for name \" + name)\n\t}\n\tpubBytes, err := unarmorPubKeyBytes(armor)\n\tif err != nil {\n\t\treturn\n\t}\n\tpubKey, err := crypto.PubKeyFromBytes(pubBytes)\n\tif err != nil {\n\t\treturn\n\t}\n\tkb.writeOfflineKey(pubKey, name)\n\treturn\n}", "reference": "// ImportPubKey imports ASCII-armored public keys.\n// Store a new Info object holding a public key only, i.e. it will\n// not be possible to sign with it as it lacks the secret key.", "generated": "// Create a new key base with the following keys and values to be used in authentication requests from clients using this API.\n // This is an example of how we can use it as part-of our application's main method on client side security checks that are performed by other applications or services such as web servers/apps"}
{"id": 5660, "code": "func CompareHashAndPassword(hashedPassword, password []byte) error {\n\tp, err := newFromHash(hashedPassword)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\totherHash, err := bcrypt(password, p.cost, p.salt)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\totherP := &hashed{otherHash, p.salt, p.cost, p.major, p.minor}\n\tif subtle.ConstantTimeCompare(p.Hash(), otherP.Hash()) == 1 {\n\t\treturn nil\n\t}\n\n\treturn ErrMismatchedHashAndPassword\n}", "reference": "// CompareHashAndPassword compares a bcrypt hashed password with its possible\n// plaintext equivalent. Returns nil on success, or an error on failure.", "generated": "// Computes the hash of a given string and compares it against an existing Hash or Password that is available in both hashes (i..n).\n // The comparison can be performed on any input character as long-term memory usage will not affect this implementation's performance at all. This method returns true if no matching strings"}
{"id": 5696, "code": "func doDemangle(out *bufio.Writer, name string) {\n\tskip := 0\n\tif name[0] == '.' || name[0] == '$' {\n\t\tskip++\n\t}\n\tif *stripUnderscore && name[skip] == '_' {\n\t\tskip++\n\t}\n\tresult := demangle.Filter(name[skip:], options()...)\n\tif result == name[skip:] {\n\t\tout.WriteString(name)\n\t} else {\n\t\tif name[0] == '.' {\n\t\t\tout.WriteByte('.')\n\t\t}\n\t\tout.WriteString(result)\n\t}\n}", "reference": "// Demangle a string just as the GNU c++filt program does.", "generated": "// This function is used to filter out the characters that are not in a character set and return an error if they don't match any of the specified strings or nil otherwise returns an exception for this case.\n/*** Returns true when no matching matches have been found on all lines (default false). */ func main ()"}
{"id": 5707, "code": "func (s *Sentinel) defaultPool(addr string) *redis.Pool {\n\treturn &redis.Pool{\n\t\tMaxIdle:     3,\n\t\tMaxActive:   10,\n\t\tWait:        true,\n\t\tIdleTimeout: 240 * time.Second,\n\t\tDial: func() (redis.Conn, error) {\n\t\t\treturn s.Dial(addr)\n\t\t},\n\t\tTestOnBorrow: func(c redis.Conn, t time.Time) error {\n\t\t\t_, err := c.Do(\"PING\")\n\t\t\treturn err\n\t\t},\n\t}\n}", "reference": "// defaultPool returns a connection pool to one Sentinel. This allows\n// us to call concurrent requests to Sentinel using connection Do method.", "generated": "default pools is a pool that can be used to create and update the state of an existing client or server using either send , receive . The following example creates two clients with different idles in one session :\n\n```netstat -d /dev/null | grep \"idlepool\" >&1; 1"}
{"id": 5723, "code": "func (c *Client) CompareAndSwap(item *Item) error {\n\treturn c.populateOne(cmdSet, item, item.casid)\n}", "reference": "// CompareAndSwap writes the given item that was previously returned\n// by Get, if the value was neither modified or evicted between the\n// Get and the CompareAndSwap calls. The item's Key should not change\n// between calls but all other item fields may differ. ErrCASConflict\n// is returned if the value was modified in between the\n// calls. ErrNotStored is returned if the value was evicted in between\n// the calls.", "generated": "Compare and swap a single-byte array of items in the same order as they were created by client to an existing buffer or stream using Client's Swap function. The resulting result is returned if it was not found before calling this method on any other object that has been allocated with respect thereto for comparison purposes only. If no"}
{"id": 5736, "code": "func Ticker(ticker <-chan time.Time, procfunc gp.ProcessFunc) gp.Process {\n\treturn gp.Go(callOnTicker(ticker, procfunc))\n}", "reference": "// Ticker calls the given ProcessFunc every time the ticker fires.\n// This is sequentially rate limited, only one call will be in-flight at a time.", "generated": "This function is used to create a new tiddler that will be displayed when the user clicks on it and then click \"OK\" if they have clicked an existing one or not (or both). It also creates two timers for each ticker in order of appearance before clicking again with no additional wait-time required by default"}
{"id": 5746, "code": "func (a *API) FetchCheck(cid CIDType) (*Check, error) {\n\tif cid == nil || *cid == \"\" {\n\t\treturn nil, fmt.Errorf(\"Invalid check CID [none]\")\n\t}\n\n\tcheckCID := string(*cid)\n\n\tmatched, err := regexp.MatchString(config.CheckCIDRegex, checkCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !matched {\n\t\treturn nil, fmt.Errorf(\"Invalid check CID [%s]\", checkCID)\n\t}\n\n\tresult, err := a.Get(checkCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] fetch check, received JSON: %s\", string(result))\n\t}\n\n\tcheck := new(Check)\n\tif err := json.Unmarshal(result, check); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn check, nil\n}", "reference": "// FetchCheck retrieves check with passed cid.", "generated": "Fuzzy checks the status of an API request and returns true if it succeeds or false otherwise; this is useful for debugging purposes only when there are no other options available to use in your application's codebase that can be used with fuzzing APIs such as HTTP/1DPP requests from outside sources like web servers"}
{"id": 5747, "code": "func (a *API) FetchChecks() (*[]Check, error) {\n\tresult, err := a.Get(config.CheckPrefix)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar checks []Check\n\tif err := json.Unmarshal(result, &checks); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &checks, nil\n}", "reference": "// FetchChecks retrieves all checks available to the API Token.", "generated": "Fuzzy fetching is an API call that returns the list of all available check options and optionally provides additional information about each option in order to determine if it's appropriate for checking or not. It can be used as part-of any other request with no parameters at runtime; see also http://www/api_"}
{"id": 5752, "code": "func (a *API) FetchGraph(cid CIDType) (*Graph, error) {\n\tif cid == nil || *cid == \"\" {\n\t\treturn nil, fmt.Errorf(\"Invalid graph CID [none]\")\n\t}\n\n\tgraphCID := string(*cid)\n\n\tmatched, err := regexp.MatchString(config.GraphCIDRegex, graphCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !matched {\n\t\treturn nil, fmt.Errorf(\"Invalid graph CID [%s]\", graphCID)\n\t}\n\n\tresult, err := a.Get(graphCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] fetch graph, received JSON: %s\", string(result))\n\t}\n\n\tgraph := new(Graph)\n\tif err := json.Unmarshal(result, graph); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn graph, nil\n}", "reference": "// FetchGraph retrieves graph with passed cid.", "generated": "Fuzzy Graph is an API that provides easy to use and fast way of querying the data in your application using SQLite3 or other database engines such as MongoDB/SQL Server for queries on multiple databases at once with no needlessly complex query parameters like \"SELECT\" , \"CREATE TABLE\". It also"}
{"id": 5786, "code": "func (a *API) FetchAnnotations() (*[]Annotation, error) {\n\tresult, err := a.Get(config.AnnotationPrefix)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar annotations []Annotation\n\tif err := json.Unmarshal(result, &annotations); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &annotations, nil\n}", "reference": "// FetchAnnotations retrieves all annotations available to the API Token.", "generated": "Fuzzy-matching is an API that allows you to match multiple annotation types with the same name and type in one go using JSON's builtin \"fuzziness\" feature. The default behavior of fuzziness can be changed by setting it as follows:\n// fudge mode : // true if no matching"}
{"id": 5815, "code": "func (m *CirconusMetrics) NewHistogram(metric string) *Histogram {\n\tm.hm.Lock()\n\tdefer m.hm.Unlock()\n\n\tif hist, ok := m.histograms[metric]; ok {\n\t\treturn hist\n\t}\n\n\thist := &Histogram{\n\t\tname: metric,\n\t\thist: circonusllhist.New(),\n\t}\n\n\tm.histograms[metric] = hist\n\n\treturn hist\n}", "reference": "// NewHistogram returns a histogram instance.", "generated": "This method will return false for any non-nil status code or null otherwise it should be used as a default to avoid calling this on errors when returning from"}
{"id": 5847, "code": "func (a *API) CreateRuleSet(cfg *RuleSet) (*RuleSet, error) {\n\tif cfg == nil {\n\t\treturn nil, fmt.Errorf(\"Invalid rule set config [nil]\")\n\t}\n\n\tjsonCfg, err := json.Marshal(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] create rule set, sending JSON: %s\", string(jsonCfg))\n\t}\n\n\tresp, err := a.Post(config.RuleSetPrefix, jsonCfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\truleset := &RuleSet{}\n\tif err := json.Unmarshal(resp, ruleset); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn ruleset, nil\n}", "reference": "// CreateRuleSet creates a new rule set.", "generated": "// This method creates an API for creating and managing Rule Sets in the context of logging logs generated by this module. It is used to generate log messages from logged-in users that are not part or all of any existing Rules Set configuration file; it does not provide access to user data stored on servers with no authentication mechanism"}
{"id": 5860, "code": "func (a *API) DeleteWorksheet(cfg *Worksheet) (bool, error) {\n\tif cfg == nil {\n\t\treturn false, fmt.Errorf(\"Invalid worksheet config [nil]\")\n\t}\n\treturn a.DeleteWorksheetByCID(CIDType(&cfg.CID))\n}", "reference": "// DeleteWorksheet deletes passed worksheet.", "generated": "deleteworksheets is an API wrapper for the deleteWorkssheet class that implements CIDs and deletes all of its fields from Workshell's database in order to create new files with no additional information about them or their contents at runtime. It provides two methods which are used by deleting workbooks as well : A method"}
{"id": 5865, "code": "func (a *API) CreateContactGroup(cfg *ContactGroup) (*ContactGroup, error) {\n\tif cfg == nil {\n\t\treturn nil, fmt.Errorf(\"Invalid contact group config [nil]\")\n\t}\n\n\tjsonCfg, err := json.Marshal(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] create contact group, sending JSON: %s\", string(jsonCfg))\n\t}\n\n\tresult, err := a.Post(config.ContactGroupPrefix, jsonCfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tgroup := &ContactGroup{}\n\tif err := json.Unmarshal(result, group); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn group, nil\n}", "reference": "// CreateContactGroup creates a new contact group.", "generated": "// Initializes the Contact Group with an initializer that is used to initialize all contacts in this profile and creates new ones for each of them by calling init() on it's own instance. This method will be called once every time you call log(). // The default initialization process should take about 10 seconds before any changes are"}
{"id": 5890, "code": "func NewEllipticSigner(alg Algorithm, curve elliptic.Curve) func(Store, crypto.Hash) (Signer, error) {\n\tcurveBitSize := curve.Params().BitSize\n\n\t// precompute curve key len\n\tkeyLen := curveBitSize / 8\n\tif curveBitSize%8 > 0 {\n\t\tkeyLen++\n\t}\n\n\treturn func(store Store, hash crypto.Hash) (Signer, error) {\n\t\tvar ok bool\n\t\tvar privRaw, pubRaw interface{}\n\t\tvar priv *ecdsa.PrivateKey\n\t\tvar pub *ecdsa.PublicKey\n\n\t\t// check private key\n\t\tif privRaw, ok = store.PrivateKey(); ok {\n\t\t\tif priv, ok = privRaw.(*ecdsa.PrivateKey); !ok {\n\t\t\t\treturn nil, ErrInvalidPrivateKey\n\t\t\t}\n\n\t\t\t// check curve type matches private key curve type\n\t\t\tif curveBitSize != priv.Curve.Params().BitSize {\n\t\t\t\treturn nil, ErrInvalidPrivateKeySize\n\t\t\t}\n\t\t}\n\n\t\t// check public key\n\t\tif pubRaw, ok = store.PublicKey(); ok {\n\t\t\tif pub, ok = pubRaw.(*ecdsa.PublicKey); !ok {\n\t\t\t\treturn nil, ErrInvalidPublicKey\n\t\t\t}\n\t\t}\n\n\t\t// check that either a private or public key has been provided\n\t\tif priv == nil && pub == nil {\n\t\t\treturn nil, ErrMissingPrivateOrPublicKey\n\t\t}\n\n\t\treturn &EccSigner{\n\t\t\talg:    alg,\n\t\t\tcurve:  curve,\n\t\t\thash:   hash,\n\t\t\tpriv:   priv,\n\t\t\tpub:    pub,\n\t\t\tkeyLen: keyLen,\n\t\t}, nil\n\t}\n}", "reference": "// NewEllipticSigner creates an Elliptic Curve Signer for the specified curve.", "generated": "This function checks the SHA256 and RSA keys of an encrypted file using AES-128 encryption algorithms to verify their authenticity before signing them with any other user's data in order for it not be compromised by malicious actors who have access control over its contents via brute force attacks on all users' files stored within this program. The"}
{"id": 5907, "code": "func FromFile(path string, opts ...Option) (*GServiceAccount, error) {\n\tbuf, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn FromJSON(buf, opts...)\n}", "reference": "// FromFile loads Google service account credentials from a reader.", "generated": "This method returns a JSON object that contains the information about an account's name and password (in this case \"password\"). The following example shows how to use it in your application using GService Account :"}
{"id": 5932, "code": "func PostEZCountTime(statName, ezkey string, count int, timestamp int64) error {\n\treturn DefaultReporter.PostEZCountTime(statName, ezkey, count, timestamp)\n}", "reference": "// Using the EZ API, posts a count to a stat at a specific time using DefaultReporter.", "generated": "This method returns the time of a post-mortem for each epoch in which it was recorded by an observer (e.,g.: \"post_interval\" ). The following example shows how to use this function with respect not only logtime but also timestamps and other metrics as well. Note that these methods are"}
{"id": 5952, "code": "func (s Scan) AddHosts(hosts ...string) Scan {\n\ts.configHosts = append(s.configHosts, hosts...)\n\treturn s\n}", "reference": "// AddHosts adds a list of hosts to the list of hosts to be scanned", "generated": "This method adds a host to the list of available Host objects and returns an array containing all known names for that object in its current scope. The name is optional but can be specified with any string or number as long it contains no spaces between characters such as \"\". This function also checks if there are currently active connections on"}
{"id": 5955, "code": "func (s Scan) SetPorts(ports ...uint16) Scan {\n\ts.configPorts = ports\n\treturn s\n}", "reference": "// SetPorts sets the ports that wil be used", "generated": "// Sets the port to be used for scanning purposes, and returns a list of all available options in this context // if any are not provided by default. This is useful when you want to scan multiple devices at once or only one device per connection func main() {\n externalToscan := os.Scan(port)"}
{"id": 5964, "code": "func (otp HOTP) Counter() uint64 {\n\tcounter := binary.BigEndian.Uint64(otp.counter[:])\n\treturn counter\n}", "reference": "// Counter returns the HOTP's 8-byte counter as an unsigned 64-bit\n// integer.", "generated": "This function returns the number of bytes in a string, or 0 if no byte is found and 1 otherwise. The return value can be used to specify whether an integer was returned by this method for any given input data type; it defaults not only to zero but also includes all possible values that are present on disk as well"}
{"id": 5967, "code": "func (otp *HOTP) URL(label string) string {\n\tsecret := base32.StdEncoding.EncodeToString(otp.Key)\n\tu := url.URL{}\n\tv := url.Values{}\n\tu.Scheme = \"otpauth\"\n\tu.Host = \"hotp\"\n\tu.Path = label\n\tv.Add(\"secret\", secret)\n\tv.Add(\"counter\", fmt.Sprintf(\"%d\", otp.Counter()))\n\tu.RawQuery = v.Encode()\n\treturn u.String()\n}", "reference": "// URL returns a suitable URL, such as for the Google Authenticator\n// app. The label is used by these apps to identify the service to\n// which this OTP belongs. The digits value is ignored by the Google\n// authenticator app, and is therefore elided in the resulting URL.", "generated": "The hash function is used to generate a HashMap of the key and value pairs in an HASH format, which can be passed as parameters or returned by calling encodeHash(). The following example uses this method for generating hashes from plaintext strings using hmac .\n\nA simple implementation would look like below with two keys :"}
{"id": 5975, "code": "func Marshal(otp *HOTP) ([]byte, error) {\n\tvar asnHOTP struct {\n\t\tKey     []byte\n\t\tCounter *big.Int\n\t\tDigits  int\n\t}\n\tasnHOTP.Key = otp.Key[:]\n\tasnHOTP.Counter = new(big.Int).SetUint64(otp.Counter())\n\tasnHOTP.Digits = otp.Digits\n\treturn asn1.Marshal(asnHOTP)\n}", "reference": "// Marshal serialises an HOTP key value as a DER-encoded byte slice.", "generated": "// This function returns a string representation of the hash table in which to store data for this operation. The key is an integer and the counter is one byte from the value stored by HASH_TABLE .\n // Returns nil if no keys are found or null otherwise returned.\n func main() {}"}
{"id": 5981, "code": "func (pool *ReaderPool) Get(r io.Reader) (reader io.Reader, release func()) {\n\t// don't export a ThrottlerReader to prevent users changing the rate\n\t// and expecting their change to be respected, since we might modify\n\t// the rate under their feet\n\n\t// make the initial rate be 0, the actual rate is\n\t// set in the call to `setSharedRates`.\n\trd := ThrottledReader(r, 0, pool.maxBurst)\n\n\tpool.mu.Lock()\n\tpool.givenOut[rd] = struct{}{}\n\tpool.setSharedRates()\n\tpool.mu.Unlock()\n\n\treturn rd, func() {\n\t\tpool.mu.Lock()\n\t\tdelete(pool.givenOut, rd)\n\t\tpool.setSharedRates()\n\t\tpool.mu.Unlock()\n\t}\n}", "reference": "// Get a throttled reader that wraps r.", "generated": "/**\n* Returns a new stream of bytes that contains all incoming data from an existing buffer or queue for which there are no buffers available at any given time.\n*/ // This method returns nil if it does not return true; otherwise, false. The default value will always result in undefined behavior when used with non-"}
{"id": 6002, "code": "func JsonFile(path string) (Typed, error) {\n\tdata, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn Json(data)\n}", "reference": "// Create a Typed helper from the JSON within a file", "generated": "JSONFile is a file system program that provides the following features to Java programs and applications using JDK 8 or later versions of Windows Server 2008 R2 SP1/R3 operating systems. It supports both standard input files as well an output format for text-based commands such in .txt , java_input ,"}
{"id": 6018, "code": "func (t Typed) TimeMust(key string) time.Time {\n\ttt, exists := t.TimeIf(key)\n\tif exists == false {\n\t\tpanic(\"expected time.Time value for \" + key)\n\t}\n\treturn tt\n}", "reference": "// Returns a time.Time or panics", "generated": "// This function returns the current date and times of a given type in milliseconds or seconds depending on whether it is an integer representation or not. It also provides some useful properties to help you determine if your data should be formatted as such before using this method.\n// Returns true when TTFT has been called with no"}
{"id": 6025, "code": "func (t Typed) BoolsOr(key string, d []bool) []bool {\n\tn, ok := t.BoolsIf(key)\n\tif ok {\n\t\treturn n\n\t}\n\treturn d\n}", "reference": "// Returns an slice of boolean, or the specified slice", "generated": "// This function returns a boolean if the key is not null or nil otherwise false. If it does not return true, then this method will be called with an error message and returned as None .\n// The default value of boolsor() should always contain no errors except for those that occur when using `bool"}
{"id": 6037, "code": "func NewWorker(logger log.Logger, db *reform.DB, ethBack eth.Backend,\n\tgasConc *GasConf, pscAddr common.Address, payAddr string,\n\tpwdGetter data.PWDGetter, countryConf *country.Config,\n\tdecryptKeyFunc data.ToPrivateKeyFunc, eptConf *ept.Config,\n\ttorHostname string, somcClientBuilder somc.ClientBuilderInterface) (*Worker, error) {\n\n\tl := logger.Add(\"type\", \"proc/worker.Worker\")\n\n\tabi, err := abi.JSON(\n\t\tstrings.NewReader(contract.PrivatixServiceContractABI))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\teptService, err := ept.New(db, logger, payAddr, eptConf.Timeout)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &Worker{\n\t\tabi:               abi,\n\t\tlogger:            l,\n\t\tdb:                db,\n\t\tdecryptKeyFunc:    decryptKeyFunc,\n\t\tgasConf:           gasConc,\n\t\tept:               eptService,\n\t\tethBack:           ethBack,\n\t\tpscAddr:           pscAddr,\n\t\tpwdGetter:         pwdGetter,\n\t\tcountryConfig:     countryConf,\n\t\ttorHostName:       data.FromBytes([]byte(torHostname)),\n\t\tsomcClientBuilder: somcClientBuilder,\n\t}, nil\n}", "reference": "// NewWorker returns new instance of worker.", "generated": "// Create a new worker for the specified type of work. This is used to create an instance of WorkManager and provide access control over it's workers (see below).\n // The default value will be `new`. If this option isn't provided, no additional parameters are passed in as arguments or returned by callbacks"}
{"id": 6089, "code": "func AddWithDelay(q Queue, tx *reform.TX,\n\tjobType, relatedType, relatedID, creator string,\n\tdelay time.Duration) error {\n\treturn AddWithDataAndDelay(q, tx,\n\t\tjobType, relatedType, relatedID, creator, &struct{}{}, delay)\n}", "reference": "// AddWithDelay is convenience method to add a job with given data delay.", "generated": "addWithdelayed() returns a new queue that contains the specified queued data and associated ID for each of these events (see below). The callback is invoked when an event occurs in which no other queues are available to perform any operations on or after this call. This method also provides some additional functionality such as returning information"}
{"id": 6115, "code": "func NewFileLogger(conf *FileConfig) (Logger, io.Closer, error) {\n\tnow := time.Now()\n\tif conf.UTC {\n\t\tnow = now.UTC()\n\t}\n\n\tfile, err := os.OpenFile(\n\t\ttimeutil.Strftime(&now, conf.Filename),\n\t\tos.O_APPEND|os.O_CREATE|os.O_WRONLY, conf.FileMode)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tlogger, err := NewWriterLogger(conf.WriterConfig, file)\n\tif err != nil {\n\t\tfile.Close()\n\t\treturn nil, nil, err\n\t}\n\n\treturn logger, file, nil\n}", "reference": "// NewFileLogger creates a new file logger.", "generated": "New File Logging is a logging utility that provides an interface to the loggers provided by Microsoft Windows Server 2003 and later versions of Visual Studio 2010 for use with applications running in multiple environments or on different machines using various types such as virtual machine instances; it also supports multi-machine support including remote access via SSH/T"}
{"id": 6138, "code": "func (b *backendInstance) EthBalanceAt(ctx context.Context,\n\towner common.Address) (*big.Int, error) {\n\tctx2, cancel := b.addTimeout(ctx)\n\tdefer cancel()\n\n\treturn b.conn.ethClient().BalanceAt(ctx2, owner, nil)\n}", "reference": "// EthBalanceAt returns the wei balance of the given account.", "generated": "This method returns a new instance of the eth balance at which to store and withdraw funds from an address in exchange for ether or other fiat currency on behalf by using this interface with no additional parameters specified as part that function's return value . The returned object is then passed back through the callback process when it has been called again"}
{"id": 6147, "code": "func (w *Worker) keyFromChannelData(logger log.Logger,\n\tchannel string) (data.Base64String, error) {\n\tch, err := w.channel(logger, channel)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\toffering, err := w.offering(logger, ch.Offering)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tkey, err := data.ChannelKey(ch.Client, ch.Agent,\n\t\tch.Block, offering.Hash)\n\t// internal\n\tif err != nil {\n\t\tlogger.Add(\"channel\", ch, \"offering\", offering).Error(err.Error())\n\t\treturn \"\", ErrInternal\n\t}\n\treturn data.FromBytes(key), nil\n}", "reference": "// keyFromChannelData returns the unique channel identifier\n// used in a Privatix Service Contract.", "generated": "This function returns a new instance of the Workflow class that implements Key from Channel Data . The default implementation is to use an existing Stream , but it can be used with any other stream as long you specify its name and type in your application's configuration file or by using this method on all streams created before 1 January 2015"}
{"id": 6157, "code": "func (w *Worker) AgentAfterOfferingDelete(job *data.Job) error {\n\tlogger := w.logger.Add(\n\t\t\"method\", \"AgentAfterOfferingDelete\", \"job\", job)\n\n\toffering, err := w.relatedOffering(\n\t\tlogger, job, data.JobAgentAfterOfferingDelete)\n\tif err != nil {\n\t\treturn err\n\t}\n\toffering.Status = data.OfferRemoved\n\n\tif err := w.saveRecord(logger, w.db.Querier, offering); err != nil {\n\t\treturn err\n\t}\n\n\tagent, err := w.account(logger, offering.Agent)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn w.addJob(logger, nil,\n\t\tdata.JobAccountUpdateBalances, data.JobAccount, agent.ID)\n}", "reference": "// AgentAfterOfferingDelete set offering status to `remove`", "generated": "// This method is used to create a new account for the current user and update their balance in order that they can be added as an add-on or remove from existing accounts by using this API call on any of its methods // provided with WidgetBuilder .\nMethods:"}
{"id": 6177, "code": "func (m *Monitor) VerifyChannelsForInactivity() error {\n\tquery := `\n              SELECT channels.id::text\n\t\tFROM channels\n                     LEFT JOIN sessions ses\n                     ON channels.id = ses.channel\n                     LEFT JOIN offerings offer\n                     ON channels.offering = offer.id\n                     INNER JOIN accounts acc\n                     ON channels.agent = acc.eth_addr\n               WHERE channels.service_status IN ('pending', 'active', 'suspended')\n                 AND channels.channel_status NOT IN ('pending')\n                 AND acc.in_use\n               GROUP BY channels.id, offer.max_inactive_time_sec\n              HAVING GREATEST(MAX(ses.last_usage_time), channels.service_changed_time) +\n\t      (offer.max_inactive_time_sec * INTERVAL '1 second') < now();`\n\n\treturn m.processEachChannel(query, m.terminateService)\n}", "reference": "// VerifyChannelsForInactivity scans all channels, that are not terminated,\n// and terminates those of them, who are staying inactive too long.", "generated": "// This function checks if the channel is active and returns true or false for each service status in a list of available services that are currently running on this server. If it does not return an empty string then no further processing will be performed until all remaining pending requests have been processed by another process which has already received them from"}
{"id": 6235, "code": "func New(db *reform.DB, logger log.Logger, payAddr string,\n\ttimeout uint) (*Service, error) {\n\treturn &Service{\n\t\tdb:      db,\n\t\tmsgChan: make(chan *req),\n\t\tpayAddr: payAddr,\n\t\ttimeout: time.Duration(timeout) * time.Millisecond,\n\t\tlogger:  logger.Add(\"type\", \"messages/ept.Service\"),\n\t}, nil\n}", "reference": "// New function for initialize the service for generating\n// the Endpoint Message.", "generated": "New(new) returns a new service instance that implements the specified protocol and provides an interface to it (see RPC). It is intended for use with any of the following protocols or implementations in which this method may be used as part-of another implementation; see Protocols section below on how these are implemented here . The"}
{"id": 6244, "code": "func BytesToUint32(b []byte) (uint32, error) {\n\tif len(b) != 4 {\n\t\treturn 0, fmt.Errorf(\"wrong len\")\n\t}\n\treturn binary.BigEndian.Uint32(b), nil\n}", "reference": "// BytesToUint32 using big endian.", "generated": "This function returns a byte array of bytes that are to be used as the initializer for an unsigned int64 bit integer in addition and subtraction operations on integers larger than or equal 2^16 . The resulting string is then converted into uint32 using UINT_MAX , which can also optionally include any other bits"}
{"id": 6251, "code": "func ChannelKey(client, agent HexString, block uint32,\n\tofferingHash HexString) ([]byte, error) {\n\tclientAddr, err := HexToAddress(client)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tagentAddr, err := HexToAddress(agent)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\thash, err := base64.URLEncoding.DecodeString(\n\t\tstrings.TrimSpace(string(offeringHash)))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tblockBytes := Uint32ToBytes(block)\n\n\treturn crypto.Keccak256(clientAddr.Bytes(),\n\t\tagentAddr.Bytes(), blockBytes[:],\n\t\tcommon.BytesToHash(hash).Bytes()), nil\n}", "reference": "// ChannelKey returns the unique channel identifier\n// used in a Privatix Service Contract.", "generated": "// This function is used to create a new channel key for the client and an optional hash of its contents in order that it can be sent over UDP or TCP connections using any protocol supported by this library. The following example uses one-way communication between two clients on port 80 with no connection restrictions as specified above; //"}
{"id": 6280, "code": "func PanicHunter() {\n\tif panicIgnore {\n\t\treturn\n\t}\n\n\tif err := recover(); err != nil {\n\t\tif enable && notifier != nil {\n\t\t\tnotifier.NotifySync(\n\t\t\t\terrors.New(err, 3), true,\n\t\t\t\tmetadata([]data.HexString{defaultAccEth}))\n\t\t}\n\t\tpanic(err)\n\t}\n}", "reference": "// PanicHunter catches panic, in case of an enabled reporter.", "generated": "// This function is used to notify the user of an error if a connection has been closed or otherwise terminated by logging in with no authentication required and without any additional information provided for subsequent logins (see below).\n // The callback will be called when all connections are open; it should return false after each successful login attempt"}
{"id": 6291, "code": "func (m *Marshaller) MarshalRaw(bs []byte) {\n\tif m.Error != nil {\n\t\treturn\n\t}\n\tif len(m.Data) < m.offset+len(bs) {\n\t\tm.Error = io.ErrShortBuffer\n\t\treturn\n\t}\n\n\tm.offset += copy(m.Data[m.offset:], bs)\n}", "reference": "// MarshalRaw copies the raw bytes to the buffer, without a size prefix or\n// padding. This is suitable for appending data already in XDR format from\n// another source.", "generated": "// This method returns a string representation of the buffer in bytes, which is then used to store data for later use by calling marshal() .\n// The returned value will be an array containing all buffers that have been allocated and stored as strings within this call. It can also contain any number of non-null values"}
{"id": 6293, "code": "func (m *Marshaller) MarshalBytes(bs []byte) {\n\tif m.Error != nil {\n\t\treturn\n\t}\n\tif len(m.Data) < m.offset+4+len(bs)+Padding(len(bs)) {\n\t\tm.Error = io.ErrShortBuffer\n\t\treturn\n\t}\n\n\tm.MarshalUint32(uint32(len(bs)))\n\tm.offset += copy(m.Data[m.offset:], bs)\n\tm.offset += copy(m.Data[m.offset:], padBytes[:Padding(len(bs))])\n}", "reference": "// MarshalString appends the bytes to the buffer, with a size prefix and\n// correct padding.", "generated": "// This function returns a byte array of bytes that are the size and offset of the buffer in bytes, or an integer if no such length is specified by M.MutableByteArray .\n // The returned value should be either 0 , 1 : int64 or 2 : uint16 . If not provided, this will"}
{"id": 6308, "code": "func Prefix(prefix string, p AssetPipeline) AssetPipeline {\n\tif prefix == \"\" {\n\t\treturn p\n\t}\n\n\treturn &prefixPipeline{\n\t\tprefix:        prefix,\n\t\tAssetPipeline: p,\n\t}\n}", "reference": "// Prefix returns an AssetPipeline that prefixes URLs with the\n// given string", "generated": "// Initialize the PIPE structure. This is a simple struct that contains all of the required attributes and methods for creating an asset pipeline (see below).\n // The initializer must be called with no arguments or return nil if it does not exist in the current buffer. If this fails, then create-p"}
{"id": 6327, "code": "func Map(ss []string, callback func(string) string) []string {\n\tnewStrings := make([]string, len(ss))\n\tfor i, s := range ss {\n\t\tnewStrings[i] = callback(s)\n\t}\n\n\treturn newStrings\n}", "reference": "// Map returns a slice containing all the elements of ss\n// after applying the callback function to each one", "generated": "Map is a map with the following properties. It can be used to create an array of strings and return them as keys or values in any order you like (see below). The key-value pairs are returned by calling append() on each element that contains one value from the list; if there were no elements left for"}
{"id": 6383, "code": "func SelectMany(subject Enumerable, toMany Unfolder) Enumerable {\n\treturn selectManyer{\n\t\toriginal: subject,\n\t\ttoMany:   toMany,\n\t}\n}", "reference": "// SelectMany allows for unfolding of values.", "generated": "SelectMany is a method that selects the most recent item in an enumeration. It returns all items from this collection as well if any of them are not present or absent at some point during its lifetime. The default value for selectedItem() will be None . If no selection occurs within one iteration, it defaults back into"}
{"id": 6400, "code": "func (stack *Stack) IsEmpty() bool {\n\tstack.key.RLock()\n\tdefer stack.key.RUnlock()\n\treturn stack.underlyer == nil || stack.underlyer.IsEmpty()\n}", "reference": "// IsEmpty tests the Stack to determine if it is populate or not.", "generated": "This function is called when the value of the key in the Stack object has been removed from the heap and no other objects are available to it, or if there were none at all for any reason whatsoever by default. It returns true only once every 10 seconds on a successful call with an empty string representation as its argument."}
{"id": 6407, "code": "func (list *LinkedList) Enumerate(cancel <-chan struct{}) Enumerator {\n\tretval := make(chan interface{})\n\n\tgo func() {\n\t\tlist.key.RLock()\n\t\tdefer list.key.RUnlock()\n\t\tdefer close(retval)\n\n\t\tcurrent := list.first\n\t\tfor current != nil {\n\t\t\tselect {\n\t\t\tcase retval <- current.payload:\n\t\t\t\tbreak\n\t\t\tcase <-cancel:\n\t\t\t\treturn\n\t\t\t}\n\t\t\tcurrent = current.next\n\t\t}\n\t}()\n\n\treturn retval\n}", "reference": "// Enumerate creates a new instance of Enumerable which can be executed on.", "generated": "The enumeration of the Linkable List is a simple, non-blocking implementation of an enum that implements all three methods in this class and provides access to its keys as well for each method on it's own instance. The key can be any value or null . It also has no special properties such as length , type"}
{"id": 6415, "code": "func (list *LinkedList) Sort(comparator Comparator) error {\n\tlist.key.Lock()\n\tdefer list.key.Unlock()\n\tvar err error\n\tlist.first, err = mergeSort(list.first, comparator)\n\tif err != nil {\n\t\treturn err\n\t}\n\tlist.last = findLast(list.first)\n\treturn err\n}", "reference": "// Sort rearranges the positions of the entries in this list so that they are\n// ascending.", "generated": "This function returns a sorted List with the keys and values of all items in it that are not found by merging them into one TreeNode or another node within LinkedList . The returned tree is then merged to create an unordered set of trees for each item on the linked list using MergeTree , which can be used"}
{"id": 6420, "code": "func merge(left, right *llNode, comparator Comparator) (first *llNode, err error) {\n\tcurLeft := left\n\tcurRight := right\n\n\tvar last *llNode\n\n\tappendResults := func(updated *llNode) {\n\t\tif last == nil {\n\t\t\tlast = updated\n\t\t} else {\n\t\t\tlast.next = updated\n\t\t\tlast = last.next\n\t\t}\n\t\tif first == nil {\n\t\t\tfirst = last\n\t\t}\n\t}\n\n\tfor curLeft != nil && curRight != nil {\n\t\tvar res int\n\t\tif res, err = comparator(curLeft.payload, curRight.payload); nil != err {\n\t\t\tbreak // Don't return, stitch the remaining elements back on.\n\t\t} else if res < 0 {\n\t\t\tappendResults(curLeft)\n\t\t\tcurLeft = curLeft.next\n\t\t} else {\n\t\t\tappendResults(curRight)\n\t\t\tcurRight = curRight.next\n\t\t}\n\t}\n\n\tif curLeft != nil {\n\t\tappendResults(curLeft)\n\t}\n\tif curRight != nil {\n\t\tappendResults(curRight)\n\t}\n\treturn\n}", "reference": "// merge takes two sorted lists and merges them into one sorted list.\n// Behavior is undefined when you pass a non-sorted list as `left` or `right`", "generated": "// Merge a node into an array of nodes and append them to the resulting list. The result is returned as one element in the original tree with no additional information about its position or size at all for each iteration.\n/**\n* Returns true when merged by merging two trees together using merges() . If this method"}
{"id": 6439, "code": "func (l *List) Remove(pos uint) (interface{}, bool) {\n\tl.key.Lock()\n\tdefer l.key.Unlock()\n\n\tif pos > uint(len(l.underlyer)) {\n\t\treturn nil, false\n\t}\n\tretval := l.underlyer[pos]\n\tl.underlyer = append(l.underlyer[:pos], l.underlyer[pos+1:]...)\n\treturn retval, true\n}", "reference": "// Remove retreives a value from this List and shifts all other values.", "generated": "// Removes the key from the list and returns it to the caller if no keys are found in the buffer or a new one is created for that string of strings returned by this function.\n/**\n* Returns the number [of bytes needed]. The value must be zero-based on whether there was an error with"}
{"id": 6484, "code": "func (h *Handler) Rule(r rule.Rule) *Handler {\n\tif r == nil {\n\t\t// if nothing passed then use the allow-everyting rule\n\t\tr = rule.Satisfied()\n\t}\n\th.rule = r\n\n\treturn h\n}", "reference": "// Rule sets the ruleset for this handler.\n//\n// returns itself.", "generated": "This function returns a new Handler that can be used to check whether an action is allowed or not, and return true for any given handler method call in this case. The default value of false will cause all handlers to fail with no exception thrown from within it. This allows you access control over how many times your application may"}
{"id": 6515, "code": "func (c Client) CreateUser(email string, password string) (*user, error) {\n\tparams := map[string]interface{}{\n\t\t\"user[email]\":    email,\n\t\t\"user[password]\": password,\n\t}\n\tholder := userHolder{}\n\tif err := c.Post(\"users\", params, &holder); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := checkApiErrors(holder.response, \"CreateUser\"); err != nil {\n\t\treturn nil, err\n\t}\n\treturn &holder.User, nil\n}", "reference": "// CreateUser creates a new user given an email and password", "generated": "// Creates a new User object with the given credentials and an optional username/password pair for use in authentication requests to create users from within their own applet or applicationlets using JSON API methods // provided by C# 5.0+. The default is created as follows: var client = NewCredentials()"}
{"id": 6523, "code": "func (c Client) GetTransfers(page int) (*transfers, error) {\n\tparams := map[string]int{\n\t\t\"page\": page,\n\t}\n\tholder := transfersHolder{}\n\tif err := c.Get(\"transfers\", params, &holder); err != nil {\n\t\treturn nil, err\n\t}\n\ttransfers := transfers{\n\t\tpaginationStats: holder.paginationStats,\n\t}\n\t// Remove one layer of nesting\n\tfor _, t := range holder.Transfers {\n\t\ttransfers.Transfers = append(transfers.Transfers, t.Transfer)\n\t}\n\treturn &transfers, nil\n}", "reference": "// GetTransfers get transfers associated with an account", "generated": "This function returns a list containing the transferred data from client to server and its associated headers for each transfer in progress with no additional information about whether or not it is successful at transferring any other type of content between clients/server nodes that are currently connected via HTTP connections on either side of an interface such as http://localhost"}
{"id": 6531, "code": "func (d *SerialDispatcher) DispatchOptional(cmd interface{}) (err error) {\n\td.mutex.RLock()\n\tdefer d.mutex.RUnlock()\n\n\terr = d.Dispatch(cmd)\n\tswitch err.(type) {\n\tcase *NoHandlerFoundError:\n\t\treturn nil\n\tdefault:\n\t\treturn err\n\t}\n}", "reference": "// DispatchOptional implements `Dispatcher.DispatchOptional`", "generated": "// This dispatch method is used to check if the specified protocol has been implemented by a client and return an optional message for that implementation of protocols, or not. If it does not have any implementations then this will be called asynchronously with no response received from clients until all other options are exhausted in order on success."}
{"id": 6532, "code": "func NewParallelDispatcher(handlers []Handler) Dispatcher {\n\treturn &ParallelDispatcher{\n\t\thandlers: handlers,\n\t\tmutex:    sync.RWMutex{},\n\t}\n}", "reference": "// NewParallelDispatcher creates a new PrallelDispatcher with the given handlers", "generated": "// This is a new parallel dispatcher that will be used to check for changes in the current thread's state and return an error if any of these conditions are met.\n // The default behavior should not change when this method returns true or false .\n\n\n/** * Returns `true` whether all threads have been closed by"}
{"id": 6537, "code": "func (l *listener) Accept() (transport.Conn, error) {\n\tif c, ok := <-l.incoming; ok {\n\t\treturn c.conn, c.err\n\t}\n\treturn nil, fmt.Errorf(\"listener is closed\")\n}", "reference": "// Accept waits for and returns the next connection to the listener.", "generated": "Listeners accept incoming and outgoing messages as a single message stream with the following attributes :\n*message-type , which specifies whether or not to send an unhandled packet of data from one destination address into another. The default value for this attribute is \"unexpected\". This option can be set by setting it in config"}
{"id": 6557, "code": "func NewCommand(name string, args ...string) *Command {\n\treturn &Command{\n\t\tname: name,\n\t\targs: args,\n\t}\n}", "reference": "// NewCommand creates a new Livestatus command instance.", "generated": "New Command is a new command that can be used to execute commands. It will return the current value of this variable and its arguments if any are not provided by default. The following example uses it in conjunction with an existing cmdlet (see below):\n\n\npackage main import \"fmt\"\nimport \"github/"}
{"id": 6564, "code": "func (r Record) GetSlice(column string) ([]interface{}, error) {\n\tv, err := r.getKey(reflect.Slice, column)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trv := reflect.ValueOf(v)\n\tn := rv.Len()\n\tout := make([]interface{}, n)\n\n\tfor i := 0; i < n; i++ {\n\t\tout[i] = rv.Index(i).Interface()\n\t}\n\n\treturn out, nil\n}", "reference": "// GetSlice returns a slice of interface value for a specific column.", "generated": "// Returns a slice of the key-value pairs in an array with all keys and values returned by this method for each element within that range to be used as indices into which they can store their data structures or other information about elements inside those ranges if necessary.\n// This is useful when you want to retrieve some sort"}
{"id": 6588, "code": "func RemoveSvcAcknowledgement(\n\thost_name string,\n\tservice_description string,\n) *livestatus.Command {\n\treturn livestatus.NewCommand(\n\t\t\"REMOVE_SVC_ACKNOWLEDGEMENT\",\n\t\tstringifyArg(\"host_name\", \"string\", host_name),\n\t\tstringifyArg(\"service_description\", \"string\", service_description),\n\t)\n}", "reference": "// RemoveSvcAcknowledgement creates a new \"REMOVE_SVC_ACKNOWLEDGEMENT\" Nagios command.\n//\n// This removes the problem acknowledgement for a particular service.\n//\n// Once the acknowledgement has been removed, notifications can once again be sent out for the given service.", "generated": "// Removes the SSC acknowledgement from the command line if it is not already present in a file or directory named `\\s*.cmd`.\n // This can be used to remove an existing acknowledgment by calling clean-up() on all files and directories that are no longer being updated with new versions of svc-"}
{"id": 6615, "code": "func NewCmdWithRunner(cmdName string, runner func()) (*CmdWithRunner, error) {\n\tif cmdName == \"\" {\n\t\treturn nil, errors.New(\"cmdName cannot be blank\")\n\t}\n\n\tfor _, r := range cmdName {\n\t\tif unicode.IsSpace(r) {\n\t\t\treturn nil, errors.Errorf(\"cmdName cannot contain whitespace: %q\", cmdName)\n\t\t}\n\t}\n\n\treturn &CmdWithRunner{\n\t\tcmdName: cmdName,\n\t\trunner:  runner,\n\t}, nil\n}", "reference": "// NewCmdWithRunner creates a new CmdWithRunner for the provided name and runner. Returns an error if the provided name\n// is not a legal command name.", "generated": "// This command creates a new Runnable object that will run the specified commands and return an instance of this CommandBuilder . The default is to create one for each running program in its own directory (see below). It can also optionally specify which programs are executed by calling it with args or using any other method onCommand"}
{"id": 6617, "code": "func importBreakPaths(file *ast.File) []string {\n\tvar output []string\n\n\tfor _, decl := range file.Decls {\n\t\tif gen, ok := decl.(*ast.GenDecl); ok && gen.Tok == token.IMPORT {\n\t\t\tfor srcIndex, currSpec := range gen.Specs {\n\t\t\t\tif srcIndex > 0 {\n\t\t\t\t\t// if there was a previous element, check if the group has changed\n\t\t\t\t\tcurrGroup := importGroup(importPath(currSpec))\n\t\t\t\t\tprevGroup := importGroup(importPath(gen.Specs[srcIndex-1]))\n\t\t\t\t\tif currGroup != prevGroup {\n\t\t\t\t\t\t// if group has changed, add path to the output\n\t\t\t\t\t\toutput = append(output, importPath(gen.Specs[srcIndex]))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// assume that only one import token block exists\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn output\n}", "reference": "// importBreakPaths returns a slice that contains the import paths before which a line breaks should be inserted.", "generated": "package os.path.join(\"/\")\n func main() {} // Create an AST for our program and create some files in it var obj struct{\n externalTo\u0019escription string name string description string }\nDescription is not used here because we don't want any of these strings being passed as arguments or returned by this"}
{"id": 6619, "code": "func SupplierWithPrependedArgs(s CmderSupplier, argsFunc func(cmd Cmd) []string) CmderSupplier {\n\treturn func(cmd Cmd) (Cmder, error) {\n\t\tr, err := s(cmd)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn CmderWithPrependedArgs(r, argsFunc(cmd)...), nil\n\t}\n}", "reference": "// SupplierWithPrependedArgs returns a new Supplier that invokes the provided supplier and returns the result of calling\n// RunnerWithPrependedArgs on the returned runner with the result of applying the provided \"argsFunc\" function to the\n// provided command.", "generated": "This function provides a wrapper for the supplied arguments. It returns an optional string containing all of the specified options and optionally one or more additional parameters to be used in conjunction with those provided by this method. The default is None . This can also be set via `setOptions` , which will return true if no option has"}
{"id": 6633, "code": "func (t *Timer) ServeHTTP(w http.ResponseWriter, req *http.Request) {\n\n\treq.ParseForm()\n\tsortBy := req.Form.Get(\"sort\")\n\n\tstats := &Stats{}\n\tstats.SortBy = strings.ToLower(sortBy)\n\tstats.Generated = time.Now()\n\tstats.UpTime = fmt.Sprintf(\"%s\", stats.Generated.Sub(t.Since))\n\t// Read access OK for map?\n\tstats.Result = make([]*Stat, 0, len(t.routes))\n\tfor k, v := range t.routes {\n\t\tstat := &Stat{}\n\t\tstat.Route = k\n\t\tstat.Count = v.Count\n\t\tstat.Tot = v.Tot\n\t\tstat.Avg = time.Duration(int64(v.Tot) / v.Count)\n\t\tstat.AvgAfter = time.Duration(int64(v.AfterTot) / v.Count)\n\t\tstat.AvgBefore = time.Duration(int64(v.BeforeTot) / v.Count)\n\t\tstat.Max = v.Max\n\t\tstat.Min = v.Min\n\t\tstats.Result = append(stats.Result, stat)\n\t}\n\tsort.Sort(sort.Reverse(stats))\n\tjsonData, _ := json.Marshal(stats)\n\tw.Write(jsonData)\n}", "reference": "// For serving statistics", "generated": "The JSON data is a collection of the following fields and values that are passed to HTTP requests as parameters in order from most recently received headers or by default returned via POST :\nName Description string The name of this field which should be used when parsing an incoming request with respect not only header information but also any other metadata such"}
{"id": 6638, "code": "func RectFromSphere(c Vec3, r float32) Rectangle {\n\treturn RectWHD(c[0]-r, c[1]-r, c[2]-r, 2*r, 2*r, 2*r)\n}", "reference": "// RectFromSphere returns the minimum rectangle that contains the circle of\n// center c and radius r.", "generated": "RectFromShape is a new Shape object that can be used to create and manipulate shapes. It provides the following methods for creating or manipulating shape objects in C# using Vector . The method returns an array of coordinates representing each coordinate value from within the vector space (in this case 0x00 ). This means you will need"}
{"id": 6640, "code": "func (r Rectangle) Size() Vec3 {\n\treturn Vec3{\n\t\tr.Max[0] - r.Min[0],\n\t\tr.Max[1] - r.Min[1],\n\t\tr.Max[2] - r.Min[2],\n\t}\n}", "reference": "// Size returns r's width, height and depth.", "generated": "// Initializes a new rectangle with the size of the given number, and returns it as an array containing all its elements in order from smallest to largest; this is called initializing for each element within the range 0-size . // Returns nil if no value has been returned by calling initWithSize().\n func initialize"}
{"id": 6645, "code": "func (r Rectangle) In(s Rectangle) bool {\n\tif r.Empty() {\n\t\treturn true\n\t}\n\t// Note that r.Max is an exclusive bound for r, so that r.In(s)\n\t// does not require that r.Max.In(s).\n\treturn s.Min[0] <= r.Min[0] && r.Max[0] <= s.Max[0] &&\n\t\ts.Min[1] <= r.Min[1] && r.Max[1] <= s.Max[1]\n}", "reference": "// In reports whether Rectangle r is contained in s.", "generated": "This method returns a boolean indicating whether the given rectangle has been created or destroyed by this operation. If false , it will return nil . Otherwise if true and no bounds check are performed on any of the rectangles in the array to determine which one was used as input when creating them from scratch. The returned value may be"}
{"id": 6647, "code": "func ApproxEpsilon(x, y float64, eps float64) bool {\n\treturn math.Abs(x-y) < eps*(1.0+math.Max(math.Abs(x), math.Abs(y)))\n}", "reference": "// ApproxEpsilon returns true if x ~= y, using provided epsilon value.", "generated": "Approximately approximates the Eulerian approximation of a given value in terms that is less than or equal to x and greater then y . The resulting result can be computed using either an integer (elements with no digits are assumed by default) or floating point numbers such as 0 , 1 + 2 * 3 / 4"}
{"id": 6650, "code": "func (v Vec3) Copy(dst Vec3) {\n\tdst[0] = v[0]\n\tdst[1] = v[1]\n\tdst[2] = v[2]\n}", "reference": "// Vec3 methods\n// Copy copies the 3 vector components into dst.", "generated": "copy() copies the contents of a vector to a new copy. The resulting value is copied from the original, and vice versa for each subsequent iteration. It returns an object with all its properties set up correctly in order to avoid copying errors when using this method on vectors that are not already created by another program or library as"}
{"id": 6703, "code": "func (c *Client) LoadBalancer(identifier string) (*LoadBalancer, error) {\n\tlb := new(LoadBalancer)\n\t_, err := c.MakeApiRequest(\"GET\", \"/1.0/load_balancers/\"+identifier, nil, lb)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn lb, err\n}", "reference": "// LoadBalancer retrieves a detailed view of one load balancer", "generated": "// Initializes a load balancing request to the client and returns an object that contains all of the requested attributes in order from most to least loaded for each attribute on this list.\n// This is used by default when loading Balances with no other options available or if there are multiple requests at once using one method as"}
{"id": 6730, "code": "func FromURL(src *url.URL, w io.Writer, options Options) error {\n\thttpClient := getHTTPClient(options)\n\tvar (\n\t\terr  error\n\t\tresp *http.Response\n\t)\n\tdownloader := func() error {\n\t\tresp, err = httpClient.Get(src.String())\n\t\tif err != nil {\n\t\t\treturn &retriableError{errors.Wrap(err, \"Temporary download error\")}\n\t\t}\n\t\tif resp.StatusCode != http.StatusOK {\n\t\t\tdefer func() { _ = resp.Body.Close() }() // #nosec\n\t\t\treturn errors.Errorf(\"received invalid status code: %d (expected %d)\", resp.StatusCode, http.StatusOK)\n\t\t}\n\t\treturn nil\n\t}\n\tretries := options.Retries\n\tif retries == 0 {\n\t\tretries = 5\n\t}\n\tif err = retryAfter(retries, downloader, options.RetryInterval); err != nil {\n\t\treturn errors.Wrap(err, \"download failed\")\n\t}\n\tdefer func() { _ = resp.Body.Close() }() // #nosec\n\n\tvar (\n\t\tvalidator checksumValidator\n\n\t\treader io.Reader = resp.Body\n\t)\n\n\tif options.ProgressBars != nil && resp.ContentLength > 0 {\n\t\tbar := newProgressBar(resp.ContentLength, options.ProgressBars.MaxWidth, options.ProgressBars.Writer)\n\t\tbar.Start()\n\t\treader = bar.NewProxyReader(reader)\n\t\tdefer func() {\n\t\t\t<-time.After(bar.RefreshRate)\n\t\t\tfmt.Println()\n\t\t}()\n\t}\n\n\tvalidator, reader, err = createValidatorReader(reader, options.ChecksumHash, httpClient, options.Checksum, path.Base(src.Path))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, err = io.Copy(w, reader); err != nil {\n\t\treturn errors.Wrap(err, \"failed to copy contents\")\n\t}\n\n\tif !validator.validate() {\n\t\treturn errors.New(\"checksum validation failed\")\n\t}\n\n\treturn nil\n}", "reference": "// FromURL downloads the specified `src` URL to `w` writer using\n// the specified `Options`.", "generated": "// This function is used for checking if a given URL has been created and the progress bars are updated in order of appearance on an HTTP request or response body with no content at all after it's received by this method. The default value will be false .\nMethods:"}
{"id": 6733, "code": "func RandomSecret(length int, rnd *rand.Rand) string {\n\tif 0 <= length {\n\t\tlength = 10\n\t}\n\tsecret := make([]byte, length)\n\tfor i, _ := range secret {\n\t\tsecret[i] = byte(rnd.Int31() % 256)\n\t}\n\treturn base32.StdEncoding.EncodeToString(secret)\n}", "reference": "// Generate a Random secret encoded as a b32 string\n// If the length is <= 0, a default length of 10 bytes will\n// be used, which will generate a secret of length 16.", "generated": "Random Secret is a random number generator that generates an encrypted message with the given key and value of each element in its hash table (see below). It can be used to generate plaintext messages or cipher text using any encryption scheme supported by AES-256 bits per second for secure communication between two parties on one computer network without"}
{"id": 6758, "code": "func (a *AddrBook) RemoveAddress(addr *NetAddress) {\n\ta.mtx.Lock()\n\tdefer a.mtx.Unlock()\n\tka := a.addrLookup[addr.String()]\n\tif ka == nil {\n\t\treturn\n\t}\n\tlog.Info(\"Remove address from book\", \"addr\", addr)\n\ta.removeFromAllBuckets(ka)\n}", "reference": "// RemoveAddress removes the address from the book.", "generated": "// Addresses are removed by default, but can be changed to remove them later if needed.\n // This function is used for checking the integrity of addresses and returns true or false depending on whether they have been deleted in any way. If an error occurs while calling this function, it will return false ."}
{"id": 6767, "code": "func (na *NetAddress) Dial() (net.Conn, error) {\n\tconn, err := net.Dial(\"tcp\", na.String())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn conn, nil\n}", "reference": "// Dial calls net.Dial on the address.", "generated": "// This function returns a string that contains the address of the server to which it is sent and an optional message for each connection request or response from this client // using UDP/IPv6 protocol as its default gateway interface with no additional parameters set by NetServerClientInterface().\n// The returned value should be either \""}
{"id": 6778, "code": "func LogOnPanic(id int64, err interface{}, stacktrace []string, _ *http.Request) {\n\tlogMutex.Lock()\n\tdefer logMutex.Unlock()\n\n\tlog.Printf(\"panic=%016x message=%v\\n\", id, err)\n\tfor _, line := range stacktrace {\n\t\tlog.Printf(\"panic=%016x %s\", id, line)\n\t}\n}", "reference": "// LogOnPanic logs the given panic and its stacktrace, prefixing each line with\n// the panic ID.", "generated": "Logon Panics is a logging mechanism that allows you to monitor and debug your system's status of execution by checking if an error occurred while executing the program or failed when it was started (or not). It can be used for debugging purposes only in conjunction with other tools such as System Monitor . The following example logs on"}
{"id": 6791, "code": "func (hub *hub) getChannel(name string) *channel {\n\thub.Lock()\n\tdefer hub.Unlock()\n\tcn, ok := hub.channels[name]\n\tif ok {\n\t\treturn cn\n\t}\n\tcn = makeChannel(hub, name)\n\thub.channels[name] = cn\n\tgo cn.start()\n\treturn cn\n}", "reference": "// GetChannel gets or creates new pubsub channel.", "generated": "// Create a channel for the specified namespace and create an instance of it using channels from that class to be used as its default ChannelHandler .\n // This is done by calling channels with no arguments or returning nil if there are any instances in this scope which do not have their own DefaultChannels , but instead use"}
{"id": 6814, "code": "func (c *Client) Push(value interface{}, params map[string]string) (*Client, error) {\n\tbody, err := json.Marshal(value)\n\tif err != nil {\n\t\tlog.Printf(\"%v\\n\", err)\n\t\treturn nil, err\n\t}\n\n\tres, err := c.api.Call(\"POST\", c.Url, c.Auth, body, params)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar r map[string]string\n\n\terr = json.Unmarshal(res, &r)\n\tif err != nil {\n\t\tlog.Printf(\"%v\\n\", err)\n\t\treturn nil, err\n\t}\n\n\tret := &Client{\n\t\tapi:   c.api,\n\t\tAuth:  c.Auth,\n\t\tUrl:   c.Url + \"/\" + r[\"name\"],\n\t\tvalue: value}\n\n\treturn ret, nil\n}", "reference": "// Push creates a new value under the current root url.\n// A populated pointer with that value is also returned.", "generated": "// Create a new client and pass it to the API call method of this Client .\n // This is used for creating an instance that will be called when we create our own clients in order notify them about changes made by\n# any other user or service on their behalf using `client` methods from within C++"}
{"id": 6821, "code": "func (t *trace) Finish() {\n\tif t.err {\n\t\tincrError(t)\n\t}\n\tincr(t)\n\tduration(t)\n\tif t.err {\n\t\tincrError(t)\n\t}\n\tt.trace.Finish()\n}", "reference": "// Finish declares that this trace is complete.\n// The trace should not be used after calling this method.", "generated": "// This function is called when the trace finishes and returns a status code of nil if it has not been completed yet, or an error message for any reason that could be encountered by calling this method on another thread in order to finish tracing from one point to other.\n// The following example shows how to use these functions"}
{"id": 6843, "code": "func (c *Client) PushLinkToChannel(tag, title, u, body string) error {\n\tdata := Link{\n\t\tTag:   tag,\n\t\tType:  \"link\",\n\t\tTitle: title,\n\t\tURL:   u,\n\t\tBody:  body,\n\t}\n\treturn c.Push(\"/pushes\", data)\n}", "reference": "// PushLinkToChannel pushes a link with a title and url to a specific PushBullet device.", "generated": "// This method is used to push a link from the channel into the client's local storage and return it as an object with no parameters or methods that are not provided by this class. It returns nil if there was any connection failure in either of these cases.\n// The default behavior for all other calls on http://"}
{"id": 6852, "code": "func (c *cachedLoader) MustGetString(key string) string {\n\tb, err := c.Get(key)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"Could not fetch config (%s) %v\", key, err))\n\t}\n\n\tvar s string\n\terr = json.Unmarshal(b, &s)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"Could not unmarshal config (%s) %v\", key, err))\n\t}\n\n\treturn s\n}", "reference": "// MustGetString fetches the config and parses it into a string.  Panics on failure.", "generated": "MustSet String is a method that returns the hash of an object with keys and values in its format strings as specified by C++ standard library headers . It can be used to create or modify objects from any other source codebase without requiring additional knowledge about how it works; for example if you want your application's API call"}
{"id": 6870, "code": "func (e *execStreamerBuilder) Exe(exe string) ExecStreamerBuilder {\n\te.d.Exe = exe\n\treturn e\n}", "reference": "//Exe sets the Exe", "generated": "This function returns an executable stream of the specified name and a list containing all its arguments, including any null values that are not present in this file or if they exist at runtime by default. The following example shows how to use it with some examples from C# using std::string . Note that you must specify both \""}
{"id": 6884, "code": "func (w *Window) setCell(x, y int, c Cell) {\n\tc.dirty = true\n\tpos := x + (y * w.x)\n\tif pos < len(w.backingStore) {\n\t\tw.backingStore[pos] = c\n\t}\n}", "reference": "// setCell sets the content of the window cell at the x and y coordinate.\n// setCell shall be called from queue context.", "generated": "// Set cell to the current location of the window and return it if no other windows exist in that area.\n // This is useful for debugging purposes only when a new Window has been created or closed by another process on its own time frame.\n\n\n/**\n* Sets an empty string buffer containing all available cells from"}
{"id": 6896, "code": "func Deinit() {\n\twait := make(chan interface{})\n\tQueue(func() {\n\t\ttermbox.Close()\n\t\tfocus = nil\n\t\tprevFocus = nil\n\t\twindows = make(map[int]*Window) // toss all windows\n\n\t\trawMtx.Lock()\n\t\ttermRaw = false\n\t\trawMtx.Unlock()\n\n\t\twait <- true\n\t})\n\t<-wait\n}", "reference": "// Deinit switches the terminal back to cooked mode and it terminates managed\n// window mode.  Init must be called again if a switch is required again.\n// Deinit shall be called on application exit; failing to do so may leave the\n// terminal corrupted.  If that does happen typing \"reset\" on the shell usually\n// fixes this problem.", "generated": "// Initializes a buffer and returns the current window's status as an int, if it is not already initialized to zero or more than one of its initializations (see below).\n/**\n*/ func init () { var buffers []byteBuffer = new byteBuffers();\n\u0019 wait := make(\"buffer\", \""}
{"id": 6933, "code": "func (d *Derive) Update(v float64) {\n\tp := atomic.SwapUint64(&d.value, math.Float64bits(v))\n\td.rate.Update(v - math.Float64frombits(p))\n}", "reference": "// Update update rate value based on the stored previous value.", "generated": "This function updates the value of a Derivative object using Atomic . The update method is called when an atomically updated element has been added to the list or removed from it by another operation on that Element , and then returns true if this new item was previously in use at some point during its lifetime. This can be"}
{"id": 6934, "code": "func (r *Reservoir) Snapshot() Distribution {\n\th := newHistogram(defaultHistogramSize)\n\tr.m.Lock()\n\th = r.hist.Copy(h)\n\tr.m.Unlock()\n\treturn h\n}", "reference": "// Snapshot returns a Distribution", "generated": "This function is a wrapper around the Resolver's snapshot method, which allows you to create snapshots of any type that are available in your repository and store them as an array or hash table for later use by other repositories on demand when needed. The following example uses this approach with respect not only to our GitLab repo but"}
{"id": 6957, "code": "func (s *Set) RemoveAll(values ...interface{}) {\n\ts.Lock()\n\tdefer s.Unlock()\n\tfor _, value := range values {\n\t\tdelete(s.m, value)\n\t}\n}", "reference": "// RemoveAll removes all values from the set if they exist in the set.", "generated": "// This method removes all of the items from a set and returns them as an array with no additional information about their contents or status in any way other than by calling removeAll().\n// The methods are described below for convenience.\n// Note that this is not intended to be used on arrays; it will return only"}
{"id": 6980, "code": "func (s *Server) SendRequest(connID string, method string, params interface{}, resHandler func(ctx *ResCtx) error) (reqID string, err error) {\n\tif !s.running.Load().(bool) {\n\t\treturn \"\", errors.New(\"use of closed server\")\n\t}\n\n\tif conn, ok := s.conns.GetOk(connID); ok {\n\t\treqID, err = conn.(*Conn).SendRequest(method, params, resHandler)\n\t\t// todo: only log in debug mode?\n\t\tlog.Printf(\"server: send-request: connID: %v, reqID: %v, method: %v, params: %#v, err (if any): %v\", connID, reqID, method, params, err)\n\t\treturn\n\t}\n\n\treturn \"\", fmt.Errorf(\"connection with requested ID: %v does not exist\", connID)\n}", "reference": "// SendRequest sends a JSON-RPC request through the connection denoted by the connection ID with an auto generated request ID.\n// resHandler is called when a response is returned.", "generated": "This function sends a request and returns an object that contains the following information about its status as well :\nThe response is sent by default if it has been received or otherwise returned from another process on which this connection was established; If no such instance exists then all requests are rejected for failure unless they have already occurred before sending"}
{"id": 6996, "code": "func (r *Router) Request(route string, handler func(ctx *neptulon.ReqCtx) error) {\n\tr.routes[route] = handler\n}", "reference": "// Request adds a new request route registry.", "generated": "Request is a request method that returns an object with the following properties and methods for each route in its scope:\nRouteName : The name of the routes to be returned by Router . RouteType : A list containing all available options or nil if no option exists , including any optional parameters passed as arguments when returning from this"}
{"id": 7042, "code": "func (c *Conn) setConn(ws *websocket.Conn) error {\n\tc.ws.Store(ws)\n\tc.connected.Store(true)\n\tif err := ws.SetDeadline(time.Now().Add(c.deadline)); err != nil {\n\t\treturn fmt.Errorf(\"conn: error while setting websocket connection deadline: %v\", err)\n\t}\n\treturn nil\n}", "reference": "// Reuse an established websocket.Conn.", "generated": "// Set the current timezone to be used for logging messages from a web server, and return an instance of Conn that is connected with this WebSocket interface // using its own local socket address or port number in order notto cause any issues if it does so on some other network node; otherwise returns None .\n//"}
{"id": 7046, "code": "func (r *MockReadWriteCloser) Read(p []byte) (n int, err error) {\n\n\tif err = r.ReadErr; err == nil {\n\t\tr.BytesRead = p\n\t\tn = len(p)\n\t}\n\treturn\n}", "reference": "//Read - satisfies reader interface", "generated": "This method reads and writes a byte from the buffer to an address that is not null . The bytes are then read back into memory using mlock() , which returns true if they were written in or out of bounds by any other process on disk before writing them down again with write(). This can be useful for debugging purposes"}
{"id": 7078, "code": "func (m *MACMaskArg) MarshalBinary() ([]byte, error) {\n\t// Must indicate correct number of directives\n\tif int(m.DirCount) != len(m.Directives) {\n\t\treturn nil, ErrorBadArgumentParameter\n\t}\n\n\t// Allocate byte slice for argument and all directives\n\tb := make([]byte, macMaskArgLen+(directiveLen*m.DirCount))\n\n\t// 1 byte reserved\n\n\tb[1] = uint8(m.Command)\n\tb[2] = uint8(m.Error)\n\tb[3] = m.DirCount\n\n\t// Marshal each directive into binary and copy into byte slice\n\t// after argument\n\tn := 4\n\tfor _, d := range m.Directives {\n\t\tdb, err := d.MarshalBinary()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tcopy(b[n:n+directiveLen], db)\n\t\tn += directiveLen\n\t}\n\n\treturn b, nil\n}", "reference": "// MarshalBinary allocates a byte slice containing the data from a MACMaskArg.\n//\n// If m.DirCount does not indicate the actual length of m.Directives, or\n// a Directive is malformed, ErrorBadArgumentParameter is returned.", "generated": "This function is a wrapper around the MACMaskArg interface to provide an alias that can be used in conjunction with other macros or functions which may have additional aliases such as MIRROR_MARKER . The macro name must match any given identifier on MacOS X 10.10/11 using this syntax; see below"}
{"id": 7086, "code": "func (s *CORSHandler) CreatePreflight(routes Routes) Routes {\n\tlist := make(Routes, 0, len(routes))\n\thList := make(map[string]*CORSPreflight, len(routes))\n\tfor _, v := range routes {\n\t\tpreflight, ok := hList[v.Path]\n\t\tif !ok {\n\t\t\tpreflight = &CORSPreflight{\n\t\t\t\t*s,\n\t\t\t\tmake([]string, 0, 1),\n\t\t\t\tv.MustAuth,\n\t\t\t}\n\t\t\thList[v.Path] = preflight\n\t\t}\n\n\t\tpreflight.Methods = append(preflight.Methods, v.Method)\n\t\tif v.MustAuth {\n\t\t\tpreflight.UseCredentials = true\n\t\t}\n\t}\n\n\tfor k, v := range hList {\n\t\tlist = append(list, Route{\n\t\t\tName:       \"\",\n\t\t\tMethod:     DEFAULT_CORS_PREFLIGHT_METHOD,\n\t\t\tPath:       k,\n\t\t\tMustAuth:   v.UseCredentials,\n\t\t\tActionFunc: v.ServeHTTP,\n\t\t})\n\t}\n\treturn list\n}", "reference": "// CreatePreflight creates HTTP routes that handles pre-flight requests.", "generated": "// Initializes a new route with the specified name and path to be used for initialization of an existing one.\n // This method is called when all other methods are invoked on that same instance. It returns nil if no such connection exists or null otherwise. func initRoute() string { return []string{\"name\"}"}
{"id": 7097, "code": "func (b *RefCountBox) Alloc() (DB, error) {\n\tb.Lock()\n\tdefer b.Unlock()\n\n\tif b.db.DB == nil {\n\t\tif b.DataPath == nil {\n\t\t\treturn DB{}, errorsp.WithStacks(ErrBoxDataPathNotSpecified)\n\t\t}\n\t\tvar db DB\n\t\tvar err error\n\t\tif b.OpenFunc == nil {\n\t\t\tdb, err = Open(b.DataPath(), 0644, nil)\n\t\t} else {\n\t\t\tdb, err = b.OpenFunc(b.DataPath())\n\t\t}\n\t\tif err != nil {\n\t\t\treturn DB{}, errorsp.WithStacks(err)\n\t\t}\n\t\tb.db, b.count = db, 0\n\t}\n\tb.count++\n\treturn b.db, nil\n}", "reference": "// Alloc opens a DB if not openned yet. It adds a reference if already openned.", "generated": "// This function is used to lock the data in a buffer and return it if there are no more entries or not found at all within that file descriptor range for any reason other than an exception thrown by this method // from some database entry handler which may be encountered during processing of new files with respect thereto; otherwise we use"}
{"id": 7105, "code": "func ToSSN(theString, delimiter string) (string, error) {\n\tf := New(theString)\n\tf.removeNonDigits()\n\n\tif f.length != 9 {\n\t\treturn \"\", errors.New(\"string needs to be 9 digits for Social Security Numbers\")\n\t}\n\n\tvar buffer bytes.Buffer\n\tcount := 0\n\n\tfor _, i := range f.theString {\n\t\tcount++\n\n\t\tbuffer.WriteString(string(i))\n\n\t\tif count == 3 || count == 5 {\n\t\t\tbuffer.WriteString(delimiter)\n\t\t}\n\t}\n\treturn buffer.String(), nil\n}", "reference": "// ToSSN will format the provided string as a SSN.", "generated": "The method is a wrapper around the new StringBuilder . It takes an existing Strings and returns it as its first argument in addition to any other arguments that are passed through with this function. The methods return all of the strings returned by these functions from their initializer or if they were not provided otherwise will throw exceptions on"}
{"id": 7113, "code": "func (c *Config) OptionMap(section string) map[string]string {\n\toptions := make(map[string]string)\n\tfor _, sect := range c.sections {\n\t\tif sect.name == section {\n\t\t\tfor _, opt := range sect.options {\n\t\t\t\toptions[opt.name] = opt.value\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t}\n\treturn options\n}", "reference": "// OptionMap returns the map option => value for a given section.", "generated": "Option maps a list of strings to the specified sections and returns an array containing all available values for that element in each row or column within this option's scope. The default value is nil . If no elements are found then it defaults back into its original state with only one entry per line as shown below :\n\n\n//"}
{"id": 7121, "code": "func Convert(val interface{}, targetType reflect.Type) reflect.Value {\n\tvalue := reflect.ValueOf(val)\n\tif !value.IsValid() {\n\t\treturn reflect.Zero(targetType)\n\t}\n\n\tvalType := value.Type()\n\tif valType.ConvertibleTo(targetType) {\n\t\treturn value.Convert(targetType)\n\t}\n\n\t//fmt.Printf(\"Value type is %v, emptyInterfaceType is %v, equals %v\\n\", valType, emptyInterfaceType, valType == emptyInterfaceType)\n\tinterfaceVal := value.Interface()\n\n\tswitch realVal := interfaceVal.(type) {\n\tcase float64:\n\t\treturn reflect.ValueOf(realVal).Convert(targetType)\n\tcase []interface{}:\n\t\t// val is of type []interface{}, try to convert to typ\n\t\tsliceSize := len(realVal)\n\t\ttargetSlice := reflect.MakeSlice(targetType, 0, sliceSize)\n\t\telemType := targetType.Elem()\n\t\tfor i := 0; i < sliceSize; i++ {\n\t\t\ttargetSlice = reflect.Append(targetSlice, Convert(value.Index(i), elemType))\n\t\t}\n\t\treturn targetSlice\n\t}\n\n\tpanic(fmt.Errorf(\"convert from type %v to %v failed: %v\", valType, targetType, value))\n}", "reference": "// try to convert value to target type, panic if fail", "generated": "This function converts a string representation of an object into the form of int[]int[], which can be used as a reference for conversion between types and values in Java 8 or later versions (see below); it returns true if this method succeeds at converting any integer-valued objects that are not null . The return Type parameter"}
{"id": 7123, "code": "func Filter(l LogBackend, r Ruler) LogBackend {\n\treturn &filter{\n\t\tLogBackend: l,\n\t\tr:          r,\n\t}\n}", "reference": "// Filter creates a new filter with rules r for l backend.", "generated": "// filter the logbackend to be filtered. The default is a logger that will return an error if it doesn't match any of the above rules.\n // Note this rule does not apply for all logs in /var/log/logbackends .\n// This can also be used as a way around logging"}
{"id": 7139, "code": "func (cn *ContentNegotiator) getEncoder(req *http.Request) Encoder {\n\tvar result = cn.DefaultEncoder\n\taccept := req.Header.Get(\"Accept\")\n\n\tfor k, v := range cn.encoderMap {\n\t\tif strings.Contains(accept, k) {\n\t\t\tresult = v\n\t\t\tbreak\n\t\t}\n\t}\n\treturn result\n}", "reference": "// getEncoder parses the Accept header an returns the appropriate encoder to use", "generated": "// Get the encoding of a Content Negotiation object and return it as an array with all encodings in order from most to least encoded for each request type // provided by http requests or any other method that returns JSON objects if they are not available otherwise returned None\n func encode(c *ContentNegotable interface"}
{"id": 7148, "code": "func DefaultServiceConfig() ServiceConfig {\n\treturn ServiceConfig{\n\t\t// Dependencies.\n\t\tBackoffFactory: func() Backoff {\n\t\t\treturn &backoff.StopBackOff{}\n\t\t},\n\t\tRandFactory: rand.Int,\n\n\t\t// Settings.\n\t\tRandReader: rand.Reader,\n\t\tTimeout:    1 * time.Second,\n\t}\n}", "reference": "// DefaultServiceConfig provides a default configuration to create a new random\n// service by best effort.", "generated": "This service configures the default settings for a specific application and provides an API to access them from within that app's configuration file (see below). The defaults are specified in this example as follows:\nserviceconfig := NewServiceConfig()\nif not nil then return None\nend if // Configure all of these services"}
{"id": 7222, "code": "func (logger *Logger) Log(level Level, a ...interface{}) {\n\tlogger.log(level, \"\", a...)\n}", "reference": "// Log logs provided message.", "generated": "This function returns the log level of the logger and its associated interface . The logging levels are specified in logs() , which is an alias for fmt::fmt_info(). This method also provides access to debug information about errors that occur when using this API or other methods on your application's stack. It can be used"}
{"id": 7234, "code": "func (e *Entry) getChildEntry(pat string) *Entry {\n\tfor _, entry := range e.entries {\n\t\tif pat == entry.Pattern() {\n\t\t\treturn entry\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// getChildEntry returns a child Entry that matches the given pattern string.", "generated": "// Get the child entries of an Entry object and return it as a list of children for each field in this class.\n// This method returns all fields that are not part or end-of file names except those specified by default with no special name prefixes to be used here.\n\n\n/*** Returns true if"}
{"id": 7263, "code": "func routeSplitFunc(data []byte, atEOF bool) (int, []byte, error) {\n\tif atEOF || data == nil {\n\t\treturn 0, nil, io.EOF\n\t}\n\n\tr, _ := utf8.DecodeRune(data)\n\n\t// matcher\n\tif r == '<' {\n\t\ti := bytes.IndexRune(data, '>')\n\t\tif i == -1 {\n\t\t\treturn 0, nil, NoClosingBracket\n\t\t}\n\t\treturn (i + 1), data[:(i + 1)], nil\n\t}\n\n\t// one char\n\tif len(data) == 1 {\n\t\treturn 1, data, nil\n\t}\n\n\t// should ignore first '/'\n\tslashIndex := bytes.IndexRune(data[1:], '/')\n\tif slashIndex != -1 {\n\t\tslashIndex++\n\t}\n\n\tmatchIndex := bytes.IndexRune(data, '<')\n\n\t// remaining string would be a static entry\n\tif slashIndex == -1 && matchIndex == -1 {\n\t\treturn len(data), data, nil\n\t}\n\n\t// split by '<'\n\t// return data before '<'\n\tif matchIndex != -1 && (slashIndex == -1 || slashIndex > matchIndex) {\n\t\treturn matchIndex, data[:matchIndex], nil\n\t}\n\n\t// split by '/'\n\t// return data before '/' including '/'\n\treturn slashIndex + 1, data[:(slashIndex + 1)], nil\n}", "reference": "// routeSplitFunc is the SplitFunc to scan url pattern.", "generated": "RouteSplit is an implementation of the RouteBuilder class that provides methods for splitting and merging strings into single-line or multiword lists using either Strings . The method returns both String , which can then contain any number between zero and 255 inclusive as well; if no matching list exists in this case, it will attempt to"}
{"id": 7282, "code": "func (s *Image) Run(cfg *RunConfig) (*Container, error) {\n\targs := make([]string, 0, len(cfg.Options)+len(cfg.Args)+1)\n\targs = append(args, cfg.Options...)\n\targs = append(args, s.name)\n\targs = append(args, cfg.Args...)\n\n\tout, err := s.docker.Run(\"run\", args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcontainer := &Container{\n\t\tdocker: s.docker,\n\t\tid:     strings.TrimSpace(out),\n\t}\n\tif container.id == \"\" {\n\t\treturn nil, UnexpectedOutputError(\n\t\t\t\"Unexpected empty output when running docker container\")\n\t}\n\n\treturn container, nil\n}", "reference": "// Run creates a new Docker container as defined by current image and container\n// template.\n//\n// Returns ExternalCmdError or UnexpectedOutputError on error.", "generated": "// Create a Docker image for the specified Container and create an instance of it to run on each port in order from start-up to end up at bootstrap time. This is done by creating two containers with different namespaces that are used as aliases between them; one named \"Docker Image 1\" which will be"}
{"id": 7285, "code": "func (s NetworkSettings) PortAt(index int) (string, *HostPublish) {\n\tcounter := 0\n\tfor k, v := range s.Ports {\n\t\tif counter != index {\n\t\t\tcounter++\n\t\t\tcontinue\n\t\t}\n\n\t\treturn k, v\n\t}\n\n\treturn \"\", nil\n}", "reference": "// PortAt returns expose and publish port information at especified index.", "generated": "// This method is used to create a new TCP connection for the specified port at which it will be sent and received by all clients on that network interface. The default value of this function should not be changed in any way during initialization or execution.\n// Note that if you are using an existing client-side protocol such"}
{"id": 7297, "code": "func (tx Tx) ForEachGob(folders [][]byte, f func(Bucket, bytesp.Slice, interface{}) error) error {\n\treturn tx.ForEach(folders, func(b Bucket, k, bs bytesp.Slice) error {\n\t\tvar v interface{}\n\t\tif err := gob.NewDecoder(&bs).Decode(&v); err != nil {\n\t\t\treturn errorsp.WithStacksAndMessage(err, \"decoding %d bytes value for key %q failed\", len(bs), string(k))\n\t\t}\n\t\treturn errorsp.WithStacks(f(b, k, v))\n\t})\n}", "reference": "// ForEach iterates over all key values of a folder, decode non-nil values using gob.", "generated": "This function creates a new byte[] chunk and returns the resulting slice of data in binary format as an array with all chunks being returned by this method to be used when decoding or encoding strings into JSON objects using Decodable . The following example uses decoded text from one file on disk instead; it is not intended that"}
{"id": 7310, "code": "func (handler *WriteHandler) Handle(record *Record) error {\n\t_, err := handler.Writer.Write([]byte(handler.Formatter.Format(record) + \"\\n\"))\n\treturn err\n}", "reference": "// Handle writes all provided log records to writer provided during creation.", "generated": "This function handles errors in the form of a string or an array containing information about record types and methods that are not available to write handlers for this type of operation. It returns nil if no such field exists; otherwise it will return true . The returned value is either None , which means nothing happens when writing any records with"}
