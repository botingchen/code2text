{"id": 24, "code": "func (c *ServiceDiscoveryConfig) Validate() error {\n\tfor _, cfg := range c.AzureSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in azure_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.ConsulSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in consul_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.DNSSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in dns_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.EC2SDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in ec2_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.FileSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in file_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.GCESDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in gce_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.KubernetesSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in kubernetes_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.MarathonSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in marathon_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.NerveSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in nerve_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.OpenstackSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in openstack_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.ServersetSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in serverset_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.StaticConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in static_configs\")\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// Validate validates the ServiceDiscoveryConfig.", "generated": "// Validate checks that all required fields have been set for each service discovery configuration.\n//\n// If any field is missing it will return an error message describing which config has the issue. This can be used to validate user input before creating a ServiceDiscovery instance. The default values from the Configs struct should always be returned if"}
{"id": 36, "code": "func NewDiscovery(conf SDConfig, logger log.Logger) (*Discovery, error) {\n\trt, err := config_util.NewRoundTripperFromConfig(conf.HTTPClientConfig, \"marathon_sd\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif len(conf.AuthToken) > 0 {\n\t\trt, err = newAuthTokenRoundTripper(conf.AuthToken, rt)\n\t} else if len(conf.AuthTokenFile) > 0 {\n\t\trt, err = newAuthTokenFileRoundTripper(conf.AuthTokenFile, rt)\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\td := &Discovery{\n\t\tclient:     &http.Client{Transport: rt},\n\t\tservers:    conf.Servers,\n\t\tappsClient: fetchApps,\n\t}\n\td.Discovery = refresh.NewDiscovery(\n\t\tlogger,\n\t\t\"marathon\",\n\t\ttime.Duration(conf.RefreshInterval),\n\t\td.refresh,\n\t)\n\treturn d, nil\n}", "reference": "// NewDiscovery returns a new Marathon Discovery.", "generated": "// NewDiscovery returns a discovery client for marathon service discovery.\n//\n// The returned Discovery object is configured to use HTTP requests over TCP\n// connections (as opposed to UDP). It also includes support for authentication\n// tokens stored in files or environment variables. If no auth token is provided\n// then it will be ignored"}
{"id": 50, "code": "func (d *Discovery) shouldWatch(name string, tags []string) bool {\n\treturn d.shouldWatchFromName(name) && d.shouldWatchFromTags(tags)\n}", "reference": "// shouldWatch returns whether the service of the given name should be watched.", "generated": "// Should watch for this name or tag combination.\n//\n// This is used to determine whether we need to poll for new nodes in\n// discovery. If it returns true then we will continue polling until no more\n// matches are found. Otherwise we can stop looking. The default behaviour is\n// to always return false"}
{"id": 52, "code": "func (d *Discovery) getDatacenter() error {\n\t// If the datacenter was not set from clientConf, let's get it from the local Consul agent\n\t// (Consul default is to use local node's datacenter if one isn't given for a query).\n\tif d.clientDatacenter != \"\" {\n\t\treturn nil\n\t}\n\n\tinfo, err := d.client.Agent().Self()\n\tif err != nil {\n\t\tlevel.Error(d.logger).Log(\"msg\", \"Error retrieving datacenter name\", \"err\", err)\n\t\trpcFailuresCount.Inc()\n\t\treturn err\n\t}\n\n\tdc, ok := info[\"Config\"][\"Datacenter\"].(string)\n\tif !ok {\n\t\terr := errors.Errorf(\"invalid value '%v' for Config.Datacenter\", info[\"Config\"][\"Datacenter\"])\n\t\tlevel.Error(d.logger).Log(\"msg\", \"Error retrieving datacenter name\", \"err\", err)\n\t\treturn err\n\t}\n\n\td.clientDatacenter = dc\n\treturn nil\n}", "reference": "// Get the local datacenter if not specified.", "generated": "// getDatacenter retrieves the datacenter information from the Consul agent or uses the provided client configuration.\n//\n// This method will return an error if there is no valid datacenter configured in either case. The caller should handle this situation appropriately,\n// e.g., by returning an empty string or using some other mechanism that indicates"}
{"id": 64, "code": "func (ls Labels) HashForLabels(names ...string) uint64 {\n\tb := make([]byte, 0, 1024)\n\n\tfor _, v := range ls {\n\t\tfor _, n := range names {\n\t\t\tif v.Name == n {\n\t\t\t\tb = append(b, v.Name...)\n\t\t\t\tb = append(b, sep)\n\t\t\t\tb = append(b, v.Value...)\n\t\t\t\tb = append(b, sep)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn xxhash.Sum64(b)\n}", "reference": "// HashForLabels returns a hash value for the labels matching the provided names.", "generated": "// HashForLabels returns a hash for all labels in this set that match any name passed to it.\n//\n// This is useful when storing sets of labels in memory or disk storage where hashes can be used to quickly check if two sets contain common elements,\n// without having to iterate over them both. The returned value will"}
{"id": 117, "code": "func ParseExpr(input string) (Expr, error) {\n\tp := newParser(input)\n\n\texpr, err := p.parseExpr()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = p.typecheck(expr)\n\treturn expr, err\n}", "reference": "// ParseExpr returns the expression parsed from the input.", "generated": "// ParseExpr parses input into Expr. It first tries to parse it as a single expression,\n// then checks if there is more than one expression in the input. If so, it returns\n// two expressions: the last one found and all others that were parsed before.\n//\n// Note that this parser doesn't handle"}
{"id": 129, "code": "func (p *parser) expectOneOf(exp1, exp2 ItemType, context string) item {\n\ttoken := p.next()\n\tif token.typ != exp1 && token.typ != exp2 {\n\t\tp.errorf(\"unexpected %s in %s, expected %s or %s\", token.desc(), context, exp1.desc(), exp2.desc())\n\t}\n\treturn token\n}", "reference": "// expectOneOf consumes the next token and guarantees it has one of the required types.", "generated": "// Expect one of two items to be next. If neither is present then error.\n//\n// This will panic if there's no match for either of them. It can also return nil,\n// but that would require additional logic to handle it properly. The caller should\n// check whether the returned value was nil before using"}
{"id": 133, "code": "func (p *parser) expectType(node Node, want ValueType, context string) {\n\tt := p.checkType(node)\n\tif t != want {\n\t\tp.errorf(\"expected type %s in %s, got %s\", documentedType(want), context, documentedType(t))\n\t}\n}", "reference": "// expectType checks the type of the node and raises an error if it\n// is not of the expected type.", "generated": "// Expect checks that node is of correct type for given value.\n//\n// If it's not then error will be printed to stderr. This method should\n// only be called from parser methods or other functions which have access\n// to current state of parser. It can't be used directly by user code because\n//"}
{"id": 145, "code": "func New(minSize, maxSize int, factor float64, makeFunc func(int) interface{}) *Pool {\n\tif minSize < 1 {\n\t\tpanic(\"invalid minimum pool size\")\n\t}\n\tif maxSize < 1 {\n\t\tpanic(\"invalid maximum pool size\")\n\t}\n\tif factor < 1 {\n\t\tpanic(\"invalid factor\")\n\t}\n\n\tvar sizes []int\n\n\tfor s := minSize; s <= maxSize; s = int(float64(s) * factor) {\n\t\tsizes = append(sizes, s)\n\t}\n\n\tp := &Pool{\n\t\tbuckets: make([]sync.Pool, len(sizes)),\n\t\tsizes:   sizes,\n\t\tmake:    makeFunc,\n\t}\n\n\treturn p\n}", "reference": "// New returns a new Pool with size buckets for minSize to maxSize\n// increasing by the given factor.", "generated": "// New creates a new Pool instance. The number of buckets is determined by the\n// provided factors (minSize to maxSize). Each bucket will be initialized using\n// the'make' function passed in. If no'make' function is given, it defaults to\n// making a new object from scratch. This"}
{"id": 165, "code": "func sendAlerts(s sender, externalURL string) rules.NotifyFunc {\n\treturn func(ctx context.Context, expr string, alerts ...*rules.Alert) {\n\t\tvar res []*notifier.Alert\n\n\t\tfor _, alert := range alerts {\n\t\t\ta := &notifier.Alert{\n\t\t\t\tStartsAt:     alert.FiredAt,\n\t\t\t\tLabels:       alert.Labels,\n\t\t\t\tAnnotations:  alert.Annotations,\n\t\t\t\tGeneratorURL: externalURL + strutil.TableLinkForExpression(expr),\n\t\t\t}\n\t\t\tif !alert.ResolvedAt.IsZero() {\n\t\t\t\ta.EndsAt = alert.ResolvedAt\n\t\t\t} else {\n\t\t\t\ta.EndsAt = alert.ValidUntil\n\t\t\t}\n\t\t\tres = append(res, a)\n\t\t}\n\n\t\tif len(alerts) > 0 {\n\t\t\ts.Send(res...)\n\t\t}\n\t}\n}", "reference": "// sendAlerts implements the rules.NotifyFunc for a Notifier.", "generated": "// sendAlerts sends all alerts to the given channel for sending.\n//\n// This is used by the Alerting system when it needs to notify users about events that have occurred in their cluster. It's also useful if you want to forward alerts from one cluster to another (e.g., so they can be seen by"}
{"id": 166, "code": "func (g *RuleGroups) Validate() (errs []error) {\n\tset := map[string]struct{}{}\n\n\tfor _, g := range g.Groups {\n\t\tif g.Name == \"\" {\n\t\t\terrs = append(errs, errors.Errorf(\"Groupname should not be empty\"))\n\t\t}\n\n\t\tif _, ok := set[g.Name]; ok {\n\t\t\terrs = append(\n\t\t\t\terrs,\n\t\t\t\terrors.Errorf(\"groupname: \\\"%s\\\" is repeated in the same file\", g.Name),\n\t\t\t)\n\t\t}\n\n\t\tset[g.Name] = struct{}{}\n\n\t\tfor i, r := range g.Rules {\n\t\t\tfor _, err := range r.Validate() {\n\t\t\t\tvar ruleName string\n\t\t\t\tif r.Alert != \"\" {\n\t\t\t\t\truleName = r.Alert\n\t\t\t\t} else {\n\t\t\t\t\truleName = r.Record\n\t\t\t\t}\n\t\t\t\terrs = append(errs, &Error{\n\t\t\t\t\tGroup:    g.Name,\n\t\t\t\t\tRule:     i,\n\t\t\t\t\tRuleName: ruleName,\n\t\t\t\t\tErr:      err,\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t}\n\n\treturn errs\n}", "reference": "// Validate validates all rules in the rule groups.", "generated": "// Validate checks that all groups have unique names and rules validate correctly.\n//\n// If there's any error it returns them to caller. Otherwise no return value means validation was successful."}
{"id": 182, "code": "func (r *AlertingRule) SetHealth(health RuleHealth) {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\tr.health = health\n}", "reference": "// SetHealth sets the current health of the alerting rule.", "generated": "// SetHealth sets the alert rule's health status to the given value.\n//\n// This is used by the AlertManager when it needs to know whether or not this\n// alert should be sent out based on its current state. The default for new rules\n// will always be \"unknown\". If set to nil then"}
{"id": 185, "code": "func (r *AlertingRule) SetEvaluationDuration(dur time.Duration) {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\tr.evaluationDuration = dur\n}", "reference": "// SetEvaluationDuration updates evaluationDuration to the duration it took to evaluate the rule on its last evaluation.", "generated": "// Evaluation duration is set to the given value in seconds.\n//\n// This field can be used by alerters that need more control over how long they evaluate their rules,\n// such as those using custom evaluation logic or external services. The default for this field is 1 second. If it's changed from its default value"}
{"id": 197, "code": "func (g *Group) GetEvaluationDuration() time.Duration {\n\tg.mtx.Lock()\n\tdefer g.mtx.Unlock()\n\treturn g.evaluationDuration\n}", "reference": "// GetEvaluationDuration returns the time in seconds it took to evaluate the rule group.", "generated": "// GetEvaluationDuration returns evaluation duration for this group.\n//\n// Evaluation duration is set when Group is created or updated by SetEvaluationDuration().\n// It's used to calculate total execution time in case of failure. If it's zero,\n// then no additional overhead will be added during execution. This value can't\n//"}
{"id": 199, "code": "func (g *Group) GetEvaluationTimestamp() time.Time {\n\tg.mtx.Lock()\n\tdefer g.mtx.Unlock()\n\treturn g.evaluationTimestamp\n}", "reference": "// GetEvaluationTimestamp returns the time the last evaluation of the rule group took place.", "generated": "// GetEvaluationTimestamp returns the timestamp when this group was evaluated.\n//\n// This is used to determine if there have been any changes since last evaluation,\n// which can be useful for caching purposes or other optimization techniques. The\n// returned value will always reflect the most recent evaluation result. If no\n// evaluation has yet"}
{"id": 212, "code": "func (w *WALWatcher) Start() {\n\tw.setMetrics()\n\tlevel.Info(w.logger).Log(\"msg\", \"starting WAL watcher\", \"queue\", w.name)\n\n\tgo w.loop()\n}", "reference": "// Start the WALWatcher.", "generated": "// Start starts the WAL watcher loop. This is called when the watch\n// object is created or reinitialized.\n//\n// The loop will continue to run until it's stopped by Stop(). It runs in its own goroutine,\n// so this method can be safely called concurrently from other goroutines. If there's already"}
{"id": 225, "code": "func (sd *StaticProvider) Run(ctx context.Context, ch chan<- []*targetgroup.Group) {\n\t// We still have to consider that the consumer exits right away in which case\n\t// the context will be canceled.\n\tselect {\n\tcase ch <- sd.TargetGroups:\n\tcase <-ctx.Done():\n\t}\n\tclose(ch)\n}", "reference": "// Run implements the Worker interface.", "generated": "// Run starts the provider's main loop where it runs indefinitely until cancelled by\n// ctx or when all target groups are done being processed. It also sends out any new\n// target group information for consumers to process. The channel is closed once\n// all target groups are done processing so we can stop consuming from this"}
{"id": 228, "code": "func NewDiscovery(\n\tsrvs []string,\n\ttimeout time.Duration,\n\tpaths []string,\n\tlogger log.Logger,\n\tpf func(data []byte, path string) (model.LabelSet, error),\n) (*Discovery, error) {\n\tif logger == nil {\n\t\tlogger = log.NewNopLogger()\n\t}\n\n\tconn, _, err := zk.Connect(\n\t\tsrvs, timeout,\n\t\tfunc(c *zk.Conn) {\n\t\t\tc.SetLogger(treecache.NewZookeeperLogger(logger))\n\t\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tupdates := make(chan treecache.ZookeeperTreeCacheEvent)\n\tsd := &Discovery{\n\t\tconn:    conn,\n\t\tupdates: updates,\n\t\tsources: map[string]*targetgroup.Group{},\n\t\tparse:   pf,\n\t\tlogger:  logger,\n\t}\n\tfor _, path := range paths {\n\t\tsd.treeCaches = append(sd.treeCaches, treecache.NewZookeeperTreeCache(conn, path, updates, logger))\n\t}\n\treturn sd, nil\n}", "reference": "// NewDiscovery returns a new discovery along Zookeeper parses with\n// the given parse function.", "generated": "// NewDiscovery creates a new discovery instance that connects to ZooKeeper.\n//\n// The connection is made using the provided servers list. If no servers are given,\n// it will connect to all available nodes in the default zookeeper cluster.\n//\n// The tree cache for each node can be configured by passing a slice of strings"}
{"id": 244, "code": "func (q *querier) Select(p *storage.SelectParams, matchers ...*labels.Matcher) (storage.SeriesSet, storage.Warnings, error) {\n\tquery, err := ToQuery(q.mint, q.maxt, matchers, p)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tremoteReadGauge := remoteReadQueries.WithLabelValues(q.client.Name())\n\tremoteReadGauge.Inc()\n\tdefer remoteReadGauge.Dec()\n\n\tres, err := q.client.Read(q.ctx, query)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn FromQueryResult(res), nil, nil\n}", "reference": "// Select implements storage.Querier and uses the given matchers to read series\n// sets from the Client.", "generated": "// Select returns data from the client's database for the given parameters.\n//\n// This is used to select all series that have been created by this querier,\n// which can be useful when debugging or testing. It also allows us to get\n// warnings about any errors in our queries. The returned SeriesSet contains"}
{"id": 298, "code": "func NewRegexp(s string) (Regexp, error) {\n\tregex, err := regexp.Compile(\"^(?:\" + s + \")$\")\n\treturn Regexp{\n\t\tRegexp:   regex,\n\t\toriginal: s,\n\t}, err\n}", "reference": "// NewRegexp creates a new anchored Regexp and returns an error if the\n// passed-in regular expression does not compile.", "generated": "// NewRegexp returns a new Regexp that matches only if it is equal to its original value.\n//\n// This can be used for validation purposes where we want to ensure that some field has exactly one specific value.\n// For example, in a form submission, this could validate that the user entered their email address correctly"}
{"id": 303, "code": "func (sp *scrapePool) reload(cfg *config.ScrapeConfig) error {\n\ttargetScrapePoolReloads.Inc()\n\tstart := time.Now()\n\n\tsp.mtx.Lock()\n\tdefer sp.mtx.Unlock()\n\n\tclient, err := config_util.NewClientFromConfig(cfg.HTTPClientConfig, cfg.JobName)\n\tif err != nil {\n\t\ttargetScrapePoolReloadsFailed.Inc()\n\t\treturn errors.Wrap(err, \"error creating HTTP client\")\n\t}\n\tsp.config = cfg\n\toldClient := sp.client\n\tsp.client = client\n\n\tvar (\n\t\twg              sync.WaitGroup\n\t\tinterval        = time.Duration(sp.config.ScrapeInterval)\n\t\ttimeout         = time.Duration(sp.config.ScrapeTimeout)\n\t\tlimit           = int(sp.config.SampleLimit)\n\t\thonorLabels     = sp.config.HonorLabels\n\t\thonorTimestamps = sp.config.HonorTimestamps\n\t\tmrc             = sp.config.MetricRelabelConfigs\n\t)\n\n\tfor fp, oldLoop := range sp.loops {\n\t\tvar (\n\t\t\tt       = sp.activeTargets[fp]\n\t\t\ts       = &targetScraper{Target: t, client: sp.client, timeout: timeout}\n\t\t\tnewLoop = sp.newLoop(scrapeLoopOptions{\n\t\t\t\ttarget:          t,\n\t\t\t\tscraper:         s,\n\t\t\t\tlimit:           limit,\n\t\t\t\thonorLabels:     honorLabels,\n\t\t\t\thonorTimestamps: honorTimestamps,\n\t\t\t\tmrc:             mrc,\n\t\t\t})\n\t\t)\n\t\twg.Add(1)\n\n\t\tgo func(oldLoop, newLoop loop) {\n\t\t\toldLoop.stop()\n\t\t\twg.Done()\n\n\t\t\tgo newLoop.run(interval, timeout, nil)\n\t\t}(oldLoop, newLoop)\n\n\t\tsp.loops[fp] = newLoop\n\t}\n\n\twg.Wait()\n\toldClient.CloseIdleConnections()\n\ttargetReloadIntervalLength.WithLabelValues(interval.String()).Observe(\n\t\ttime.Since(start).Seconds(),\n\t)\n\treturn nil\n}", "reference": "// reload the scrape pool with the given scrape configuration. The target state is preserved\n// but all scrape loops are restarted with the new scrape configuration.\n// This method returns after all scrape loops that were stopped have stopped scraping.", "generated": "// reload is called when scrape pool configuration changes. It will stop all existing scrapers, then start up to n number of new ones based on the updated interval value in the config. The new scrapers run concurrently until they reach their respective limits or times out. After that, it stops them again. This ensures that"}
{"id": 332, "code": "func NewDiscovery(conf *SDConfig, logger log.Logger) *Discovery {\n\tif logger == nil {\n\t\tlogger = log.NewNopLogger()\n\t}\n\n\tdisc := &Discovery{\n\t\tpaths:      conf.Files,\n\t\tinterval:   time.Duration(conf.RefreshInterval),\n\t\ttimestamps: make(map[string]float64),\n\t\tlogger:     logger,\n\t}\n\tfileSDTimeStamp.addDiscoverer(disc)\n\treturn disc\n}", "reference": "// NewDiscovery returns a new file discovery for the given paths.", "generated": "// NewDiscovery creates new discovery instance from given configuration.\n//\n// If no logger is provided it will be set to NopLogger which doesn't do anything.\n//\n// This method should only be called once in lifetime of application. It's used internally by SDClient when client starts up for first time. After that this"}
{"id": 349, "code": "func (r *ewmaRate) tick() {\n\tnewEvents := atomic.LoadInt64(&r.newEvents)\n\tatomic.AddInt64(&r.newEvents, -newEvents)\n\tinstantRate := float64(newEvents) / r.interval.Seconds()\n\n\tr.mutex.Lock()\n\tdefer r.mutex.Unlock()\n\n\tif r.init {\n\t\tr.lastRate += r.alpha * (instantRate - r.lastRate)\n\t} else {\n\t\tr.init = true\n\t\tr.lastRate = instantRate\n\t}\n}", "reference": "// tick assumes to be called every r.interval.", "generated": "// tick updates rate based on new events received since last update.\n//\n// This is called every interval seconds to ensure that rate remains accurate,\n// even if there's no data being sent for long periods of time.  It also ensures\n// that we don't get stuck in an infinite loop trying to calculate rate from"}
{"id": 390, "code": "func (a *Args) GetBool(key string) bool {\n\tswitch b2s(a.Peek(key)) {\n\t// Support the same true cases as strconv.ParseBool\n\t// See: https://github.com/golang/go/blob/4e1b11e2c9bdb0ddea1141eed487be1a626ff5be/src/strconv/atob.go#L12\n\t// and Y and Yes versions.\n\tcase \"1\", \"t\", \"T\", \"true\", \"TRUE\", \"True\", \"y\", \"yes\", \"Y\", \"YES\", \"Yes\":\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}", "reference": "// GetBool returns boolean value for the given key.\n//\n// true is returned for \"1\", \"t\", \"T\", \"true\", \"TRUE\", \"True\", \"y\", \"yes\", \"Y\", \"YES\", \"Yes\",\n// otherwise false is returned.", "generated": "// GetBool returns whether key is set to 1 or 'true'. If it's neither,\n// then this will return false. This can be used for boolean flags in\n// command-line arguments. The value must match one of these strings exactly;\n// no partial matches are allowed. For example, if you have"}
{"id": 420, "code": "func (cc *LBClient) DoTimeout(req *Request, resp *Response, timeout time.Duration) error {\n\tdeadline := time.Now().Add(timeout)\n\treturn cc.get().DoDeadline(req, resp, deadline)\n}", "reference": "// DoTimeout calculates deadline and calls DoDeadline on the least loaded client", "generated": "// DoTimeout sends a request to the server but allows for some extra\n// latency before timing out. This is useful when we're waiting for a\n// long-running operation like a database query or a network call.\n//\n// If this returns nil it means that the request was successful without any errors,\n// otherwise it"}
{"id": 430, "code": "func (ctx *RequestCtx) TLSConnectionState() *tls.ConnectionState {\n\ttlsConn, ok := ctx.c.(connTLSer)\n\tif !ok {\n\t\treturn nil\n\t}\n\tstate := tlsConn.ConnectionState()\n\treturn &state\n}", "reference": "// TLSConnectionState returns TLS connection state.\n//\n// The function returns nil if the underlying connection isn't tls.Conn.\n//\n// The returned state may be used for verifying TLS version, client certificates,\n// etc.", "generated": "// Returns the current connection state for this request's TLS connection.\n//\n// This is useful when debugging issues related to SSL/TLS connections,\n// such as verifying that the client has sent its certificate or checking if\n// there was any error during the handshake process. The returned value will be\n// nil if no TLS"}
{"id": 453, "code": "func (s *Server) Serve(ln net.Listener) error {\n\tvar lastOverflowErrorTime time.Time\n\tvar lastPerIPErrorTime time.Time\n\tvar c net.Conn\n\tvar err error\n\n\ts.mu.Lock()\n\t{\n\t\tif s.ln != nil {\n\t\t\ts.mu.Unlock()\n\t\t\treturn ErrAlreadyServing\n\t\t}\n\n\t\ts.ln = ln\n\t\ts.done = make(chan struct{})\n\t}\n\ts.mu.Unlock()\n\n\tmaxWorkersCount := s.getConcurrency()\n\ts.concurrencyCh = make(chan struct{}, maxWorkersCount)\n\twp := &workerPool{\n\t\tWorkerFunc:      s.serveConn,\n\t\tMaxWorkersCount: maxWorkersCount,\n\t\tLogAllErrors:    s.LogAllErrors,\n\t\tLogger:          s.logger(),\n\t\tconnState:       s.setState,\n\t}\n\twp.Start()\n\n\t// Count our waiting to accept a connection as an open connection.\n\t// This way we can't get into any weird state where just after accepting\n\t// a connection Shutdown is called which reads open as 0 because it isn't\n\t// incremented yet.\n\tatomic.AddInt32(&s.open, 1)\n\tdefer atomic.AddInt32(&s.open, -1)\n\n\tfor {\n\t\tif c, err = acceptConn(s, ln, &lastPerIPErrorTime); err != nil {\n\t\t\twp.Stop()\n\t\t\tif err == io.EOF {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\ts.setState(c, StateNew)\n\t\tatomic.AddInt32(&s.open, 1)\n\t\tif !wp.Serve(c) {\n\t\t\tatomic.AddInt32(&s.open, -1)\n\t\t\ts.writeFastError(c, StatusServiceUnavailable,\n\t\t\t\t\"The connection cannot be served because Server.Concurrency limit exceeded\")\n\t\t\tc.Close()\n\t\t\ts.setState(c, StateClosed)\n\t\t\tif time.Since(lastOverflowErrorTime) > time.Minute {\n\t\t\t\ts.logger().Printf(\"The incoming connection cannot be served, because %d concurrent connections are served. \"+\n\t\t\t\t\t\"Try increasing Server.Concurrency\", maxWorkersCount)\n\t\t\t\tlastOverflowErrorTime = time.Now()\n\t\t\t}\n\n\t\t\t// The current server reached concurrency limit,\n\t\t\t// so give other concurrently running servers a chance\n\t\t\t// accepting incoming connections on the same address.\n\t\t\t//\n\t\t\t// There is a hope other servers didn't reach their\n\t\t\t// concurrency limits yet :)\n\t\t\t//\n\t\t\t// See also: https://github.com/valyala/fasthttp/pull/485#discussion_r239994990\n\t\t\tif s.SleepWhenConcurrencyLimitsExceeded > 0 {\n\t\t\t\ttime.Sleep(s.SleepWhenConcurrencyLimitsExceeded)\n\t\t\t}\n\t\t}\n\t\tc = nil\n\t}\n}", "reference": "// Serve serves incoming connections from the given listener.\n//\n// Serve blocks until the given listener returns permanent error.", "generated": "// Serve starts serving HTTP requests from given listener. It will stop when\n// done channel is closed or if there's no more listeners available for listening.\n// If there's already one instance of this method being executed then return\n// ErrAlreadyServing immediately. Also, don't start new workers while another\n//"}
{"id": 480, "code": "func (req *Request) SetBodyString(body string) {\n\treq.RemoveMultipartFormFiles()\n\treq.closeBodyStream()\n\treq.bodyBuffer().SetString(body)\n}", "reference": "// SetBodyString sets request body.", "generated": "// Sets the body to be sent in this request using the provided\n// string value.\n//\n// This is useful for sending JSON or XML data that can't be encoded into\n// multipart/form-data streams.  The content type will still be set to \"application/x-www-form-urlencoded\" by default,\n// but it"}
{"id": 511, "code": "func (h *ResponseHeader) SetCookie(cookie *Cookie) {\n\th.cookies = setArgBytes(h.cookies, cookie.Key(), cookie.Cookie(), argsHasValue)\n}", "reference": "// SetCookie sets the given response cookie.\n//\n// It is save re-using the cookie after the function returns.", "generated": "// SetCookie sets the Cookie header value to the provided\n// cookie object. The key is taken from the cookie's Key() method,\n// while its value comes directly from the cookie's Value(). If\n// no such field exists in the cookie, it will be ignored.\n//\n// This can also be used for"}
{"id": 513, "code": "func (h *ResponseHeader) DelCookie(key string) {\n\th.cookies = delAllArgs(h.cookies, key)\n}", "reference": "// DelCookie removes cookie under the given key from response header.\n//\n// Note that DelCookie doesn't remove the cookie from the client.\n// Use DelClientCookie instead.", "generated": "// Delete cookie by name from header cookies\n//\n// This is used to remove all instances of a specific cookie in the headers.\n// If there's only one instance then it will be removed entirely otherwise\n// just its value will be cleared. The result can't contain any other values,\n// so if this method returns"}
{"id": 517, "code": "func (h *ResponseHeader) PeekBytes(key []byte) []byte {\n\th.bufKV.key = append(h.bufKV.key[:0], key...)\n\tnormalizeHeaderKey(h.bufKV.key, h.disableNormalizing)\n\treturn h.peek(h.bufKV.key)\n}", "reference": "// PeekBytes returns header value for the given key.\n//\n// Returned value is valid until the next call to ResponseHeader.\n// Do not store references to returned value. Make copies instead.", "generated": "// PeekBytes returns the value for the given header key without consuming it.\n//\n// This is useful when we need to peek at the value but don't want to consume\n// any bytes from the buffer yet. The returned slice will be empty if there's no\n// corresponding value in the headers. If the key"}
{"id": 525, "code": "func (h *RequestHeader) WriteTo(w io.Writer) (int64, error) {\n\tn, err := w.Write(h.Header())\n\treturn int64(n), err\n}", "reference": "// WriteTo writes request header to w.\n//\n// WriteTo implements io.WriterTo interface.", "generated": "// WriteTo writes header to writer. Returns number of bytes written.\n// If there is no more headers then returns 0. Error will be returned if it occurs while writing."}
{"id": 536, "code": "func (c *Cookie) Expire() time.Time {\n\texpire := c.expire\n\tif expire.IsZero() {\n\t\texpire = CookieExpireUnlimited\n\t}\n\treturn expire\n}", "reference": "// Expire returns cookie expiration time.\n//\n// CookieExpireUnlimited is returned if cookie doesn't expire", "generated": "// Expire returns the expiration date for this cookie.\n//\n// If it is set to zero, then there will be no expiration date. The default value\n// is 30 days from now. This can also be set by setting the \"Expires\" header in\n// HTTP responses or using the Set method's third"}
{"id": 537, "code": "func (c *Cookie) SetValue(value string) {\n\tc.value = append(c.value[:0], value...)\n}", "reference": "// SetValue sets cookie value.", "generated": "// Set the cookie's value to be sent in the HTTP request body.\n//\n// This is used by clients like curl when they want to send\n// cookies back to the server.  The default behavior for most browsers\n// will set this field automatically if it exists.  However, some servers may\n// require"}
{"id": 577, "code": "func (mx *Mux) Patch(pattern string, handlerFn http.HandlerFunc) {\n\tmx.handle(mPATCH, pattern, handlerFn)\n}", "reference": "// Patch adds the route `pattern` that matches a PATCH http method to\n// execute the `handlerFn` http.HandlerFunc.", "generated": "// Patch adds a new route to this MUX for handling HTTP PATCH requests.\n//\n// The path is passed in as a parameter to the handler function. This\n// allows handlers to be registered without having to worry about\n// parsing the request method or URL parameters. For example,\n//\n//   mx.Patch(\"/"}
{"id": 579, "code": "func (mx *Mux) Put(pattern string, handlerFn http.HandlerFunc) {\n\tmx.handle(mPUT, pattern, handlerFn)\n}", "reference": "// Put adds the route `pattern` that matches a PUT http method to\n// execute the `handlerFn` http.HandlerFunc.", "generated": "// Put is used to register a new route for PUT requests.\n//\n// The first argument should be a regular expression that matches\n// the path part of the URL.  This will match any request where the\n// method is \"PUT\" or \"PATCH\".  If no regex is provided then it's\n//"}
{"id": 600, "code": "func SearchArticles(w http.ResponseWriter, r *http.Request) {\n\trender.RenderList(w, r, NewArticleListResponse(articles))\n}", "reference": "// SearchArticles searches the Articles data for a matching article.\n// It's just a stub, but you get the idea.", "generated": "// Search articles by keyword\n//\n// This is used to search for all articles that contain the given keyword.\n// The results will be sorted in descending order based on their creation date,\n// so new articles appear at the top of the list. If no matches were found then\n// it returns 0 items. You"}
{"id": 603, "code": "func UpdateArticle(w http.ResponseWriter, r *http.Request) {\n\tarticle := r.Context().Value(\"article\").(*Article)\n\n\tdata := &ArticleRequest{Article: article}\n\tif err := render.Bind(r, data); err != nil {\n\t\trender.Render(w, r, ErrInvalidRequest(err))\n\t\treturn\n\t}\n\tarticle = data.Article\n\tdbUpdateArticle(article.ID, article)\n\n\trender.Render(w, r, NewArticleResponse(article))\n}", "reference": "// UpdateArticle updates an existing Article in our persistent store.", "generated": "// UpdateArticle updates the given Article in the database.\n//\n// The request body must contain all fields that need to be updated for this\n// operation to succeed. If any field is missing from the request body,\n// it will remain unchanged in the database. This method returns 204 No Content if\n// no changes"}
{"id": 605, "code": "func adminRouter() chi.Router {\n\tr := chi.NewRouter()\n\tr.Use(AdminOnly)\n\tr.Get(\"/\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(\"admin: index\"))\n\t})\n\tr.Get(\"/accounts\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(\"admin: list accounts..\"))\n\t})\n\tr.Get(\"/users/{userId}\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(fmt.Sprintf(\"admin: view user id %v\", chi.URLParam(r, \"userId\"))))\n\t})\n\treturn r\n}", "reference": "// A completely separate router for administrator routes", "generated": "// Returns router for Admin only routes. This is used to protect all admin endpoints from public access.\n//\n// Note that this will also block any requests coming in via HTTP/2 or WebSockets,\n// since they don't support the necessary headers to indicate which request was sent over\n// which connection. If you"}
{"id": 606, "code": "func AdminOnly(next http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tisAdmin, ok := r.Context().Value(\"acl.admin\").(bool)\n\t\tif !ok || !isAdmin {\n\t\t\thttp.Error(w, http.StatusText(http.StatusForbidden), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}", "reference": "// AdminOnly middleware restricts access to just administrators.", "generated": "// AdminOnly is used to restrict access to routes that require admin privileges.\n//\n// This handler will check if the request context contains an \"admin\" key set to true,\n// then call next in its place. If it doesn't find this value or the user isn't\n// authenticated, it returns 403 Forbidden"}
{"id": 612, "code": "func DefaultCompress(next http.Handler) http.Handler {\n\treturn Compress(flate.DefaultCompression)(next)\n}", "reference": "// DefaultCompress is a middleware that compresses response\n// body of predefined content types to a data format based\n// on Accept-Encoding request header. It uses a default\n// compression level.\n// DEPRECATED", "generated": "// Wrap handler to compress responses using flate compression.\n//\n// This is useful for serving static files or other content that can be compressed\n// without significant loss in quality.  The default compression level used by this\n// wrapper is 6 (which corresponds to \"best\" compression).  You may want to use"}
{"id": 623, "code": "func canonicalHostedZone(hostname string) string {\n\tfor suffix, zone := range canonicalHostedZones {\n\t\tif strings.HasSuffix(hostname, suffix) {\n\t\t\treturn zone\n\t\t}\n\t}\n\n\treturn \"\"\n}", "reference": "// canonicalHostedZone returns the matching canonical zone for a given hostname.", "generated": "// Returns the canonical hosted zone for hostname.\n//\n// If no match is found, returns \"\" (empty). This method should be used to get\n// the correct hosted zone name when creating DNS records in AWS. The returned\n// value will always end with \".amazonaws.com\". For example,\n// \"example.com"}
{"id": 629, "code": "func InMemoryWithLogging() InMemoryOption {\n\treturn func(p *InMemoryProvider) {\n\t\tp.OnApplyChanges = func(changes *plan.Changes) {\n\t\t\tfor _, v := range changes.Create {\n\t\t\t\tlog.Infof(\"CREATE: %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.UpdateOld {\n\t\t\t\tlog.Infof(\"UPDATE (old): %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.UpdateNew {\n\t\t\t\tlog.Infof(\"UPDATE (new): %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.Delete {\n\t\t\t\tlog.Infof(\"DELETE: %v\", v)\n\t\t\t}\n\t\t}\n\t}\n}", "reference": "// InMemoryWithLogging injects logging when ApplyChanges is called", "generated": "// InMemoryWithLogging returns an option that logs all operations in memory.\n//\n// This is useful for debugging purposes or when testing. It will log every\n// operation performed by the provider, including create, update, delete,\n// and drop statements. The logging level can be set using the logger's\n// Set"}
{"id": 656, "code": "func (sc *serviceSource) filterByAnnotations(services []*v1.Service) ([]*v1.Service, error) {\n\tlabelSelector, err := metav1.ParseToLabelSelector(sc.annotationFilter)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tselector, err := metav1.LabelSelectorAsSelector(labelSelector)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// empty filter returns original list\n\tif selector.Empty() {\n\t\treturn services, nil\n\t}\n\n\tfilteredList := []*v1.Service{}\n\n\tfor _, service := range services {\n\t\t// convert the service's annotations to an equivalent label selector\n\t\tannotations := labels.Set(service.Annotations)\n\n\t\t// include service if its annotations match the selector\n\t\tif selector.Matches(annotations) {\n\t\t\tfilteredList = append(filteredList, service)\n\t\t}\n\t}\n\n\treturn filteredList, nil\n}", "reference": "// filterByAnnotations filters a list of services by a given annotation selector.", "generated": "// filterByAnnotations filters out services that do not have any matching annotation.\n//\n// This is useful for filtering out services based on their annotations when they're being created or updated in the cluster. The default value for this field is false which means no filtering will be done by default. If set to true then only those"}
{"id": 658, "code": "func (p *Plan) Calculate() *Plan {\n\tt := newPlanTable()\n\n\tfor _, current := range filterRecordsForPlan(p.Current) {\n\t\tt.addCurrent(current)\n\t}\n\tfor _, desired := range filterRecordsForPlan(p.Desired) {\n\t\tt.addCandidate(desired)\n\t}\n\n\tchanges := &Changes{}\n\tchanges.Create = t.getCreates()\n\tchanges.Delete = t.getDeletes()\n\tchanges.UpdateNew, changes.UpdateOld = t.getUpdates()\n\tfor _, pol := range p.Policies {\n\t\tchanges = pol.Apply(changes)\n\t}\n\n\tplan := &Plan{\n\t\tCurrent: p.Current,\n\t\tDesired: p.Desired,\n\t\tChanges: changes,\n\t}\n\n\treturn plan\n}", "reference": "// Calculate computes the actions needed to move current state towards desired\n// state. It then passes those changes to the current policy for further\n// processing. It returns a copy of Plan with the changes populated.", "generated": "// Calculate returns a Plan that represents all possible plans for this set of records.\n//\n// This is done by creating two tables - one to hold the current state of each record,\n// and another to hold the candidates for each record's next state. The policies then apply their rules in order to determine which candidate should be"}
{"id": 662, "code": "func NewTargets(target ...string) Targets {\n\tt := make(Targets, 0, len(target))\n\tt = append(t, target...)\n\treturn t\n}", "reference": "// NewTargets is a convenience method to create a new Targets object from a vararg of strings", "generated": "// NewTargets returns new targets from given slice.\n//\n// This is used to create a copy of existing targets or set initial values for newly created targets. It's more efficient than calling Append() multiple times because it avoids unnecessary allocations. If no arguments were passed then empty TargetSlice will be returned. The result can't"}
{"id": 721, "code": "func NewRfc2136Provider(host string, port int, zoneName string, insecure bool, keyName string, secret string, secretAlg string, axfr bool, domainFilter DomainFilter, dryRun bool, actions rfc2136Actions) (Provider, error) {\n\tsecretAlgChecked, ok := tsigAlgs[secretAlg]\n\tif !ok && !insecure {\n\t\treturn nil, errors.Errorf(\"%s is not supported TSIG algorithm\", secretAlg)\n\t}\n\n\tr := &rfc2136Provider{\n\t\tnameserver:   net.JoinHostPort(host, strconv.Itoa(port)),\n\t\tzoneName:     dns.Fqdn(zoneName),\n\t\tinsecure:     insecure,\n\t\tdomainFilter: domainFilter,\n\t\tdryRun:       dryRun,\n\t\taxfr:         axfr,\n\t}\n\tif actions != nil {\n\t\tr.actions = actions\n\t} else {\n\t\tr.actions = r\n\t}\n\n\tif !insecure {\n\t\tr.tsigKeyName = dns.Fqdn(keyName)\n\t\tr.tsigSecret = secret\n\t\tr.tsigSecretAlg = secretAlgChecked\n\t}\n\n\tlog.Infof(\"Configured RFC2136 with zone '%s' and nameserver '%s'\", r.zoneName, r.nameserver)\n\treturn r, nil\n}", "reference": "// NewRfc2136Provider is a factory function for OpenStack rfc2136 providers", "generated": "// NewRFC2136Provider returns a new instance of Provider that uses RFC 2136 for DNS updates.\n//\n// The returned provider will be configured to use the specified host and port for the nameserver,\n// along with any other configuration options provided in this call. If no values were passed in,\n// then default"}
{"id": 734, "code": "func (p *AWSSDProvider) RegisterInstance(service *sd.Service, ep *endpoint.Endpoint) error {\n\tfor _, target := range ep.Targets {\n\t\tlog.Infof(\"Registering a new instance \\\"%s\\\" for service \\\"%s\\\" (%s)\", target, *service.Name, *service.Id)\n\n\t\tattr := make(map[string]*string)\n\n\t\tif ep.RecordType == endpoint.RecordTypeCNAME {\n\t\t\tif p.isAWSLoadBalancer(target) {\n\t\t\t\tattr[sdInstanceAttrAlias] = aws.String(target)\n\t\t\t} else {\n\t\t\t\tattr[sdInstanceAttrCname] = aws.String(target)\n\t\t\t}\n\t\t} else if ep.RecordType == endpoint.RecordTypeA {\n\t\t\tattr[sdInstanceAttrIPV4] = aws.String(target)\n\t\t} else {\n\t\t\treturn fmt.Errorf(\"invalid endpoint type (%v)\", ep)\n\t\t}\n\n\t\tif !p.dryRun {\n\t\t\t_, err := p.client.RegisterInstance(&sd.RegisterInstanceInput{\n\t\t\t\tServiceId:  service.Id,\n\t\t\t\tAttributes: attr,\n\t\t\t\tInstanceId: aws.String(p.targetToInstanceID(target)),\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "reference": "// RegisterInstance creates a new instance in given service.", "generated": "// RegisterInstance registers instances in AWS EC2 for given services.\n//\n// This method is used to register instances that will be managed by this provider.\n// It's called when registering a service or updating its attributes. The registration process may take some time depending on how long it takes to create the instances.\n// If dry"}
{"id": 769, "code": "func canonicalizeDomainName(d string) string {\n\tif !strings.HasSuffix(d, \".\") {\n\t\td += \".\"\n\t}\n\treturn strings.ToLower(d)\n}", "reference": "// converts domain name to FQDN", "generated": "// Canonicalizes domain name by converting it to lowercase and adding trailing dot if missing.\n//\n// This is used for consistency in DNS queries when resolving hostnames from\n// different domains. It's also useful for generating consistent hostname names\n// that can be used across multiple platforms (e.g., Windows vs Linux). The"}
{"id": 772, "code": "func addEndpoint(ep *endpoint.Endpoint, recordSets map[string]*recordSet, delete bool) {\n\tkey := fmt.Sprintf(\"%s/%s\", ep.DNSName, ep.RecordType)\n\trs := recordSets[key]\n\tif rs == nil {\n\t\trs = &recordSet{\n\t\t\tdnsName:    canonicalizeDomainName(ep.DNSName),\n\t\t\trecordType: ep.RecordType,\n\t\t\tnames:      make(map[string]bool),\n\t\t}\n\t}\n\tif rs.zoneID == \"\" {\n\t\trs.zoneID = ep.Labels[designateZoneID]\n\t}\n\tif rs.recordSetID == \"\" {\n\t\trs.recordSetID = ep.Labels[designateRecordSetID]\n\t}\n\tfor _, rec := range strings.Split(ep.Labels[designateOriginalRecords], \"\\000\") {\n\t\tif _, ok := rs.names[rec]; !ok && rec != \"\" {\n\t\t\trs.names[rec] = true\n\t\t}\n\t}\n\ttargets := ep.Targets\n\tif ep.RecordType == endpoint.RecordTypeCNAME {\n\t\ttargets = canonicalizeDomainNames(targets)\n\t}\n\tfor _, t := range targets {\n\t\trs.names[t] = !delete\n\t}\n\trecordSets[key] = rs\n}", "reference": "// adds endpoint into recordset aggregation, loading original values from endpoint labels first", "generated": "// Add adds or updates records for this zone in the given record sets.\n//\n// If no record set is found it will be created if necessary. The target names\n// must match exactly (case sensitive). This means that even though DNS names can\n// have subdomains they should still use the same case when used"}
{"id": 787, "code": "func (ms *dedupSource) Endpoints() ([]*endpoint.Endpoint, error) {\n\tresult := []*endpoint.Endpoint{}\n\tcollected := map[string]bool{}\n\n\tendpoints, err := ms.source.Endpoints()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ep := range endpoints {\n\t\tidentifier := ep.DNSName + \" / \" + ep.Targets.String()\n\n\t\tif _, ok := collected[identifier]; ok {\n\t\t\tlog.Debugf(\"Removing duplicate endpoint %s\", ep)\n\t\t\tcontinue\n\t\t}\n\n\t\tcollected[identifier] = true\n\t\tresult = append(result, ep)\n\t}\n\n\treturn result, nil\n}", "reference": "// Endpoints collects endpoints from its wrapped source and returns them without duplicates.", "generated": "// Endpoints returns all endpoints from source. If there is any duplicates,\n// they will be removed to avoid duplication in dedupe table.\n//\n// Note: This method should only be called once per instance of Deduper. It's\n// recommended that this method is used when initializing the Deduper object or\n//"}
{"id": 791, "code": "func (sdr *AWSSDRegistry) ApplyChanges(changes *plan.Changes) error {\n\tfilteredChanges := &plan.Changes{\n\t\tCreate:    changes.Create,\n\t\tUpdateNew: filterOwnedRecords(sdr.ownerID, changes.UpdateNew),\n\t\tUpdateOld: filterOwnedRecords(sdr.ownerID, changes.UpdateOld),\n\t\tDelete:    filterOwnedRecords(sdr.ownerID, changes.Delete),\n\t}\n\n\tsdr.updateLabels(filteredChanges.Create)\n\tsdr.updateLabels(filteredChanges.UpdateNew)\n\tsdr.updateLabels(filteredChanges.UpdateOld)\n\tsdr.updateLabels(filteredChanges.Delete)\n\n\treturn sdr.provider.ApplyChanges(filteredChanges)\n}", "reference": "// ApplyChanges filters out records not owned the External-DNS, additionally it adds the required label\n// inserted in the AWS SD instance as a CreateID field", "generated": "// ApplyChanges applies all changes to AWS SD Registry.\n//\n// This method is called by plan.Changes when there's something that needs\n// updating in the registry. It updates labels for records created or updated\n// and deletes any old versions if necessary. The provider handles actual\n// application of these changes. If"}
{"id": 800, "code": "func createDiskImage(dest string, size int, r io.Reader) error {\n\t// Convert a raw image from stdin to the dest VMDK image.\n\tsizeBytes := int64(size) << 20 // usually won't fit in 32-bit int (max 2GB)\n\t// FIXME: why isn't this just using the vbm*() functions?\n\tcmd := exec.Command(vboxManageCmd, \"convertfromraw\", \"stdin\", dest,\n\t\tfmt.Sprintf(\"%d\", sizeBytes), \"--format\", \"VMDK\")\n\n\tlog.Debug(cmd)\n\n\tif os.Getenv(\"MACHINE_DEBUG\") != \"\" {\n\t\tcmd.Stdout = os.Stdout\n\t\tcmd.Stderr = os.Stderr\n\t}\n\n\tstdin, err := cmd.StdinPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Starting command\")\n\n\tif err := cmd.Start(); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Copying to stdin\")\n\n\tn, err := io.Copy(stdin, r)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Filling zeroes\")\n\n\t// The total number of bytes written to stdin must match sizeBytes, or\n\t// VBoxManage.exe on Windows will fail. Fill remaining with zeros.\n\tif left := sizeBytes - n; left > 0 {\n\t\tif err := zeroFill(stdin, left); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tlog.Debug(\"Closing STDIN\")\n\n\t// cmd won't exit until the stdin is closed.\n\tif err := stdin.Close(); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Waiting on cmd\")\n\n\treturn cmd.Wait()\n}", "reference": "// createDiskImage makes a disk image at dest with the given size in MB. If r is\n// not nil, it will be read as a raw disk image to convert from.", "generated": "// Create a disk image by copying data into it. This can be used for creating\n// virtual machines that require a specific type of storage device. For example,\n// when running a VM with a non-standard OS like Solaris, we may need to use\n// a different format than the default one provided by Virtual"}
{"id": 802, "code": "func (n *hostOnlyNetwork) SaveIPv4(vbox VBoxManager) error {\n\tif n.IPv4.IP != nil && n.IPv4.Mask != nil {\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tlog.Warn(\"Windows might ask for the permission to configure a network adapter. Sometimes, such confirmation window is minimized in the taskbar.\")\n\t\t}\n\n\t\tif err := vbox.vbm(\"hostonlyif\", \"ipconfig\", n.Name, \"--ip\", n.IPv4.IP.String(), \"--netmask\", net.IP(n.IPv4.Mask).String()); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}", "reference": "// SaveIPv4 changes the ipv4 configuration of the host-only network.", "generated": "// SaveIPv4 saves IPv4 configuration if it exists. It will only be called when host-only networks have IP addresses assigned.\n//\n// If there's no need to save anything then this method returns immediately without calling any VBox API calls. This can happen if we're running inside a Docker container or another virtualization"}
{"id": 821, "code": "func (d *Driver) Restart() error {\n\tcs := d.client()\n\t_, err := cs.RequestWithContext(context.TODO(), &egoscale.RebootVirtualMachine{\n\t\tID: d.ID,\n\t})\n\n\treturn err\n}", "reference": "// Restart reboots the existing VM instance.", "generated": "// Restart restarts the virtual machine in this driver instance. The VM will be restarted after 5 seconds.\n//\n// This method is idempotent; if it's called multiple times for the same VM, only one request to reboot the VM will be sent. If there was already a pending reboot when calling this method"}
{"id": 822, "code": "func (d *Driver) Remove() error {\n\tclient := d.client()\n\n\t// Destroy the SSH key from CloudStack\n\tif d.KeyPair != \"\" {\n\t\tkey := &egoscale.SSHKeyPair{Name: d.KeyPair}\n\t\tif err := client.DeleteWithContext(context.TODO(), key); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Destroy the virtual machine\n\tif d.ID != \"\" {\n\t\tvm := &egoscale.VirtualMachine{ID: d.ID}\n\t\tif err := client.DeleteWithContext(context.TODO(), vm); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tlog.Infof(\"The Anti-Affinity group and Security group were not removed\")\n\n\treturn nil\n}", "reference": "// Remove destroys the VM instance and the associated SSH key.", "generated": "// Remove removes all resources created by this driver. This is typically used when a user wants to remove their entire setup. The anti-affinity group will be deleted first followed by any security groups that have been added to it. Note that if there was no anti-affinity group then only the security groups would be deleted."}
{"id": 823, "code": "func (d *Driver) getCloudInit() ([]byte, error) {\n\tvar err error\n\tif d.UserDataFile != \"\" {\n\t\td.UserData, err = ioutil.ReadFile(d.UserDataFile)\n\t}\n\n\treturn d.UserData, err\n}", "reference": "// Build a cloud-init user data string that will install and run\n// docker.", "generated": "// getCloudInit returns cloud init data from user provided file or default one.\n//\n// If no Userdata is set then it will return empty byte slice. It's used for\n// testing purposes only. In production environment we should always use\n// user-provided userdata to avoid any issues that might occur if there"}
{"id": 834, "code": "func deviceFlowAuth(oauthCfg azure.OAuthConfig, clientID, resource string) (*azure.ServicePrincipalToken, error) {\n\tcl := oauthClient()\n\tdeviceCode, err := azure.InitiateDeviceAuth(&cl, oauthCfg, clientID, resource)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to start device auth: %v\", err)\n\t}\n\tlog.Debug(\"Retrieved device code.\", logutil.Fields{\n\t\t\"expires_in\": to.Int64(deviceCode.ExpiresIn),\n\t\t\"interval\":   to.Int64(deviceCode.Interval),\n\t})\n\n\t// Example message: \u201cTo sign in, open https://aka.ms/devicelogin and enter\n\t// the code 0000000 to authenticate.\u201d\n\tlog.Infof(\"Microsoft Azure: %s\", to.String(deviceCode.Message))\n\n\ttoken, err := azure.WaitForUserCompletion(&cl, deviceCode)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to complete device auth: %v\", err)\n\t}\n\n\tspt, err := azure.NewServicePrincipalTokenFromManualToken(oauthCfg, clientID, resource, *token)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error constructing service principal token: %v\", err)\n\t}\n\treturn spt, nil\n}", "reference": "// deviceFlowAuth prints a message to the screen for user to take action to\n// consent application on a browser and in the meanwhile the authentication\n// endpoint is polled until user gives consent, denies or the flow times out.\n// Returned token must be saved.", "generated": "// deviceFlowAuth is used for authentication when using the Microsoft Azure SDK.\n//\n// This method will prompt the user to go through the flow required by the\n// Microsoft Azure SDK (https://docs.microsoft.com/en-us/azure/active-directory/develop/scenario-device-code). The returned\n// ServicePrincipalToken can"}
{"id": 842, "code": "func (c *ComputeUtil) staticAddress() (string, error) {\n\t// is the address a name?\n\tisName, err := regexp.MatchString(\"[a-z]([-a-z0-9]*[a-z0-9])?\", c.address)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif !isName {\n\t\treturn c.address, nil\n\t}\n\n\t// resolve the address by name\n\texternalAddress, err := c.service.Addresses.Get(c.project, c.region(), c.address).Do()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn externalAddress.Address, nil\n}", "reference": "// staticAddress returns the external static IP address.", "generated": "// Returns the IP address associated with this Compute instance's network interface.\n//\n// If the address is a name, it will be resolved to its corresponding IP address using the service's DNS API. Otherwise,\n// the returned value will simply be the original string passed in. This method returns an error if there was an issue"}
{"id": 849, "code": "func (c *ComputeUtil) startInstance() error {\n\top, err := c.service.Instances.Start(c.project, c.zone, c.instanceName).Do()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Infof(\"Waiting for instance to start.\")\n\treturn c.waitForRegionalOp(op.Name)\n}", "reference": "// startInstance starts the instance.", "generated": "// Start starts the specified instance in this project's zone.\n//\n// This method will wait until the operation is complete before returning,\n// even if it takes longer than 30 seconds. If there was no error during\n// execution, then the instance has been successfully started. Otherwise,\n// an error message describing any errors"}
{"id": 867, "code": "func osDiskStorageContainerURL(account *storage.AccountProperties, vmName string) string {\n\treturn fmt.Sprintf(\"%s%s/\", to.String(account.PrimaryEndpoints.Blob), osDiskStorageContainerName(vmName))\n}", "reference": "// osDiskStorageContainerURL crafts a URL with a trailing slash pointing\n// to the full Azure Blob Container URL for given VM name.", "generated": "// Returns URL for disk storage container in specified account. The\n// returned url is relative path from root endpoint. It should be used when\n// calling blob service methods that require absolute URLs.\n//\n// Note: This method returns empty string if primary endpoints or account name\n// is nil. In this case it's"}
{"id": 892, "code": "func (d *Driver) Create() error {\n\tlog.Infof(\"Generating SSH Key\")\n\n\tif err := ssh.GenerateSSHKey(d.GetSSHKeyPath()); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Infof(\"Creating host...\")\n\n\tc, err := newComputeUtil(d)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := c.openFirewallPorts(d); err != nil {\n\t\treturn err\n\t}\n\n\tif d.UseExisting {\n\t\treturn c.configureInstance(d)\n\t}\n\treturn c.createInstance(d)\n}", "reference": "// Create creates a GCE VM instance acting as a docker host.", "generated": "// Create creates a new instance using the provided configuration.\n//\n// If UseExisting is true then it will use existing resources instead of creating them from scratch.\n// This can be useful for testing or when there's already some infrastructure set up in place that we want to leverage.\n// However this should only be used sparingly"}
{"id": 908, "code": "func (d *Driver) Restart() error {\n\tif err := d.checkLegacyDriver(true); err != nil {\n\t\treturn err\n\t}\n\n\t// NOTE(ahmetalpbalkan) Azure will always keep the VM in Running state\n\t// during the restart operation. Hence we rely on returned async operation\n\t// polling to make sure the reboot is waited upon.\n\tc, err := d.newAzureClient()\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn c.RestartVirtualMachine(d.ResourceGroup, d.naming().VM())\n}", "reference": "// Restart reboots the virtual machine instance.", "generated": "// Restart starts the virtual machine by sending a request to Microsoft Azure's API. The result can be checked using Polling or WaitUntilRunning methods. If there was any issue while restarting the vm then it returns an error. This method should only be called once per instance. It also checks if legacy driver exists before calling"}
{"id": 914, "code": "func (d *Driver) Start() error {\n\tif err := cmd(\"Hyper-V\\\\Start-VM\", d.MachineName); err != nil {\n\t\treturn err\n\t}\n\n\tip, err := d.waitForIP()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\td.IPAddress = ip\n\n\treturn nil\n}", "reference": "// Start starts an host", "generated": "// Start starts the VM in HyperV. It waits for it to be ready before returning.\n//\n// If there is no IP address assigned yet then this will return immediately without waiting for the machine to start up. This can happen if the network adapter was disabled when creating the virtual machine or if the host has multiple networks"}
{"id": 921, "code": "func (d *BaseDriver) GetSSHUsername() string {\n\tif d.SSHUser == \"\" {\n\t\td.SSHUser = DefaultSSHUser\n\t}\n\treturn d.SSHUser\n}", "reference": "// GetSSHUsername returns the ssh user name, root if not specified", "generated": "// GetSSHUsername returns SSH username for this driver instance.\n//\n// If no value is set in the config, it will use default one defined by BaseDriver. It's used to connect to remote server via ssh protocol. This method should be called before connecting to any host using SSH connection methods provided by this base class"}
{"id": 937, "code": "func NewDriver(machineName, storePath string) drivers.Driver {\n\tlog.Debug(\"Instantiating Rackspace driver.\", map[string]string{\"machineName\": machineName})\n\n\tinner := openstack.NewDerivedDriver(machineName, storePath)\n\tdriver := &Driver{\n\t\tDriver: inner,\n\t}\n\tinner.SetClient(&Client{\n\t\tdriver: driver,\n\t})\n\n\treturn driver\n}", "reference": "// NewDriver instantiates a Rackspace driver.", "generated": "// NewDriver returns a new instance of Driver for use in OpenStack. The client is initialized to point at the specified machine name.\n//\n// This method should be called only once per application lifetime. It will return the same driver object if it has already been created. If this happens, then there may have been some"}
{"id": 945, "code": "func (d *Driver) GetCreateFlags() []mcnflag.Flag {\n\treturn []mcnflag.Flag{\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_CPU_COUNT\",\n\t\t\tName:   \"vmwarevsphere-cpu-count\",\n\t\t\tUsage:  \"vSphere CPU number for docker VM\",\n\t\t\tValue:  defaultCpus,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_MEMORY_SIZE\",\n\t\t\tName:   \"vmwarevsphere-memory-size\",\n\t\t\tUsage:  \"vSphere size of memory for docker VM (in MB)\",\n\t\t\tValue:  defaultMemory,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_DISK_SIZE\",\n\t\t\tName:   \"vmwarevsphere-disk-size\",\n\t\t\tUsage:  \"vSphere size of disk for docker VM (in MB)\",\n\t\t\tValue:  defaultDiskSize,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_BOOT2DOCKER_URL\",\n\t\t\tName:   \"vmwarevsphere-boot2docker-url\",\n\t\t\tUsage:  \"vSphere URL for boot2docker image\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER\",\n\t\t\tName:   \"vmwarevsphere-vcenter\",\n\t\t\tUsage:  \"vSphere IP/hostname for vCenter\",\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER_PORT\",\n\t\t\tName:   \"vmwarevsphere-vcenter-port\",\n\t\t\tUsage:  \"vSphere Port for vCenter\",\n\t\t\tValue:  defaultSDKPort,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_USERNAME\",\n\t\t\tName:   \"vmwarevsphere-username\",\n\t\t\tUsage:  \"vSphere username\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_PASSWORD\",\n\t\t\tName:   \"vmwarevsphere-password\",\n\t\t\tUsage:  \"vSphere password\",\n\t\t},\n\t\tmcnflag.StringSliceFlag{\n\t\t\tEnvVar: \"VSPHERE_NETWORK\",\n\t\t\tName:   \"vmwarevsphere-network\",\n\t\t\tUsage:  \"vSphere network where the docker VM will be attached\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATASTORE\",\n\t\t\tName:   \"vmwarevsphere-datastore\",\n\t\t\tUsage:  \"vSphere datastore for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATACENTER\",\n\t\t\tName:   \"vmwarevsphere-datacenter\",\n\t\t\tUsage:  \"vSphere datacenter for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_FOLDER\",\n\t\t\tName:   \"vmwarevsphere-folder\",\n\t\t\tUsage:  \"vSphere folder for the docker VM. This folder must already exist in the datacenter.\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_POOL\",\n\t\t\tName:   \"vmwarevsphere-pool\",\n\t\t\tUsage:  \"vSphere resource pool for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_HOSTSYSTEM\",\n\t\t\tName:   \"vmwarevsphere-hostsystem\",\n\t\t\tUsage:  \"vSphere compute resource where the docker VM will be instantiated. This can be omitted if using a cluster with DRS.\",\n\t\t},\n\t\tmcnflag.StringSliceFlag{\n\t\t\tEnvVar: \"VSPHERE_CFGPARAM\",\n\t\t\tName:   \"vmwarevsphere-cfgparam\",\n\t\t\tUsage:  \"vSphere vm configuration parameters (used for guestinfo)\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_CLOUDINIT\",\n\t\t\tName:   \"vmwarevsphere-cloudinit\",\n\t\t\tUsage:  \"vSphere cloud-init file or url to set in the guestinfo\",\n\t\t},\n\t}\n}", "reference": "// GetCreateFlags registers the flags this driver adds to\n// \"docker-machine create\"", "generated": "// GetCreateFlags returns all flags that need to be passed when creating\n// a new Docker container from a vSphere environment.\n//\n// These include cpu count, memory size, disk size, etc... The user is expected\n// to have these values configured via their environment variables. If they do\n// not then"}
{"id": 963, "code": "func (v *View) Data() interface{} {\n\tv.dataLock.RLock()\n\tdefer v.dataLock.RUnlock()\n\treturn v.data\n}", "reference": "// Data returns the most-recently-received data from Consul for this View.", "generated": "// Data returns data associated to this view. The returned value is always immutable.\n// If no data has been set for this view then it will return nil. This method should be called only once,\n// otherwise unexpected behaviour may occur due to concurrent access. It's recommended that all views have\n// their own lock so"}
{"id": 1020, "code": "func NewKVListQuery(s string) (*KVListQuery, error) {\n\tif s != \"\" && !KVListQueryRe.MatchString(s) {\n\t\treturn nil, fmt.Errorf(\"kv.list: invalid format: %q\", s)\n\t}\n\n\tm := regexpMatch(KVListQueryRe, s)\n\treturn &KVListQuery{\n\t\tstopCh: make(chan struct{}, 1),\n\t\tdc:     m[\"dc\"],\n\t\tprefix: m[\"prefix\"],\n\t}, nil\n}", "reference": "// NewKVListQuery parses a string into a dependency.", "generated": "// NewKVListQuery returns a new KVListQuery instance from a given query string.\n//\n// The returned value is non-nil if the input was successfully parsed,\n// otherwise it's nil along with an error message describing why the parsing failed. If\n// there were no errors during parsing but the result doesn't match"}
{"id": 1021, "code": "func NewDedupManager(config *config.DedupConfig, clients *dep.ClientSet, brain *template.Brain, templates []*template.Template) (*DedupManager, error) {\n\td := &DedupManager{\n\t\tconfig:    config,\n\t\tclients:   clients,\n\t\tbrain:     brain,\n\t\ttemplates: templates,\n\t\tleader:    make(map[*template.Template]<-chan struct{}),\n\t\tlastWrite: make(map[*template.Template]uint64),\n\t\tupdateCh:  make(chan struct{}, 1),\n\t\tstopCh:    make(chan struct{}),\n\t}\n\treturn d, nil\n}", "reference": "// NewDedupManager creates a new Dedup manager", "generated": "// NewDedupManager creates a new DedupManager instance from given parameters.\n//\n// The manager is responsible for managing deduplicated data across all nodes in the cluster.\n// It maintains a map of template instances that have been written to disk since last update.\n// When a node joins or leaves the cluster, it"}
{"id": 1045, "code": "func NewVaultReadQuery(s string) (*VaultReadQuery, error) {\n\ts = strings.TrimSpace(s)\n\ts = strings.Trim(s, \"/\")\n\tif s == \"\" {\n\t\treturn nil, fmt.Errorf(\"vault.read: invalid format: %q\", s)\n\t}\n\n\tsecretURL, err := url.Parse(s)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &VaultReadQuery{\n\t\tstopCh:      make(chan struct{}, 1),\n\t\trawPath:     secretURL.Path,\n\t\tqueryValues: secretURL.Query(),\n\t}, nil\n}", "reference": "// NewVaultReadQuery creates a new datacenter dependency.", "generated": "// NewVaultReadQuery creates a new Vault read query from a URL.\n//\n// The raw path is used to construct the vault request. If it's empty or\n// starts with '/', then no prefix will be added to the vault request.\n//\n// This method returns an error if there was any problem parsing the input"}
{"id": 1057, "code": "func (c *Child) Kill() {\n\tlog.Printf(\"[INFO] (child) killing process\")\n\tc.Lock()\n\tdefer c.Unlock()\n\tc.kill()\n}", "reference": "// Kill sends the kill signal to the child process and waits for successful\n// termination. If no kill signal is defined, the process is killed with the\n// most aggressive kill signal. If the process does not gracefully stop within\n// the provided KillTimeout, the process is force-killed. If a splay was\n// provided, this function will sleep for a random period of time between 0 and\n// the provided splay value to reduce the thundering herd problem. This function\n// does not return any errors because it guarantees the process will be dead by\n// the return of the function call.", "generated": "// Kill stops child from running. This is useful when testing or debugging.\n// Note that this will only work if the child has been started using\n// Start(). If it was created directly by New(), then calling Kill won't have any effect. In such case,\n// use Stop instead to stop the goroutine."}
{"id": 1064, "code": "func NewRunner(config *config.Config, dry, once bool) (*Runner, error) {\n\tlog.Printf(\"[INFO] (runner) creating new runner (dry: %v, once: %v)\", dry, once)\n\n\trunner := &Runner{\n\t\tconfig: config,\n\t\tdry:    dry,\n\t\tonce:   once,\n\t}\n\n\tif err := runner.init(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn runner, nil\n}", "reference": "// NewRunner accepts a slice of TemplateConfigs and returns a pointer to the new\n// Runner and any error that occurred during creation.", "generated": "// NewRunner creates a new Runner instance from given configuration.\n//\n// If dry is true then no actual commands will be executed but all necessary\n// information for execution will still be gathered. Once flag means that only one command can be run at most in this process. This prevents race conditions when running multiple commands concurrently."}
{"id": 1102, "code": "func base64URLDecode(s string) (string, error) {\n\tv, err := base64.URLEncoding.DecodeString(s)\n\tif err != nil {\n\t\treturn \"\", errors.Wrap(err, \"base64URLDecode\")\n\t}\n\treturn string(v), nil\n}", "reference": "// base64URLDecode decodes the given string as a URL-safe base64 string.", "generated": "// base64URLDecode decodes a URL-safe Base64 encoded byte slice.\n//\n// The input is expected to be in the format of urlsafe_base64 encoding which uses\n// - A-Z-Fa-f-z0-9+/\n// - / instead of + for padding characters\n//\n// This function returns"}
{"id": 1107, "code": "func in(l, v interface{}) (bool, error) {\n\tlv := reflect.ValueOf(l)\n\tvv := reflect.ValueOf(v)\n\n\tswitch lv.Kind() {\n\tcase reflect.Array, reflect.Slice:\n\t\t// if the slice contains 'interface' elements, then the element needs to be extracted directly to examine its type,\n\t\t// otherwise it will just resolve to 'interface'.\n\t\tvar interfaceSlice []interface{}\n\t\tif reflect.TypeOf(l).Elem().Kind() == reflect.Interface {\n\t\t\tinterfaceSlice = l.([]interface{})\n\t\t}\n\n\t\tfor i := 0; i < lv.Len(); i++ {\n\t\t\tvar lvv reflect.Value\n\t\t\tif interfaceSlice != nil {\n\t\t\t\tlvv = reflect.ValueOf(interfaceSlice[i])\n\t\t\t} else {\n\t\t\t\tlvv = lv.Index(i)\n\t\t\t}\n\n\t\t\tswitch lvv.Kind() {\n\t\t\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\t\t\tswitch vv.Kind() {\n\t\t\t\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\t\t\t\tif vv.Int() == lvv.Int() {\n\t\t\t\t\t\treturn true, nil\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase reflect.Float32, reflect.Float64:\n\t\t\t\tswitch vv.Kind() {\n\t\t\t\tcase reflect.Float32, reflect.Float64:\n\t\t\t\t\tif vv.Float() == lvv.Float() {\n\t\t\t\t\t\treturn true, nil\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase reflect.String:\n\t\t\t\tif vv.Type() == lvv.Type() && vv.String() == lvv.String() {\n\t\t\t\t\treturn true, nil\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tcase reflect.String:\n\t\tif vv.Type() == lv.Type() && strings.Contains(lv.String(), vv.String()) {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\n\treturn false, nil\n}", "reference": "// in searches for a given value in a given interface.", "generated": "// in checks whether two values match each other.\n//\n// The first value is checked against all possible types that can be assigned from the second one.\n// If there's no matching type found for both values, they're considered different.\n//\n// This method returns immediately when either of them has been determined to be equal or"}
{"id": 1110, "code": "func parseBool(s string) (bool, error) {\n\tif s == \"\" {\n\t\treturn false, nil\n\t}\n\n\tresult, err := strconv.ParseBool(s)\n\tif err != nil {\n\t\treturn false, errors.Wrap(err, \"parseBool\")\n\t}\n\treturn result, nil\n}", "reference": "// parseBool parses a string into a boolean", "generated": "// ParseBool parses a boolean value from a given string.\n//\n// If the input is empty or cannot be parsed to bool it returns false. The returned\n// error will contain more information about why parsing failed. This can happen if\n// the input contains non-boolean values like numbers that have been converted to strings"}
{"id": 1111, "code": "func parseFloat(s string) (float64, error) {\n\tif s == \"\" {\n\t\treturn 0.0, nil\n\t}\n\n\tresult, err := strconv.ParseFloat(s, 10)\n\tif err != nil {\n\t\treturn 0, errors.Wrap(err, \"parseFloat\")\n\t}\n\treturn result, nil\n}", "reference": "// parseFloat parses a string into a base 10 float", "generated": "// parseFloat parses a float from a given string.\n//\n// If parsing fails it returns zero value for the type. The returned error is wrapped in\n// errors.New to provide more context about which field failed to parse. This can be used by\n// the caller to determine if there was any problem at all or just"}
{"id": 1132, "code": "func (c *cache) Delete(k string) {\n\tc.mu.Lock()\n\tv, evicted := c.delete(k)\n\tc.mu.Unlock()\n\tif evicted {\n\t\tc.onEvicted(k, v)\n\t}\n}", "reference": "// Delete an item from the cache. Does nothing if the key is not in the cache.", "generated": "// delete removes key-value pair from cache.\n//\n// If value is already expired or has been removed by another goroutine,\n// it will be returned immediately without calling onEvicted callback.\n// Otherwise, if value was successfully retrieved before deletion\n// then its expiration time will be updated to now + 1 second."}
{"id": 1133, "code": "func (c *cache) DeleteExpired() {\n\tvar evictedItems []keyAndValue\n\tnow := time.Now().UnixNano()\n\tc.mu.Lock()\n\tfor k, v := range c.items {\n\t\t// \"Inlining\" of expired\n\t\tif v.Expiration > 0 && now > v.Expiration {\n\t\t\tov, evicted := c.delete(k)\n\t\t\tif evicted {\n\t\t\t\tevictedItems = append(evictedItems, keyAndValue{k, ov})\n\t\t\t}\n\t\t}\n\t}\n\tc.mu.Unlock()\n\tfor _, v := range evictedItems {\n\t\tc.onEvicted(v.key, v.value)\n\t}\n}", "reference": "// Delete all expired items from the cache.", "generated": "// DeleteExpired removes items that have expired from cache.\n//\n// This is called periodically by the main loop to clean up old entries,\n// but it can also be manually triggered if needed. The expiration times for\n// all keys in the cache must be set before calling this method; otherwise,\n// no items will ever"}
{"id": 1137, "code": "func djb33(seed uint32, k string) uint32 {\n\tvar (\n\t\tl = uint32(len(k))\n\t\td = 5381 + seed + l\n\t\ti = uint32(0)\n\t)\n\t// Why is all this 5x faster than a for loop?\n\tif l >= 4 {\n\t\tfor i < l-4 {\n\t\t\td = (d * 33) ^ uint32(k[i])\n\t\t\td = (d * 33) ^ uint32(k[i+1])\n\t\t\td = (d * 33) ^ uint32(k[i+2])\n\t\t\td = (d * 33) ^ uint32(k[i+3])\n\t\t\ti += 4\n\t\t}\n\t}\n\tswitch l - i {\n\tcase 1:\n\tcase 2:\n\t\td = (d * 33) ^ uint32(k[i])\n\tcase 3:\n\t\td = (d * 33) ^ uint32(k[i])\n\t\td = (d * 33) ^ uint32(k[i+1])\n\tcase 4:\n\t\td = (d * 33) ^ uint32(k[i])\n\t\td = (d * 33) ^ uint32(k[i+1])\n\t\td = (d * 33) ^ uint32(k[i+2])\n\t}\n\treturn d ^ (d >> 16)\n}", "reference": "// djb2 with better shuffling. 5x faster than FNV with the hash.Hash overhead.", "generated": "// djb33 implements the \"djb\" hashing algorithm from http://www.cse.york.ac.uk/courses/concepts/strings/djb.html.\n//\n// This hash function takes two arguments: `seed` which should be initialized to some value,\n// and `k`, which can contain any characters. The"}
{"id": 1143, "code": "func (m *MockTaskEngine) MarshalJSON() ([]byte, error) {\n\tret := m.ctrl.Call(m, \"MarshalJSON\")\n\tret0, _ := ret[0].([]byte)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// MarshalJSON mocks base method", "generated": "// MockTaskEngine's MarshalJSON method is a mock for TaskEngine's MarshalJSON.\n// It calls the real task engine's MarshalJSON method but returns nil instead of\n// the result to avoid calling it in this context. This allows us to test that\n// we're getting called correctly without actually marshaling anything"}
{"id": 1149, "code": "func (mr *MockImageManagerMockRecorder) AddAllImageStates(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"AddAllImageStates\", reflect.TypeOf((*MockImageManager)(nil).AddAllImageStates), arg0)\n}", "reference": "// AddAllImageStates indicates an expected call of AddAllImageStates", "generated": "// AddAllImageStates returns mock result for AddAllImageStates method call. This is a type-specific recorder method that records the last time this method was called. It takes one argument: image states to add. The recorded value will be returned by GetLastCall() when this recorders GetLastCall() or Get"}
{"id": 1150, "code": "func (m *MockImageManager) GetImageStateFromImageName(arg0 string) (*image.ImageState, bool) {\n\tret := m.ctrl.Call(m, \"GetImageStateFromImageName\", arg0)\n\tret0, _ := ret[0].(*image.ImageState)\n\tret1, _ := ret[1].(bool)\n\treturn ret0, ret1\n}", "reference": "// GetImageStateFromImageName mocks base method", "generated": "// GetImageStateFromImageName returns image state for given name.\n//\n// This method is used to get image state from image name. It takes one argument,\n// which is the name of the image. The returned value will be nil if no such\n// image exists in the registry or it's already been deleted"}
{"id": 1181, "code": "func (mr *MockContainerMetadataResolverMockRecorder) ResolveContainer(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"ResolveContainer\", reflect.TypeOf((*MockContainerMetadataResolver)(nil).ResolveContainer), arg0)\n}", "reference": "// ResolveContainer indicates an expected call of ResolveContainer", "generated": "// ResolveContainer returns mock call for method ResolveContainer. This is\n// generated by the go-mocks library package. It will be called when calling\n// this method directly or any other method that calls it in its code path.\n//\n// Use this to verify the order of methods during execution. To do so,"}
{"id": 1183, "code": "func NewTaskResponse(taskARN string,\n\tstate dockerstate.TaskEngineState,\n\tecsClient api.ECSClient,\n\tcluster string,\n\taz string,\n\tcontainerInstanceArn string,\n\tpropagateTags bool) (*TaskResponse, error) {\n\ttask, ok := state.TaskByArn(taskARN)\n\tif !ok {\n\t\treturn nil, errors.Errorf(\"v2 task response: unable to find task '%s'\", taskARN)\n\t}\n\n\tresp := &TaskResponse{\n\t\tCluster:          cluster,\n\t\tTaskARN:          task.Arn,\n\t\tFamily:           task.Family,\n\t\tRevision:         task.Version,\n\t\tDesiredStatus:    task.GetDesiredStatus().String(),\n\t\tKnownStatus:      task.GetKnownStatus().String(),\n\t\tAvailabilityZone: az,\n\t}\n\n\ttaskCPU := task.CPU\n\ttaskMemory := task.Memory\n\tif taskCPU != 0 || taskMemory != 0 {\n\t\ttaskLimits := &LimitsResponse{}\n\t\tif taskCPU != 0 {\n\t\t\ttaskLimits.CPU = &taskCPU\n\t\t}\n\t\tif taskMemory != 0 {\n\t\t\ttaskLimits.Memory = &taskMemory\n\t\t}\n\t\tresp.Limits = taskLimits\n\t}\n\n\tif timestamp := task.GetPullStartedAt(); !timestamp.IsZero() {\n\t\tresp.PullStartedAt = aws.Time(timestamp.UTC())\n\t}\n\tif timestamp := task.GetPullStoppedAt(); !timestamp.IsZero() {\n\t\tresp.PullStoppedAt = aws.Time(timestamp.UTC())\n\t}\n\tif timestamp := task.GetExecutionStoppedAt(); !timestamp.IsZero() {\n\t\tresp.ExecutionStoppedAt = aws.Time(timestamp.UTC())\n\t}\n\tcontainerNameToDockerContainer, ok := state.ContainerMapByArn(task.Arn)\n\tif !ok {\n\t\tseelog.Warnf(\"V2 task response: unable to get container name mapping for task '%s'\",\n\t\t\ttask.Arn)\n\t\treturn resp, nil\n\t}\n\n\teni := task.GetTaskENI()\n\tfor _, dockerContainer := range containerNameToDockerContainer {\n\t\tcontainerResponse := newContainerResponse(dockerContainer, eni, state)\n\t\tresp.Containers = append(resp.Containers, containerResponse)\n\t}\n\n\tif propagateTags {\n\t\tpropagateTagsToMetadata(state, ecsClient, containerInstanceArn, taskARN, resp)\n\t}\n\n\treturn resp, nil\n}", "reference": "// NewTaskResponse creates a new response object for the task", "generated": "// NewTaskResponse returns a TaskResponse object from v2 task data.\n//\n// This is used by the Docker client when it receives a v2 task event from ECS.\n// The returned TaskResponse contains all necessary information about the task in\n// JSON format that can be sent back to the user's application. It"}
{"id": 1195, "code": "func (m *MockTime) After(arg0 time.Duration) <-chan time.Time {\n\tret := m.ctrl.Call(m, \"After\", arg0)\n\tret0, _ := ret[0].(<-chan time.Time)\n\treturn ret0\n}", "reference": "// After mocks base method", "generated": "// After returns a channel that will be sent when the mock is called again after the specified duration.\n//\n// The returned value can only be used until the next call to After or Stop. If the mock is stopped,\n// any pending calls will return immediately without sending anything through this channel. This method\n// should be"}
{"id": 1200, "code": "func (mr *MockTimeMockRecorder) Sleep(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Sleep\", reflect.TypeOf((*MockTime)(nil).Sleep), arg0)\n}", "reference": "// Sleep indicates an expected call of Sleep", "generated": "// Sleep records call to MockTime.Sleep. Args are passed by value since we don't\n// know the type of arguments that will be passed in. We can only record the method name,\n// so this is just a placeholder for now until we have more information about how\n// time mocking should work. This mock"}
{"id": 1205, "code": "func (mr *MockTimerMockRecorder) Stop() *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Stop\", reflect.TypeOf((*MockTimer)(nil).Stop))\n}", "reference": "// Stop indicates an expected call of Stop", "generated": "// Stop is called by MockTimer to stop its timer. It returns nil if no\n// call was made. If it has been called before then it will return the mock\n// object that was passed in when Start was called. This allows for mocking\n// of the returned value from this method. The default behaviour"}
{"id": 1216, "code": "func (imageState *ImageState) AddImageName(imageName string) {\n\timageState.lock.Lock()\n\tdefer imageState.lock.Unlock()\n\tif !imageState.HasImageName(imageName) {\n\t\tseelog.Infof(\"Adding image name- %v to Image state- %v\", imageName, imageState.Image.ImageID)\n\t\timageState.Image.Names = append(imageState.Image.Names, imageName)\n\t}\n}", "reference": "// AddImageName adds image name to image state", "generated": "// AddImageName adds new image-name into existing list if it is already present in\n// image-state then just update its position at correct index.\n//\n// This method should be called only by one goroutine for each image-state instance,\n// otherwise this can lead to race condition. It's recommended that all calls to"}
{"id": 1254, "code": "func copyMetricsMetadata(metadata *ecstcs.MetricsMetadata, fin bool) *ecstcs.MetricsMetadata {\n\treturn &ecstcs.MetricsMetadata{\n\t\tCluster:           aws.String(*metadata.Cluster),\n\t\tContainerInstance: aws.String(*metadata.ContainerInstance),\n\t\tIdle:              aws.Bool(*metadata.Idle),\n\t\tMessageId:         aws.String(*metadata.MessageId),\n\t\tFin:               aws.Bool(fin),\n\t}\n}", "reference": "// copyMetricsMetadata creates a new MetricsMetadata object from a given MetricsMetadata object.\n// It copies all the fields from the source object to the new object and sets the 'Fin' field\n// as specified by the argument.", "generated": "// Copy metrics metadata to new instance. This is used when we need\n// to create a new metric set from existing one but don't want to\n// update original. It's also useful for testing purposes where\n// we can easily change values without affecting live data.\n//\n// Note that this method doesn't modify"}
{"id": 1285, "code": "func (cgroup *CgroupResource) Create() error {\n\terr := cgroup.setupTaskCgroup()\n\tif err != nil {\n\t\tseelog.Criticalf(\"Cgroup resource [%s]: unable to setup cgroup root: %v\", cgroup.taskARN, err)\n\t\treturn err\n\t}\n\treturn nil\n}", "reference": "// Create creates cgroup root for the task", "generated": "// Create creates a new CGroup resource for this task. This method is called by\n// NewCgroup when creating a new instance of it. It sets up the necessary resources,\n// including setting up the cgroup root if one hasn't been set already.\n//\n// If there's any issue during creation, we"}
{"id": 1293, "code": "func NewECRFactory(acceptInsecureCert bool) ECRFactory {\n\treturn &ecrFactory{\n\t\thttpClient: httpclient.New(roundtripTimeout, acceptInsecureCert),\n\t}\n}", "reference": "// NewECRFactory returns an ECRFactory capable of producing ECRSDK clients", "generated": "// New returns a new instance of the factory for creating clients to\n// interact with Amazon Elastic Container Registry (ECR). The client is created using\n// the provided HTTP client which can be configured by setting the roundTripTimeOut\n// variable or calling SetAcceptInSecureCert() method.\n//\n// If Accept"}
{"id": 1313, "code": "func (err CannotStopContainerError) IsRetriableError() bool {\n\tif _, ok := err.FromError.(NoSuchContainerError); ok {\n\t\treturn false\n\t}\n\n\treturn true\n}", "reference": "// IsRetriableError returns a boolean indicating whether the call that\n// generated the error can be retried.\n// When stopping a container, most errors that we can get should be\n// considered retriable. However, in the case where the container is\n// already stopped or doesn't exist at all, there's no sense in\n// retrying.", "generated": "// IsRetriableError returns whether this error is retrievable by calling Container.Stop(). If it's not possible to stop container then this method will return false.\n//\n// This can be used when we want to retry stopping container if initial attempt fails due to some reason like network issues or other external factors. However,"}
{"id": 1327, "code": "func (m *MockEC2MetadataClient) DefaultCredentials() (*ec2.RoleCredentials, error) {\n\tret := m.ctrl.Call(m, \"DefaultCredentials\")\n\tret0, _ := ret[0].(*ec2.RoleCredentials)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// DefaultCredentials mocks base method", "generated": "// DefaultCredentials returns default credentials for EC2 metadata service.\n//\n// This method is called by AWS SDKs to get default credentials from the client,\n// which can be used when no other credential provider has been set up or configured.\n//\n// The returned role credentials will have access to all resources in the account that"}
{"id": 1340, "code": "func (mr *MockClientSDKMockRecorder) DescribeTags(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"DescribeTags\", reflect.TypeOf((*MockClientSDK)(nil).DescribeTags), arg0)\n}", "reference": "// DescribeTags indicates an expected call of DescribeTags", "generated": "// DescribeTags is mock method for client SDK's DescribeTags. It takes one argument: tags. The returned call will be recorded if it matches the given signature. Description of this method is available at https://docs.aws.amazon.com/sdkforgo/latest/api Reference.html#DescribeTags. See also: https://godoc"}
{"id": 1352, "code": "func (agent *ecsAgent) setClusterInConfig(previousCluster string) error {\n\t// TODO Handle default cluster in a sane and unified way across the codebase\n\tconfiguredCluster := agent.cfg.Cluster\n\tif configuredCluster == \"\" {\n\t\tseelog.Debug(\"Setting cluster to default; none configured\")\n\t\tconfiguredCluster = config.DefaultClusterName\n\t}\n\tif previousCluster != configuredCluster {\n\t\terr := clusterMismatchError{\n\t\t\tfmt.Errorf(clusterMismatchErrorFormat, previousCluster, configuredCluster),\n\t\t}\n\t\tseelog.Criticalf(\"%v\", err)\n\t\treturn err\n\t}\n\tagent.cfg.Cluster = previousCluster\n\tseelog.Infof(\"Restored cluster '%s'\", agent.cfg.Cluster)\n\n\treturn nil\n}", "reference": "// setClusterInConfig sets the cluster name in the config object based on\n// previous state. It returns an error if there's a mismatch between the\n// the current cluster name with what's restored from the cluster state", "generated": "// Set cluster from configuration if it has changed since last run.\n//\n// This is used for backwards compatibility when running multiple times without restarting the container.\n// If no cluster was specified previously then we will use the first one that appears in the config file,\n// which should be the default cluster name.  We also log"}
{"id": 1377, "code": "func handleInvalidParamException(err error, events *list.List, eventToSubmit *list.Element) {\n\tif utils.IsAWSErrorCodeEqual(err, ecs.ErrCodeInvalidParameterException) {\n\t\tevent := eventToSubmit.Value.(*sendableEvent)\n\t\tseelog.Warnf(\"TaskHandler: Event is sent with invalid parameters; just removing: %s\", event.toString())\n\t\tevents.Remove(eventToSubmit)\n\t}\n}", "reference": "// handleInvalidParamException removes the event from event queue when its parameters are\n// invalid to reduce redundant API call", "generated": "// Handle Invalid Parameter Exception by logging it to stderr and\n// removing from list if necessary.\n//\n// This will be called when there's an exception in TaskHandler that indicates\n// some parameter was passed incorrectly (e.g., wrong number or type). It logs this\n// information at warn level so we can see"}
{"id": 1402, "code": "func NewJitteredTicker(ctx context.Context, start, end time.Duration) <-chan time.Time {\n\tticker := make(chan time.Time, 1)\n\n\tgo func() {\n\t\tdefer close(ticker)\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tdefault:\n\t\t\t\ttime.Sleep(randomDuration(start, end))\n\t\t\t\tsendNow(ticker)\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn ticker\n}", "reference": "// NewJitteredTicker works like a time.Ticker except with randomly distributed ticks\n// between start and end duration.", "generated": "// NewJitteredTicker returns a channel that sends time.Time values at random intervals between start and end.\n//\n// The interval is chosen randomly from the range [start, end). This means it's possible for the first value to be sent before the last one,\n// but never after the second-to-last one."}
{"id": 1411, "code": "func (m *MockECSClient) GetResourceTags(arg0 string) ([]*ecs.Tag, error) {\n\tret := m.ctrl.Call(m, \"GetResourceTags\", arg0)\n\tret0, _ := ret[0].([]*ecs.Tag)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// GetResourceTags mocks base method", "generated": "// GetResourceTags returns tags for resource specified by ARN. The returned list is sorted alphabetically. If no tags exist, it will return nil. This method can be used to get all tags associated with a specific AWS service or instance type. For example: GetResourceTags(\"arn:aws:ec2:"}
{"id": 1417, "code": "func (m *MockSaveableOption) AddSaveable(arg0 string, arg1 statemanager.Saveable) statemanager.Option {\n\tret := m.ctrl.Call(m, \"AddSaveable\", arg0, arg1)\n\tret0, _ := ret[0].(statemanager.Option)\n\treturn ret0\n}", "reference": "// AddSaveable mocks base method", "generated": "// AddSaveable adds saveable to options. This is used by state managers that want to be saved when they're closed.\n//\n// The argument should contain all fields required for saving this object. If it's nil,\n// then no fields will be added. It must also implement Saveable interface. Otherwise,\n//"}
{"id": 1440, "code": "func (state *DockerTaskEngineState) TaskByArn(arn string) (*apitask.Task, bool) {\n\tstate.lock.RLock()\n\tdefer state.lock.RUnlock()\n\n\treturn state.taskByArn(arn)\n}", "reference": "// TaskByArn returns a task for a given ARN", "generated": "// Returns task by ARN if exists in Docker engine's state.\n//\n// If no such task is found then returns nil along with false value\n// indicating that this task was never created or deleted from docker engine's state."}
{"id": 1448, "code": "func (state *DockerTaskEngineState) AddTaskIPAddress(addr string, taskARN string) {\n\tstate.lock.Lock()\n\tdefer state.lock.Unlock()\n\n\tstate.ipToTask[addr] = taskARN\n}", "reference": "// AddTaskIPAddress adds ip adddress for a task arn into the state", "generated": "// Adds IP address to Docker engine's internal map for later use when running tasks.\n//\n// This is used internally by docker-engine to keep track of which container was started from this machine,\n// so that it can be restarted if needed. It also allows us to run multiple containers at once without having\n// to restart"}
{"id": 1457, "code": "func (c *Container) GetKnownStatus() apicontainerstatus.ContainerStatus {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.KnownStatusUnsafe\n}", "reference": "// GetKnownStatus returns the known status of the container", "generated": "// GetKnownStatus returns known status for this container.\n//\n// This is used to determine if we can use cached information about the container's state,\n// or if it needs to be fetched from Docker.  If there was no previous call to SetKnownStatus(),\n// then return ContainerUnknownState.  Otherwise, return"}
{"id": 1458, "code": "func (c *Container) SetKnownStatus(status apicontainerstatus.ContainerStatus) {\n\tc.lock.Lock()\n\tdefer c.lock.Unlock()\n\n\tc.KnownStatusUnsafe = status\n\tc.updateAppliedStatusUnsafe(status)\n}", "reference": "// SetKnownStatus sets the known status of the container and update the container\n// applied status", "generated": "// SetKnownStatus sets known status for container.\n//\n// This is used to set the initial state when we first get this object from\n// the API server. It's also used in case of restarts or other events that\n// change the running status but don't affect the known status. The known\n//"}
{"id": 1466, "code": "func (c *Container) ShouldPullWithExecutionRole() bool {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.RegistryAuthentication != nil &&\n\t\tc.RegistryAuthentication.Type == AuthTypeECR &&\n\t\tc.RegistryAuthentication.ECRAuthData != nil &&\n\t\tc.RegistryAuthentication.ECRAuthData.UseExecutionRole\n}", "reference": "// ShouldPullWithExecutionRole returns whether this container has its own ECR credentials", "generated": "// ShouldPullWithExecutionRole returns true if this container should pull from ECR using execution role authentication.\n//\n// This is only used when running in AWS Lambda or other environments where EC2 Container Registry V2 is supported,\n// but we don't have access to the IAM credentials for pulling images directly. In such cases"}
{"id": 1497, "code": "func (c *Container) GetV3EndpointID() string {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.V3EndpointID\n}", "reference": "// GetV3EndpointID returns the v3 endpoint id of container", "generated": "// GetV3EndpointID returns the V3 endpoint ID for this container.\n//\n// This is used to identify the container in the Docker API v2.1 or later,\n// which allows us to get its logs using docker logs -f --container <id>.  The\n// returned value will be empty if"}
{"id": 1507, "code": "func (secret *ASMSecretResource) retrieveASMSecretValue(apiSecret apicontainer.Secret, iamCredentials credentials.IAMRoleCredentials, wg *sync.WaitGroup, errorEvents chan error) {\n\tdefer wg.Done()\n\n\tasmClient := secret.asmClientCreator.NewASMClient(apiSecret.Region, iamCredentials)\n\tseelog.Infof(\"ASM secret resource: retrieving resource for secret %v in region %s for task: [%s]\", apiSecret.ValueFrom, apiSecret.Region, secret.taskARN)\n\t//for asm secret, ValueFrom can be arn or name\n\tsecretValue, err := asm.GetSecretFromASM(apiSecret.ValueFrom, asmClient)\n\tif err != nil {\n\t\terrorEvents <- fmt.Errorf(\"fetching secret data from AWS Secrets Manager in region %s: %v\", apiSecret.Region, err)\n\t\treturn\n\t}\n\n\tsecret.lock.Lock()\n\tdefer secret.lock.Unlock()\n\n\t// put secret value in secretData\n\tsecretKey := apiSecret.GetSecretResourceCacheKey()\n\tsecret.secretData[secretKey] = secretValue\n}", "reference": "// retrieveASMSecretValue reads secret value from cache first, if not exists, call GetSecretFromASM to retrieve value\n// AWS secrets Manager", "generated": "//retrieveASMSecretValue retrieves the secret value from AWS Secrets Manager.\n//\n// This method is called by the main loop to fetch the secret values when they become available,\n// so that we don't have stale secrets stored locally. It also logs any errors encountered during this process. The\n// returned error will only"}
{"id": 1516, "code": "func handleInactivityTimeout(reader io.ReadCloser, timeout time.Duration, cancelRequest func(), canceled *uint32) (io.ReadCloser, chan<- struct{}) {\n\tdone := make(chan struct{})\n\tproxyReader := &proxyReader{ReadCloser: reader}\n\tgo func() {\n\t\tvar lastCallCount uint64\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-time.After(timeout):\n\t\t\tcase <-done:\n\t\t\t\treturn\n\t\t\t}\n\t\t\tcurCallCount := proxyReader.callCount()\n\t\t\tif curCallCount == lastCallCount {\n\t\t\t\tatomic.AddUint32(canceled, 1)\n\t\t\t\tcancelRequest()\n\t\t\t\treturn\n\t\t\t}\n\t\t\tlastCallCount = curCallCount\n\t\t}\n\t}()\n\treturn proxyReader, done\n}", "reference": "// When pulling an image, the docker api will pull and then subsequently unzip the downloaded artifacts. Docker does\n// not separate the \"pull\" from the \"unpack\" step. What this means is that this timeout doesn't 'tick' while unpacking\n// the downloaded files. This only causes noticeable impact with large files, but we should investigate improving this.", "generated": "// This is used to detect if there has been no activity in the connection for too long.\n// If this happens we will close the channel that was passed into it so that all goroutines can exit cleanly. The caller must ensure they have called cancelRequest before calling return. It also ensures that any other goroutine waiting"}
{"id": 1519, "code": "func (imageManager *dockerImageManager) RemoveContainerReferenceFromImageState(container *apicontainer.Container) error {\n\t// the image state has been updated, save the new state\n\tdefer imageManager.saver.ForceSave()\n\t// this lock is for reading image states and finding the one that the container belongs to\n\timageManager.updateLock.RLock()\n\tdefer imageManager.updateLock.RUnlock()\n\tif container.ImageID == \"\" {\n\t\treturn fmt.Errorf(\"Invalid container reference: Empty image id\")\n\t}\n\n\t// Find image state that this container is part of, and remove the reference\n\timageState, ok := imageManager.getImageState(container.ImageID)\n\tif !ok {\n\t\treturn fmt.Errorf(\"Cannot find image state for the container to be removed\")\n\t}\n\t// Found matching ImageState\n\treturn imageState.RemoveContainerReference(container)\n}", "reference": "// RemoveContainerReferenceFromImageState removes container reference from the corresponding imageState object", "generated": "// RemoveContainerReferenceFromImageState removes the given Container from its associated ImageState.\n//\n// This method should only be called when updating the Docker images in the manager's internal cache,\n// since it updates the image state directly. If there was no match found then an error will be returned.\n// The caller must ensure"}
{"id": 1540, "code": "func (td *TransitionDependenciesMap) UnmarshalJSON(b []byte) error {\n\tdepMap := make(map[apicontainerstatus.ContainerStatus]TransitionDependencySet)\n\terr := json.Unmarshal(b, &depMap)\n\tif err == nil {\n\t\t*td = depMap\n\t\treturn nil\n\t}\n\tseelog.Debugf(\"Unmarshal 'TransitionDependencySet': %s, not a map: %v\", string(b), err)\n\t// Unmarshal to deprecated 'TransitionDependencySet' and then convert to a map\n\ttdSet := TransitionDependencySet{}\n\tif err := json.Unmarshal(b, &tdSet); err != nil {\n\t\treturn errors.Wrapf(err,\n\t\t\t\"Unmarshal 'TransitionDependencySet': does not comply with any of the dependency types\")\n\t}\n\tfor _, dep := range tdSet.ContainerDependencies {\n\t\tdependentStatus := dep.DependentStatus\n\t\t// no need for DependentStatus field anymore, since it becomes the map's key\n\t\tdep.DependentStatus = 0\n\t\tif _, ok := depMap[dependentStatus]; !ok {\n\t\t\tdepMap[dependentStatus] = TransitionDependencySet{}\n\t\t}\n\t\tdeps := depMap[dependentStatus]\n\t\tdeps.ContainerDependencies = append(deps.ContainerDependencies, dep)\n\t\tdepMap[dependentStatus] = deps\n\t}\n\t*td = depMap\n\treturn nil\n}", "reference": "// UnmarshalJSON decodes the TransitionDependencySet tag in the JSON encoded string\n// into the TransitionDependenciesMap object", "generated": "// Unmarshals JSON data into TransitionDependenciesMap. The input is expected to be in one of two formats.\n//\n// First format: A simple map where each value is a TransitionDependencySet containing only ContainerDependencies that depend on a specific status.\n//\n// Second format: An array of TransitionDependencySets which can contain"}
{"id": 1543, "code": "func NewMockCgroup(ctrl *gomock.Controller) *MockCgroup {\n\tmock := &MockCgroup{ctrl: ctrl}\n\tmock.recorder = &MockCgroupMockRecorder{mock}\n\treturn mock\n}", "reference": "// NewMockCgroup creates a new mock instance", "generated": "// NewMockCgroup returns a MockCgroup object that can be used for testing.\n//\n// The returned MockCgroup is \"writable\" but any calls to it will be ignored by default.\n// Use SetOperations to make the mock writable if needed. If no operations have been set,\n// then calling c"}
{"id": 1579, "code": "func (m *MockSecretsManagerAPI) DeleteResourcePolicyWithContext(arg0 aws.Context, arg1 *secretsmanager.DeleteResourcePolicyInput, arg2 ...request.Option) (*secretsmanager.DeleteResourcePolicyOutput, error) {\n\tvarargs := []interface{}{arg0, arg1}\n\tfor _, a := range arg2 {\n\t\tvarargs = append(varargs, a)\n\t}\n\tret := m.ctrl.Call(m, \"DeleteResourcePolicyWithContext\", varargs...)\n\tret0, _ := ret[0].(*secretsmanager.DeleteResourcePolicyOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// DeleteResourcePolicyWithContext mocks base method", "generated": "// DeleteResourcePolicyWithContext is the same as DeleteResourcePolicy but takes context instead of options. It is an alias for DeleteResourcePolicyWithContextOptions. See also: DeleteResourcePolicyWithContextOptions. // Package secretsmanager imports this type from package context. // DeleteResourcePolicyWithContext is used to delete a resource policy. You"}
{"id": 1595, "code": "func (m *MockSecretsManagerAPI) ListSecretVersionIds(arg0 *secretsmanager.ListSecretVersionIdsInput) (*secretsmanager.ListSecretVersionIdsOutput, error) {\n\tret := m.ctrl.Call(m, \"ListSecretVersionIds\", arg0)\n\tret0, _ := ret[0].(*secretsmanager.ListSecretVersionIdsOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// ListSecretVersionIds mocks base method", "generated": "// ListSecretVersionIds is a mock for secretsmanager.ListSecretVersionIds method call. It takes one argument: input. The returned value will be nil if there was no actual method call made. Otherwise it returns the first element of the slice passed to ctrl.Call. If an error occurred during the method call, it"}
{"id": 1612, "code": "func (m *MockSecretsManagerAPI) RotateSecret(arg0 *secretsmanager.RotateSecretInput) (*secretsmanager.RotateSecretOutput, error) {\n\tret := m.ctrl.Call(m, \"RotateSecret\", arg0)\n\tret0, _ := ret[0].(*secretsmanager.RotateSecretOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// RotateSecret mocks base method", "generated": "// RotateSecret is called by SecretsManager to rotate secrets in a secret store.\n//\n// The input should be a single argument: a RotateSecretInput object that contains all necessary information about which secrets need rotating,\n// including their names, current expiration dates, and desired rotation periods. This method returns a RotateSecretOutput object"}
{"id": 1616, "code": "func (m *MockSecretsManagerAPI) TagResourceRequest(arg0 *secretsmanager.TagResourceInput) (*request.Request, *secretsmanager.TagResourceOutput) {\n\tret := m.ctrl.Call(m, \"TagResourceRequest\", arg0)\n\tret0, _ := ret[0].(*request.Request)\n\tret1, _ := ret[1].(*secretsmanager.TagResourceOutput)\n\treturn ret0, ret1\n}", "reference": "// TagResourceRequest mocks base method", "generated": "// MockSecretsManagerAPI's TagResourceRequest method is a mock for secretsmanager.TagResourceRequest.\n//\n// This method takes one argument: arg0 - The input to be passed to secretsmanager.TagResourceRequest.\n//\n// It returns two values: 1st value is request.Request returned from secretsmanager.TagResource"}
{"id": 1628, "code": "func (manager *metadataManager) parseMetadataAtContainerCreate(task *apitask.Task, containerName string) Metadata {\n\treturn Metadata{\n\t\tcluster: manager.cluster,\n\t\ttaskMetadata: TaskMetadata{\n\t\t\tcontainerName:          containerName,\n\t\t\ttaskARN:                task.Arn,\n\t\t\ttaskDefinitionFamily:   task.Family,\n\t\t\ttaskDefinitionRevision: task.Version,\n\t\t},\n\t\tcontainerInstanceARN:  manager.containerInstanceARN,\n\t\tmetadataStatus:        MetadataInitial,\n\t\tavailabilityZone:      manager.availabilityZone,\n\t\thostPublicIPv4Address: manager.hostPublicIPv4Address,\n\t}\n}", "reference": "// parseMetadataAtContainerCreate gathers metadata from task and cluster configurations\n// then packages it for JSON Marshaling. We use this version to get data\n// available prior to container creation\n// Since we accept incomplete metadata fields, we should not return\n// errors here and handle them at this or the above stage.", "generated": "// parseMetadataAtContainerCreate returns metadata for the specified\n// container at creation time. The returned metadata is used to populate\n// the Container instance in the cluster's state machine. This method\n// should be called only once per container during its lifetime.\n//\n// If this method fails due to lack of permissions or"}
{"id": 1649, "code": "func (m *MockTaskResource) Cleanup() error {\n\tret := m.ctrl.Call(m, \"Cleanup\")\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// Cleanup mocks base method", "generated": "// Cleanup is called when the task resource has been removed from the cluster.\n//\n// This method should be used to clean up any resources that were created by this\n// TaskResource object. It will only be called if the task was successfully\n// added to the cluster. If it fails then no cleanup will occur."}
{"id": 1669, "code": "func (f *factory) GetClient(version dockerclient.DockerVersion) (sdkclient.Client, error) {\n\tfor _, v := range getWindowsReplaceableVersions() {\n\t\tif v == version {\n\t\t\tversion = minDockerAPIVersion\n\t\t\tbreak\n\t\t}\n\t}\n\treturn f.getClient(version)\n}", "reference": "// GetClient will replace some versions of Docker on Windows. We need this because\n// agent assumes that it can always call older versions of the docker API.", "generated": "// GetClient returns a client for Docker API V1 or later.\n//\n// If no suitable version is found in the list of replaceable versions,\n// it will return a client using the minimum supported version. This can be useful if\n// there's only one available version that works across all platforms. The caller must"}
{"id": 1739, "code": "func (task *Task) GetExecutionCredentialsID() string {\n\ttask.lock.RLock()\n\tdefer task.lock.RUnlock()\n\n\treturn task.ExecutionCredentialsID\n}", "reference": "// GetExecutionCredentialsID gets the credentials ID for the task", "generated": "// GetExecutionCredentialsID returns ExecutionCredentials ID for this Task.\n//\n// This is used to identify execution credentials that were created by this task,\n// such as AWS IAM roles or Azure service principal identities. The returned value\n// should be unique across all tasks in the same cluster. If no execution\n// credentials have"}
{"id": 1757, "code": "func (task *Task) RecordExecutionStoppedAt(container *apicontainer.Container) {\n\tif !container.Essential {\n\t\treturn\n\t}\n\tif container.GetKnownStatus() != apicontainerstatus.ContainerStopped {\n\t\treturn\n\t}\n\t// If the essential container is stopped, set the ExecutionStoppedAt timestamp\n\tnow := time.Now()\n\tok := task.SetExecutionStoppedAt(now)\n\tif !ok {\n\t\t// ExecutionStoppedAt was already recorded. Nothing to left to do here\n\t\treturn\n\t}\n\tseelog.Infof(\"Task [%s]: recording execution stopped time. Essential container [%s] stopped at: %s\",\n\t\ttask.Arn, container.Name, now.String())\n}", "reference": "// RecordExecutionStoppedAt checks if this is an essential container stopped\n// and set the task executionStoppedAt timestamps", "generated": "// RecordExecutionStoppedAt records that this task's execution has been stopped.\n//\n// This method will only be called if the task's execution status is ContainerStopped,\n// which means we know it has actually finished running. It also requires the container\n// to have its \"essential\" flag enabled in order for us to"}
{"id": 1767, "code": "func (task *Task) getPIDMode() string {\n\ttask.lock.RLock()\n\tdefer task.lock.RUnlock()\n\n\treturn task.PIDMode\n}", "reference": "// Retrieves a Task's PIDMode", "generated": "// getPIDMode returns PID mode for this task. If it is set to 0 then no special handling will be done when running tasks in parallel.\n//\n// Note: This method should only be called from within the Task object's lock scope. It may cause deadlock if accessed concurrently by multiple goroutines. The caller"}
{"id": 1793, "code": "func (healthStatus *ContainerHealthStatus) UnmarshalJSON(b []byte) error {\n\t*healthStatus = ContainerHealthUnknown\n\n\tif strings.ToLower(string(b)) == \"null\" {\n\t\treturn nil\n\t}\n\tif b[0] != '\"' || b[len(b)-1] != '\"' {\n\t\treturn errors.New(\"container health status unmarshal: status must be a string or null; Got \" + string(b))\n\t}\n\n\tstrStatus := string(b[1 : len(b)-1])\n\tswitch strStatus {\n\tcase \"UNKNOWN\":\n\t// The health status is already set to ContainerHealthUnknown initially\n\tcase \"HEALTHY\":\n\t\t*healthStatus = ContainerHealthy\n\tcase \"UNHEALTHY\":\n\t\t*healthStatus = ContainerUnhealthy\n\tdefault:\n\t\treturn errors.New(\"container health status unmarshal: unrecognized status: \" + string(b))\n\t}\n\treturn nil\n}", "reference": "// UnmarshalJSON overrides the logic for parsing the JSON-encoded container health data", "generated": "// Unmarshals JSON data into container health status. If it's null then returns ContainerHealthUnknown.\n//\n// This method should only be used when deserializing from json. It will return ContainerHealthUnknown if the value was null in the original json,\n// otherwise it sets the field based on the provided string."}
{"id": 1797, "code": "func (m *MockDockerClient) APIVersion() (dockerclient.DockerVersion, error) {\n\tret := m.ctrl.Call(m, \"APIVersion\")\n\tret0, _ := ret[0].(dockerclient.DockerVersion)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// APIVersion mocks base method", "generated": "// Mock returns mock values for this method call. This is useful when testing Docker client methods that don't need to be called in order to test their side effects. The returned values will always match the provided arguments but may differ from actual results depending on how the method behaves. By default, it returns nil for both return"}
{"id": 1807, "code": "func (m *MockDockerClient) ListContainers(arg0 context.Context, arg1 bool, arg2 time.Duration) dockerapi.ListContainersResponse {\n\tret := m.ctrl.Call(m, \"ListContainers\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(dockerapi.ListContainersResponse)\n\treturn ret0\n}", "reference": "// ListContainers mocks base method", "generated": "// ListContainers is a mock for Docker's list containers method. It returns a fake result from the controller. The first argument must be a context object that will be passed to the real method if it were called. If this call was made by a test, then the second argument should be true; otherwise, false."}
{"id": 1823, "code": "func (mtask *managedTask) waitForHostResources() {\n\tif mtask.StartSequenceNumber == 0 {\n\t\t// This is the first transition on this host. No need to wait\n\t\treturn\n\t}\n\tif mtask.GetDesiredStatus().Terminal() {\n\t\t// Task's desired status is STOPPED. No need to wait in this case either\n\t\treturn\n\t}\n\n\tseelog.Infof(\"Managed task [%s]: waiting for any previous stops to complete. Sequence number: %d\",\n\t\tmtask.Arn, mtask.StartSequenceNumber)\n\n\tothersStoppedCtx, cancel := context.WithCancel(mtask.ctx)\n\tdefer cancel()\n\n\tgo func() {\n\t\tmtask.taskStopWG.Wait(mtask.StartSequenceNumber)\n\t\tcancel()\n\t}()\n\n\tfor !mtask.waitEvent(othersStoppedCtx.Done()) {\n\t\tif mtask.GetDesiredStatus().Terminal() {\n\t\t\t// If we end up here, that means we received a start then stop for this\n\t\t\t// task before a task that was expected to stop before it could\n\t\t\t// actually stop\n\t\t\tbreak\n\t\t}\n\t}\n\tseelog.Infof(\"Managed task [%s]: wait over; ready to move towards status: %s\",\n\t\tmtask.Arn, mtask.GetDesiredStatus().String())\n}", "reference": "// waitForHostResources waits for host resources to become available to start\n// the task. This involves waiting for previous stops to complete so the\n// resources become free.", "generated": "// waitForHostResources waits until all other tasks have stopped or completed their transitions.\n// It will block indefinitely if there are no other managed tasks running at the same time,\n// but otherwise should return quickly once they've finished transitioning out of STARTING."}
{"id": 1857, "code": "func (m *MockWebsocketConn) ReadMessage() (int, []byte, error) {\n\tret := m.ctrl.Call(m, \"ReadMessage\")\n\tret0, _ := ret[0].(int)\n\tret1, _ := ret[1].([]byte)\n\tret2, _ := ret[2].(error)\n\treturn ret0, ret1, ret2\n}", "reference": "// ReadMessage mocks base method", "generated": "// MockWebsocketConn.ReadMessage returns mock value for ReadMessage method. The original method is called by calling this function. This can be used to test that ReadMessage behaves correctly when it's called in isolation from other methods. It should only be used during unit testing. If you're using this outside of a test"}
{"id": 1890, "code": "func (engine *DockerTaskEngine) isTaskManaged(arn string) bool {\n\tengine.tasksLock.RLock()\n\tdefer engine.tasksLock.RUnlock()\n\t_, ok := engine.managedTasks[arn]\n\treturn ok\n}", "reference": "// isTaskManaged checks if task for the corresponding arn is present", "generated": "// isTaskManaged checks if task arn has been managed by this Docker Task Engine.\n//\n// This method should be called only once per call to avoid race conditions when multiple goroutines access tasks concurrently. It's recommended that it's used in conjunction with a lock or mutex for concurrent access protection. The caller must ensure"}
{"id": 1896, "code": "func (engine *DockerTaskEngine) sweepTask(task *apitask.Task) {\n\tfor _, cont := range task.Containers {\n\t\terr := engine.removeContainer(task, cont)\n\t\tif err != nil {\n\t\t\tseelog.Debugf(\"Task engine [%s]: unable to remove old container [%s]: %v\",\n\t\t\t\ttask.Arn, cont.Name, err)\n\t\t}\n\t\t// Internal container(created by ecs-agent) state isn't recorded\n\t\tif cont.IsInternal() {\n\t\t\tcontinue\n\t\t}\n\t\terr = engine.imageManager.RemoveContainerReferenceFromImageState(cont)\n\t\tif err != nil {\n\t\t\tseelog.Errorf(\"Task engine [%s]: Unable to remove container [%s] reference from image state: %v\",\n\t\t\t\ttask.Arn, cont.Name, err)\n\t\t}\n\t}\n\n\t// Clean metadata directory for task\n\tif engine.cfg.ContainerMetadataEnabled {\n\t\terr := engine.metadataManager.Clean(task.Arn)\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Task engine [%s]: clean task metadata failed: %v\", task.Arn, err)\n\t\t}\n\t}\n\tengine.saver.Save()\n}", "reference": "// sweepTask deletes all the containers associated with a task", "generated": "// Sweep task removes all containers that were created before this one.\n// It also cleans up any references in the image states. This is necessary because\n// when we create new tasks, they will have different names than previous ones,\n// but their images may still be referenced under those older names. If these\n// references"}
{"id": 1906, "code": "func (engine *DockerTaskEngine) updateTaskUnsafe(task *apitask.Task, update *apitask.Task) {\n\tmanagedTask, ok := engine.managedTasks[task.Arn]\n\tif !ok {\n\t\tseelog.Criticalf(\"Task engine [%s]: ACS message for a task we thought we managed, but don't!  Aborting.\",\n\t\t\ttask.Arn)\n\t\treturn\n\t}\n\t// Keep the lock because sequence numbers cannot be correct unless they are\n\t// also read in the order addtask was called\n\t// This does block the engine's ability to ingest any new events (including\n\t// stops for past tasks, ack!), but this is necessary for correctness\n\tupdateDesiredStatus := update.GetDesiredStatus()\n\tseelog.Debugf(\"Task engine [%s]: putting update on the acs channel: [%s] with seqnum [%d]\",\n\t\ttask.Arn, updateDesiredStatus.String(), update.StopSequenceNumber)\n\tmanagedTask.emitACSTransition(acsTransition{\n\t\tdesiredStatus: updateDesiredStatus,\n\t\tseqnum:        update.StopSequenceNumber,\n\t})\n\tseelog.Debugf(\"Task engine [%s]: update taken off the acs channel: [%s] with seqnum [%d]\",\n\t\ttask.Arn, updateDesiredStatus.String(), update.StopSequenceNumber)\n}", "reference": "// updateTaskUnsafe determines if a new transition needs to be applied to the\n// referenced task, and if needed applies it. It should not be called anywhere\n// but from 'AddTask' and is protected by the tasksLock lock there.", "generated": "// Update a running task by sending it back to the ACSCore.\n//\n// The caller must hold the lock so that no other goroutines can modify the\n// state while we're updating the task. If there were multiple concurrent updates\n// then the desired status would never match up correctly. We will always send"}
{"id": 1918, "code": "func (m *MockFileSystem) Copy(arg0 io.Writer, arg1 io.Reader) (int64, error) {\n\tret := m.ctrl.Call(m, \"Copy\", arg0, arg1)\n\tret0, _ := ret[0].(int64)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// Copy mocks base method", "generated": "// Copy copies data from one file to another. The destination is opened in append mode.\n//\n// If there's no existing file at the source location then it will be created,\n// otherwise its contents will be overwritten. This method returns the number of bytes written or -1 if an I/O error occurred. It also"}
{"id": 1919, "code": "func (m *MockFileSystem) Exit(arg0 int) {\n\tm.ctrl.Call(m, \"Exit\", arg0)\n}", "reference": "// Exit mocks base method", "generated": "// Exit is called when the process exits. The exit code will be passed to\n// the main goroutine's runtime.Exit() call. This allows for additional\n// cleanup before exiting. If this method returns early, it may cause\n// unexpected behavior in the program. It should only be used by tests.\n//"}
{"id": 1920, "code": "func (m *MockFileSystem) MkdirAll(arg0 string, arg1 os.FileMode) error {\n\tret := m.ctrl.Call(m, \"MkdirAll\", arg0, arg1)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// MkdirAll mocks base method", "generated": "// MkdirAll is the mock method for MkdirAll. It takes two arguments: \n//\n//  - arg0: The path to create.\n//  - arg1: The mode in which to create it.\n//\n// If there's no actual method call made then this will return nil. Otherwise,\n//"}
{"id": 1937, "code": "func (m *MockTaskEngineState) AllTasks() []*task.Task {\n\tret := m.ctrl.Call(m, \"AllTasks\")\n\tret0, _ := ret[0].([]*task.Task)\n\treturn ret0\n}", "reference": "// AllTasks mocks base method", "generated": "// AllTasks returns all tasks in this engine state. This is used by the task manager to get a list of all running or pending tasks for any given engine state. The returned slice contains pointers to the actual Task objects so that they can be safely passed around without copying them. If there are no tasks then nil will"}
{"id": 1948, "code": "func (containerType ContainerType) String() string {\n\tfor str, contType := range stringToContainerType {\n\t\tif contType == containerType {\n\t\t\treturn str\n\t\t}\n\t}\n\n\treturn \"NORMAL\"\n}", "reference": "// String converts the container type enum to a string", "generated": "// String returns the name of this type in human readable format.\n//\n// This is used for logging purposes to make it easier to understand which\n// container type was requested by the user. For example: 'normal', 'docker',\n// etc... The actual value returned will be one of these strings or NORMAL if"}
{"id": 1959, "code": "func (f *factory) GetClient(version dockerclient.DockerVersion) (sdkclient.Client, error) {\n\treturn f.getClient(version)\n}", "reference": "// GetClient on linux will simply return the cached client from the map", "generated": "// GetClient returns a client for the given Docker version.\n//\n// This is used to create clients that support different versions\n// of Docker. The returned client will be configured according to\n// the provided Docker version. If there's no matching client,\n// it will return nil along with an appropriate error message."}
{"id": 2002, "code": "func (engine *DockerStatsEngine) removeContainer(dockerID string) {\n\tengine.lock.Lock()\n\tdefer engine.lock.Unlock()\n\n\t// Make sure that this container belongs to a task.\n\ttask, err := engine.resolver.ResolveTask(dockerID)\n\tif err != nil {\n\t\tseelog.Debugf(\"Could not map container to task, ignoring, err: %v, id: %s\", err, dockerID)\n\t\treturn\n\t}\n\n\t_, taskExists := engine.tasksToContainers[task.Arn]\n\tif !taskExists {\n\t\tseelog.Debugf(\"Container not being watched, id: %s\", dockerID)\n\t\treturn\n\t}\n\n\t// task arn exists in map.\n\tcontainer, containerExists := engine.tasksToContainers[task.Arn][dockerID]\n\tif !containerExists {\n\t\t// container arn does not exist in map.\n\t\tseelog.Debugf(\"Container not being watched, id: %s\", dockerID)\n\t\treturn\n\t}\n\n\tengine.doRemoveContainerUnsafe(container, task.Arn)\n}", "reference": "// removeContainer deletes the container from the map of containers being watched.\n// It also stops the periodic usage data collection for the container.", "generated": "// Remove a Docker stats container from the list of containers we're watching. This is called when a container goes away or if it's no longer part of any running tasks. The container will be removed from our internal state but may still have some pending operations left over. If there were any pending operations for this container,"}
{"id": 2004, "code": "func (engine *DockerStatsEngine) taskContainerMetricsUnsafe(taskArn string) ([]*ecstcs.ContainerMetric, error) {\n\tcontainerMap, taskExists := engine.tasksToContainers[taskArn]\n\tif !taskExists {\n\t\treturn nil, fmt.Errorf(\"Task not found\")\n\t}\n\n\tvar containerMetrics []*ecstcs.ContainerMetric\n\tfor _, container := range containerMap {\n\t\tdockerID := container.containerMetadata.DockerID\n\t\t// Check if the container is terminal. If it is, make sure that it is\n\t\t// cleaned up properly. We might sometimes miss events from docker task\n\t\t// engine and this helps in reconciling the state. The tcs client's\n\t\t// GetInstanceMetrics probe is used as the trigger for this.\n\t\tif engine.stopTrackingContainerUnsafe(container, taskArn) {\n\t\t\tcontinue\n\t\t}\n\n\t\tif !container.statsQueue.enoughDatapointsInBuffer() &&\n\t\t\t!container.statsQueue.resetThresholdElapsed(queueResetThreshold) {\n\t\t\tseelog.Debugf(\"Stats not ready for container %s\", dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Container is not terminal. Get CPU stats set.\n\t\tcpuStatsSet, err := container.statsQueue.GetCPUStatsSet()\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Error getting cpu stats, err: %v, container: %v\", err, dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Get memory stats set.\n\t\tmemoryStatsSet, err := container.statsQueue.GetMemoryStatsSet()\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Error getting memory stats, err: %v, container: %v\", err, dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\tcontainerMetrics = append(containerMetrics, &ecstcs.ContainerMetric{\n\t\t\tCpuStatsSet:    cpuStatsSet,\n\t\t\tMemoryStatsSet: memoryStatsSet,\n\t\t})\n\n\t}\n\n\treturn containerMetrics, nil\n}", "reference": "// taskContainerMetricsUnsafe gets all container metrics for a task arn.", "generated": "// taskContainerMetricsUnsafe returns metrics for all containers running under\n// the given task ARN. This method should be called only when we have enough\n// data to ensure accuracy. It will return empty list or errors if there isn't\n// any data available yet. Note that this call may block indefinitely until"}
{"id": 2025, "code": "func NewNamedError(err error) *DefaultNamedError {\n\tif namedErr, ok := err.(NamedError); ok {\n\t\treturn &DefaultNamedError{Err: namedErr.Error(), Name: namedErr.ErrorName()}\n\t}\n\treturn &DefaultNamedError{Err: err.Error()}\n}", "reference": "// NewNamedError creates a NamedError.", "generated": "// NewNamedError returns a new DefaultNamedError if possible.\n//\n// If it is already a NamedError then return that one otherwise\n// create a default one. This will be useful for errors returned by\n// functions like http.Get() or net.Dial(). The name field can also be used to\n// provide"}
{"id": 2037, "code": "func (r *eventLogReceiver) ReceiveMessage(message string, level seelog.LogLevel, context seelog.LogContextInterface) error {\n\tswitch level {\n\tcase seelog.DebugLvl, seelog.InfoLvl:\n\t\treturn eventLog.Info(eventLogID, message)\n\tcase seelog.WarnLvl:\n\t\treturn eventLog.Warning(eventLogID, message)\n\tcase seelog.ErrorLvl, seelog.CriticalLvl:\n\t\treturn eventLog.Error(eventLogID, message)\n\t}\n\treturn nil\n}", "reference": "// ReceiveMessage receives a log line from seelog and emits it to the Windows event log", "generated": "// ReceiveMessage is called when we receive a log entry from the eventlog.\n//\n// It will be used to send that log entry into our own logging system,\n// which can then forward it onto other systems if needed.  If there's no\n// need for this, just return nil.  Otherwise, call"}
{"id": 2051, "code": "func (m *MockIOUtil) WriteFile(arg0 string, arg1 []byte, arg2 os.FileMode) error {\n\tret := m.ctrl.Call(m, \"WriteFile\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// WriteFile mocks base method", "generated": "// MockWriteFile is a mock for IOUtil's WriteFile method. It returns nil if no arguments were passed to it. Otherwise, it calls the real WriteFile method. The returned value will be non-nil only when there was at least one argument passed in. If this happens, then the first element of the"}
{"id": 2052, "code": "func (mr *MockIOUtilMockRecorder) WriteFile(arg0, arg1, arg2 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"WriteFile\", reflect.TypeOf((*MockIOUtil)(nil).WriteFile), arg0, arg1, arg2)\n}", "reference": "// WriteFile indicates an expected call of WriteFile", "generated": "// WriteFile mock method record call. This is a generated, empty method that must be filled in by a MockIOUtil instance. It will automatically receive any arguments passed to it when its underlying IOUtil.WriteFile() method is called. The returned Call object can then be used to verify that WriteFile was actually called"}
{"id": 2060, "code": "func NewVolumesResponse(dockerContainer *apicontainer.DockerContainer) []VolumeResponse {\n\tcontainer := dockerContainer.Container\n\tvar resp []VolumeResponse\n\n\tvolumes := container.GetVolumes()\n\n\tfor _, volume := range volumes {\n\t\tvolResp := VolumeResponse{\n\t\t\tDockerName:  volume.Name,\n\t\t\tSource:      volume.Source,\n\t\t\tDestination: volume.Destination,\n\t\t}\n\n\t\tresp = append(resp, volResp)\n\t}\n\treturn resp\n}", "reference": "// NewVolumesResponse creates VolumeResponse for a container", "generated": "// NewVolumesResponse returns a list of Docker Volumes for this Container.\n//\n// This is used to populate the \"volumes\" field in the API response when\n// retrieving information about a running container. The returned slice will be empty if no volumes were specified during creation or mounting. If there was only one volume"}
{"id": 2062, "code": "func NewPublishMetricsRequest(metadata *MetricsMetadata, taskMetrics []*TaskMetric) *PublishMetricsRequest {\n\treturn &PublishMetricsRequest{\n\t\tMetadata:    metadata,\n\t\tTaskMetrics: taskMetrics,\n\t\tTimestamp:   aws.Time(time.Now()),\n\t}\n}", "reference": "// NewPublishMetricsRequest creates a PublishMetricsRequest object.", "generated": "// NewPublishMetricsRequest creates new PublishMetricsRequest instance.\n//\n// It takes in MetricsMetadata and TaskMetrics to be published along\n// with current timestamp. The returned request is ready for sending\n// via AWS API Gateway. If there's any error during creation process it will panic."}
{"id": 2092, "code": "func (m *MockCNI) AddNetworkList(arg0 *libcni.NetworkConfigList, arg1 *libcni.RuntimeConf) (types.Result, error) {\n\tret := m.ctrl.Call(m, \"AddNetworkList\", arg0, arg1)\n\tret0, _ := ret[0].(types.Result)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// AddNetworkList mocks base method", "generated": "// AddNetworkList is the mock method for cni.AddNetworkList. It takes two arguments: NetworkConfigList and RuntimeConf. The return value is Result and error respectively. This method can be used to create a mock object that satisfies this method call. When the mock object is created, it will automatically track calls"}
{"id": 2094, "code": "func (mr *MockCNIMockRecorder) DelNetwork(arg0, arg1 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"DelNetwork\", reflect.TypeOf((*MockCNI)(nil).DelNetwork), arg0, arg1)\n}", "reference": "// DelNetwork indicates an expected call of DelNetwork", "generated": "// DelNetwork records call to MockCNI.DelNetwork. Args: 0 = networkId, 1 = cniConfig\n//\n// Usage:\n//  m.CNIDeleteNetwork(\"network-id\", &cni.Config{...}) // returns mock result\n//  m.CNIDe"}
{"id": 2114, "code": "func (v *StackSwitcher) native() *C.GtkStackSwitcher {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkStackSwitcher(p)\n}", "reference": "// native returns a pointer to the underlying GtkStackSwitcher.", "generated": "// native returns the underlying native object for this StackSwitcher.\n//\n// This is useful when working directly with GTK+ code or other external libraries that expect a pointer to a\n// GtkStackSwitcher. The returned value will be NULL if this StackSwitcher was created from a Glib object,\n// which means"}
{"id": 2116, "code": "func (v *ComboBoxText) native() *C.GtkComboBoxText {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkComboBoxText(p)\n}", "reference": "// native returns a pointer to the underlying GtkComboBoxText.", "generated": "// native returns the underlying native widget for this ComboBoxText.\n//\n// This is useful when working directly with GTK code or using libgtk3's API,\n// but it should generally be avoided in favor of using the provided methods to interact with the widget."}
{"id": 2124, "code": "func (v *Variant) GetString() string {\n\tvar len C.gsize\n\tgc := C.g_variant_get_string(v.native(), &len)\n\tdefer C.g_free(C.gpointer(gc))\n\treturn C.GoStringN((*C.char)(gc), (C.int)(len))\n}", "reference": "// GetString returns the string value of the variant.", "generated": "// Get returns the value of this variant as a string.\n//\n// The returned string is owned by Go and will be freed when it goes out of scope,\n// unless you store it in a pointer to avoid garbage collection.  If you need to\n// keep the string around for longer than that, use g_variant"}
{"id": 2143, "code": "func (v *StyleContext) native() *C.GtkStyleContext {\n\tif v == nil || v.Object == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkStyleContext(p)\n}", "reference": "// native returns a pointer to the underlying GtkStyleContext.", "generated": "// native returns the underlying style context for this object.\n//\n// This is only valid if the object has been successfully created using\n// StyleContextNew(). If it was created by another method then this will be\n// NULL. The returned pointer must never go out of scope unless you also set\n// the object to"}
{"id": 2148, "code": "func (m *Matrix) InitRotate(radians float64) {\n\tC.cairo_matrix_init_rotate(m.native(), C.double(radians))\n}", "reference": "// InitRotate initializes a matrix with the given rotation", "generated": "// InitRotate sets up matrix for rotation by radians degrees.\n//\n// This is used to rotate points in 2D space around origin point\n// without changing their position relative to each other. It's also useful when drawing shapes,\n// like circles or ellipses, where we want them to be centered at some"}
{"id": 2165, "code": "func NewSurface(s uintptr, needsRef bool) *Surface {\n\tsurface := WrapSurface(s)\n\tif needsRef {\n\t\tsurface.reference()\n\t}\n\truntime.SetFinalizer(surface, (*Surface).destroy)\n\treturn surface\n}", "reference": "// NewSurface creates a gotk3 cairo Surface from a pointer to a\n// C cairo_surface_t.  This is primarily designed for use with other\n// gotk3 packages and should be avoided by applications.", "generated": "// NewSurface creates a new Surface object from a given pointer to a\n// native surface. If needsRef is true then it will also set up finalizers for\n// this surface so that they can be garbage collected when no longer needed.\n//\n// Note: This should only ever be called by the C code in"}
{"id": 2167, "code": "func AddFont(fontPath string) {\n\tpath := (*C.uchar)(unsafe.Pointer(C.CString(fontPath)))\n\tC.addFont(path)\n}", "reference": "// AddFont adds the font to the configuration.", "generated": "// AddFont adds font to current context.\n//\n// This is used by Cgo interface for adding fonts in C code. It's\n// called from c_add_font() function which takes path argument.\n// The path should be null terminated string (i.e., it must end with '\\0').\n// If this method"}
{"id": 2168, "code": "func (v *Label) native() *C.GtkLabel {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkLabel(p)\n}", "reference": "// native returns a pointer to the underlying GtkLabel.", "generated": "// native returns the underlying label object for this Label instance.\n//\n// This is useful when working directly with GTK code or using libgtk3's API,\n// but it should generally be avoided in favor of accessing properties via the\n// Label interface. The returned pointer will become invalid if the Label is\n// garbage collected"}
{"id": 2182, "code": "func (v *ActionGroup) ChangeActionState(actionName string, value *Variant) {\n\tC.g_action_group_change_action_state(v.native(), (*C.gchar)(C.CString(actionName)), value.native())\n}", "reference": "// ChangeActionState is a wrapper around g_action_group_change_action_state", "generated": "// Change action state for given group name.\n//\n// This is used to change the state of actions in groups. The new\n// variant will be applied when this method is called again. If it's already set,\n// then nothing happens. It can also be used to reset all variants by passing nil.\n// Note"}
{"id": 2186, "code": "func (v *GLArea) native() *C.GtkGLArea {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkGLArea(p)\n}", "reference": "// native returns a pointer to the underlying GtkGLArea.", "generated": "// native returns the underlying GL area object for this widget. This is used internally by GTK+ to communicate between the two worlds.\n//\n// Note that if this method fails it will return nil. You should always check its result before using it. If you need more information about why it failed,\n// use gtk_widget_get"}
{"id": 2188, "code": "func (v *TreeView) SetSearchEqualSubstringMatch() {\n\tC.gtk_tree_view_set_search_equal_func(\n\t\tv.native(),\n\t\t(C.GtkTreeViewSearchEqualFunc)(unsafe.Pointer(C.substring_match_equal_func)),\n\t\tnil,\n\t\tnil)\n}", "reference": "// SetSearchEqualSubstringMatch sets TreeView to search by substring match.", "generated": "// SetSearchEqualSubstringMatch sets the search equal substring match\n// for this tree view to use when searching in the text column.\n//\n// This is used by the \"equal\" search mode.  The default value is nil which means that no special handling will be done.  If you want to do something different"}
{"id": 2202, "code": "func (v *ShortcutsShortcut) native() *C.GtkShortcutsShortcut {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkShortcutsShortcut(p)\n}", "reference": "// native returns a pointer to the underlying GtkShortcutsShortcut.", "generated": "// native returns the underlying native object for this shortcut.\n//\n// This is useful when working directly with GTK+ code or other external libraries that expect a pointer to a\n// GtkShortcutsShortcut instead of a Shortcut. Note that this method will return nil if the Shortcut has been\n// garbage collected since it was created"}
{"id": 2203, "code": "func SimpleActionGroupNew() *SimpleActionGroup {\n\tc := C.g_simple_action_group_new()\n\tif c == nil {\n\t\treturn nil\n\t}\n\treturn wrapSimpleActionGroup(wrapObject(unsafe.Pointer(c)))\n}", "reference": "// SimpleActionGroupNew is a wrapper around g_simple_action_group_new", "generated": "// New returns a new instance of SimpleActionGroup. The returned object must be freed by the caller using g_object_unref(). If this is NULL then no action group was created. This can happen if there were errors during initialization or when trying to create an empty action group. In that case it's safe to call g"}
{"id": 2208, "code": "func (v *Action) GetParameterType() *VariantType {\n\tc := C.g_action_get_parameter_type(v.native())\n\tif c == nil {\n\t\treturn nil\n\t}\n\treturn newVariantType((*C.GVariantType)(c))\n}", "reference": "// GetParameterType is a wrapper around g_action_get_parameter_type", "generated": "// GetParameterType returns the type of parameter associated with this action.\n//\n// This is used to determine whether or not we need to use a specific variant for\n// the parameter when calling g_variant_new().  If it's unknown, then we can't do anything,\n// so just return NULL.  We don"}
{"id": 2218, "code": "func (v *Bin) native() *C.GtkBin {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkBin(p)\n}", "reference": "// native returns a pointer to the underlying GtkBin.", "generated": "// native returns the underlying native object for this Bin. If it is already set,\n// then that value will be returned; otherwise, NULL will be returned.\n//\n// This method should only be called from within the GTK+ main loop. It's not safe to call\n// this outside of the main loop because it"}
{"id": 2221, "code": "func (v *CellRendererSpinner) native() *C.GtkCellRendererSpinner {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkCellRendererSpinner(p)\n}", "reference": "// native returns a pointer to the underlying GtkCellRendererSpinner.", "generated": "// native returns the underlying native object for this CellRendererSpinner.\n//\n// This is used internally by the library to interact directly with the GTK+ API,\n// but it can also be useful if you need direct access to the renderer's properties or methods.  Note that this method will return nil if the cell renderer has"}
{"id": 2247, "code": "func (v *FileChooserDialog) native() *C.GtkFileChooserDialog {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkFileChooserDialog(p)\n}", "reference": "// native returns a pointer to the underlying GtkFileChooserDialog.", "generated": "// native returns the underlying native file dialog object for this chooser.\n//\n// This is useful if you need to interact directly with the native file dialog,\n// but be aware that it's only valid until the next call to destroy(). If you're\n// using this method in conjunction with other methods provided by this package,"}
{"id": 2267, "code": "func (v *Paned) native() *C.GtkPaned {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkPaned(p)\n}", "reference": "// native returns a pointer to the underlying GtkPaned.", "generated": "// native returns the underlying native object for this Paned instance.\n//\n// This is useful when working directly with GTK+ code or other external libraries that expect a pointer to a\n// GtkPaned instead of a Paned. The returned value will be NULL if there was no valid paned associated with\n// this"}
{"id": 2303, "code": "func (v *TreePath) GetIndices() []int {\n\tvar depth C.gint\n\tvar goindices []int\n\tvar ginthelp C.gint\n\tindices := uintptr(unsafe.Pointer(C.gtk_tree_path_get_indices_with_depth(v.native(), &depth)))\n\tsize := unsafe.Sizeof(ginthelp)\n\tfor i := 0; i < int(depth); i++ {\n\t\tgoind := int(*((*C.gint)(unsafe.Pointer(indices))))\n\t\tgoindices = append(goindices, goind)\n\t\tindices += size\n\t}\n\treturn goindices\n}", "reference": "// GetIndices is a wrapper around gtk_tree_path_get_indices_with_depth", "generated": "// GetIndices returns all indices in this path. The returned list is sorted by index value.\n//\n// Note: This method only works for tree paths that have been created using gtk_tree_path_new_from_string(). If used elsewhere,\n// it will return garbage values. Use at your own risk! See http://developer.g"}
{"id": 2313, "code": "func (v *Window) native() *C.GtkWindow {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkWindow(p)\n}", "reference": "// native returns a pointer to the underlying GtkWindow.", "generated": "// native returns the underlying window object for this Window instance.\n//\n// This is useful when working directly with GTK+ code or using libgtk3's API,\n// but it should be used sparingly since it can lead to unexpected behavior if\n// the Window has been garbage collected while still being referenced by other\n//"}
{"id": 2348, "code": "func hideConsoleWindowOnWindows() {\n\tpid, err := getCurrentProcessId()\n\tif err != nil {\n\t\t// Ignore errors because:\n\t\t// 1. It is not critical if the console can't be hid.\n\t\t// 2. There is nothing to do when errors happen.\n\t\treturn\n\t}\n\tw, err := getConsoleWindow()\n\tif err != nil {\n\t\t// Ignore errors\n\t\treturn\n\t}\n\t// Get the process ID of the console's creator.\n\tcpid, err := getWindowThreadProcessId(w)\n\tif err != nil {\n\t\t// Ignore errors\n\t\treturn\n\t}\n\tif pid == cpid {\n\t\t// The current process created its own console. Hide this.\n\t\tshowWindowAsync(w, windows.SW_HIDE)\n\t}\n}", "reference": "// hideConsoleWindowOnWindows will hide the console window that is showing when\n// compiling on Windows without specifying the '-ldflags \"-Hwindowsgui\"' flag.", "generated": "// hides the console window for the given application. This should only be called once,\n// before any other calls that require focus (e.g., input). If it has already been done,\n// then calling again will have no effect. Note: Windows API functions may return error codes\n// even in case of success;"}
{"id": 2349, "code": "func DepthMask(flag bool) {\n\tC.glowDepthMask(gpDepthMask, (C.GLboolean)(boolToInt(flag)))\n}", "reference": "// enable or disable writing into the depth buffer", "generated": "// Set or clear depth mask for glow effect.\n//\n// The flag is true if the depth mask should be enabled; false otherwise.\n// If this value is set to 1 then all pixels will have their alpha\n// component multiplied by the corresponding color components in the\n// current frame buffer. This can help create"}
{"id": 2354, "code": "func scaleUpdater() {\n\tfor {\n\t\ts := getscale(0, 0)\n\t\tatomic.StoreUint64(&cachedScale, math.Float64bits(s))\n\t\ttime.Sleep(cacheUpdateWait)\n\t}\n}", "reference": "// run as goroutine. Will keep the desktop scale up to date.\n// This can be removed once the scale change event is implemented in GLFW 3.3", "generated": "// This is a goroutine that runs in the background to update cached\n// scaling information every cacheUpdateWait seconds.\n//\n// It uses atomic operations so it can be safely called from multiple threads,\n// which makes this very useful for use cases where we need to run concurrently\n// (like when running multiple workers)."}
{"id": 2359, "code": "func (b *Board) Draw(boardImage *ebiten.Image) {\n\tboardImage.Fill(frameColor)\n\tfor j := 0; j < b.size; j++ {\n\t\tfor i := 0; i < b.size; i++ {\n\t\t\tv := 0\n\t\t\top := &ebiten.DrawImageOptions{}\n\t\t\tx := i*tileSize + (i+1)*tileMargin\n\t\t\ty := j*tileSize + (j+1)*tileMargin\n\t\t\top.GeoM.Translate(float64(x), float64(y))\n\t\t\tr, g, b, a := colorToScale(tileBackgroundColor(v))\n\t\t\top.ColorM.Scale(r, g, b, a)\n\t\t\tboardImage.DrawImage(tileImage, op)\n\t\t}\n\t}\n\tanimatingTiles := map[*Tile]struct{}{}\n\tnonAnimatingTiles := map[*Tile]struct{}{}\n\tfor t := range b.tiles {\n\t\tif t.IsMoving() {\n\t\t\tanimatingTiles[t] = struct{}{}\n\t\t} else {\n\t\t\tnonAnimatingTiles[t] = struct{}{}\n\t\t}\n\t}\n\tfor t := range nonAnimatingTiles {\n\t\tt.Draw(boardImage)\n\t}\n\tfor t := range animatingTiles {\n\t\tt.Draw(boardImage)\n\t}\n}", "reference": "// Draw draws the board to the given boardImage.", "generated": "// Draw draws all tiles onto board image. Tiles that have animation enabled will be drawn in their current state.\n//\n// Note: This is called by ebiten's draw loop so it should only take O(1). If this were to happen more than once per frame,\n// we'd need some kind of caching"}
{"id": 2441, "code": "func (i *Image) makeStale() {\n\ti.basePixels = nil\n\ti.drawTrianglesHistory = nil\n\ti.stale = true\n\n\t// Don't have to call makeStale recursively here.\n\t// Restoring is done after topological sorting is done.\n\t// If an image depends on another stale image, this means that\n\t// the former image can be restored from the latest state of the latter image.\n}", "reference": "// makeStale makes the image stale.", "generated": "// Make sure all images in the graph are up-to-date by calling this method before doing any work,\n// such as drawing or restoring. This ensures that we don't try to restore anything until it's been made\n// stale first. The only exception is when making a new image - then we need to do some"}
{"id": 2498, "code": "func (u *UserInterface) setScreenSize(width, height int, scale float64, fullscreen bool, vsync bool) bool {\n\tif u.width == width && u.height == height && u.scale == scale && u.isFullscreen() == fullscreen && u.vsync == vsync {\n\t\treturn false\n\t}\n\tu.forceSetScreenSize(width, height, scale, fullscreen, vsync)\n\treturn true\n}", "reference": "// setScreenSize must be called from the main thread.", "generated": "// Set screen size to new values if they differ from current ones or if we need to change some other parameters like isFullsreen or VSync.\n//\n// Returns whether any changes were made. If no changes were made then it returns false. Otherwise return true. This can be used for debugging purposes."}
{"id": 2504, "code": "func (q *commandQueue) Flush() {\n\tif q.err != nil {\n\t\treturn\n\t}\n\n\tes := q.indices\n\tvs := q.vertices\n\tif recordLog() {\n\t\tfmt.Println(\"--\")\n\t}\n\n\ttheGraphicsDriver.Begin()\n\tfor len(q.commands) > 0 {\n\t\tnv := 0\n\t\tne := 0\n\t\tnc := 0\n\t\tfor _, c := range q.commands {\n\t\t\tif c.NumIndices() > graphics.IndicesNum {\n\t\t\t\tpanic(fmt.Sprintf(\"graphicscommand: c.NumIndices() must be <= graphics.IndicesNum but not at Flush: c.NumIndices(): %d, graphics.IndicesNum: %d\", c.NumIndices(), graphics.IndicesNum))\n\t\t\t}\n\t\t\tif ne+c.NumIndices() > graphics.IndicesNum {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tnv += c.NumVertices()\n\t\t\tne += c.NumIndices()\n\t\t\tnc++\n\t\t}\n\t\tif 0 < ne {\n\t\t\ttheGraphicsDriver.SetVertices(vs[:nv], es[:ne])\n\t\t\tes = es[ne:]\n\t\t\tvs = vs[nv:]\n\t\t}\n\t\tindexOffset := 0\n\t\tfor _, c := range q.commands[:nc] {\n\t\t\tif err := c.Exec(indexOffset); err != nil {\n\t\t\t\tq.err = err\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif recordLog() {\n\t\t\t\tfmt.Printf(\"%s\\n\", c)\n\t\t\t}\n\t\t\t// TODO: indexOffset should be reset if the command type is different\n\t\t\t// from the previous one. This fix is needed when another drawing command is\n\t\t\t// introduced than drawTrianglesCommand.\n\t\t\tindexOffset += c.NumIndices()\n\t\t}\n\t\tif 0 < nc {\n\t\t\t// Call glFlush to prevent black flicking (especially on Android (#226) and iOS).\n\t\t\ttheGraphicsDriver.Flush()\n\t\t}\n\t\tq.commands = q.commands[nc:]\n\t}\n\ttheGraphicsDriver.End()\n\tq.commands = nil\n\tq.nvertices = 0\n\tq.nindices = 0\n\tq.tmpNumIndices = 0\n\tq.nextIndex = 0\n}", "reference": "// Flush flushes the command queue.", "generated": "// Flush executes all commands in queue until it's empty or there are no more indices left for rendering. It also flushes any pending OpenGL operations before returning. The result will depend on whether we have reached the end of the vertex buffer array or not. If so, then the last frame was rendered correctly; otherwise,"}
{"id": 2534, "code": "func flattenClusterHostGroup(d *schema.ResourceData, obj *types.ClusterHostGroup) error {\n\tvar hostIDs []string\n\tfor _, v := range obj.Host {\n\t\thostIDs = append(hostIDs, v.Value)\n\t}\n\n\treturn structure.SetBatch(d, map[string]interface{}{\n\t\t\"host_system_ids\": hostIDs,\n\t})\n}", "reference": "// flattenClusterHostGroup saves a ClusterHostGroup into the supplied ResourceData.", "generated": "// Flatten cluster_host_group resource data into a batch of key-value pairs.\n//\n// This is used to convert the ClusterHostGroup object's Host field from a slice of strings\n// (the actual system IDs in the underlying Kubernetes API) to a list of string values that can be\n// serialized by the client library"}
{"id": 2535, "code": "func resourceVSphereComputeClusterHostGroupFlattenID(cluster *object.ClusterComputeResource, name string) (string, error) {\n\tclusterID := cluster.Reference().Value\n\treturn strings.Join([]string{clusterID, name}, \":\"), nil\n}", "reference": "// resourceVSphereComputeClusterHostGroupFlattenID makes an ID for the\n// vsphere_cluster_host_group resource.", "generated": "// Flatten ID for VSphere Compute Cluster Host Group. This is used to create a unique identifier that can be passed into the API.\n//\n// The format will look something like this: <cluster_id>:<host_group_name> where both values must match exactly in order to return valid results from the API. If either"}
{"id": 2590, "code": "func MoveToFolder(client *govmomi.Client, vm *object.VirtualMachine, relative string) error {\n\tlog.Printf(\"[DEBUG] Moving virtual %q to VM path %q\", vm.InventoryPath, relative)\n\tf, err := folder.VirtualMachineFolderFromObject(client, vm, relative)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn folder.MoveObjectTo(vm.Reference(), f)\n}", "reference": "// MoveToFolder moves a virtual machine to the specified folder.", "generated": "// Moves a virtual machine into its own folder in the root directory.\n//\n// This is useful for creating a new folder when moving a virtual machine from one host's\n// inventory to another. The name of the folder will be based off the virtual machines\n// Inventory Path. If this fails then it returns an error"}
{"id": 2611, "code": "func FromPath(client *govmomi.Client, name string, dc *object.Datacenter) (*object.VirtualApp, error) {\n\tfinder := find.NewFinder(client.Client, false)\n\n\tctx, cancel := context.WithTimeout(context.Background(), provider.DefaultAPITimeout)\n\tdefer cancel()\n\tif dc != nil {\n\t\tfinder.SetDatacenter(dc)\n\t}\n\treturn finder.VirtualApp(ctx, name)\n}", "reference": "// FromPath returns a VirtualApp via its supplied path.", "generated": "// Find returns virtual app by path or data center if specified.\n//\n// If no DC is provided it will search for all apps in the default\n// data centers. The client must be connected to the vCenter server.\n//\n// This method can return errors even when there's nothing found,\n// e.g., due"}
{"id": 2643, "code": "func resourceVSphereComputeClusterApplyCreate(d *schema.ResourceData, meta interface{}) (*object.ClusterComputeResource, error) {\n\tlog.Printf(\"[DEBUG] %s: Processing compute cluster creation\", resourceVSphereComputeClusterIDString(d))\n\tclient, err := resourceVSphereComputeClusterClient(meta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdc, err := datacenterFromID(client, d.Get(\"datacenter_id\").(string))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot locate datacenter: %s\", err)\n\t}\n\n\t// Find the folder based off the path to the datacenter. This is where we\n\t// create the datastore cluster.\n\tf, err := folder.FromPath(client, d.Get(\"folder\").(string), folder.VSphereFolderTypeHost, dc)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot locate folder: %s\", err)\n\t}\n\n\t// Create the cluster. We use an empty config spec so that we can move the\n\t// necessary hosts into the cluster *before* we send the full configuration,\n\t// ensuring that any host-dependent configuration does not break.\n\tcluster, err := clustercomputeresource.Create(f, d.Get(\"name\").(string), types.ClusterConfigSpecEx{})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error creating cluster: %s\", err)\n\t}\n\n\t// Set the ID now before proceeding any further. Any other operation past\n\t// this point is recoverable.\n\td.SetId(cluster.Reference().Value)\n\n\treturn cluster, nil\n}", "reference": "// resourceVSphereComputeClusterApplyCreate processes the creation part of\n// resourceVSphereComputeClusterCreate.", "generated": "// Apply creates or updates a VSphere Compute Cluster in the specified Datastore. The\n// name must be unique within the given Folder. If it already exists then no action will occur. A new\n// cluster will always be created if one doesn't exist. Note that all resources associated with\n// the existing cluster"}
{"id": 2650, "code": "func resourceVSphereComputeClusterSaveDatacenter(\n\td *schema.ResourceData,\n\tmeta interface{},\n\tcluster *object.ClusterComputeResource,\n) error {\n\tlog.Printf(\"[DEBUG] %s: Saving datacenter\", resourceVSphereComputeClusterIDString(d))\n\tclient, err := resourceVSphereComputeClusterClient(meta)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tp, err := folder.RootPathParticleHost.SplitDatacenter(cluster.InventoryPath)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error parsing datacenter path from cluster: %s\", err)\n\t}\n\n\tdc, err := getDatacenter(client, p)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error fetching datacenter for cluster: %s\", err)\n\t}\n\n\treturn d.Set(\"datacenter_id\", dc.Reference().Value)\n}", "reference": "// resourceVSphereComputeClusterSaveDatacenter saves the datacenter that the\n// cluster is a member of for correctness on imports.", "generated": "// resourceVSphereComputeClusterSaveDatacenter saves the current state to local storage.\n//\n// This is used by the provider's internal save functionality when it needs to store\n// information about the object in local storage (e.g., during shutdown). It also\n// updates the \"last_modified\" field if necessary."}
{"id": 2677, "code": "func expandClusterDrsConfigInfo(d *schema.ResourceData) *types.ClusterDrsConfigInfo {\n\tobj := &types.ClusterDrsConfigInfo{\n\t\tDefaultVmBehavior:         types.DrsBehavior(d.Get(\"drs_automation_level\").(string)),\n\t\tEnabled:                   structure.GetBool(d, \"drs_enabled\"),\n\t\tEnableVmBehaviorOverrides: structure.GetBool(d, \"drs_enable_vm_overrides\"),\n\t\tVmotionRate:               int32(d.Get(\"drs_migration_threshold\").(int)),\n\t\tOption:                    expandResourceVSphereComputeClusterDrsAdvancedOptions(d),\n\t}\n\n\treturn obj\n}", "reference": "// expandClusterDrsConfigInfo reads certain ResourceData keys and returns a\n// ClusterDrsConfigInfo.", "generated": "// Expand cluster drs config info resource data into ClusterDRSConfigInfo object. This is used to convert raw input from user or API into structured format that can be passed to functions like CreateVM, DeleteVM etc. It also performs validation checks for each field in the struct before returning it back to caller. If"}
{"id": 2689, "code": "func Rename(pod *object.StoragePod, name string) error {\n\tlog.Printf(\"[DEBUG] Renaming storage pod %q to %s\", pod.InventoryPath, name)\n\tctx, cancel := context.WithTimeout(context.Background(), provider.DefaultAPITimeout)\n\tdefer cancel()\n\ttask, err := pod.Rename(ctx, name)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn task.Wait(ctx)\n}", "reference": "// Rename renames a StoragePod.", "generated": "// Rename renames a Storage Pod by its Inventory Path. The new path is returned in the result.\n//\n// If there's no existing Storage Pod at that inventory path, this will return an error. This method can be used for testing purposes only,\n// since it doesn't check if the target exists before renaming."}
{"id": 2727, "code": "func createHardDisk(client *govmomi.Client, size int, diskPath string, diskType string, adapterType string, dc string) error {\n\tvar vDiskType string\n\tswitch diskType {\n\tcase \"thin\":\n\t\tvDiskType = \"thin\"\n\tcase \"eagerZeroedThick\":\n\t\tvDiskType = \"eagerZeroedThick\"\n\tcase \"lazy\":\n\t\tvDiskType = \"preallocated\"\n\t}\n\n\tvirtualDiskManager := object.NewVirtualDiskManager(client.Client)\n\tspec := &types.FileBackedVirtualDiskSpec{\n\t\tVirtualDiskSpec: types.VirtualDiskSpec{\n\t\t\tAdapterType: adapterType,\n\t\t\tDiskType:    vDiskType,\n\t\t},\n\t\tCapacityKb: int64(1024 * 1024 * size),\n\t}\n\tdatacenter, err := getDatacenter(client, dc)\n\tif err != nil {\n\t\treturn err\n\t}\n\tlog.Printf(\"[DEBUG] Disk spec: %v\", spec)\n\n\ttask, err := virtualDiskManager.CreateVirtualDisk(context.TODO(), diskPath, datacenter, spec)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = task.WaitForResult(context.TODO(), nil)\n\tif err != nil {\n\t\tlog.Printf(\"[INFO] Failed to create disk:  %v\", err)\n\t\treturn err\n\t}\n\tlog.Printf(\"[INFO] Created disk.\")\n\n\treturn nil\n}", "reference": "// createHardDisk creates a new Hard Disk.", "generated": "// Create a new hard disk in the specified location.\n//\n// This will return an error if there is no available space for the disk or if it fails to be created. The returned value can then be used by other functions that require this disk (like the VM's boot device). If successful, the disk path should"}
{"id": 2729, "code": "func (p *nasDatastoreMountProcessor) processMountOperations() (*object.Datastore, error) {\n\thosts := p.diffNewOld()\n\tif len(hosts) < 1 {\n\t\t// Nothing to do\n\t\treturn p.ds, nil\n\t}\n\t// Validate we are vCenter if we are working with multiple hosts\n\tif len(hosts) > 1 {\n\t\tif err := viapi.ValidateVirtualCenter(p.client); err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"cannot mount on multiple hosts: %s\", err)\n\t\t}\n\t}\n\tfor _, hsID := range hosts {\n\t\tdss, err := hostDatastoreSystemFromHostSystemID(p.client, hsID)\n\t\tif err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\t\tdefer cancel()\n\t\tds, err := dss.CreateNasDatastore(ctx, *p.volSpec)\n\t\tif err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t\tif err := p.validateDatastore(ds); err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"datastore validation error on host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t}\n\treturn p.ds, nil\n}", "reference": "// processMountOperations processes all pending mount operations by diffing old\n// and new and adding any hosts that were not found in old. The datastore is\n// returned, along with any error.", "generated": "// processMountOperations mounts datastores for all specified hosts in this processor.\n//\n// This method is called after all other operations have been processed by this\n// processor. It will attempt to create a new datastore per each host that was\n// added or removed from the list since last time it was run. If there"}
{"id": 2733, "code": "func tagByName(client *tags.RestClient, name, categoryID string) (string, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\ttags, err := client.GetTagByNameForCategory(ctx, name, categoryID)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"could not get tag for name %q: %s\", name, err)\n\t}\n\n\tif len(tags) < 1 {\n\t\treturn \"\", fmt.Errorf(\"tag name %q not found in category ID %q\", name, categoryID)\n\t}\n\tif len(tags) > 1 {\n\t\t// This situation is very similar to the one in tagCategoryByName. The API\n\t\t// docs even say that tags need to be unique in categories, yet\n\t\t// GetTagByNameForCategory still returns multiple results.\n\t\treturn \"\", fmt.Errorf(vSphereTagSearchErrMultiple, name)\n\t}\n\n\treturn tags[0].ID, nil\n}", "reference": "// tagByName locates a tag by it supplied name and category ID. Use\n// tagCategoryByName to get the tag category ID if require the category ID as\n// well.", "generated": "// TagByCategoryName retrieves all tags by their names from given category ID.\n//\n// If there's only one matching tag it will return its id otherwise it will panic.\n//\n// Note: this method should never fail because we know that if no such tag exists,\n// then GetTagByNameForCategory would have returned"}
{"id": 2752, "code": "func expandVMwareDVSConfigSpec(d *schema.ResourceData) *types.VMwareDVSConfigSpec {\n\tobj := &types.VMwareDVSConfigSpec{\n\t\tDVSConfigSpec: types.DVSConfigSpec{\n\t\t\tName:                                d.Get(\"name\").(string),\n\t\t\tConfigVersion:                       d.Get(\"config_version\").(string),\n\t\t\tDefaultPortConfig:                   expandVMwareDVSPortSetting(d),\n\t\t\tHost:                                expandSliceOfDistributedVirtualSwitchHostMemberConfigSpec(d),\n\t\t\tDescription:                         d.Get(\"description\").(string),\n\t\t\tContact:                             expandDVSContactInfo(d),\n\t\t\tSwitchIpAddress:                     d.Get(\"ipv4_address\").(string),\n\t\t\tInfrastructureTrafficResourceConfig: expandSliceOfDvsHostInfrastructureTrafficResource(d),\n\t\t\tNetworkResourceControlVersion:       d.Get(\"network_resource_control_version\").(string),\n\t\t\tUplinkPortPolicy:                    expandDVSNameArrayUplinkPortPolicy(d),\n\t\t},\n\t\tMaxMtu:                      int32(d.Get(\"max_mtu\").(int)),\n\t\tLinkDiscoveryProtocolConfig: expandLinkDiscoveryProtocolConfig(d),\n\t\tIpfixConfig:                 expandVMwareIpfixConfig(d),\n\t\tLacpApiVersion:              d.Get(\"lacp_api_version\").(string),\n\t\tMulticastFilteringMode:      d.Get(\"multicast_filtering_mode\").(string),\n\t}\n\treturn obj\n}", "reference": "// expandVMwareDVSConfigSpec reads certain ResourceData keys and\n// returns a VMwareDVSConfigSpec.", "generated": "// Expand VMware DVS Config Spec resource data into a VMWare DVS config spec object.\n//\n// This is used to convert raw input from the user (e.g., JSON or YAML)\n// into a usable format for further processing by other functions in this package,\n// such as generating the configuration file that will be"}
{"id": 2765, "code": "func expandVirtualMachineResourceAllocation(d *schema.ResourceData, key string) *types.ResourceAllocationInfo {\n\tshareLevelKey := fmt.Sprintf(\"%s_share_level\", key)\n\tshareCountKey := fmt.Sprintf(\"%s_share_count\", key)\n\tlimitKey := fmt.Sprintf(\"%s_limit\", key)\n\treservationKey := fmt.Sprintf(\"%s_reservation\", key)\n\n\tobj := &types.ResourceAllocationInfo{\n\t\tLimit:       structure.GetInt64PtrEmptyZero(d, limitKey),\n\t\tReservation: structure.GetInt64PtrEmptyZero(d, reservationKey),\n\t}\n\tshares := &types.SharesInfo{\n\t\tLevel:  types.SharesLevel(d.Get(shareLevelKey).(string)),\n\t\tShares: int32(d.Get(shareCountKey).(int)),\n\t}\n\tobj.Shares = shares\n\treturn obj\n}", "reference": "// expandVirtualMachineResourceAllocation reads the VM resource allocation\n// resource data keys for the type supplied by key and returns an appropriate\n// types.ResourceAllocationInfo reference.", "generated": "// Expand virtual machine resource allocation into its constituent parts. This is used to create a new ResourceAllocationInfo object from the data in d. The returned value will be populated by default values if no other information was provided for this particular field. If there were any errors during expansion then they should have been reported via error reporting"}
{"id": 2781, "code": "func expandClusterDasVMConfigInfo(\n\td *schema.ResourceData,\n\tmeta interface{},\n\tvm *object.VirtualMachine,\n) (*types.ClusterDasVmConfigInfo, error) {\n\tclient, err := resourceVSphereHAVMOverrideClient(meta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tversion := viapi.ParseVersionFromClient(client)\n\n\tobj := &types.ClusterDasVmConfigInfo{\n\t\tDasSettings: expandClusterDasVMSettings(d, version),\n\t\tKey:         vm.Reference(),\n\t}\n\n\t// Expand ha_vm_monitoring_use_cluster_defaults here as it's not included in\n\t// the base vsphere_compute_cluster resource.\n\tobj.DasSettings.VmToolsMonitoringSettings.ClusterSettings = structure.GetBool(d, \"ha_vm_monitoring_use_cluster_defaults\")\n\n\treturn obj, nil\n}", "reference": "// expandClusterDasVMConfigInfo reads certain ResourceData keys and returns a\n// ClusterDasVmConfigInfo.", "generated": "// expandClusterDasVMConfigInfo returns expanded Cluster Das VM Config Info for\n// given Virtual Machine object. It also includes additional settings like\n// das_settings.vim_ha_vm_monitoring_use_cluster_defaults which is used to set\n// monitoring configuration based on cluster defaults or virtual machine specific\n// settings. This"}
{"id": 2819, "code": "func expandVmwareUplinkPortTeamingPolicy(d *schema.ResourceData) *types.VmwareUplinkPortTeamingPolicy {\n\tobj := &types.VmwareUplinkPortTeamingPolicy{\n\t\tPolicy:          structure.GetStringPolicy(d, \"teaming_policy\"),\n\t\tNotifySwitches:  structure.GetBoolPolicy(d, \"notify_switches\"),\n\t\tRollingOrder:    structure.GetBoolPolicyReverse(d, \"failback\"),\n\t\tFailureCriteria: expandDVSFailureCriteria(d),\n\t\tUplinkPortOrder: expandVMwareUplinkPortOrderPolicy(d),\n\t}\n\n\tif structure.AllFieldsEmpty(obj) {\n\t\treturn nil\n\t}\n\treturn obj\n}", "reference": "// expandVmwareUplinkPortTeamingPolicy reads certain ResourceData keys and\n// returns a VmwareUplinkPortTeamingPolicy.", "generated": "// Expand VMware Uplink Port Teaming Policy resource data into its corresponding types.VmwareUplinkPortTeamingPolicy object.\n//\n// This is used to convert raw input from the user (e.g., JSON or YAML)\n// into something that can be processed by the vSphere API. The result will"}
{"id": 2824, "code": "func flattenVMwareUplinkLacpPolicy(d *schema.ResourceData, obj *types.VMwareUplinkLacpPolicy) error {\n\tif obj == nil {\n\t\treturn nil\n\t}\n\n\tstructure.SetBoolPolicy(d, \"lacp_enabled\", obj.Enable)\n\tstructure.SetStringPolicy(d, \"lacp_mode\", obj.Mode)\n\treturn nil\n}", "reference": "// flattenVMwareUplinkLacpPolicy reads various fields from a\n// VMwareUplinkLacpPolicy into the passed in ResourceData.", "generated": "// Flatten VMware Uplink Lacp Policy resource into data structure. This is used for marshaling and unmarshalling to/from JSON/YAML. It takes in a pointer to the ResourceData object which will be populated/updated with the flattened configuration from the VMWare Uplink Lacp policy object passed-in."}
{"id": 2841, "code": "func (r *CdromSubresource) ValidateDiff() error {\n\tlog.Printf(\"[DEBUG] %s: Beginning CDROM configuration validation\", r)\n\tdsID := r.Get(\"datastore_id\").(string)\n\tpath := r.Get(\"path\").(string)\n\tclientDevice := r.Get(\"client_device\").(bool)\n\tswitch {\n\tcase clientDevice && (dsID != \"\" || path != \"\"):\n\t\treturn fmt.Errorf(\"Cannot have both client_device parameter and ISO file parameters (datastore_id, path) set\")\n\tcase !clientDevice && (dsID == \"\" || path == \"\"):\n\t\treturn fmt.Errorf(\"Either client_device or datastore_id and path must be set\")\n\t}\n\tlog.Printf(\"[DEBUG] %s: Config validation complete\", r)\n\treturn nil\n}", "reference": "// ValidateDiff performs any complex validation of an individual\n// cdrom sub-resource that can't be done in schema alone.", "generated": "// Validates that all required fields in this resource's diff object match their values from the parent resource.\n//\n// This is used to validate the data before it is written back into the API. If any field fails validation,\n// then the entire request will fail. The log message for each failed validation includes the name of the"}
{"id": 2848, "code": "func verifyVAppCdromIso(d *schema.ResourceData, device *types.VirtualCdrom, l object.VirtualDeviceList, c *govmomi.Client) (bool, error) {\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: Checking if CDROM is using a vApp ISO\")\n\t// If the CDROM is using VirtualCdromIsoBackingInfo and matches the ISO\n\t// naming pattern, it has been used as a vApp CDROM, and we can move on to\n\t// checking if the parent VM supports ISO transport.\n\tif backing, ok := device.Backing.(*types.VirtualCdromIsoBackingInfo); ok {\n\t\tdp := &object.DatastorePath{}\n\t\tif ok := dp.FromString(backing.FileName); !ok {\n\t\t\t// If the ISO path can not be read, we can't tell if a vApp ISO is\n\t\t\t// connected.\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: Cannot read ISO path, cannot determine if CDROM is used for vApp\")\n\t\t\treturn false, nil\n\t\t}\n\t\t// The pattern used for vApp ISO naming is\n\t\t// \"<vmname>/_ovfenv-<vmname>.iso\"\n\t\tre := regexp.MustCompile(\".*/_ovfenv-.*.iso\")\n\t\tif !re.MatchString(dp.Path) {\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: ISO is name does not match vApp ISO naming pattern (<vmname>/_ovfenv-<vmname>.iso): %s\", dp.Path)\n\t\t\treturn false, nil\n\t\t}\n\t} else {\n\t\t// vApp CDROMs must be backed by an ISO.\n\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: CDROM is not backed by an ISO\")\n\t\treturn false, nil\n\t}\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: CDROM has a vApp ISO inserted\")\n\t// Set the vApp transport methods\n\ttm := d.Get(\"vapp_transport\").([]interface{})\n\tfor _, t := range tm {\n\t\tif t.(string) == \"iso\" {\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: vApp ISO transport is supported\")\n\t\t\treturn true, nil\n\t\t}\n\t}\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: vApp ISO transport is not required\")\n\treturn false, nil\n}", "reference": "// verifyVAppCdromIso takes VirtualCdrom and determines if it is needed for\n// vApp ISO transport. It does this by first checking if it has an ISO inserted\n// that matches the vApp ISO naming pattern. If it does, then the next step is\n// to see if vApp ISO transport is supported on the VM. If both of those\n// conditions are met, then the CDROM is considered in use for vApp transport.", "generated": "// Verify that this virtual cdrom uses a VApp iso file. This will check whether\n// the CDROM contains a valid ISO image or not. It also checks whether the\n// parent vm supports ISO transport. If both conditions are met then return\n// true; otherwise return false. In case there's any"}
{"id": 2853, "code": "func soapFault(err error) (*soap.Fault, bool) {\n\tif soap.IsSoapFault(err) {\n\t\treturn soap.ToSoapFault(err), true\n\t}\n\treturn nil, false\n}", "reference": "// soapFault extracts the SOAP fault from an error fault, if it exists. Check\n// the returned boolean value to see if you have a SoapFault.", "generated": "// soapFault returns a SoapFault if err is a SOAP fault or otherwise returns nil.\n//\n// If it's a SOAP fault then we return the Fault object along with whether this was\n// caused by a SOAP fault. Otherwise we just return nil. This can be used to\n// handle errors in a way that"}
{"id": 2860, "code": "func isConcurrentAccessError(err error) bool {\n\t// ConcurrentAccess comes from a task more than it usually does from a direct\n\t// SOAP call, so we need to handle both here.\n\tvar f types.AnyType\n\tvar ok bool\n\tf, ok = vimSoapFault(err)\n\tif !ok {\n\t\tf, ok = taskFault(err)\n\t}\n\tif ok {\n\t\tswitch f.(type) {\n\t\tcase types.ConcurrentAccess, *types.ConcurrentAccess:\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "reference": "// isConcurrentAccessError checks an error to see if it's of the\n// ConcurrentAccess type.", "generated": "// isConcurrentAccessError returns whether or not the given error was caused by concurrent access. This can happen if two tasks try to update the same file at the same time. The check for this case only works when there's no other fault in the error message. If that's the case then the result will be"}
{"id": 2882, "code": "func validateCloneSnapshots(props *mo.VirtualMachine) error {\n\tif props.Snapshot == nil {\n\t\treturn fmt.Errorf(\"virtual machine or template %s must have a snapshot to be used as a linked clone\", props.Config.Uuid)\n\t}\n\t// Root snapshot list can only have a singular element\n\tif len(props.Snapshot.RootSnapshotList) != 1 {\n\t\treturn fmt.Errorf(\"virtual machine or template %s must have exactly one root snapshot (has: %d)\", props.Config.Uuid, len(props.Snapshot.RootSnapshotList))\n\t}\n\t// Check to make sure the root snapshot has no children\n\tif len(props.Snapshot.RootSnapshotList[0].ChildSnapshotList) > 0 {\n\t\treturn fmt.Errorf(\"virtual machine or template %s's root snapshot must not have children\", props.Config.Uuid)\n\t}\n\t// Current snapshot must match root snapshot (this should be the case anyway)\n\tif props.Snapshot.CurrentSnapshot.Value != props.Snapshot.RootSnapshotList[0].Snapshot.Value {\n\t\treturn fmt.Errorf(\"virtual machine or template %s's current snapshot must match root snapshot\", props.Config.Uuid)\n\t}\n\treturn nil\n}", "reference": "// validateCloneSnapshots checks a VM to make sure it has a single snapshot\n// with no children, to make sure there is no ambiguity when selecting a\n// snapshot for linked clones.", "generated": "// Validate that all required fields for cloning virtual machines exist.\n//\n// This is called by CloneVM() before attempting to create a new VM from the given\n// source VM. It checks if there exists at least one root snapshot in the source\n// VM which will serve as the base image for the cloned VM."}
{"id": 2893, "code": "func dvsProperties(dvs *object.VmwareDistributedVirtualSwitch) (*mo.VmwareDistributedVirtualSwitch, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\tvar props mo.VmwareDistributedVirtualSwitch\n\tif err := dvs.Properties(ctx, dvs.Reference(), nil, &props); err != nil {\n\t\treturn nil, err\n\t}\n\treturn &props, nil\n}", "reference": "// dvsProperties is a convenience method that wraps fetching the DVS MO from\n// its higher-level object.", "generated": "// DVS properties returns the distributed virtual switch's properties.\n//\n// The returned object is populated from the server's response to this request,\n// which may contain additional fields depending on the server version and other factors.\n// Use this method sparingly (e.g., only once per VMDriver instance), since it requires"}
{"id": 2907, "code": "func (r *Subresource) Hash() int {\n\thf := schema.HashResource(&schema.Resource{Schema: r.schema})\n\treturn hf(r.data)\n}", "reference": "// Hash calculates a set hash for the current data. If you want a hash for\n// error reporting a device address, it's probably a good idea to run this at\n// the beginning of a run as any set calls will change the value this\n// ultimately calculates.", "generated": "// Hash returns a hash value for this resource's data. This is used to\n// determine whether two resources have changed since they were last saved.\n// The returned integer can be passed directly into the `Hash` method of any\n// provider that supports it. If no such method exists, the result will still"}
{"id": 2919, "code": "func createSCSIController(l *object.VirtualDeviceList, ct string, st string) ([]types.BaseVirtualDeviceConfigSpec, error) {\n\tnc, err := l.CreateSCSIController(ct)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnc.(types.BaseVirtualSCSIController).GetVirtualSCSIController().SharedBus = types.VirtualSCSISharing(st)\n\tcspec, err := object.VirtualDeviceList{nc}.ConfigSpec(types.VirtualDeviceConfigSpecOperationAdd)\n\t*l = applyDeviceChange(*l, cspec)\n\treturn cspec, err\n}", "reference": "// createSCSIController creates a new SCSI controller of the specified type and\n// sharing mode.", "generated": "// CreateSCSIController creates a new virtual SCSI controller in the specified list.\n//\n// The device is created using the provided configuration spec. If no config spec is given,\n// then it will be generated automatically based on the type of controller being added to the\n// list. This method returns any errors that occur during"}
{"id": 2933, "code": "func resourceVSphereComputeClusterVMDependencyRuleFetchObjects(\n\tmeta interface{},\n\tclusterID string,\n\tkey int32,\n) (*object.ClusterComputeResource, int32, error) {\n\tclient, err := resourceVSphereComputeClusterVMDependencyRuleClient(meta)\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\n\tcluster, err := clustercomputeresource.FromID(client, clusterID)\n\tif err != nil {\n\t\treturn nil, 0, fmt.Errorf(\"cannot locate cluster: %s\", err)\n\t}\n\n\treturn cluster, key, nil\n}", "reference": "// resourceVSphereComputeClusterVMDependencyRuleFetchObjects fetches the \"objects\"\n// for a cluster rule. This is currently just the cluster object as the rule\n// key a static value and a pass-through - this is to keep its workflow\n// consistent with other cluster-dependent resources that derive from\n// ArrayUpdateSpec that have managed object as keys, such as VM and host\n// overrides.", "generated": "// Fetch objects for dependency rule fetch operation. This is used to get all\n// dependencies required by the given compute cluster VM's. The object returned\n// will be the Compute Resource that this VM belongs to. If there was no match then\n// it returns nil along with -1 in case of failure. Error"}
{"id": 2938, "code": "func resourceVSphereDatastoreClusterReadCustomAttributes(d *schema.ResourceData, meta interface{}, pod *object.StoragePod) error {\n\tclient := meta.(*VSphereClient).vimClient\n\t// Read custom attributes\n\tif customattribute.IsSupported(client) {\n\t\tlog.Printf(\"[DEBUG] %s: Reading custom attributes\", resourceVSphereDatastoreClusterIDString(d))\n\t\tprops, err := storagepod.Properties(pod)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcustomattribute.ReadFromResource(client, props.Entity(), d)\n\t} else {\n\t\tlog.Printf(\"[DEBUG] %s: Custom attributes unsupported on this connection, skipping\", resourceVSphereDatastoreClusterIDString(d))\n\t}\n\n\treturn nil\n}", "reference": "// resourceVSphereDatastoreClusterReadCustomAttributes reads the custom\n// attributes for vsphere_datastore_cluster.", "generated": "// resourceVSphereDatastoreClusterReadCustomAttributes reads custom attributes from the cluster object.\n//\n// This is used to support additional properties that may be present in the cluster object but which do not have their own resources or types defined within the VSphere provider.  The client must implement the vim.Client interface for this method to"}
{"id": 2958, "code": "func flattenStorageDrsOptionSpec(d *schema.ResourceData, opts []types.BaseOptionValue) error {\n\tm := make(map[string]interface{})\n\tfor _, opt := range opts {\n\t\tm[opt.GetOptionValue().Key] = opt.GetOptionValue().Value\n\t}\n\n\treturn d.Set(\"sdrs_advanced_options\", m)\n}", "reference": "// flattenStorageDrsOptionSpec saves a StorageDrsOptionSpec into the supplied\n// ResourceData.", "generated": "// Flatten storage drs option spec into resource data. This is used to convert\n// sdrs advanced options from a map to a struct that can be set in the\n// ResourceData object. The result will contain all keys from the original\n// map but only values for those which were present when this was called"}
{"id": 2965, "code": "func diskApplyOperationDelete(\n\tindex int,\n\toldData map[string]interface{},\n\tnewDataSet []interface{},\n\tc *govmomi.Client,\n\td *schema.ResourceData,\n\tl *object.VirtualDeviceList,\n\tspec *[]types.BaseVirtualDeviceConfigSpec,\n) error {\n\tdidx := -1\n\tfor ni, ne := range newDataSet {\n\t\tnewData := ne.(map[string]interface{})\n\t\tvar name string\n\t\tvar err error\n\t\tif name, err = diskLabelOrName(newData); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif (name == diskDeletedName || name == diskDetachedName) && oldData[\"uuid\"] == newData[\"uuid\"] {\n\t\t\tdidx = ni\n\t\t\tbreak\n\t\t}\n\t}\n\tif didx < 0 {\n\t\t// Deleted entry not found\n\t\treturn nil\n\t}\n\tr := NewDiskSubresource(c, d, oldData, nil, index)\n\tdspec, err := r.Delete(*l)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"%s: %s\", r.Addr(), err)\n\t}\n\t*l = applyDeviceChange(*l, dspec)\n\t*spec = append(*spec, dspec...)\n\treturn nil\n}", "reference": "// diskApplyOperationDelete is an inner-loop helper for disk deletion\n// operations.", "generated": "// Delete deletes a virtual device from the system. The operation is only possible if there's no other reference to this object in the system.\n//\n// This method will return an error if it can't find any references for the given uuid or if the resource doesn't exist. If the delete fails due to permissions issues,"}
{"id": 2974, "code": "func (r *DiskSubresource) Delete(l object.VirtualDeviceList) ([]types.BaseVirtualDeviceConfigSpec, error) {\n\tlog.Printf(\"[DEBUG] %s: Beginning delete\", r)\n\tdisk, err := r.findVirtualDisk(l, false)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot find disk device: %s\", err)\n\t}\n\tdeleteSpec, err := object.VirtualDeviceList{disk}.ConfigSpec(types.VirtualDeviceConfigSpecOperationRemove)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(deleteSpec) != 1 {\n\t\treturn nil, fmt.Errorf(\"incorrect number of config spec items returned - expected 1, got %d\", len(deleteSpec))\n\t}\n\tif r.Get(\"keep_on_remove\").(bool) || r.Get(\"attach\").(bool) {\n\t\t// Clear file operation so that the disk is kept on remove.\n\t\tdeleteSpec[0].GetVirtualDeviceConfigSpec().FileOperation = \"\"\n\t}\n\tlog.Printf(\"[DEBUG] %s: Device config operations from update: %s\", r, DeviceChangeString(deleteSpec))\n\tlog.Printf(\"[DEBUG] %s: Delete completed\", r)\n\treturn deleteSpec, nil\n}", "reference": "// Delete deletes a vsphere_virtual_machine disk sub-resource.", "generated": "// Delete deletes virtual disks in this sub-resource. The DiskSubresource must be configured to keep devices when they're removed or attached. If it's set to \"remove\" then all disks will be deleted if there aren't any other attachments. Otherwise only those specified by the attach parameter will remain after removal. This method"}
{"id": 2979, "code": "func (r *DiskSubresource) String() string {\n\tp := diskPathOrName(r.data)\n\tif p == \"\" {\n\t\tp = \"<unknown>\"\n\t}\n\treturn fmt.Sprintf(\"%s (%s)\", r.Subresource.String(), p)\n}", "reference": "// String prints out the disk sub-resource's information including the ID at\n// time of instantiation, the path of the disk, and the current device\n// key and address.", "generated": "// String returns a human-readable representation of this DiskSubresource object.\n// The format is \"subresource <path>\" where path can be either a full\n// filesystem path or just a name if it's in the same directory as the subresource. If\n// neither is available then '<unknown>' will be used"}
{"id": 2993, "code": "func hostNetworkSystemFromHostSystem(hs *object.HostSystem) (*object.HostNetworkSystem, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\treturn hs.ConfigManager().NetworkSystem(ctx)\n}", "reference": "// hostNetworkSystemFromHostSystem locates a HostNetworkSystem from a specified\n// HostSystem.", "generated": "// HostNetworkSystem returns the network system for this host from its\n// configuration manager. This is used to get the current state of the\n// network system in case it has changed since last time we checked.\n//\n// If there was no previous check then return nil. The caller must ensure that\n// they do"}
{"id": 3011, "code": "func (b *EnvironmentBrowser) QueryConfigOptionDescriptor(ctx context.Context) ([]types.VirtualMachineConfigOptionDescriptor, error) {\n\treq := types.QueryConfigOptionDescriptor{\n\t\tThis: b.Reference(),\n\t}\n\tres, err := methods.QueryConfigOptionDescriptor(ctx, b.Client(), &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn res.Returnval, nil\n}", "reference": "// QueryConfigOptionDescriptor returns a list the list of ConfigOption keys\n// available on the environment that this browser targets. The keys can be used\n// as query options for DefaultDevices and other functions, facilitating the\n// specification of results specific to a certain VM version.", "generated": "// QueryConfigOptionDescriptor returns virtual machine configuration option descriptors for this environment browser.\n//\n// This method is used to get information about all available options that can be configured in the current environment,\n// such as CPU architecture or memory size. The returned list contains only those options which have been explicitly set by\n// the user"}
{"id": 3033, "code": "func lookupAddrs(svc *compute.Service, project, zone, tag string) ([]string, error) {\n\tvar addrs []string\n\tf := func(page *compute.InstanceList) error {\n\t\tfor _, v := range page.Items {\n\t\t\tif len(v.NetworkInterfaces) == 0 || v.NetworkInterfaces[0].NetworkIP == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor _, t := range v.Tags.Items {\n\t\t\t\tif t == tag {\n\t\t\t\t\taddrs = append(addrs, v.NetworkInterfaces[0].NetworkIP)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tcall := svc.Instances.List(project, zone)\n\tif err := call.Pages(oauth2.NoContext, f); err != nil {\n\t\treturn nil, err\n\t}\n\treturn addrs, nil\n}", "reference": "// lookupAddrs retrieves the private ip addresses of all instances in a given\n// project and zone which have a matching tag value.", "generated": "// Lookup addresses for instances in a given service that match a specific\n// network interface IP address or have a particular tag. The results will be\n// returned sorted by instance name. If no matching instances were found,\n// return an empty slice. This is useful when trying to find which VMs can\n// communicate"}
{"id": 3055, "code": "func virtualMachinesForTag(ctx context.Context, client *vSphereClient, id string) ([]*object.VirtualMachine, error) {\n\tlogger.Printf(\"[DEBUG] Locating all virtual machines under tag ID %q\", id)\n\n\tvar vms []*object.VirtualMachine\n\n\tobjs, err := client.TagsClient.ListAttachedObjects(ctx, id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor i, obj := range objs {\n\t\tswitch {\n\t\tcase obj.Type == nil || obj.ID == nil:\n\t\t\tlogger.Printf(\"[WARN] Discovered object at index %d has either no ID or type\", i)\n\t\t\tcontinue\n\t\tcase *obj.Type != \"VirtualMachine\":\n\t\t\tlogger.Printf(\"[DEBUG] Discovered object ID %q is not a virutal machine\", *obj.ID)\n\t\t\tcontinue\n\t\t}\n\t\tvm, err := virtualMachineFromMOID(ctx, client.VimClient, *obj.ID)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error locating virtual machine with ID %q: %s\", *obj.ID, err)\n\t\t}\n\t\tvms = append(vms, vm)\n\t}\n\n\tlogger.Printf(\"[DEBUG] Discovered virtual machines: %s\", virtualMachineNames(vms))\n\treturn vms, nil\n}", "reference": "// virtualMachinesForTag discovers all of the virtual machines that match a\n// specific tag ID and returns their higher level helper objects.", "generated": "// virtualMachinesForTag returns all virtual machines that have been attached to this VM.\n//\n// This method will return any virtual machines which were created by attaching them directly to this VM,\n// but it may also include other virtual machines if they share the same parent folder (i.e., their root directory).\n//\n//"}
{"id": 3071, "code": "func (ctx *Context) RemoteAddr() string {\n\taddr := ctx.Req.Header.Get(\"X-Real-IP\")\n\tif len(addr) == 0 {\n\t\taddr = ctx.Req.Header.Get(\"X-Forwarded-For\")\n\t\tif addr == \"\" {\n\t\t\taddr = ctx.Req.RemoteAddr\n\t\t\tif i := strings.LastIndex(addr, \":\"); i > -1 {\n\t\t\t\taddr = addr[:i]\n\t\t\t}\n\t\t}\n\t}\n\treturn addr\n}", "reference": "// RemoteAddr returns more real IP address.", "generated": "// Returns remote address from headers or request if no header is found.\n//\n// If X-Real-IP is present it will be used otherwise X-Forwarded-For,\n// then the IP in the Request's RemoteAddress field. The returned value may\n// have trailing colons removed for consistency across different systems"}
{"id": 3085, "code": "func (ctx *Context) GetCookie(name string) string {\n\tcookie, err := ctx.Req.Cookie(name)\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\tval, _ := url.QueryUnescape(cookie.Value)\n\treturn val\n}", "reference": "// GetCookie returns given cookie value from request header.", "generated": "// GetCookie returns cookie value for given name from request context.\n//\n// If no such cookie is found in request headers it will return empty string.\n// This method should be used only when cookies are sent over HTTP protocol,\n// otherwise use GetHeader to get values from header field \"Set-Cookie\". See\n//"}
{"id": 3090, "code": "func (ctx *Context) GetSecureCookie(key string) (string, bool) {\n\treturn ctx.GetSuperSecureCookie(defaultCookieSecret, key)\n}", "reference": "// GetSecureCookie returns given cookie value from request header with default secret string.", "generated": "// GetSecureCookie returns the value for the given cookie name from\n// super secure cookies.\n//\n// If no such cookie exists it will return nil along with false to indicate that\n// this is not a super secure cookie. The default secret used here can be changed by calling\n// SetDefaultSecureSecret() method"}
{"id": 3092, "code": "func (ctx *Context) GetSuperSecureCookie(secret, name string) (string, bool) {\n\tval := ctx.GetCookie(name)\n\tif val == \"\" {\n\t\treturn \"\", false\n\t}\n\n\ttext, err := hex.DecodeString(val)\n\tif err != nil {\n\t\treturn \"\", false\n\t}\n\n\tkey := pbkdf2.Key([]byte(secret), []byte(secret), 1000, 16, sha256.New)\n\ttext, err = com.AESGCMDecrypt(key, text)\n\treturn string(text), err == nil\n}", "reference": "// GetSuperSecureCookie returns given cookie value from request header with secret string.", "generated": "// GetSuperSecureCookie returns super secure cookie from context.\n//\n// The returned value is only valid for one request to this server. If it's used in another request,\n// it will be invalid because its signature has been lost during transmission. It should never be sent over HTTP or HTTPS.\n//\n// This method can"}
{"id": 3127, "code": "func (app *App) ReloadConfig() error {\n\tapp.Lock()\n\tdefer app.Unlock()\n\n\tvar err error\n\tif err = app.configure(); err != nil {\n\t\treturn err\n\t}\n\n\truntime.GOMAXPROCS(app.Config.Common.MaxCPU)\n\n\tapp.Cache.SetMaxSize(app.Config.Cache.MaxSize)\n\tapp.Cache.SetWriteStrategy(app.Config.Cache.WriteStrategy)\n\tapp.Cache.SetTagsEnabled(app.Config.Tags.Enabled)\n\n\tif app.Persister != nil {\n\t\tapp.Persister.Stop()\n\t\tapp.Persister = nil\n\t}\n\n\tif app.Tags != nil {\n\t\tapp.Tags.Stop()\n\t\tapp.Tags = nil\n\t}\n\n\tapp.startPersister()\n\n\tif app.Collector != nil {\n\t\tapp.Collector.Stop()\n\t\tapp.Collector = nil\n\t}\n\n\tapp.Collector = NewCollector(app)\n\n\treturn nil\n}", "reference": "// ReloadConfig reloads some settings from config", "generated": "// ReloadConfig reloads all configuration settings for this application.\n//\n// This is typically called when the config file changes or other external factors cause the\n// current state to be invalid. It will stop any currently running collectors/persisters,\n// reset their states, then restart them in order to ensure they're using the"}
{"id": 3133, "code": "func (d *Duration) UnmarshalText(text []byte) error {\n\tvar err error\n\td.Duration, err = time.ParseDuration(string(text))\n\treturn err\n}", "reference": "// UnmarshalText from TOML", "generated": "// UnmarshalText implements the unmarshaling interface for Duration.\n//\n// The text is expected to be in the format \"Xs\", where X is a number between 0 and 9999,\n// or \"Yms\" where Y is a number between 1 and 59, or \"Zh\""}
{"id": 3147, "code": "func (p *Points) Eq(other *Points) bool {\n\tif other == nil {\n\t\treturn false\n\t}\n\tif p.Metric != other.Metric {\n\t\treturn false\n\t}\n\tif p.Data == nil && other.Data == nil {\n\t\treturn true\n\t}\n\tif (p.Data == nil || other.Data == nil) && (p.Data != nil || other.Data != nil) {\n\t\treturn false\n\t}\n\tif len(p.Data) != len(other.Data) {\n\t\treturn false\n\t}\n\tfor i := 0; i < len(p.Data); i++ {\n\t\tif p.Data[i].Value != other.Data[i].Value {\n\t\t\treturn false\n\t\t}\n\t\tif p.Data[i].Timestamp != other.Data[i].Timestamp {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}", "reference": "// Eq points check", "generated": "// Eq checks if two points have equal metric value or both data is empty.\n//\n// If one point has non-empty data while another doesn't it returns false.\n//\n// It also considers timestamp to be equal for same values. This means that even\n// different timestamps can represent same time in this context. For example"}
{"id": 3152, "code": "func (app *App) Restore(storeFunc func(*points.Points), path string, rps int) {\n\tif rps > 0 {\n\t\tticker := persister.NewThrottleTicker(rps)\n\t\tdefer ticker.Stop()\n\n\t\tthrottledStoreFunc := func(p *points.Points) {\n\t\t\tfor i := 0; i < len(p.Data); i++ {\n\t\t\t\t<-ticker.C\n\t\t\t}\n\t\t\tstoreFunc(p)\n\t\t}\n\n\t\tapp.RestoreFromDir(path, throttledStoreFunc)\n\t} else {\n\t\tapp.RestoreFromDir(path, storeFunc)\n\t}\n}", "reference": "// Restore from dump.path", "generated": "// Restore restores points from directory to database.\n//\n// If rate limiting is enabled then it will throttle writes by the specified number of times per second,\n// otherwise it simply calls storeFunc for each point in dir. The default value for this parameter is zero which means no rate limiting is applied. This can be useful if"}
{"id": 3183, "code": "func (client *Client) CreateComment(handle, message string) (*Comment, error) {\n\tvar out reqComment\n\tcomment := Comment{Message: String(message)}\n\tif len(handle) > 0 {\n\t\tcomment.Handle = String(handle)\n\t}\n\tif err := client.doJsonRequest(\"POST\", \"/v1/comments\", &comment, &out); err != nil {\n\t\treturn nil, err\n\t}\n\treturn out.Comment, nil\n}", "reference": "// CreateComment adds a new comment to the system.", "generated": "// Creates a new comment for a given handle or commit hash.\n//\n// Returns the newly created comment if successful; otherwise returns an error. The returned comment is in JSON format. If no arguments were provided to this method, it will return all comments that have been made by the current user. This can be useful when"}
{"id": 3185, "code": "func (client *Client) EditComment(id int, handle, message string) error {\n\tcomment := Comment{Message: String(message)}\n\tif len(handle) > 0 {\n\t\tcomment.Handle = String(handle)\n\t}\n\treturn client.doJsonRequest(\"PUT\", fmt.Sprintf(\"/v1/comments/%d\", id),\n\t\t&comment, nil)\n}", "reference": "// EditComment changes the message and possibly handle of a particular comment.", "generated": "// EditComment edits the given comment by updating its content or adding\n// additional information to it.\n//\n// The edit operation is only possible if the user has permission to do so,\n// which means they must be either the author of the commit that this comment was added for, or have been granted permissions to modify comments"}
{"id": 3254, "code": "func (c *Check) GetTimestampOk() (string, bool) {\n\tif c == nil || c.Timestamp == nil {\n\t\treturn \"\", false\n\t}\n\treturn *c.Timestamp, true\n}", "reference": "// GetTimestampOk returns a tuple with the Timestamp field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetTimestampOk returns timestamp if it is set otherwise return empty string.\n//\n// This method should be called only once in lifetime of Check object to avoid race condition when multiple goroutines access same check instance concurrently. If this call fails then result will always be false regardless of actual value of Timestamp field. In case of"}
{"id": 3256, "code": "func (c *Comment) GetRelatedId() int {\n\tif c == nil || c.RelatedId == nil {\n\t\treturn 0\n\t}\n\treturn *c.RelatedId\n}", "reference": "// GetRelatedId returns the RelatedId field if non-nil, zero value otherwise.", "generated": "// GetRelatedId returns related id for this comment.\n//\n// If there is no relation to other comments then it will return zero. This field can be set by user when creating new comment or from database if exists in db. It's used only for internal purposes like sorting comments. For example, if we have two"}
{"id": 3292, "code": "func (d *Downtime) GetRecurrence() Recurrence {\n\tif d == nil || d.Recurrence == nil {\n\t\treturn Recurrence{}\n\t}\n\treturn *d.Recurrence\n}", "reference": "// GetRecurrence returns the Recurrence field if non-nil, zero value otherwise.", "generated": "// GetRecurrence returns the recurrence for this downtime event.\n//\n// If no recurrence is set then it will return default value which is 1 day per week,\n// every Sunday at midnight. This means that if there's only one occurrence in the\n// schedule, it'll be scheduled to run once a week."}
{"id": 3293, "code": "func (d *Downtime) GetRecurrenceOk() (Recurrence, bool) {\n\tif d == nil || d.Recurrence == nil {\n\t\treturn Recurrence{}, false\n\t}\n\treturn *d.Recurrence, true\n}", "reference": "// GetRecurrenceOk returns a tuple with the Recurrence field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetRecurrenceOk returns whether there is data available for this field.\n// If no value exists or it's zero, it will return false. Otherwise,\n// it will return the actual value. You can use IsSet to check if the\n// returned value has been set before calling Get(). The returned value must"}
{"id": 3310, "code": "func (g *Graph) GetDefinition() GraphDefinition {\n\tif g == nil || g.Definition == nil {\n\t\treturn GraphDefinition{}\n\t}\n\treturn *g.Definition\n}", "reference": "// GetDefinition returns the Definition field if non-nil, zero value otherwise.", "generated": "// GetDefinition returns the graph definition for this node in the graph.\n//\n// If there is no graph defined then it will return an empty GraphDefinition object. This can be used to check if a graph has been created or not. The default value returned by NewNode is an empty GraphDefinition object. It's up"}
{"id": 3320, "code": "func (g *GraphDefinitionMarker) GetValOk() (json.Number, bool) {\n\tif g == nil || g.Val == nil {\n\t\treturn \"\", false\n\t}\n\treturn *g.Val, true\n}", "reference": "// GetValOk returns a tuple with the Val field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetValOk returns val if it is ok to get its value from graph definition marker.\n//\n// If there's no error or invalid data in Val then return val along with true,\n// otherwise return empty json number and false. This method should be called only once for each GraphDef. It will set flag to"}
{"id": 3325, "code": "func (g *GraphDefinitionRequest) GetStacked() bool {\n\tif g == nil || g.Stacked == nil {\n\t\treturn false\n\t}\n\treturn *g.Stacked\n}", "reference": "// GetStacked returns the Stacked field if non-nil, zero value otherwise.", "generated": "// GetStacked returns whether this graph definition is stacked or not.\n//\n// Stacked means that all nodes in the graph have been merged into one node,\n// which represents the entire stack. This can be useful for debugging purposes.\n// However, it's generally more efficient to use separate nodes per component if possible."}
{"id": 3343, "code": "func (h *HostActionMute) GetEndTime() string {\n\tif h == nil || h.EndTime == nil {\n\t\treturn \"\"\n\t}\n\treturn *h.EndTime\n}", "reference": "// GetEndTime returns the EndTime field if non-nil, zero value otherwise.", "generated": "// GetEndTime returns the end time for this host action mute in ISO 8601 format.\n//\n// If no end date has been set then it will return \"0000-00-00T00:00:00Z\". This is used to indicate that there is no end date specified yet. The caller can"}
{"id": 3366, "code": "func (i *IntegrationGCPCreateRequest) GetClientX509CertURL() string {\n\tif i == nil || i.ClientX509CertURL == nil {\n\t\treturn \"\"\n\t}\n\treturn *i.ClientX509CertURL\n}", "reference": "// GetClientX509CertURL returns the ClientX509CertURL field if non-nil, zero value otherwise.", "generated": "// GetClientX509CertURL returns client X509 certificate URL if set in IntegrationGCPCreateRequest. Otherwise it returns empty string.\n// Set method is used to get or set ClientX509CertURL property. If new value assigned then previous one will be discarded. Use Assign method instead for assigning multiple values at"}
{"id": 3375, "code": "func (i *IntegrationGCPCreateRequest) HasPrivateKeyID() bool {\n\tif i != nil && i.PrivateKeyID != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasPrivateKeyID returns a boolean if a field has been set.", "generated": "// HasPrivateKeyID returns whether this request has PrivateKeyID set.\n//\n// This is used to determine if we need to use the private key for signing requests,\n// or just use the public certificate. If it's present then we will be using the\n// private key; otherwise we'll only be using the public"}
{"id": 3394, "code": "func (m *MetricMetadata) HasStatsdInterval() bool {\n\tif m != nil && m.StatsdInterval != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasStatsdInterval returns a boolean if a field has been set.", "generated": "// HasStatsdInterval returns whether this metric has statsd interval set.\n//\n// This is used to determine if we need to send metrics via statsd or not. If it's\n// empty then no statsd will be sent for that metric. It can also be zero which means\n// there was never any"}
{"id": 3423, "code": "func (o *Options) GetLockedOk() (bool, bool) {\n\tif o == nil || o.Locked == nil {\n\t\treturn false, false\n\t}\n\treturn *o.Locked, true\n}", "reference": "// GetLockedOk returns a tuple with the Locked field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetLockedOk returns whether this option is locked or unlocked.\n//\n// If it's locked then all other options will be ignored when set,\n// because they're effectively disabled by being overridden in\n// the lock.  This can help prevent unexpected changes to\n// configuration if there are conflicting settings that need to"}
{"id": 3431, "code": "func (o *Options) GetQueryConfig() QueryConfig {\n\tif o == nil || o.QueryConfig == nil {\n\t\treturn QueryConfig{}\n\t}\n\treturn *o.QueryConfig\n}", "reference": "// GetQueryConfig returns the QueryConfig field if non-nil, zero value otherwise.", "generated": "// GetQueryConfig returns the query config for this options object.\n//\n// If no query config is set in the Options struct then it will return default values. This can be used to override any defaults that may have been applied when creating the client. The returned value should always contain at least one field: \"query\"."}
{"id": 3444, "code": "func (o *Options) GetThresholdWindowsOk() (ThresholdWindows, bool) {\n\tif o == nil || o.ThresholdWindows == nil {\n\t\treturn ThresholdWindows{}, false\n\t}\n\treturn *o.ThresholdWindows, true\n}", "reference": "// GetThresholdWindowsOk returns a tuple with the ThresholdWindows field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetThresholdWindowsOk returns value of ThresholdWindows field if it is set, zero value otherwise.\n// This method has no effect when IsSetThresholdWindows is false. If this method returns a non-zero value,\n// then the structure must be in one of its three possible states: {Zero(), SetThresholdWindows(false"}
{"id": 3465, "code": "func (r *Recurrence) GetUntilDateOk() (int, bool) {\n\tif r == nil || r.UntilDate == nil {\n\t\treturn 0, false\n\t}\n\treturn *r.UntilDate, true\n}", "reference": "// GetUntilDateOk returns a tuple with the UntilDate field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetUntilDateOk returns whether there is data available for this field.\n//\n// If it's present then its value will be returned in the second return argument,\n// otherwise zero will be returned in that position. The first return value indicates\n// if the date was successfully retrieved from the database or not. It can"}
{"id": 3475, "code": "func (r *reqComment) HasComment() bool {\n\tif r != nil && r.Comment != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasComment returns a boolean if a field has been set.", "generated": "// HasComment returns whether this request has any comments associated.\n//\n// This is used to determine if we need to send a \"comment\" field in our\n// response body or not. If there's no comment then it will be empty so that\n// the server can handle it correctly. We don't want to"}
{"id": 3483, "code": "func (r *reqGetTags) GetTagsOk() (TagMap, bool) {\n\tif r == nil || r.Tags == nil {\n\t\treturn TagMap{}, false\n\t}\n\treturn *r.Tags, true\n}", "reference": "// GetTagsOk returns a tuple with the Tags field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetTagsOk returns tags if they exist otherwise it will return empty tag map.\n//\n// This is used to check whether there were any errors in parsing the request body or\n// if the server returned no data for this endpoint. If there was an error then we can't\n// use the tags so we just"}
{"id": 3485, "code": "func (r *Rule) GetThreshold() json.Number {\n\tif r == nil || r.Threshold == nil {\n\t\treturn \"\"\n\t}\n\treturn *r.Threshold\n}", "reference": "// GetThreshold returns the Threshold field if non-nil, zero value otherwise.", "generated": "// GetThreshold returns threshold value for this rule. If it is set to 0,\n// then no limit will be applied. Otherwise, if it's greater than zero,\n// then all requests that exceed the specified number of concurrent connections\n// will return a \"429 Too Many Requests\" error. The default value is"}
{"id": 3492, "code": "func (s *Screenboard) GetSharedOk() (bool, bool) {\n\tif s == nil || s.Shared == nil {\n\t\treturn false, false\n\t}\n\treturn *s.Shared, true\n}", "reference": "// GetSharedOk returns a tuple with the Shared field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetShared returns whether this screen is shared or not.\n//\n// If it's shared then both fields will be set to true. Otherwise they'll be\n// false. The second field indicates that we're currently in edit mode for\n// this screen. This can only happen if there's another user editing at the"}
{"id": 3495, "code": "func (s *Series) GetAggrOk() (string, bool) {\n\tif s == nil || s.Aggr == nil {\n\t\treturn \"\", false\n\t}\n\treturn *s.Aggr, true\n}", "reference": "// GetAggrOk returns a tuple with the Aggr field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetAggrOk returns whether Aggregation is enabled for this series.\n//\n// Returns: A tuple containing the aggregation type if it's set,\n//          or \"\" otherwise; also indicates that the value was found in memory. If\n//          the value wasn't found in memory but could be retrieved from disk,"}
{"id": 3518, "code": "func (s *SyntheticsDevice) GetIsMobileOk() (bool, bool) {\n\tif s == nil || s.IsMobile == nil {\n\t\treturn false, false\n\t}\n\treturn *s.IsMobile, true\n}", "reference": "// GetIsMobileOk returns a tuple with the IsMobile field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetIsMobileOk returns whether this device is mobile or not.\n//\n// Returns: A boolean indicating if it's mobile, along with a flag to indicate that we're sure about our answer. If unsure,\n//          then the second value will be set to false. This can happen when there isn't enough information"}
{"id": 3522, "code": "func (s *SyntheticsDevice) HasUserAgent() bool {\n\tif s != nil && s.UserAgent != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasUserAgent returns a boolean if a field has been set.", "generated": "// HasUserAgent returns whether this device has user agent information set.\n//\n// This is used to determine if we should use the default or custom User Agent for\n// all devices in our application. If it's set then we will always use that one,\n// otherwise we'll fall back to using the default. We"}
{"id": 3534, "code": "func (s *SyntheticsOptions) HasMinLocationFailed() bool {\n\tif s != nil && s.MinLocationFailed != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasMinLocationFailed returns a boolean if a field has been set.", "generated": "// HasMinLocationFailed returns whether MinLocationFailed is set in this options object.\n//\n// This field indicates that at least one synthetic location failed to be created or updated successfully during the last run. If it's set,\n// then all subsequent runs will fail until either MinLocationSuccessCount or MaxRunAttempts is reached"}
{"id": 3541, "code": "func (s *SyntheticsRequest) GetMethod() string {\n\tif s == nil || s.Method == nil {\n\t\treturn \"\"\n\t}\n\treturn *s.Method\n}", "reference": "// GetMethod returns the Method field if non-nil, zero value otherwise.", "generated": "// GetMethod returns the method for this request. If no value is set it will return empty string.\n//\n// Methods: GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS, CONNECT, TRACE, COPY, MOVE, LOCK, PROPFIND, PROPPATCH, MKCOL, COMPARE, MER"}
{"id": 3548, "code": "func (s *SyntheticsTest) GetConfigOk() (SyntheticsConfig, bool) {\n\tif s == nil || s.Config == nil {\n\t\treturn SyntheticsConfig{}, false\n\t}\n\treturn *s.Config, true\n}", "reference": "// GetConfigOk returns a tuple with the Config field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetConfigOk returns whether config is ok for this test case or not.\n//\n// If it's ok then we return the config object itself along with a boolean value indicating that the config was successfully retrieved from the synthetics service. Otherwise,\n// we return default values to indicate failure. This method should be called after"}
{"id": 3551, "code": "func (s *SyntheticsTest) GetDeletedAtOk() (string, bool) {\n\tif s == nil || s.DeletedAt == nil {\n\t\treturn \"\", false\n\t}\n\treturn *s.DeletedAt, true\n}", "reference": "// GetDeletedAtOk returns a tuple with the DeletedAt field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetDeletedAt returns deleted at timestamp if present in synthetics object.\n//\n// Returns empty string and false when no such field is found or it's set to zero value. If returned values indicate that this test has been deleted then they should be used for further processing. Otherwise return error message indicating that this test was"}
{"id": 3577, "code": "func (t *ThresholdCount) GetTimeAggregator() string {\n\tif t == nil || t.TimeAggregator == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.TimeAggregator\n}", "reference": "// GetTimeAggregator returns the TimeAggregator field if non-nil, zero value otherwise.", "generated": "// GetTimeAggregator returns time aggregator for threshold count metric.\n//\n// If no time aggregator is set then it will return empty string. Otherwise,\n// it will return value from TimeAggregator field. This method should be used to get\n// time aggregator that was passed when ThresholdCount object was created or updated."}
{"id": 3579, "code": "func (t *ThresholdCount) HasTimeAggregator() bool {\n\tif t != nil && t.TimeAggregator != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasTimeAggregator returns a boolean if a field has been set.", "generated": "// HasTimeAggregator returns whether this Threshold has time aggregator.\n//\n// Time aggregators can be used to aggregate multiple thresholds into one,\n// which is useful for metrics that have many values over different times.\n//\n// For example, if we want to track CPU usage at 1 second intervals, then\n// we"}
{"id": 3582, "code": "func (t *ThresholdCount) HasUnknown() bool {\n\tif t != nil && t.Unknown != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasUnknown returns a boolean if a field has been set.", "generated": "// HasUnknown returns whether this threshold has unknown values.\n//\n// This is used to determine if we need to use the default value for the metric,\n// or if it's safe to return 0. It will be set when there are no known thresholds\n// defined in the configuration file. If there are any other"}
{"id": 3583, "code": "func (t *ThresholdCount) GetWarning() json.Number {\n\tif t == nil || t.Warning == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.Warning\n}", "reference": "// GetWarning returns the Warning field if non-nil, zero value otherwise.", "generated": "// GetWarning returns threshold warning value if exists otherwise return empty string.\n//\n// @author: Saurabh Singh <saurabh.singh@infiniscale.com> 2017-01-03. All Rights Reserved. Infiniscale Inc. Copyright 2016-2017 Infin"}
{"id": 3589, "code": "func (t *ThresholdWindows) GetRecoveryWindow() string {\n\tif t == nil || t.RecoveryWindow == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.RecoveryWindow\n}", "reference": "// GetRecoveryWindow returns the RecoveryWindow field if non-nil, zero value otherwise.", "generated": "// GetRecoveryWindow returns the recovery window for this threshold.\n//\n// The recovery window is used to determine when a node should be considered recovered after it has been down for some time. If no value is set,\n// then there will be no recovery period. This field can only be changed by setting the Threshold object"}
{"id": 3597, "code": "func (t *TileDefRequest) HasQueryType() bool {\n\tif t != nil && t.QueryType != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasQueryType returns a boolean if a field has been set.", "generated": "// HasQueryType returns whether this request has query type set.\n//\n// This is used to determine if we need to send additional data in the request body or just use it for filtering purposes only. If there's no QueryType then we can't do anything else than filter by default. We don't want to add"}
{"id": 3598, "code": "func (t *TileDefRequest) GetTextFilter() string {\n\tif t == nil || t.TextFilter == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.TextFilter\n}", "reference": "// GetTextFilter returns the TextFilter field if non-nil, zero value otherwise.", "generated": "// GetTextFilter returns text filter value from TileDefRequest object; never return nil. If no TextFilter is set then this method will always return empty string. Nil pointer assertion is performed during first call to this method. After that it's safe to call it without checking for nil. This method only has getter functionality"}
{"id": 3604, "code": "func (t *TimeRange) GetLive() bool {\n\tif t == nil || t.Live == nil {\n\t\treturn false\n\t}\n\treturn *t.Live\n}", "reference": "// GetLive returns the Live field if non-nil, zero value otherwise.", "generated": "// GetLive returns true if this time range is live or has been updated recently.\n//\n// This method should be called only once per second to avoid unnecessary updates,\n// which can lead to performance issues in large-scale applications. If it's set\n// to true for more than one second, then all subsequent calls will"}
{"id": 3606, "code": "func (t *TimeRange) HasLive() bool {\n\tif t != nil && t.Live != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasLive returns a boolean if a field has been set.", "generated": "// HasLive returns whether this time range has live data available.\n//\n// This is only applicable for TimeRanges that have been created from a LiveSource,\n// which means they will always be up to date if there's any live data available in the source.\n// If no live data exists then it simply checks if the"}
{"id": 3613, "code": "func (t *TimeseriesRequestStyle) GetLineType() string {\n\tif t == nil || t.LineType == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.LineType\n}", "reference": "// GetLineType returns the LineType field if non-nil, zero value otherwise.", "generated": "// GetLineType returns the line type for this request style.\n//\n// The default is \"line\". If set to \"\" or nil it will be ignored by the client. This field can only be used when sending requests that require a specific line format. For example, if using the \"timeseries\" endpoint, then"}
{"id": 3626, "code": "func (t *TraceServiceDefinition) GetShowBreakdownOk() (bool, bool) {\n\tif t == nil || t.ShowBreakdown == nil {\n\t\treturn false, false\n\t}\n\treturn *t.ShowBreakdown, true\n}", "reference": "// GetShowBreakdownOk returns a tuple with the ShowBreakdown field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetShowBreakdownOk returns whether to show breakdowns in trace service definition.\n//\n// This is used by the client when calling TraceServiceDefinition.Get(). It will return\n// true if ShowBreakdown was set to true or false otherwise. The second value returned\n// indicates that this field has been successfully read"}
{"id": 3631, "code": "func (t *TraceServiceDefinition) GetShowErrors() bool {\n\tif t == nil || t.ShowErrors == nil {\n\t\treturn false\n\t}\n\treturn *t.ShowErrors\n}", "reference": "// GetShowErrors returns the ShowErrors field if non-nil, zero value otherwise.", "generated": "// GetShowErrors returns whether to show errors in trace output.\n//\n// This is used by the tracing service when it's configured to display error messages for each span that has an error. If this option is set,\n// then all spans will be shown even if they have no data or other issues. Otherwise only spans"}
{"id": 3702, "code": "func (w *Widget) HasMustShowHits() bool {\n\tif w != nil && w.MustShowHits != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasMustShowHits returns a boolean if a field has been set.", "generated": "// MustShowHits returns whether this widget must show hits or not.\n//\n// If it is set to true then all widgets that have Hits will be shown,\n// otherwise only those which do not have Hits will be shown.  This can also\n// be used in conjunction with other flags like HideEmptyResults to control"}
{"id": 3703, "code": "func (w *Widget) GetMustShowLatency() bool {\n\tif w == nil || w.MustShowLatency == nil {\n\t\treturn false\n\t}\n\treturn *w.MustShowLatency\n}", "reference": "// GetMustShowLatency returns the MustShowLatency field if non-nil, zero value otherwise.", "generated": "// GetMustShowLatency returns whether this widget must show latency information.\n//\n// This is used to determine if we need to display latency in the UI or not,\n// based on the current state of the system. If it's true then we will always\n// display latency info for all widgets that have MustShow"}
{"id": 3726, "code": "func (w *Widget) HasTileDef() bool {\n\tif w != nil && w.TileDef != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasTileDef returns a boolean if a field has been set.", "generated": "// HasTileDef returns whether this widget has a tile definition set.\n//\n// This is used to determine if we need to render tiles or not. If it's empty,\n// then no rendering will be done for that particular widget. The default value\n// is always false because widgets don't have any tile definitions by"}
{"id": 3747, "code": "func (w *WidgetConditionalFormat) HasImageUrl() bool {\n\tif w != nil && w.ImageUrl != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasImageUrl returns a boolean if a field has been set.", "generated": "// HasImageUrl returns whether this widget has an image URL set.\n//\n// This is used to determine if we need to render an image for this cell,\n// or just use the default background color.  If there's no image url then\n// it will be rendered using the default background color.  The image can"}
{"id": 3762, "code": "func (t *templateData) addArrayType(x *ast.ArrayType, receiverType, fieldName string) {\n\t// TODO: should we make this dynamic? Could handle more cases than string only\n\tvar eltType string\n\tswitch elt := x.Elt.(type) {\n\tcase *ast.Ident:\n\t\teltType = elt.String()\n\tdefault:\n\t\tlogf(\"addArrayType: type %q, field %q: unknown element type: %T %+v; skipping.\", receiverType, fieldName, elt, elt)\n\t\treturn\n\t}\n\n\tt.Accessors = append(t.Accessors, newAccessor(receiverType, fieldName, \"[]\"+eltType, \"nil\"))\n}", "reference": "// addArrayType adds an accessor for a array type for a given receiver and field", "generated": "// AddArray adds support for array types to template data.\n//\n// This is currently limited to strings because it's easier to implement that way,\n// but could be made more general if needed. The idea here is to create accessor objects\n// which can then be used in templates like any other value. For example:"}
{"id": 3764, "code": "func (client *Client) UpdateDowntime(downtime *Downtime) error {\n\treturn client.doJsonRequest(\"PUT\", fmt.Sprintf(\"/v1/downtime/%d\", *downtime.Id),\n\t\tdowntime, nil)\n}", "reference": "// UpdateDowntime takes a downtime that was previously retrieved through some method\n// and sends it back to the server.", "generated": "// UpdateDowntime updates downtime information for given Id.\n//\n// Returns error if update fails or returns updated Downtime object\n// otherwise. If no errors occur then it will return nil. The returned value is always non-nil,\n// even in case of success. This allows caller to check whether request was successful"}
{"id": 3768, "code": "func (k *APIKey) UnmarshalJSON(data []byte) error {\n\ttype Alias APIKey\n\taux := &struct {\n\t\tCreated *string `json:\"created,omitempty\"`\n\t\t*Alias\n\t}{\n\t\tAlias: (*Alias)(k),\n\t}\n\tif err := json.Unmarshal(data, &aux); err != nil {\n\t\treturn err\n\t}\n\n\tif created, err := time.Parse(createdTimeLayout, *aux.Created); err != nil {\n\t\treturn err\n\t} else {\n\t\tk.Created = &created\n\t}\n\n\treturn nil\n}", "reference": "// UnmarshalJSON is a custom method for handling datetime unmarshalling", "generated": "// UnmarshalJSON implements the unmarshaling interface for APIKey.\n//\n// This is used to convert JSON data into an API key object. The \"created\" field must be present in order to successfully unmarshal this struct. If it's missing,\n// then the returned value will contain nil. It can also happen"}
{"id": 3770, "code": "func (client *Client) GetAPIKey(key string) (*APIKey, error) {\n\tvar out reqAPIKey\n\tif err := client.doJsonRequest(\"GET\", fmt.Sprintf(\"/v1/api_key/%s\", key), nil, &out); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn out.APIKey, nil\n}", "reference": "// GetAPIKey returns a single API key or error on failure", "generated": "// GetAPIKey retrieves information about API keys for this instance.\n//\n// Returns: The retrieved API key or an error if retrieval failed. If no such key exists,\n//          returns nil. This method is used to retrieve information from the server-side\n//          database that stores all available API keys. It's recommended"}
{"id": 3791, "code": "func (t *bufferedObjectStream) WriteObject(obj interface{}) error {\n\tt.mu.Lock()\n\tdefer t.mu.Unlock()\n\tif err := t.codec.WriteObject(t.w, obj); err != nil {\n\t\treturn err\n\t}\n\treturn t.w.Flush()\n}", "reference": "// WriteObject implements ObjectStream.", "generated": "// WriteObject writes object to stream. If there is no writer available,\n// it will block until one becomes available or until timeout occurs.\n//\n// This method should be used when writing objects that do not have any\n// associated metadata such as headers. When using this method for large\n// objects, consider buffering them"}
{"id": 3794, "code": "func (r *Request) SetMeta(v interface{}) error {\n\tb, err := json.Marshal(v)\n\tif err != nil {\n\t\treturn err\n\t}\n\tr.Meta = (*json.RawMessage)(&b)\n\treturn nil\n}", "reference": "// SetMeta sets r.Meta to the JSON representation of v. If JSON\n// marshaling fails, it returns an error.", "generated": "// SetMeta sets meta data for this request. This is used to store metadata that can be accessed later by the client.\n//\n// Note: The Meta field will only work if it's set before sending the request. If it's sent after the request has been made,\n// then any changes won't take effect until"}
{"id": 3795, "code": "func (r *Response) SetResult(v interface{}) error {\n\tb, err := json.Marshal(v)\n\tif err != nil {\n\t\treturn err\n\t}\n\tr.Result = (*json.RawMessage)(&b)\n\treturn nil\n}", "reference": "// SetResult sets r.Result to the JSON representation of v. If JSON\n// marshaling fails, it returns an error.", "generated": "// SetResult sets result field to v. If there is any JSON encoding errors,\n// it returns them. Otherwise, it returns nil.\n//\n// Note: This method should be used only when setting raw data in Response object.\n// It's recommended to use r.SetRawJSON() instead for better safety. See documentation"}
{"id": 3804, "code": "func PickID(id ID) CallOption {\n\treturn callOptionFunc(func(r *Request) error {\n\t\tr.ID = id\n\t\treturn nil\n\t})\n}", "reference": "// PickID returns a call option which sets the ID on a request. Care must be\n// taken to ensure there are no conflicts with any previously picked ID, nor\n// with the default sequence ID.", "generated": "// PickID sets the request's ID to the given value.\n//\n// This option is used when sending requests that require an ID,\n// such as creating or updating resources in some APIs. The default\n// value for this option will be set by the client if no other\n// options have been specified. If multiple"}
{"id": 3863, "code": "func (c *Cursor) Backspace() {\n\ta := c.input\n\ti := c.Position\n\tif i == 0 {\n\t\t// Shrug\n\t\treturn\n\t}\n\tif i == len(a) {\n\t\tc.input = a[:i-1]\n\t} else {\n\t\tc.input = append(a[:i-1], a[i:]...)\n\t}\n\t// now it's pointing to the i+1th element\n\tc.Move(-1)\n}", "reference": "// Backspace removes the rune that precedes the cursor\n//\n// It handles being at the beginning or end of the row, and moves the cursor to\n// the appropriate position.", "generated": "// Backspace moves cursor back one character in input string.\n//\n// If there is no characters before current position then nothing happens,\n// otherwise we remove last char from input string and move cursor backwards."}
{"id": 3870, "code": "func (p *Package) Type(name string) (t *Type) {\n\tt, _ = p.Members[name].(*Type)\n\treturn\n}", "reference": "// Type returns the package-level type of the specified name,\n// or nil if not found.\n//", "generated": "// Type returns type for given name in package members. If member is not found,\n// it will return nil. This method should be used only when we know that there's\n// at least one member by this name. Otherwise use Members() to get all members.\n//\n// Usage: t := p.Type(\"My"}
{"id": 3892, "code": "func (b *builder) switchStmt(fn *Function, s *ast.SwitchStmt, label *lblock) {\n\t// We treat SwitchStmt like a sequential if-else chain.\n\t// Multiway dispatch can be recovered later by ssautil.Switches()\n\t// to those cases that are free of side effects.\n\tif s.Init != nil {\n\t\tb.stmt(fn, s.Init)\n\t}\n\tvar tag Value = vTrue\n\tif s.Tag != nil {\n\t\ttag = b.expr(fn, s.Tag)\n\t}\n\tdone := fn.newBasicBlock(\"switch.done\")\n\tif label != nil {\n\t\tlabel._break = done\n\t}\n\t// We pull the default case (if present) down to the end.\n\t// But each fallthrough label must point to the next\n\t// body block in source order, so we preallocate a\n\t// body block (fallthru) for the next case.\n\t// Unfortunately this makes for a confusing block order.\n\tvar dfltBody *[]ast.Stmt\n\tvar dfltFallthrough *BasicBlock\n\tvar fallthru, dfltBlock *BasicBlock\n\tncases := len(s.Body.List)\n\tfor i, clause := range s.Body.List {\n\t\tbody := fallthru\n\t\tif body == nil {\n\t\t\tbody = fn.newBasicBlock(\"switch.body\") // first case only\n\t\t}\n\n\t\t// Preallocate body block for the next case.\n\t\tfallthru = done\n\t\tif i+1 < ncases {\n\t\t\tfallthru = fn.newBasicBlock(\"switch.body\")\n\t\t}\n\n\t\tcc := clause.(*ast.CaseClause)\n\t\tif cc.List == nil {\n\t\t\t// Default case.\n\t\t\tdfltBody = &cc.Body\n\t\t\tdfltFallthrough = fallthru\n\t\t\tdfltBlock = body\n\t\t\tcontinue\n\t\t}\n\n\t\tvar nextCond *BasicBlock\n\t\tfor _, cond := range cc.List {\n\t\t\tnextCond = fn.newBasicBlock(\"switch.next\")\n\t\t\t// TODO(adonovan): opt: when tag==vTrue, we'd\n\t\t\t// get better code if we use b.cond(cond)\n\t\t\t// instead of BinOp(EQL, tag, b.expr(cond))\n\t\t\t// followed by If.  Don't forget conversions\n\t\t\t// though.\n\t\t\tcond := emitCompare(fn, token.EQL, tag, b.expr(fn, cond), cond.Pos())\n\t\t\temitIf(fn, cond, body, nextCond)\n\t\t\tfn.currentBlock = nextCond\n\t\t}\n\t\tfn.currentBlock = body\n\t\tfn.targets = &targets{\n\t\t\ttail:         fn.targets,\n\t\t\t_break:       done,\n\t\t\t_fallthrough: fallthru,\n\t\t}\n\t\tb.stmtList(fn, cc.Body)\n\t\tfn.targets = fn.targets.tail\n\t\temitJump(fn, done)\n\t\tfn.currentBlock = nextCond\n\t}\n\tif dfltBlock != nil {\n\t\temitJump(fn, dfltBlock)\n\t\tfn.currentBlock = dfltBlock\n\t\tfn.targets = &targets{\n\t\t\ttail:         fn.targets,\n\t\t\t_break:       done,\n\t\t\t_fallthrough: dfltFallthrough,\n\t\t}\n\t\tb.stmtList(fn, *dfltBody)\n\t\tfn.targets = fn.targets.tail\n\t}\n\temitJump(fn, done)\n\tfn.currentBlock = done\n}", "reference": "// switchStmt emits to fn code for the switch statement s, optionally\n// labelled by label.\n//", "generated": "// switchStmt is similar to stmt but it's used specifically for switch statements.\n// It will create all necessary blocks and jump targets. The caller should then\n// call stmtList to add any additional statements before jumping out of the\n// current basic block. This ensures proper ordering of the control flow graph. In"}
{"id": 3913, "code": "func yaml_emitter_flush(emitter *yaml_emitter_t) bool {\n\tif emitter.write_handler == nil {\n\t\tpanic(\"write handler not set\")\n\t}\n\n\t// Check if the buffer is empty.\n\tif emitter.buffer_pos == 0 {\n\t\treturn true\n\t}\n\n\tif err := emitter.write_handler(emitter, emitter.buffer[:emitter.buffer_pos]); err != nil {\n\t\treturn yaml_emitter_set_writer_error(emitter, \"write error: \"+err.Error())\n\t}\n\temitter.buffer_pos = 0\n\treturn true\n}", "reference": "// Flush the output buffer.", "generated": "// Flush writes all remaining data to the underlying writer. If there's no more\n// data in the buffer, it returns immediately without doing anything. This method\n// should be called when the end of the YAML document has been reached or after\n// writing a final line (e.g., at EOF). It will"}
{"id": 3930, "code": "func TCPDialCheck(addr string, timeout time.Duration) Check {\n\treturn func() error {\n\t\tconn, err := net.DialTimeout(\"tcp\", addr, timeout)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn conn.Close()\n\t}\n}", "reference": "// TCPDialCheck returns a Check that checks TCP connectivity to the provided\n// endpoint.", "generated": "// TCPDialCheck returns a check that will close any open connections to the given address.\n//\n// This is useful for testing whether a connection can be established before attempting to use it,\n// which helps prevent false positives from tests where multiple goroutines attempt to connect at once."}
{"id": 3934, "code": "func NewMetricsHandler(registry prometheus.Registerer, namespace string) Handler {\n\treturn &metricsHandler{\n\t\thandler:   NewHandler(),\n\t\tregistry:  registry,\n\t\tnamespace: namespace,\n\t}\n}", "reference": "// NewMetricsHandler returns a healthcheck Handler that also exposes metrics\n// into the provided Prometheus registry.", "generated": "// NewMetricsHandler returns a metrics handler that registers all\n// metrics in the given registry under the specified namespace.\n//\n// This is useful for registering metrics from multiple sources into one\n// place. The returned handler will automatically register any new metrics\n// added to the registry after it's created. It also provides methods"}
{"id": 3938, "code": "func (p *Pinger) AddIP(ipaddr string) error {\n\taddr := net.ParseIP(ipaddr)\n\tif addr == nil {\n\t\treturn fmt.Errorf(\"%s is not a valid textual representation of an IP address\", ipaddr)\n\t}\n\tp.mu.Lock()\n\tp.addrs[addr.String()] = &net.IPAddr{IP: addr}\n\tif isIPv4(addr) {\n\t\tp.hasIPv4 = true\n\t} else if isIPv6(addr) {\n\t\tp.hasIPv6 = true\n\t}\n\tp.mu.Unlock()\n\treturn nil\n}", "reference": "// AddIP adds an IP address to Pinger. ipaddr arg should be a string like\n// \"192.0.2.1\".", "generated": "// AddIP adds an IPv4 or IPv6 address to pingers list.\n//\n// If there's already an entry for this address in pingers list,\n// it will be overwritten by new value. This can happen when same\n// host sends multiple requests at once. The caller should ensure that\n// only one"}
{"id": 3943, "code": "func Substitute(s string, sub map[string]string) (buf string) {\n\tbuf = s\n\tvar keys []string\n\tfor k := range sub {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)\n\n\tfor _, key := range keys {\n\t\tbuf = strings.Replace(buf, key, sub[key], -1)\n\t}\n\treturn\n}", "reference": "// Substitute returns string with superseded all substrings from\n// provided substitution map. Substitution map will be applied in alphabetic\n// order. Many passes, on one substitution another one could apply.", "generated": "// Substitute replaces all occurrences in buf of each key from sub.\n//\n// The order of replacement is determined by the lexicographical ordering of\n// the keys in sub. If there's a conflict between two replacements for different\n// keys, only the first one will be applied to the result. This means that if"}
{"id": 3945, "code": "func Parse() error {\n\targs := os.Args\n\tif len(args) == 1 {\n\t\treturn nil\n\t}\n\n\t// Global flags.\n\tfset := flag.CommandLine\n\tfset.Usage = Usage\n\tout := fsetOutput(fset)\n\n\tif err := fset.Parse(args[1:]); err != nil {\n\t\treturn err\n\t}\n\n\t// Handle version request.\n\tif f := fset.Lookup(VersionBoolFlag); f != nil {\n\t\tif v, ok := f.Value.(flag.Getter); ok {\n\t\t\t// All values implemented by the flag package implement the flag.Getter interface.\n\t\t\tif b, ok := v.Get().(bool); ok && b {\n\t\t\t\t// The flag was defined as a bool and is set.\n\t\t\t\tprogram := programName(args[0])\n\t\t\t\tfmt.Fprintf(out, \"%s version %s %s/%s\\n\",\n\t\t\t\t\tprogram, buildinfo(),\n\t\t\t\t\truntime.GOOS, runtime.GOARCH)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n\n\t// No cmdflag.\n\tif fset.NArg() == 0 {\n\t\treturn nil\n\t}\n\n\t// Subcommand.\n\tidx := len(args) - fset.NArg()\n\ts := args[idx]\n\targs = args[idx+1:]\n\tfor _, sub := range subs {\n\t\tif sub.name != s {\n\t\t\tcontinue\n\t\t}\n\n\t\tfs, handler := sub.init(out)\n\t\tif err := fs.Parse(args); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn handler(args[len(args)-fs.NArg():]...)\n\t}\n\n\treturn fmt.Errorf(\"%s is not a valid cmdflag\", s)\n}", "reference": "// Parse parses the command line arguments including the global flags and, if any, the cmdflag and its flags.\n//\n// If the VersionBoolFlag is defined as a global boolean flag, then the program version is displayed and the program stops.", "generated": "// Parse parses command line arguments for this binary. It returns any errors that occur during parsing or execution of the requested commands. If no errors occurred it will return nil. This method should be called before calling run(), which executes all registered handlers in order until one fails to parse its arguments. After running all handlers, if"}
{"id": 3946, "code": "func (xxh XXHZero) Sum(b []byte) []byte {\n\th32 := xxh.Sum32()\n\treturn append(b, byte(h32), byte(h32>>8), byte(h32>>16), byte(h32>>24))\n}", "reference": "// Sum appends the current hash to b and returns the resulting slice.\n// It does not change the underlying hash state.", "generated": "// Sum returns the sum of b in 64-bit integer format.\n//\n// The returned value is a slice containing four bytes representing\n// two 32-bit integers: h1 and h2 where h1 = h2 << 32. This can be used to verify that\n// the input was correctly zeroed"}
{"id": 3949, "code": "func (xxh *XXHZero) Sum32() uint32 {\n\th32 := uint32(xxh.totalLen)\n\tif h32 >= 16 {\n\t\th32 += rol1(xxh.v1) + rol7(xxh.v2) + rol12(xxh.v3) + rol18(xxh.v4)\n\t} else {\n\t\th32 += prime32_5\n\t}\n\n\tp := 0\n\tn := xxh.bufused\n\tbuf := xxh.buf\n\tfor n := n - 4; p <= n; p += 4 {\n\t\th32 += binary.LittleEndian.Uint32(buf[p:p+4]) * prime32_3\n\t\th32 = rol17(h32) * prime32_4\n\t}\n\tfor ; p < n; p++ {\n\t\th32 += uint32(buf[p]) * prime32_5\n\t\th32 = rol11(h32) * prime32_1\n\t}\n\n\th32 ^= h32 >> 15\n\th32 *= prime32_2\n\th32 ^= h32 >> 13\n\th32 *= prime32_3\n\th32 ^= h32 >> 16\n\n\treturn h32\n}", "reference": "// Sum32 returns the 32 bits Hash value.", "generated": "// Sum32 returns the sum of all bytes in this XXH object. The result is always non-zero.\n//\n// This method can be used to verify that no data was written into the buffer before it's closed,\n// or if there were any errors during compression/decompression. It also serves as a checksum for"}
{"id": 3956, "code": "func (z *Writer) Write(buf []byte) (int, error) {\n\tif !z.Header.done {\n\t\tif err := z.writeHeader(); err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t}\n\tif debugFlag {\n\t\tdebug(\"input buffer len=%d index=%d\", len(buf), z.idx)\n\t}\n\n\tzn := len(z.data)\n\tvar n int\n\tfor len(buf) > 0 {\n\t\tif z.idx == 0 && len(buf) >= zn {\n\t\t\t// Avoid a copy as there is enough data for a block.\n\t\t\tif err := z.compressBlock(buf[:zn]); err != nil {\n\t\t\t\treturn n, err\n\t\t\t}\n\t\t\tn += zn\n\t\t\tbuf = buf[zn:]\n\t\t\tcontinue\n\t\t}\n\t\t// Accumulate the data to be compressed.\n\t\tm := copy(z.data[z.idx:], buf)\n\t\tn += m\n\t\tz.idx += m\n\t\tbuf = buf[m:]\n\t\tif debugFlag {\n\t\t\tdebug(\"%d bytes copied to buf, current index %d\", n, z.idx)\n\t\t}\n\n\t\tif z.idx < len(z.data) {\n\t\t\t// Buffer not filled.\n\t\t\tif debugFlag {\n\t\t\t\tdebug(\"need more data for compression\")\n\t\t\t}\n\t\t\treturn n, nil\n\t\t}\n\n\t\t// Buffer full.\n\t\tif err := z.compressBlock(z.data); err != nil {\n\t\t\treturn n, err\n\t\t}\n\t\tz.idx = 0\n\t}\n\n\treturn n, nil\n}", "reference": "// Write compresses data from the supplied buffer into the underlying io.Writer.\n// Write does not return until the data has been written.", "generated": "// Write writes input into writer's internal buffers. The caller must ensure that\n// all blocks have been written before calling this method again. If it has,\n// then the next call will start writing new blocks. This ensures efficient use\n// of memory by avoiding unnecessary copies when compressing multiple small\n// chunks together"}
{"id": 3959, "code": "func (z *Writer) Close() error {\n\tif !z.Header.done {\n\t\tif err := z.writeHeader(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := z.Flush(); err != nil {\n\t\treturn err\n\t}\n\n\tif debugFlag {\n\t\tdebug(\"writing last empty block\")\n\t}\n\tif err := z.writeUint32(0); err != nil {\n\t\treturn err\n\t}\n\tif !z.NoChecksum {\n\t\tchecksum := z.checksum.Sum32()\n\t\tif debugFlag {\n\t\t\tdebug(\"stream checksum %x\", checksum)\n\t\t}\n\t\tif err := z.writeUint32(checksum); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// Close closes the Writer, flushing any unwritten data to the underlying io.Writer, but does not close the underlying io.Writer.", "generated": "// Close writes any remaining data to the underlying writer and closes it.\n//\n// If there is no more data in the stream then this will return immediately without writing anything,\n// but if there is still some data left over from previous calls to Write or WriteAt then that will be written out before closing the file descriptor."}
{"id": 4014, "code": "func (d *FileSelectDialog) detectPath() {\n\tp := d.currPath\n\tif p == \"\" {\n\t\td.currPath, _ = os.Getwd()\n\t\treturn\n\t}\n\n\tp = filepath.Clean(p)\n\tfor {\n\t\t_, err := os.Stat(p)\n\t\tif err == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tdirUp := filepath.Dir(p)\n\t\tif dirUp == p {\n\t\t\tp, _ = os.Getwd()\n\t\t\tbreak\n\t\t}\n\n\t\tp = dirUp\n\t}\n\td.currPath = p\n}", "reference": "// Tries to find the best fit for the given path.\n// It goes up until it gets into the existing directory.\n// If all fails it returns working directory.", "generated": "// Detects current path by checking if it is valid or exists.\n//\n// If currPath is empty then Getwd will be used to get the current working directory,\n// otherwise we try to find parent directories until we reach one that has no errors when stat'd. This should give us the root of our project."}
{"id": 4018, "code": "func (d *dbCache) preload(firstRow, rowCount int) {\n\tif firstRow == d.firstRow && rowCount == d.rowCount {\n\t\t// fast path: view area is the same, return immediately\n\t\treturn\n\t}\n\n\t// slow path: refill cache\n\tfNames := []string{\"Jack\", \"Alisa\", \"Richard\", \"Paul\", \"Nicole\", \"Steven\", \"Jane\"}\n\tlNames := []string{\"Smith\", \"Catcher\", \"Stone\", \"White\", \"Black\"}\n\tposts := []string{\"Engineer\", \"Manager\", \"Janitor\", \"Driver\"}\n\tdeps := []string{\"IT\", \"Financial\", \"Support\"}\n\tsalary := []int{40000, 38000, 41000, 32000}\n\n\td.data = make([][]string, rowCount, rowCount)\n\tfor i := 0; i < rowCount; i++ {\n\t\tabsIndex := firstRow + i\n\t\td.data[i] = make([]string, columnInTable, columnInTable)\n\t\td.data[i][0] = fNames[absIndex%len(fNames)]\n\t\td.data[i][1] = lNames[absIndex%len(lNames)]\n\t\td.data[i][2] = fmt.Sprintf(\"%08d\", 100+absIndex)\n\t\td.data[i][3] = posts[absIndex%len(posts)]\n\t\td.data[i][4] = deps[absIndex%len(deps)]\n\t\td.data[i][5] = fmt.Sprintf(\"%d k/year\", salary[absIndex%len(salary)]/1000)\n\t}\n\n\t// do not forget to save the last values\n\td.firstRow = firstRow\n\td.rowCount = rowCount\n}", "reference": "// cache data from a new row span\n// It imitates a random data by selecting values from predefined arrays. Sizes\n// of all arrays should be different to make TableView data look more random", "generated": "// preload loads data into dbCache for faster access.\n//\n// This method should be called only once when database connection is established,\n// otherwise it will cause memory leak because all loaded rows will remain in\n// memory until they are garbage collected by Go's runtime. It also has some overhead\n// due to copying data"}
{"id": 4037, "code": "func PopClip() {\n\tif len(canvas.clipStack) == 0 {\n\t\treturn\n\t}\n\tc := canvas.clipStack[len(canvas.clipStack)-1]\n\tcanvas.clipStack = canvas.clipStack[:len(canvas.clipStack)-1]\n\tSetClipRect(c.x, c.y, c.w, c.h)\n}", "reference": "// PopClip restores saved with PushClip clipping window", "generated": "// PopClip removes the last clip from the stack. If there is no clipping set,\n// it has no effect. This should be used to undo previous clips when drawing.\n// The current clip will remain in place after this call. It can only be called if\n// there is at least one clip currently active ("}
{"id": 4038, "code": "func InClipRect(x, y int) bool {\n\treturn x >= canvas.clipX && y >= canvas.clipY &&\n\t\tx < canvas.clipX+canvas.clipW &&\n\t\ty < canvas.clipY+canvas.clipH\n}", "reference": "// InClipRect returns true if x and y position is inside current clipping\n// rectangle", "generated": "// InClipRect returns true if the point is in the clip rectangle.\n//\n// The coordinates must be non-negative integers. If they exceed the size of\n// the image or the clipping area, this will return false. Otherwise,\n// it checks whether the point's position falls within the bounds defined by\n// the"}
{"id": 4049, "code": "func FillRect(x, y, w, h int, r rune) {\n\tx, y, w, h = clip(x, y, w, h)\n\tif w < 1 || y < -1 {\n\t\treturn\n\t}\n\n\tfor yy := y; yy < y+h; yy++ {\n\t\tfor xx := x; xx < x+w; xx++ {\n\t\t\tputCharUnsafe(xx, yy, r)\n\t\t}\n\t}\n}", "reference": "// FillRect paints the area with r character using the current colors", "generated": "// FillRect draws a rectangle from (x,y) to (x+y,w*y). The character is filled in at each point.\n//\n// This function uses putCharUnsafe because it's faster than putChar for large areas,\n// but be aware that if there was any error writing to the screen this will leave garbage"}
{"id": 4058, "code": "func (l *ListBox) SelectedItemText() string {\n\tif l.currSelection == -1 {\n\t\treturn \"\"\n\t}\n\n\treturn l.items[l.currSelection]\n}", "reference": "// SelectedItemText returns text of currently selected item or empty sting if nothing is\n// selected or ListBox is empty.", "generated": "// Returns text for currently selected item in listbox. If no selection is made,\n// returns empty string. This method should be called only after ListBox has been\n// initialized or updated to reflect current state of items. It's recommended that\n// this method is used instead of direct access to currSelection field because it"}
{"id": 4070, "code": "func ColorToString(attr term.Attribute) string {\n\tvar out string\n\n\trawClr := attr & 15\n\tif rawClr < 8 {\n\t\tfor k, v := range colorMap {\n\t\t\tif v == rawClr {\n\t\t\t\tout += k + \" \"\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tif attr&term.AttrBold != 0 {\n\t\tout += \"bold \"\n\t}\n\tif attr&term.AttrUnderline != 0 {\n\t\tout += \"underline \"\n\t}\n\tif attr&term.AttrReverse != 0 {\n\t\tout += \"reverse \"\n\t}\n\n\treturn strings.TrimSpace(out)\n}", "reference": "// ColorToString returns string representation of the attribute", "generated": "// ColorToString converts a term attribute to its corresponding ANSI escape code.\n//\n// The returned value is in the format: bold underline reverse color_name,\n// where 'color_name' can be one of red green yellow blue magenta cyan white black\n// or any other valid color name from the color_map map. If"}
{"id": 4074, "code": "func DeactivateControls(parent Control) {\n\tfor _, ctrl := range parent.Children() {\n\t\tif ctrl.Active() {\n\t\t\tctrl.SetActive(false)\n\t\t\tctrl.ProcessEvent(Event{Type: EventActivate, X: 0})\n\t\t}\n\n\t\tDeactivateControls(ctrl)\n\t}\n}", "reference": "// DeactivateControls makes all children of parent inactive", "generated": "// Deactivate all controls in this control tree. This is useful for\n// deactivating all controls when we want to stop listening to events.\n//\n// Note that if there's any active event being processed by one of these\n// controls, it will be cancelled before they're deactivated. If no such\n//"}
{"id": 4089, "code": "func (c *CheckBox) SetAllow3State(enable bool) {\n\tif !enable && c.state == 2 {\n\t\tc.state = 0\n\t}\n\tc.allow3state = enable\n}", "reference": "// SetAllow3State sets if ComboBox should use 3 states. If the current\n// state is unknown and one disables Allow3State option then the current\n// value resets to off", "generated": "// SetAllow3State sets whether to allow three states for this checkbox.\n//\n// If set to true then it will be possible to have two checked boxes in one row,\n// but only if there is at least one unchecked box between them. The default value\n// is false which means that no such arrangement can occur"}
{"id": 4109, "code": "func (b *ProgressBar) SecondaryColors() (term.Attribute, term.Attribute) {\n\treturn b.emptyFg, b.emptyBg\n}", "reference": "// SecondaryColors returns text and background colors for empty\n// part of the ProgressBar", "generated": "// Returns secondary colors for progress bar. These can be used to change color when text is displayed in terminal.\n//\n// The default values returned by this method will always display black foreground and white background,\n// which means that no changes should occur if these methods return empty attributes. If you want different\n// colors than those"}
{"id": 4219, "code": "func NewMemoryKeyCacher(maxKeyAge time.Duration, maxCacheSize int) KeyCacher {\n\treturn &memoryKeyCacher{\n\t\tentries:      map[string]keyCacherEntry{},\n\t\tmaxKeyAge:    maxKeyAge,\n\t\tmaxCacheSize: maxCacheSize,\n\t}\n}", "reference": "// NewMemoryKeyCacher creates a new Keycacher interface with option\n// to set max age of cached keys and max size of the cache.", "generated": "// NewMemoryKeyCacher returns a new memory key cacher that stores keys in\n// RAM for fast access but will evict older entries when cache is full.\n//\n// The maximum age of each entry can be set using MaxKeyAge parameter which defaults to 1 hour.\n// If the number of entries exceeds"}
{"id": 4226, "code": "func validColor(c string) bool {\n\tvalid := false\n\tif validColors[c] {\n\t\tvalid = true\n\t}\n\treturn valid\n}", "reference": "// validColor will make sure the given color is actually allowed", "generated": "// Returns whether c is a color name or not.\n//\n// This returns true if c is one of the following: \"black\", \"blue\", \"cyan\",\n// \"darkGray\", \"gray\", \"lightBlue\", \"lightGreen\", \"magenta\", \"red\",\n// \"white\". Otherwise it will return"}
{"id": 4230, "code": "func (s *Spinner) Reverse() {\n\ts.lock.Lock()\n\tdefer s.lock.Unlock()\n\tfor i, j := 0, len(s.chars)-1; i < j; i, j = i+1, j-1 {\n\t\ts.chars[i], s.chars[j] = s.chars[j], s.chars[i]\n\t}\n}", "reference": "// Reverse will reverse the order of the slice assigned to the indicator", "generated": "// Reverse reverses the spinner's characters in place. This is useful if\n// we want to create a new spinner that has its characters reversed from the original one.\n//\n// Note: this operation modifies the underlying slice, so it should be called after any other operations have been performed,\n// otherwise the results may become"}
{"id": 4237, "code": "func NewMultiplex(con net.Conn, initiator bool) *Multiplex {\n\tmp := &Multiplex{\n\t\tcon:       con,\n\t\tinitiator: initiator,\n\t\tbuf:       bufio.NewReader(con),\n\t\tchannels:  make(map[streamID]*Stream),\n\t\tclosed:    make(chan struct{}),\n\t\tshutdown:  make(chan struct{}),\n\t\twrTkn:     make(chan struct{}, 1),\n\t\tnstreams:  make(chan *Stream, 16),\n\t}\n\n\tgo mp.handleIncoming()\n\n\tmp.wrTkn <- struct{}{}\n\n\treturn mp\n}", "reference": "// NewMultiplex creates a new multiplexer session.", "generated": "// NewMultiplex creates a new multiplexer instance for handling incoming streams.\n//\n// The returned object is ready to be used immediately after creation. It will start listening for incoming connections in its goroutine. When it receives data from another peer, it starts a stream using that connection. If there's no available channel slot"}
{"id": 4242, "code": "func (b Box) Round() (lat, lng float64) {\n\tx := maxDecimalPower(b.MaxLat - b.MinLat)\n\tlat = math.Ceil(b.MinLat/x) * x\n\tx = maxDecimalPower(b.MaxLng - b.MinLng)\n\tlng = math.Ceil(b.MinLng/x) * x\n\treturn\n}", "reference": "// Round returns a point inside the box, making an effort to round to minimal\n// precision.", "generated": "// Round returns rounded latitude and longitude values for this box.\n//\n// The rounding is done by first calculating how many decimal places to round up,\n// then multiplying that number times the step size in degrees between each digit.\n// This ensures that we get whole numbers when possible, but still have enough precision\n// if necessary"}
{"id": 4327, "code": "func (c *Client) DeleteCheckoutKey(account, repo, fingerprint string) error {\n\treturn c.request(\"DELETE\", fmt.Sprintf(\"project/%s/%s/checkout-key/%s\", account, repo, fingerprint), nil, nil, nil)\n}", "reference": "// DeleteCheckoutKey fetches the checkout key for the given project by fingerprint", "generated": "// DeleteCheckoutKey deletes a checkout key for a given repository in a project.\n//\n// This is used to remove keys that have been generated by other means than\n// this client. If there's already another key associated with it,\n// deleting one will result in an error. The key must be deleted from the"}
{"id": 4332, "code": "func (c *Client) Timing(bucket string, value interface{}) {\n\tif c.skip() {\n\t\treturn\n\t}\n\tc.conn.metric(c.prefix, bucket, value, \"ms\", c.rate, c.tags)\n}", "reference": "// Timing sends a timing value to a bucket.", "generated": "// Timing records a metric for timing purposes.\n//\n// This is used to measure how long it takes to execute certain operations,\n// such as database queries or network requests. The returned metrics can be\n// accessed via the `GetMetric` method. Note that this will only record if\n// the client has been configured"}
{"id": 4333, "code": "func (t Timing) Send(bucket string) {\n\tt.c.Timing(bucket, int(t.Duration()/time.Millisecond))\n}", "reference": "// Send sends the time elapsed since the creation of the Timing.", "generated": "// Send sends timing information to the given bucket in the time series database.\n//\n// This is used by the test runner to track how long each test takes. The\n// duration will be divided into milliseconds for easier comparison across tests,\n// but it's still accurate enough that we can use this data to determine which"}
{"id": 4348, "code": "func SpatialEntropy(match match.Match, turns int, shiftCount int) float64 {\n\tvar s, d float64\n\tif match.DictionaryName == \"qwerty\" || match.DictionaryName == \"dvorak\" {\n\t\t//todo: verify qwerty and dvorak have the same length and degree\n\t\ts = float64(len(adjacency.BuildQwerty().Graph))\n\t\td = adjacency.BuildQwerty().CalculateAvgDegree()\n\t} else {\n\t\ts = float64(keyPadStartingPositions)\n\t\td = keyPadAvgDegree\n\t}\n\n\tpossibilities := float64(0)\n\n\tlength := float64(len(match.Token))\n\n\t//TODO: Should this be <= or just < ?\n\t//Estimate the number of possible patterns w/ length L or less with t turns or less\n\tfor i := float64(2); i <= length+1; i++ {\n\t\tpossibleTurns := math.Min(float64(turns), i-1)\n\t\tfor j := float64(1); j <= possibleTurns+1; j++ {\n\t\t\tx := zxcvbnmath.NChoseK(i-1, j-1) * s * math.Pow(d, j)\n\t\t\tpossibilities += x\n\t\t}\n\t}\n\n\tentropy := math.Log2(possibilities)\n\t//add extra entropu for shifted keys. ( % instead of 5 A instead of a)\n\t//Math is similar to extra entropy for uppercase letters in dictionary matches.\n\n\tif S := float64(shiftCount); S > float64(0) {\n\t\tpossibilities = float64(0)\n\t\tU := length - S\n\n\t\tfor i := float64(0); i < math.Min(S, U)+1; i++ {\n\t\t\tpossibilities += zxcvbnmath.NChoseK(S+U, i)\n\t\t}\n\n\t\tentropy += math.Log2(possibilities)\n\t}\n\n\treturn entropy\n}", "reference": "// SpatialEntropy calculates the entropy for spatial matches", "generated": "//SpatialEntropy estimates the spatial entropy given a token and its position.\n//\n//This method uses the following assumptions about the distribution of tokens:\n//\n//* The probability that any two adjacent characters will appear together is equal,\n//and therefore can be modeled by a uniform distribution over all pairs of characters.\n//\n//* The"}
{"id": 4354, "code": "func Null(in []byte, pos int) (int, error) {\n\tswitch in[pos] {\n\tcase 'n':\n\t\treturn expect(in, pos, n...)\n\t\treturn pos + 4, nil\n\tdefault:\n\t\treturn 0, errUnexpectedValue\n\t}\n}", "reference": "// Null verifies the contents of bytes provided is a null starting as pos", "generated": "// Null returns null value if input is \"null\". Otherwise it continues to parse.\n//\n// This method should be used when parsing JSON data that may contain both valid values\n// and invalid ones like \"null\" or \"\" which can cause errors during unmarshalling. It's also\n// useful for testing purposes where"}
{"id": 4404, "code": "func (b *Base64) SetBSON(raw bson.Raw) error {\n\tvar m bson.M\n\tif err := raw.Unmarshal(&m); err != nil {\n\t\treturn err\n\t}\n\n\tif data, ok := m[\"data\"].(string); ok {\n\t\t*b = Base64(data)\n\t\treturn nil\n\t}\n\n\treturn errors.New(\"couldn't unmarshal bson raw value as Base64\")\n}", "reference": "// SetBSON sets the Base64 from raw bson data", "generated": "// SetBSON sets the base64 encoded string from the given BSON Raw object.\n//\n// If the \"data\" field is present in the BSON document then it will be set to this\n// instance's Base64 representation. Otherwise an error will be returned. The\n// result can also be obtained by calling Get"}
{"id": 4413, "code": "func (e *Email) UnmarshalEasyJSON(in *jlexer.Lexer) {\n\tif data := in.String(); in.Ok() {\n\t\t*e = Email(data)\n\t}\n}", "reference": "// UnmarshalEasyJSON sets the Email from a easyjson.Lexer", "generated": "// UnmarshalEasyJSON is used to unmarshal JSON into this struct.\n//\n// This method will only be called if it's present in the interface definition\n// for the type being marshaled/unmarshaled. It should never call itself recursively,\n// or else you'll end up in an infinite loop.  If"}
{"id": 4422, "code": "func (u *IPv6) DeepCopy() *IPv6 {\n\tif u == nil {\n\t\treturn nil\n\t}\n\tout := new(IPv6)\n\tu.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new IPv6.", "generated": "// DeepCopy creates a deep copy of this IPv6 object. This is useful for testing or when you need to ensure that any field you use is initialized before it's used -- something that isn't possible with assignment. It will also guarantee that any struct sub-objects in this object are finished (i.e. have been"}
{"id": 4452, "code": "func (h *HexColor) DeepCopy() *HexColor {\n\tif h == nil {\n\t\treturn nil\n\t}\n\tout := new(HexColor)\n\th.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new HexColor.", "generated": "// DeepCopy creates a deep copy of this HexColor object. This is useful for\n// testing or when you need to ensure that two objects aren't the same. The\n// returned object will be initialized independently from the original. Both\n// objects can be used safely concurrently. Only the pointer is copied. If both"}
{"id": 4466, "code": "func (t DateTime) MarshalJSON() ([]byte, error) {\n\tvar w jwriter.Writer\n\tt.MarshalEasyJSON(&w)\n\treturn w.BuildBytes()\n}", "reference": "// MarshalJSON returns the DateTime as JSON", "generated": "// MarshalJSON implements the json.Marshaler interface for DateTime.\n//\n// This is used to serialize datetime objects into JSON format that can be sent over HTTP or stored in databases. The resulting string will have the following format: \"YYYY-MM-DD HH:MM:SS.mmmmmm\". If this value cannot fit within"}
{"id": 4474, "code": "func (d *Duration) Scan(raw interface{}) error {\n\tswitch v := raw.(type) {\n\t// TODO: case []byte: // ?\n\tcase int64:\n\t\t*d = Duration(v)\n\tcase float64:\n\t\t*d = Duration(int64(v))\n\tcase nil:\n\t\t*d = Duration(0)\n\tdefault:\n\t\treturn fmt.Errorf(\"cannot sql.Scan() strfmt.Duration from: %#v\", v)\n\t}\n\n\treturn nil\n}", "reference": "// Scan reads a Duration value from database driver type.", "generated": "// Scan implements the Scanner interface for strfmt.Duration.\n//\n// This is used to convert values read in by SQL.Scanner into strfmt.Duration objects,\n// which can be safely passed around without worrying about overflow or underflow errors.\n// The conversion will always round down if there's any possibility that the value could exceed"}
{"id": 4491, "code": "func (d *Date) DeepCopy() *Date {\n\tif d == nil {\n\t\treturn nil\n\t}\n\tout := new(Date)\n\td.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new Date.", "generated": "// DeepCopy creates a deep copy of this Date object. This is useful for testing or when you need to ensure that two objects aren't the same. The default implementation uses the Copy method provided by the parent type. If no DeepCopy method exists in the type, it will panic at runtime. You can override this method if"}
{"id": 4522, "code": "func GrepNot(r string) Filter {\n\tre, err := regexp.Compile(r)\n\tif err != nil {\n\t\treturn FilterFunc(func(Arg) error { return err })\n\t}\n\treturn If(func(s string) bool { return !re.MatchString(s) })\n}", "reference": "// GrepNot emits every input x that does not match the regular expression r.", "generated": "// GrepNot returns a filter that matches strings which do NOT contain\n// the given regular expression pattern.  The returned filter is\n// lazily compiled to avoid unnecessary compilation overhead.\n//\n// Usage: f := GrepNot(\"foo\") or f := GrepNot(`bar`) or f := Grep"}
{"id": 4537, "code": "func FetchVersion(v discovery.ServerVersionInterface) (ret ServerVersion, err error) {\n\tversion, err := v.ServerVersion()\n\tif err != nil {\n\t\treturn ServerVersion{}, err\n\t}\n\treturn ParseVersion(version)\n}", "reference": "// FetchVersion fetches version information from discovery client, and parses", "generated": "// FetchVersion fetches server version from given interface.\n//\n// This is used to get current version when running in non-test mode,\n// or if we're trying to determine whether it's a test run based on\n// the version string.  It returns an error if there was any problem\n// fetching the version"}
{"id": 4543, "code": "func (n ImageName) RegistryRepoName() string {\n\trepo := n.Repository\n\tif repo == \"\" {\n\t\trepo = \"library\"\n\t}\n\treturn fmt.Sprintf(\"%s/%s\", repo, n.Name)\n}", "reference": "// RegistryRepoName returns the \"repository\" as used in the registry URL", "generated": "// RegistryRepoName returns the registry repository name for this image.\n//\n// If no Repository is set then it defaults to 'library'. Otherwise,\n// it uses that value. The Name field must be non-empty in order to use\n// this method. This will return the same result if both Repository and\n// Name"}
{"id": 4556, "code": "func MarkdownHelper(body string, help HelperContext) (template.HTML, error) {\n\tvar err error\n\tif help.HasBlock() {\n\t\tbody, err = help.Block()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\tb := github_flavored_markdown.Markdown([]byte(body))\n\treturn template.HTML(b), err\n}", "reference": "// Markdown converts the string into HTML using GitHub flavored markdown.", "generated": "// MarkdownHelper converts markdown to HTML for use in templates.\n//\n// If there is no block present it will return the original body unchanged,\n// otherwise it will convert the block into html using GitHub Flavoured MarkDown.\n// The result can be used directly in a template or passed through other functions that expect HTML input"}
{"id": 4565, "code": "func (t *Template) Exec(ctx hctx.Context) (string, error) {\n\terr := t.Parse()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tev := compiler{\n\t\tctx:     ctx,\n\t\tprogram: t.program,\n\t}\n\n\ts, err := ev.compile()\n\treturn s, err\n}", "reference": "// Exec the template using the content and return the results", "generated": "// Execute executes the template's program in the given context.\n//\n// The result is returned as a string. If there was an error executing the\n// program, it will be returned instead. This method should only be called once;\n// if this method returns an error, subsequent calls to Render() or other methods"}
{"id": 4576, "code": "func hasPathPrefix(p string, s map[string]string) bool {\n\tfor prefix := range s {\n\t\tif strings.HasPrefix(p, prefix+\"/\") {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "reference": "// hasPathPrefix returns true if any of s is the prefix of p.", "generated": "// hasPathPrefix checks if p is in any path prefixed by one or more slashes.\n//\n// This can be used to check for paths that have been normalized (e.g., \"a/b/c\" vs \"/a/b/c\").\n// It's also useful when checking against a set of prefixes where some may contain additional"}
{"id": 4588, "code": "func (a *Args) similar(r *Args, similar Similarity) bool {\n\tif a.Elided != r.Elided || len(a.Values) != len(r.Values) {\n\t\treturn false\n\t}\n\tif similar == AnyValue {\n\t\treturn true\n\t}\n\tfor i, l := range a.Values {\n\t\tswitch similar {\n\t\tcase ExactFlags, ExactLines:\n\t\t\tif l != r.Values[i] {\n\t\t\t\treturn false\n\t\t\t}\n\t\tdefault:\n\t\t\tif l.IsPtr() != r.Values[i].IsPtr() || (!l.IsPtr() && l != r.Values[i]) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\treturn true\n}", "reference": "// similar returns true if the two Args are equal or almost but not quite\n// equal.", "generated": "// similar checks if two Args have values that match each other according to the given similarity rules.\n//\n// If no specific rule is specified, it will use any value matching. For example,\n// \"any\" means all fields must be equal or both null; \"exact\" means they can't differ at all;\n//"}
{"id": 4597, "code": "func (s *Stack) merge(r *Stack) *Stack {\n\t// Assumes similar stacks have the same length.\n\tout := &Stack{\n\t\tCalls:  make([]Call, len(s.Calls)),\n\t\tElided: s.Elided,\n\t}\n\tfor i := range s.Calls {\n\t\tout.Calls[i] = s.Calls[i].merge(&r.Calls[i])\n\t}\n\treturn out\n}", "reference": "// merge merges two similar Stack, zapping out differences.", "generated": "// Merge two stack traces into one. This is useful for combining error messages from different goroutines or threads in a single log message. The resulting trace will be longer than either input if they were merged at any point. If there's no overlap between them then it just copies all calls to the output. It assumes that"}
{"id": 4624, "code": "func (b *base57) stringToNum(s string) (string, error) {\n\tn := big.NewInt(0)\n\n\tfor i := len(s) - 1; i >= 0; i-- {\n\t\tn.Mul(n, big.NewInt(b.alphabet.Length()))\n\n\t\tindex, err := b.alphabet.Index(string(s[i]))\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\n\t\tn.Add(n, big.NewInt(index))\n\t}\n\n\tx := fmt.Sprintf(\"%x\", n)\n\n\tif len(x) < 32 {\n\t\t// Pad the most significant bit (MSG) with 0 (zero) if the string is too short.\n\t\tx = strings.Repeat(\"0\", 32-len(x)) + x\n\t} else if len(x) > 32 {\n\t\treturn \"\", fmt.Errorf(\"UUID length overflow for %q\", s)\n\t}\n\n\treturn fmt.Sprintf(\"%s-%s-%s-%s-%s\", x[0:8], x[8:12], x[12:16], x[16:20], x[20:32]), nil\n}", "reference": "// stringToNum converts a string a number using the given alpabet.", "generated": "// stringToNum converts base58 encoded UUID to uint64 value. The result will be padded with leading zeros until it reaches 32 characters in length. If the input string has more than 32 characters then it's considered invalid. It also handles case where the first character is \"0\" which means that there was"}
{"id": 4644, "code": "func (geoIndex *geoIndex) AddEntryAt(point Point) interface{} {\n\tsquare := cellOf(point, geoIndex.resolution)\n\n\tif _, ok := geoIndex.index[square]; !ok {\n\t\tgeoIndex.index[square] = geoIndex.newEntry()\n\t}\n\n\treturn geoIndex.index[square]\n}", "reference": "// AddEntryAt adds an entry if missing, returns the entry at specific position.", "generated": "// AddEntryAt adds point to index at given location. Returns entry associated\n// with square that contains point. If no such entry exists it creates new one.\n//\n// This is used for fast lookup in spatial indexes when we know which cells\n// contain our data points. It's faster than iterating over all entries"}
{"id": 4662, "code": "func BearingTo(p1, p2 Point) float64 {\n\tdLon := toRadians(p2.Lon() - p1.Lon())\n\n\tlat1 := toRadians(p1.Lat())\n\tlat2 := toRadians(p2.Lat())\n\n\ty := math.Sin(dLon) * math.Cos(lat2)\n\tx := math.Cos(lat1)*math.Sin(lat2) -\n\t\tmath.Sin(lat1)*math.Cos(lat2)*math.Cos(dLon)\n\tbrng := toDegrees(math.Atan2(y, x))\n\n\treturn brng\n}", "reference": "// BearingTo returns the bearing from p1 to p2", "generated": "// bearing returns the angle between two points in degrees.\n//\n// The returned value is measured clockwise from north (0\u00b0). If the first point's latitude\n// is greater than the second point's latitude then it will be negative; otherwise positive.\n//\n// This method uses the Haversine formula for calculating distances over"}
{"id": 4720, "code": "func AddRelayTransport(ctx context.Context, h host.Host, upgrader *tptu.Upgrader, opts ...RelayOpt) error {\n\tn, ok := h.Network().(tpt.Network)\n\tif !ok {\n\t\treturn fmt.Errorf(\"%v is not a transport network\", h.Network())\n\t}\n\n\tr, err := NewRelay(ctx, h, upgrader, opts...)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// There's no nice way to handle these errors as we have no way to tear\n\t// down the relay.\n\t// TODO\n\tif err := n.AddTransport(r.Transport()); err != nil {\n\t\tlog.Error(\"failed to add relay transport:\", err)\n\t} else if err := n.Listen(r.Listener().Multiaddr()); err != nil {\n\t\tlog.Error(\"failed to listen on relay transport:\", err)\n\t}\n\treturn nil\n}", "reference": "// AddRelayTransport constructs a relay and adds it as a transport to the host network.", "generated": "// AddRelayTransport adds a new relay connection for this node in the given\n// transport network. The relay will be added after it has been established,\n// so there may be some delay before it appears in the list of transports. If\n// any part of adding the relay fails (e.g., because another"}
{"id": 4731, "code": "func NewServer() http.Handler {\n\tr := mux.NewRouter()\n\tr.Path(\"/hello\").Methods(\"GET\").HandlerFunc(handleHello)\n\treturn r\n}", "reference": "// NewServer makes a new example server.", "generated": "// NewServer returns a new server that listens for requests to /hello.\n//\n// The handler is set up so it will return \"Hello World!\" when requested by any client,\n// regardless of whether or not they have authenticated successfully. This can be useful in development environments where authentication isn't enabled yet. In production,"}
{"id": 4742, "code": "func StringFindBetween(s, start, stop string) (between, remainder string, found bool) {\n\tbegin := strings.Index(s, start)\n\tif begin == -1 {\n\t\treturn \"\", s, false\n\t}\n\tbetween = s[begin+len(start):]\n\tend := strings.Index(between, stop)\n\tif end == -1 {\n\t\treturn \"\", s, false\n\t}\n\treturn between[:end], s[begin+len(start)+end+len(stop):], true\n}", "reference": "// StringFindBetween returns the string between the first occurrences of the tokens start and stop.\n// The remainder of the string after the stop token will be returned if found.\n// If the tokens couldn't be found, then the whole string will be returned as remainder.", "generated": "// StringFindBetween returns three values: the substring that is \"start\" followed by \"stop\", \n// the remaining part after removing these two substrings from original string.\n//\n// If there's no such occurrence in the string it will return empty string for all 3 variables,\n// and false value to indicate that"}
{"id": 4755, "code": "func HTTPPostJSON(url string, data interface{}) error {\n\tb, err := json.MarshalIndent(data, \"\", \"  \")\n\tif err != nil {\n\t\treturn err\n\t}\n\tresponse, err := http.Post(url, \"application/json\", bytes.NewBuffer(b))\n\tif err == nil && (response.StatusCode < 200 || response.StatusCode > 299) {\n\t\terr = errors.New(response.Status)\n\t}\n\treturn err\n}", "reference": "// HTTPPostJSON marshalles data as JSON\n// and sends it as HTTP POST request to url.\n// If the response status code is not 200 OK,\n// then the status is returned as an error.", "generated": "// HTTPPostJSON sends JSON to server via POST request.\n//\n// This is similar to HTTPPost but it marshals the input into JSON format before sending,\n// which can be useful for more complex objects that aren't easily serialized by other methods. The result will contain any status code returned from the server. If there"}
{"id": 4764, "code": "func FileSize(filename string) int64 {\r\n\tinfo, err := os.Stat(filename)\r\n\tif err != nil {\r\n\t\treturn 0\r\n\t}\r\n\treturn info.Size()\r\n}", "reference": "// FileSize returns the size of a file or zero in case of an error.", "generated": "// Returns the size in bytes for the given file. If there is no such file,\n// returns zero. The error returned by Stat() will be ignored if it's\n// ErrNoSuchFileError (which happens when trying to get stats from a non-existent file)."}
{"id": 4781, "code": "func LoadTOMLBytes(conf interface{}, src []byte) error {\n\treturn loadConfigBytes(conf, src, nil, toml.Unmarshal)\n}", "reference": "// LoadTOMLBytes loads TOML bytes", "generated": "// LoadTOMLBytes loads TOML configuration from byte slice into given config.\n//\n// If conf is already populated then it will be overwritten by new values\n// in the source data. Otherwise if conf is empty, it will be initialized\n// based on the contents of the source data. The result can only"}
{"id": 4787, "code": "func Crop(img image.Image, c Config) (image.Image, error) {\n\tmaxBounds := c.maxBounds(img.Bounds())\n\tsize := c.computeSize(maxBounds, image.Point{c.Width, c.Height})\n\tcr := c.computedCropArea(img.Bounds(), size)\n\tcr = img.Bounds().Intersect(cr)\n\n\tif c.Options&Copy == Copy {\n\t\treturn cropWithCopy(img, cr)\n\t}\n\tif dImg, ok := img.(subImageSupported); ok {\n\t\treturn dImg.SubImage(cr), nil\n\t}\n\treturn cropWithCopy(img, cr)\n}", "reference": "// Crop retrieves an image that is a\n// cropped copy of the original img.\n//\n// The crop is made given the informations provided in config.", "generated": "// Crop returns a cropped version of the input image.\n//\n// The cropping is done in two ways: either by copying the region from the original\n// image or by creating a new sub-image that represents only this part of the image.\n// If both options are enabled at once, it will be used to create a"}
{"id": 4788, "code": "func (c Config) computeSize(bounds image.Rectangle, ratio image.Point) (p image.Point) {\n\tif c.Options&Ratio == Ratio {\n\t\t// Ratio option is on, so we take the biggest size available that fit the given ratio.\n\t\tif float64(ratio.X)/float64(bounds.Dx()) > float64(ratio.Y)/float64(bounds.Dy()) {\n\t\t\tp = image.Point{bounds.Dx(), (bounds.Dx() / ratio.X) * ratio.Y}\n\t\t} else {\n\t\t\tp = image.Point{(bounds.Dy() / ratio.Y) * ratio.X, bounds.Dy()}\n\t\t}\n\t} else {\n\t\tp = image.Point{ratio.X, ratio.Y}\n\t}\n\treturn\n}", "reference": "// computeSize retrieve the effective size of the cropped image.\n// It is defined by Height, Width, and Ratio option.", "generated": "// Compute the new bounding box for the image based on the provided rectangle,\n// taking into account any scaling factor specified in the config options. If no\n// scaling factor was requested then it will be set to its original value. The\n// resulting point must have at least one dimension greater than zero. This method"}
{"id": 4790, "code": "func NewThen(command string, args ...string) Then {\n\treturn &gitCmd{command: command, args: args}\n}", "reference": "// NewThen creates a new Then command.", "generated": "// NewThen returns a new then command instance.\n//\n// This is used to create a gitcmd that will be executed after all\n// commands in this pipeline have completed successfully. The command\n// should start with \"then\". If it contains arguments they must come before\n// any other options or flags. For example"}
{"id": 4792, "code": "func (g *gitCmd) Command() string {\n\treturn g.command + \" \" + strings.Join(g.args, \" \")\n}", "reference": "// Command returns the full command as configured in Caddyfile.", "generated": "// Command returns the command to be executed by gitcmd. This is used for\n// debugging purposes only. The returned value should never be passed directly\n// into any Git commands. It's always safe to pass it through a shell or other\n// process that can handle quoted arguments. If there was no error in"}
{"id": 4812, "code": "func (r *Repo) pull() error {\n\n\t// if not pulled, perform clone\n\tif !r.pulled {\n\t\treturn r.clone()\n\t}\n\n\t// if latest tag config is set\n\tif r.Branch == latestTag {\n\t\treturn r.checkoutLatestTag()\n\t}\n\n\tparams := append([]string{\"pull\"}, append(r.PullArgs, \"origin\", r.Branch)...)\n\tvar err error\n\tif err = r.gitCmd(params, r.Path); err == nil {\n\t\tr.pulled = true\n\t\tr.lastPull = time.Now()\n\t\tLogger().Printf(\"%v pulled.\\n\", r.URL)\n\t\tr.lastCommit, err = r.mostRecentCommit()\n\t}\n\treturn err\n}", "reference": "// pull performs git pull, or git clone if repository does not exist.", "generated": "// Pulls from remote repository. If branch has been updated since last pull,\n// it will be checked out after pulling. Otherwise, it simply pulls without checking.\n//\n// Returns any errors that occurred during the process. The repo's state can now be used to determine whether or not there was an update. This method"}
{"id": 4815, "code": "func (r *Repo) Prepare() error {\n\t// check if directory exists or is empty\n\t// if not, create directory\n\tfs, err := gos.ReadDir(r.Path)\n\tif err != nil || len(fs) == 0 {\n\t\treturn gos.MkdirAll(r.Path, os.FileMode(0755))\n\t}\n\n\t// validate git repo\n\tisGit := false\n\tfor _, f := range fs {\n\t\tif f.IsDir() && f.Name() == \".git\" {\n\t\t\tisGit = true\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif isGit {\n\t\t// check if same repository\n\t\tvar repoURL string\n\t\tif repoURL, err = r.originURL(); err == nil {\n\t\t\tif strings.TrimSuffix(repoURL, \".git\") == strings.TrimSuffix(r.URL.Val(), \".git\") {\n\t\t\t\tr.pulled = true\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"cannot retrieve repo url for %v Error: %v\", r.Path, err)\n\t\t}\n\t\treturn fmt.Errorf(\"another git repo '%v' exists at %v\", repoURL, r.Path)\n\t}\n\treturn fmt.Errorf(\"cannot git clone into %v, directory not empty\", r.Path)\n}", "reference": "// Prepare prepares for a git pull\n// and validates the configured directory", "generated": "// prepare checks that there's no other git repositories in this path,\n// then creates one if necessary. If it already has another git\n// repository here, returns an error message indicating which one to use.\n//\n// This method should be called before any operations involving the Git\n// repository. It will also set pulled"}
{"id": 4819, "code": "func (g *gitCmd) Stdin(stdin io.Reader) {\n\tg.Cmd.Stdin = stdin\n}", "reference": "// Stdin sets the process's standard input.", "generated": "// SetStdin sets the standard input for this command to be read from the given reader.\n//\n// This is useful when running commands that require user input but don't want it to come in over stderr,\n// or if they need to use stdout for something else while still reading from stdin.  The default value will"}
{"id": 4831, "code": "func (t TravisHook) handleSignature(r *http.Request, secret string) error {\n\tsignature := r.Header.Get(\"Authorization\")\n\tif signature == \"\" {\n\t\treturn errors.New(\"request sent no authorization signature\")\n\t}\n\tif secret == \"\" {\n\t\tLogger().Print(\"Unable to verify request signature. Secret not set in caddyfile!\\n\")\n\t\treturn nil\n\t}\n\n\tcontent := r.Header.Get(\"Travis-Repo-Slug\") + secret\n\thash := sha256.Sum256([]byte(content))\n\texpectedMac := hex.EncodeToString(hash[:])\n\tif signature != expectedMac {\n\t\tfmt.Println(signature, expectedMac)\n\t\treturn errors.New(\"Invalid authorization header\")\n\t}\n\treturn nil\n}", "reference": "// Check for an authorization signature in the request. Reject if not present. If validation required, check the sha", "generated": "// handleSignature verifies that the provided Authorization header is valid for this hook.\n//\n// The value should be \"sha1 <secret> <repo-slug>\". If it's invalid,\n// we log an error message but continue running the hook anyway. This can happen if\n// someone tries to forge requests or if there"}
{"id": 4833, "code": "func hookName(h hookHandler) string {\n\tfor name, handler := range handlers {\n\t\tif handler == h {\n\t\t\treturn name\n\t\t}\n\t}\n\treturn \"\"\n}", "reference": "// hookName returns the name of the hookHanlder h.", "generated": "// hookName returns the name associated with the given hookHandler.\n//\n// If no matching handler is found, it will return an empty string. This can be used to identify which hook was triggered by the event. The returned value should always match one of the names in the handlers map. It's also safe for concurrent"}
{"id": 4861, "code": "func (u *URL) Short() string {\n\tif u.Scheme == \"\" {\n\t\treturn \"\"\n\t}\n\n\ts := schemeMap[u.Scheme].Aliases[0]\n\n\tif u.Scheme == \"odbc\" || u.Scheme == \"oleodbc\" {\n\t\tn := u.Proto\n\t\tif v, ok := schemeMap[n]; ok {\n\t\t\tn = v.Aliases[0]\n\t\t}\n\t\ts += \"+\" + n\n\t} else if u.Proto != \"tcp\" {\n\t\ts += \"+\" + u.Proto\n\t}\n\n\ts += \":\"\n\n\tif u.User != nil {\n\t\tif un := u.User.Username(); un != \"\" {\n\t\t\ts += un + \"@\"\n\t\t}\n\t}\n\n\tif u.Host != \"\" {\n\t\ts += u.Host\n\t}\n\n\tif u.Path != \"\" && u.Path != \"/\" {\n\t\ts += u.Path\n\t}\n\n\tif u.Opaque != \"\" {\n\t\ts += u.Opaque\n\t}\n\n\treturn s\n}", "reference": "// Short provides a short description of the user, host, and database.", "generated": "// Short returns short version of URL in format like http://example.com/path?query#fragment.\n// If url is empty or has no path then it will return just host part. It also handles some special cases for odbc/oleodbc urls where they need to be prefixed by their respective schemes. For example"}
{"id": 4873, "code": "func (e *hdbError) Error() string {\n\tif e.stmtNo != -1 {\n\t\treturn fmt.Sprintf(\"SQL %s %d - %s (statement no: %d)\", e.errorLevel, e.errorCode, e.errorText, e.stmtNo)\n\t}\n\treturn fmt.Sprintf(\"SQL %s %d - %s\", e.errorLevel, e.errorCode, e.errorText)\n}", "reference": "// Error implements the Error interface.", "generated": "// Error returns error message for this hdb.Error object.\n//\n// If there is more information available in the HDB error,\n// it will be returned instead of just the SQL statement number\n// or the generic \"unknown\" text. The caller should check if\n// stmtNo is still set before calling this method"}
{"id": 4883, "code": "func StringSize(s string) int {\n\tn := 0\n\tfor _, r := range s {\n\t\tn += RuneLen(r)\n\t}\n\treturn n\n}", "reference": "// StringSize is like Size with a string as parameter.", "generated": "// Returns the size in bytes for the given string.\n//\n// This is useful when working with byte arrays or other data structures that require fixed-size strings,\n// such as JSON encodings. It's also used internally by the encoding/json package to determine the length\n// required for a field in a struct. The returned"}
{"id": 4887, "code": "func On() bool {\n\ttracer.mu.RLock()\n\ton := tracer.on\n\ttracer.mu.RUnlock()\n\treturn on\n}", "reference": "// On returns if tracing methods output is active.", "generated": "// Returns whether tracing is currently enabled.\n//\n// This should be called only once per goroutine to avoid race conditions when\n// multiple goroutines call this method concurrently. The returned value will\n// remain true until the next time On() returns false or until the program exits,\n// whichever comes first. If tracing is"}
{"id": 4913, "code": "func (r *Reader) ReadUint32() uint32 {\n\tif r.err != nil {\n\t\treturn 0\n\t}\n\tvar n int\n\tn, r.err = io.ReadFull(r.rd, r.b[:4])\n\tr.cnt += n\n\tif r.err != nil {\n\t\treturn 0\n\t}\n\treturn binary.LittleEndian.Uint32(r.b[:4])\n}", "reference": "// ReadUint32 reads and returns an uint32.", "generated": "// ReadUint32 reads four bytes from the reader into a Uint32 value.\n//\n// The returned value is in network byte order. If there's no more data to read,\n// this returns zero. This method will panic if it encounters any errors while reading. It also panics if the number of bytes that were"}
{"id": 4918, "code": "func (r *Reader) ReadCesu8(size int) []byte {\n\tif r.err != nil {\n\t\treturn nil\n\t}\n\tp := make([]byte, size)\n\tvar n int\n\tn, r.err = io.ReadFull(r.rd, p)\n\tr.cnt += n\n\tif r.err != nil {\n\t\treturn nil\n\t}\n\tr.tr.Reset()\n\tif n, _, r.err = r.tr.Transform(p, p, true); r.err != nil { // inplace transformation\n\t\treturn nil\n\t}\n\treturn p[:n]\n}", "reference": "// ReadCesu8 reads a size CESU-8 encoded byte sequence and returns an UTF-8 byte slice.", "generated": "// ReadCesu8 reads up to'size' bytes from the reader into a byte slice.\n//\n// The returned data is transformed by cesu8's transform function if it exists,\n// otherwise no change occurs. If there was an error reading or transforming the\n// data, this method returns nil instead."}
{"id": 4923, "code": "func (w *Writer) Write(p []byte) {\n\tif w.err != nil {\n\t\treturn\n\t}\n\tw.wr.Write(p)\n}", "reference": "// Write writes the contents of p.", "generated": "// Write writes data to writer. If there is error in writer it will be stored here.\n// It's safe for concurrent access if only one goroutine can call this method at time,\n// because we use mutex lock internally. But if multiple goroutines try to write\n// simultaneously then they may interfere each other."}
{"id": 4938, "code": "func (c *Connector) Locale() string {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\treturn c.locale\n}", "reference": "// Locale returns the locale of the connector.", "generated": "// Returns the locale used by this connector. This is set when the connector was created,\n// or changed using SetLocale(). The default value for the locale is \"en_US.UTF-8\". If no\n// locale has been specified then it will be returned in its original form. For example if\n// the locale"}
{"id": 4942, "code": "func (c *Connector) SetTLSConfig(tlsConfig *tls.Config) error {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.tlsConfig = tlsConfig\n\treturn nil\n}", "reference": "// SetTLSConfig sets the TLS configuration of the connector.", "generated": "// SetTLSConfig sets the TLS configuration for this connector.\n//\n// This method is used to set up the SSL/TLS connection parameters,\n// such as certificates, key sizes, cipher suites, etc., that will be used when establishing connections.\n//\n// If no TLS config has been specified yet, it's assumed that"}
{"id": 4958, "code": "func Slice(arr []byte, count int) [][]byte {\n\n\tsliceCount := len(arr) / count\n\tresult := make([][]byte, sliceCount)\n\n\tfor i := 0; i < sliceCount; i++ {\n\t\tstart := i * count\n\t\tend := i*count + count\n\n\t\tresult[i] = arr[start:end]\n\t}\n\n\treturn result\n}", "reference": "// Slice is splitting input byte array into slice of subarrays. Each of count length.", "generated": "// Split byte array into slices of equal length.\n//\n// This is useful for splitting large arrays that need to be processed in chunks,\n// such as when reading from disk or network connections where data may come in\n// larger than one chunk at a time. The resulting slices can then be passed around\n// independently without"}
{"id": 4965, "code": "func Decode(data string) ([]byte,error) {\n\tdata = strings.Replace(data, \"-\", \"+\", -1) // 62nd char of encoding\n\tdata = strings.Replace(data, \"_\", \"/\", -1) // 63rd char of encoding\n\t\n\tswitch(len(data) % 4) { // Pad with trailing '='s\n\t\tcase 0:             // no padding\n\t\tcase 2: data+=\"==\"  // 2 pad chars\n\t\tcase 3:\tdata+=\"=\"   // 1 pad char\t\t\n\t}\n\t\t\n\treturn base64.StdEncoding.DecodeString(data)\n}", "reference": "// Decode decodes base64url string to byte array", "generated": "// Decode decodes a Base64 encoded byte slice into a raw byte array.\n//\n// The input is expected to be in URL-safe format (i.e., it contains only\n// alphanumeric characters, +, /, and =). If this isn't the case,\n// Decode will panic. It's also worth noting"}
{"id": 4969, "code": "func DerivePBKDF2(password, salt []byte, iterationCount, keyBitLength int, h hash.Hash) []byte {\n\n\tprf := hmac.New(func() hash.Hash { return h }, password)\n\thLen := prf.Size()\n\tdkLen := keyBitLength >> 3 //size of derived key in bytes\n\n\tl := int(math.Ceil(float64(dkLen) / float64(hLen))) // l = CEIL (dkLen / hLen)\n\tr := dkLen - (l-1)*hLen\n\n\t// 1. If dkLen > (2^32 - 1) * hLen, output \"derived key too long\" and stop.\n\tif dkLen > MaxInt {\n\t\tpanic(fmt.Sprintf(\"kdf.DerivePBKDF2: expects derived key size to be not more that (2^32-1) bits, but was requested %v bits.\", keyBitLength))\n\t}\n\n\tdk := make([]byte, 0, dkLen)\n\n\tfor i := 0; i < l; i++ {\n\n\t\tt := f(salt, iterationCount, i+1, prf) // T_l = F (P, S, c, l)\n\n\t\tif i == (l - 1) {\n\t\t\tt = t[:r]\n\t\t} // truncate last block to r bits\n\n\t\tdk = append(dk, t...) // DK = T_1 || T_2 ||  ...  || T_l<0..r-1>\n\t}\n\n\treturn dk\n}", "reference": "// DerivePBKDF2 implements Password Based Key Derivation Function 2, RFC 2898. Derives key of keyBitLength size, given password, salt, iteration count and hash function", "generated": "// DerivePBKDF2 derives a kdf.DerivedKey from a given password using PBKDF2,\n// which is defined by RFC2898. The resulting key will have length equal to\n// keyBitLength/8 bits. This method uses the provided hash.H for hashing. It's"}
{"id": 4970, "code": "func ReadPrivate(raw []byte) (key *ecdsa.PrivateKey,err error) {\n\tvar encoded *pem.Block\n\n\tif encoded, _ = pem.Decode(raw); encoded == nil {\n\t\treturn nil, errors.New(\"Ecc.ReadPrivate(): Key must be PEM encoded PKCS1 or PKCS8 EC private key\")\n\t}\n\n\tvar parsedKey interface{}\n\n\tif parsedKey,err=x509.ParseECPrivateKey(encoded.Bytes);err!=nil {\n\t\tif parsedKey, err = x509.ParsePKCS8PrivateKey(encoded.Bytes);err!=nil {\n\t\t\treturn nil,err\n\t\t}\n\t}\n\n\tvar ok bool\n\t\t\n\tif key,ok=parsedKey.(*ecdsa.PrivateKey);!ok {\n\t\treturn nil, errors.New(\"Ecc.ReadPrivate(): Key is not valid *ecdsa.PrivateKey\")\n\t}\n\t\n\treturn key,nil\n}", "reference": "// ReadPrivate loads ecdsa.PrivateKey from given PKCS1 or PKCS8 blobs", "generated": "// ReadPrivate reads raw data from input stream into ecDSA PrivateKey.\n//\n// The returned value will contain only the first 0x80 byte if it's a compressed key,\n// otherwise it contains all bytes in the input slice. If there was no error reading\n// the key then this method returns true to"}
{"id": 4978, "code": "func (c *Consumer) TailingLogs(appGuid, authToken string) (<-chan *events.LogMessage, <-chan error) {\n\treturn c.tailingLogs(appGuid, authToken, true)\n}", "reference": "// TailingLogs listens indefinitely for log messages only; other event types\n// are dropped.\n// Whenever an error is encountered, the error will be sent down the error\n// channel and TailingLogs will attempt to reconnect up to 5 times.  After\n// five failed reconnection attempts, TailingLogs will give up and close the\n// error and LogMessage channels.\n//\n// If c is closed, the returned channels will both be closed.\n//\n// Errors must be drained from the returned error channel for it to continue\n// retrying; if they are not drained, the connection attempts will hang.", "generated": "// TailingLogs returns two channels: one for log messages and another\n// for errors that occur while reading logs from the consumer.\n//\n// The returned channel is closed when the underlying reader closes or if there's\n// no more data to read. If there's an error in the stream, it will be sent"}
{"id": 4980, "code": "func (c *Consumer) Stream(appGuid string, authToken string) (outputChan <-chan *events.Envelope, errorChan <-chan error) {\n\treturn c.runStream(appGuid, authToken, true)\n}", "reference": "// Stream listens indefinitely for all log and event messages.\n//\n// Messages are presented in the order received from the loggregator server.\n// Chronological or other ordering is not guaranteed. It is the responsibility\n// of the consumer of these channels to provide any desired sorting mechanism.\n//\n// Whenever an error is encountered, the error will be sent down the error\n// channel and Stream will attempt to reconnect indefinitely.", "generated": "// Stream returns two channels: one for output events from the consumer\n// and another channel to report errors that occur during processing.\n//\n// The returned channels will be closed when the stream is stopped or if there's\n// no more data available in the queue. If the application has already been\n// shut down then"}
{"id": 5001, "code": "func (d *Dataset) Snapshot(name string, recursive bool) (*Dataset, error) {\n\targs := make([]string, 1, 4)\n\targs[0] = \"snapshot\"\n\tif recursive {\n\t\targs = append(args, \"-r\")\n\t}\n\tsnapName := fmt.Sprintf(\"%s@%s\", d.Name, name)\n\targs = append(args, snapName)\n\t_, err := zfs(args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn GetDataset(snapName)\n}", "reference": "// Snapshot creates a new ZFS snapshot of the receiving dataset, using the\n// specified name.  Optionally, the snapshot can be taken recursively, creating\n// snapshots of all descendent filesystems in a single, atomic operation.", "generated": "// Snapshot creates a snapshot of this dataset. The resulting dataset is returned.\n//\n// If -r is specified then all sub-datasets will be included in the snapshot,\n// otherwise only top level datasets will be captured. Snapshots can't have names that start or end with /\n// or contain / characters other than those"}
{"id": 5017, "code": "func DialWithTimeout(url string, timeout time.Duration) (*Session, error) {\n\tinfo, err := ParseURL(url)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tinfo.Timeout = timeout\n\treturn DialWithInfo(info)\n}", "reference": "// DialWithTimeout works like Dial, but uses timeout as the amount of time to\n// wait for a server to respond when first connecting and also on follow up\n// operations in the session. If timeout is zero, the call may block\n// forever waiting for a connection to be made.\n//\n// See SetSyncTimeout for customizing the timeout for the session.", "generated": "// DialWithTimeout returns a new session for the given URL.\n//\n// The returned session will be closed when it is garbage collected or explicitly\n// called Close(). If no errors occur during connection setup, then the session\n// can be used to send requests without blocking indefinitely if there's network\n// issues. However"}
{"id": 5025, "code": "func (s *Session) LogoutAll() {\n\ts.m.Lock()\n\tfor _, cred := range s.creds {\n\t\tif s.masterSocket != nil {\n\t\t\ts.masterSocket.Logout(cred.Source)\n\t\t}\n\t\tif s.slaveSocket != nil {\n\t\t\ts.slaveSocket.Logout(cred.Source)\n\t\t}\n\t}\n\ts.creds = s.creds[0:0]\n\ts.m.Unlock()\n}", "reference": "// LogoutAll removes all established authentication credentials for the session.", "generated": "// LogoutAll logs out all users from this session's master and slave sockets.\n//\n// This is useful when we want to clear up resources after logging in multiple\n// people. It will log them out immediately if they're currently logged in,\n// but it won't do anything for those who aren't logged in yet"}
{"id": 5048, "code": "func (q *Query) LogReplay() *Query {\n\tq.m.Lock()\n\tq.op.flags |= flagLogReplay\n\tq.m.Unlock()\n\treturn q\n}", "reference": "// LogReplay enables an option that optimizes queries that are typically\n// made on the MongoDB oplog for replaying it. This is an internal\n// implementation aspect and most likely uninteresting for other uses.\n// It has seen at least one use case, though, so it's exposed via the API.", "generated": "// LogReplay sets the log replay flag for this query. This is used to enable logging of all queries that have been executed in order to allow us to debug issues like deadlocks or other problems caused by concurrent execution of multiple queries at once. The default value is false. If set, then any errors encountered during"}
{"id": 5071, "code": "func tokenFor(t *transaction) token {\n\tnonce := t.Nonce\n\tif nonce == \"\" {\n\t\tnonce = newNonce()\n\t}\n\treturn token(t.Id.Hex() + \"_\" + nonce)\n}", "reference": "// tokenFor returns a unique transaction token that\n// is composed by t's id and a nonce. If t already has\n// a nonce assigned to it, it will be used, otherwise\n// a new nonce will be generated.", "generated": "// token returns a unique identifier for this transaction. The returned value is\n// guaranteed to be different from any other transactions that have been created.\n//\n// This method should only be called once per transaction; if it's called multiple times,\n// the same ID will always return. If there was no previous call (i"}
{"id": 5073, "code": "func (r *Runner) Run(ops []Op, id bson.ObjectId, info interface{}) (err error) {\n\tconst efmt = \"error in transaction op %d: %s\"\n\tfor i := range ops {\n\t\top := &ops[i]\n\t\tif op.C == \"\" || op.Id == nil {\n\t\t\treturn fmt.Errorf(efmt, i, \"C or Id missing\")\n\t\t}\n\t\tchanges := 0\n\t\tif op.Insert != nil {\n\t\t\tchanges++\n\t\t}\n\t\tif op.Update != nil {\n\t\t\tchanges++\n\t\t}\n\t\tif op.Remove {\n\t\t\tchanges++\n\t\t}\n\t\tif changes > 1 {\n\t\t\treturn fmt.Errorf(efmt, i, \"more than one of Insert/Update/Remove set\")\n\t\t}\n\t\tif changes == 0 && op.Assert == nil {\n\t\t\treturn fmt.Errorf(efmt, i, \"none of Assert/Insert/Update/Remove set\")\n\t\t}\n\t}\n\tif id == \"\" {\n\t\tid = bson.NewObjectId()\n\t}\n\n\t// Insert transaction sooner rather than later, to stay on the safer side.\n\tt := transaction{\n\t\tId:    id,\n\t\tOps:   ops,\n\t\tState: tpreparing,\n\t\tInfo:  info,\n\t}\n\tif err = r.tc.Insert(&t); err != nil {\n\t\treturn err\n\t}\n\tif err = flush(r, &t); err != nil {\n\t\treturn err\n\t}\n\tif t.State == taborted {\n\t\treturn ErrAborted\n\t} else if t.State != tapplied {\n\t\tpanic(fmt.Errorf(\"invalid state for %s after flush: %q\", &t, t.State))\n\t}\n\treturn nil\n}", "reference": "// Run creates a new transaction with ops and runs it immediately.\n// The id parameter specifies the transaction id, and may be written\n// down ahead of time to later verify the success of the change and\n// resume it, when the procedure is interrupted for any reason. If\n// empty, a random id will be generated.\n// The info parameter, if not nil, is included under the \"i\"\n// field of the transaction document.\n//\n// Operations across documents are not atomically applied, but are\n// guaranteed to be eventually all applied in the order provided or\n// all aborted, as long as the affected documents are only modified\n// through transactions. If documents are simultaneously modified\n// by transactions and out of transactions the behavior is undefined.\n//\n// If Run returns no errors, all operations were applied successfully.\n// If it returns ErrAborted, one or more operations can't be applied\n// and the transaction was entirely aborted with no changes performed.\n// Otherwise, if the transaction is interrupted while running for any\n// reason, it may be resumed explicitly or by attempting to apply\n// another transaction on any of the documents targeted by ops, as\n// long as the interruption was made after the transaction document\n// itself was inserted. Run Resume with the obtained transaction id\n// to confirm whether the transaction was applied or not.\n//\n// Any number of transactions may be run concurrently, with one\n// runner or many.", "generated": "// Run runs all operations within this runner's current transaction. If any errors occur during execution, they will be returned immediately. The result is always nil regardless of whether there was an error or not. This method should only be called from within a single goroutine. It may block indefinitely until it completes its work. See"}
{"id": 5076, "code": "func SetChaos(c Chaos) {\n\tchaosSetting = c\n\tchaosEnabled = c.KillChance > 0 || c.SlowdownChance > 0\n}", "reference": "// SetChaos sets the failure injection parameters to c.", "generated": "// SetChaos sets chaos settings for this service.\n//\n// This is used to set up kill chance or slowdown chance in case of failure,\n// which can be useful during testing. The default values will still apply if no\n// value has been specified here. If both KillChance and SlowdownChance have\n//"}
{"id": 5099, "code": "func NewObjectIdWithTime(t time.Time) ObjectId {\n\tvar b [12]byte\n\tbinary.BigEndian.PutUint32(b[:4], uint32(t.Unix()))\n\treturn ObjectId(string(b[:]))\n}", "reference": "// NewObjectIdWithTime returns a dummy ObjectId with the timestamp part filled\n// with the provided number of seconds from epoch UTC, and all other parts\n// filled with zeroes. It's not safe to insert a document with an id generated\n// by this method, it is useful only for queries to find documents with ids\n// generated before or after the specified timestamp.", "generated": "// NewObjectIdWithTime returns new ObjectId that is based on current Unix timestamp.\n//\n// This method can be used to generate unique identifiers for objects in distributed systems,\n// where it's necessary to ensure uniqueness across different nodes or servers. The generated\n// identifier will have 16 bytes length (8 bytes for UUID +"}
{"id": 5102, "code": "func (id ObjectId) Time() time.Time {\n\t// First 4 bytes of ObjectId is 32-bit big-endian seconds from epoch.\n\tsecs := int64(binary.BigEndian.Uint32(id.byteSlice(0, 4)))\n\treturn time.Unix(secs, 0)\n}", "reference": "// Time returns the timestamp part of the id.\n// It's a runtime error to call this method with an invalid id.", "generated": "// Time returns the date/time when this object was created in UTC timezone. The\n// returned value will be nil if it's zero-length ObjectId. This method should only\n// be called once per ObjectID instance to avoid potential race conditions that can occur\n// due to concurrent access by multiple goroutines. If you"}
{"id": 5107, "code": "func hasMinOf(top interface{}, current interface{}, field interface{}, param string) bool {\n\n\treturn isGte(top, current, field, param)\n}", "reference": "// min tests whether a variable value is larger or equal to a given\n// number. For number types, it's a simple lesser-than test; for\n// strings it tests the number of characters whereas for maps\n// and slices it tests the number of items.", "generated": "// hasMin checks if top >= current for given parameter.\n//\n// If true returns true; otherwise false\n//\n// @param top: The value to compare against\n// @param current: The value we want to check\n// @param field: Field name in struct that contains min/max values\n// @param"}
{"id": 5109, "code": "func Connect() {\n\turi := os.Getenv(\"MONGODB_URL\")\n\n\tif len(uri) == 0 {\n\t\turi = MongoDBUrl\n\t}\n\n\tmongo, err := mgo.ParseURL(uri)\n\ts, err := mgo.Dial(uri)\n\tif err != nil {\n\t\tfmt.Printf(\"Can't connect to mongo, go error %v\\n\", err)\n\t\tpanic(err.Error())\n\t}\n\ts.SetSafe(&mgo.Safe{})\n\tfmt.Println(\"Connected to\", uri)\n\tSession = s\n\tMongo = mongo\n}", "reference": "// Connect connects to mongodb", "generated": "// Connect connects to the database specified by MONGODB_URL environment variable.\n// If that is empty it will use default url from config file. It sets Session,\n// Mongo variables for further usage in this application. You can call this method only once!"}
{"id": 5112, "code": "func (file *GridFile) SetChunkSize(bytes int) {\n\tfile.assertMode(gfsWriting)\n\tdebugf(\"GridFile %p: setting chunk size to %d\", file, bytes)\n\tfile.m.Lock()\n\tfile.doc.ChunkSize = bytes\n\tfile.m.Unlock()\n}", "reference": "// SetChunkSize sets size of saved chunks.  Once the file is written to, it\n// will be split in blocks of that size and each block saved into an\n// independent chunk document.  The default chunk size is 256kb.\n//\n// It is a runtime error to call this function once the file has started\n// being written to.", "generated": "// SetChunkSize sets the number of bytes in each chunk for this GridFile.\n//\n// This is used by the underlying storage system when writing data to disk,\n// so it should be set before calling Write().  If no value has been specified yet,\n// then ChunkSize will default to the maximum possible value that"}
{"id": 5120, "code": "func (file *GridFile) Read(b []byte) (n int, err error) {\n\tfile.assertMode(gfsReading)\n\tfile.m.Lock()\n\tdebugf(\"GridFile %p: reading at offset %d into buffer of length %d\", file, file.offset, len(b))\n\tdefer file.m.Unlock()\n\tif file.offset == file.doc.Length {\n\t\treturn 0, io.EOF\n\t}\n\tfor err == nil {\n\t\ti := copy(b, file.rbuf)\n\t\tn += i\n\t\tfile.offset += int64(i)\n\t\tfile.rbuf = file.rbuf[i:]\n\t\tif i == len(b) || file.offset == file.doc.Length {\n\t\t\tbreak\n\t\t}\n\t\tb = b[i:]\n\t\tfile.rbuf, err = file.getChunk()\n\t}\n\treturn n, err\n}", "reference": "// Read reads into b the next available data from the file and\n// returns the number of bytes written and an error in case\n// something wrong happened.  At the end of the file, n will\n// be zero and err will be set to os.EOF.\n//\n// The parameters and behavior of this function turn the file\n// into an io.Reader.", "generated": "// Read reads from this GridFile's underlying stream into the given byte slice.\n//\n// The returned number is how many bytes were read. If no more data can be\n// read then it will return zero. This method may block if there isn't enough\n// space in the rbuf to hold all remaining data"}
{"id": 5123, "code": "func invertAttributes(windowsMode uint16) uint16 {\n\treturn (COMMON_LVB_MASK & windowsMode) | ((FOREGROUND_MASK & windowsMode) << 4) | ((BACKGROUND_MASK & windowsMode) >> 4)\n}", "reference": "// invertAttributes inverts the foreground and background colors of a Windows attributes value", "generated": "// Inverts attributes for Windows mode by setting foreground to background\n// and vice versa while keeping common LVB flags unchanged. This is useful when\n// switching from text-based console to graphical one or vice versa. The result\n// will be used in Windows API calls like SetConsoleTextAttribute() where it's"}
{"id": 5157, "code": "func (s *SegmentStack) Peek() int64 {\n\tif s.Len() == 0 {\n\t\treturn rootSegment\n\t}\n\treturn s.s[s.Len()-1]\n}", "reference": "// Peek returns id from the top of the stack. It returns rootSegment if the stack is empty.", "generated": "// Peek returns the value at index n in segment stack without removing it.\n//\n// If there is no element at position n then return rootSegment. This method can be used to peek into the stack before popping from it. It's safe for concurrent access if lock is held when calling this method. The caller must hold"}
{"id": 5171, "code": "func (t *tx) StartExternal(host, name string) error {\n\tt.mtx.Lock()\n\tdefer t.mtx.Unlock()\n\n\tid, err := t.Tracer.BeginExternalSegment(t.id, t.ss.Peek(), host, name)\n\tif err != nil {\n\t\treturn err\n\t}\n\tt.ss.Push(id)\n\treturn nil\n}", "reference": "// StartExternal starts an external segment.", "generated": "// StartExternal starts tracing for external service calls.\n//\n// This is used to start tracing when calling services that do not support\n// tracing directly from our application code. The tracer will automatically\n// stop tracing once it has finished processing all segments in this transaction,\n// or if there's an error while doing so."}
{"id": 5186, "code": "func NewClusterWithHost(hosts ...*URI) *Cluster {\n\tcluster := DefaultCluster()\n\tfor _, host := range hosts {\n\t\tcluster.AddHost(host)\n\t}\n\treturn cluster\n}", "reference": "// NewClusterWithHost returns a cluster with the given URIs.", "generated": "// NewClusterWithHost returns a new Cluster instance that includes all provided Host instances.\n//\n// This is useful when creating clusters from existing hosts without having to create them first,\n// or for testing purposes where we want to test multiple hosts at once in one go. The returned\n// cluster will be empty if no hosts"}
{"id": 5206, "code": "func (idx *Index) BatchQuery(queries ...PQLQuery) *PQLBatchQuery {\n\tstringQueries := make([]string, 0, len(queries))\n\thasKeys := false\n\tfor _, query := range queries {\n\t\tserializedQuery := query.Serialize()\n\t\thasKeys = hasKeys || serializedQuery.HasWriteKeys()\n\t\tstringQueries = append(stringQueries, serializedQuery.String())\n\t}\n\treturn &PQLBatchQuery{\n\t\tindex:   idx,\n\t\tqueries: stringQueries,\n\t\thasKeys: hasKeys,\n\t}\n}", "reference": "// BatchQuery creates a batch query with the given queries.", "generated": "// BatchQuery returns a new PQLBatchQuery that can be used to execute multiple\n// queries in one go. The returned object is safe for concurrent use.\n//\n// Note that this method will only work if all queries have keys or no keys at\n// all. If any query contains both key-value pairs and"}
{"id": 5218, "code": "func OptFieldTypeMutex(cacheType CacheType, cacheSize int) FieldOption {\n\treturn func(options *FieldOptions) {\n\t\toptions.fieldType = FieldTypeMutex\n\t\toptions.cacheType = cacheType\n\t\toptions.cacheSize = cacheSize\n\t}\n}", "reference": "// OptFieldTypeMutex adds a mutex field.", "generated": "// OptFieldTypeMutex sets field type to FieldTypeMutex for given options.\n//\n// This option is used when we want to use mutex lock in order to protect access\n// to shared data stored inside the cache. It's useful if there are multiple goroutines\n// accessing same cache at the same time. The mutex will"}
{"id": 5230, "code": "func (f *Field) Rows() *PQLRowsQuery {\n\ttext := fmt.Sprintf(\"Rows(field='%s')\", f.name)\n\treturn NewPQLRowsQuery(text, f.index, nil)\n}", "reference": "// Rows creates a Rows query with defaults", "generated": "// Returns PQL query for rows matching field name. This is used to get all\n// records that have this field set in any row. The index parameter can be\n// provided if there's already an existing index created by another method.\n//\n// Note: If no index has been created yet, it will create"}
{"id": 5261, "code": "func OptClientConnectTimeout(timeout time.Duration) ClientOption {\n\treturn func(options *ClientOptions) error {\n\t\toptions.ConnectTimeout = timeout\n\t\treturn nil\n\t}\n}", "reference": "// OptClientConnectTimeout is the maximum time to connect in nanoseconds.", "generated": "// OptClientConnectTimeout sets the connect timeout for client connections.\n//\n// This option is used to set the maximum amount of time that the client will wait before giving up when trying to establish a connection to a server. If this value is 0 or negative, then there is no limit imposed by this option. The"}
{"id": 5271, "code": "func OptImportThreadCount(count int) ImportOption {\n\treturn func(options *ImportOptions) error {\n\t\toptions.threadCount = count\n\t\treturn nil\n\t}\n}", "reference": "// OptImportThreadCount is the number of goroutines allocated for import.", "generated": "// OptImportThreadCount sets the number of threads to use for importing.\n//\n// This option is useful when dealing with large datasets that can be split into smaller chunks,\n// allowing multiple goroutines to run concurrently without blocking each other. The default value\n// is 1 (i.e., no concurrency). If set"}
{"id": 5282, "code": "func NewValueIterator(format Format, reader io.Reader) *Iterator {\n\treturn NewIterator(reader, FieldValueUnmarshaller(format))\n}", "reference": "// NewValueIterator creates a new iterator for value data.", "generated": "// NewValueIterator returns a new iterator that reads values from\n// the given format using the provided reader. The returned value is\n// wrapped in a Value struct to provide additional functionality.\n//\n// This method creates a new instance of Iterator which will read all fields\n// until it encounters a field that has no corresponding"}
{"id": 5287, "code": "func elementsFromLine(config *Config, line string) []interface{} {\n\tseparated := strings.Split(line, config.Delim)\n\telements := make([]interface{}, len(separated))\n\tfor i, field := range separated {\n\t\tvalue := field\n\t\tif !config.NoTrim {\n\t\t\tvalue = strings.TrimSpace(field)\n\t\t}\n\n\t\t// Apply the empty value, if configured.\n\t\tif value == \"\" && config.Empty != \"\" {\n\t\t\tvalue = config.Empty\n\t\t}\n\t\telements[i] = value\n\t}\n\treturn elements\n}", "reference": "// elementsFromLine returns a list of elements, each representing a single\n// item which will belong to a column of output.", "generated": "// elementsFromLine parses a single input line into individual fields,\n// returning them in a slice. The returned values can be used directly or passed to other functions for further processing. If no delimiter is specified (i.e., it's set to an empty string), then all characters will be treated as one element. This"}
{"id": 5306, "code": "func postEOFCheck(c *Cmp, r io.Reader, buf []byte) bool {\n\ttmpLR, isLR := r.(*io.LimitedReader)\n\tif isLR {\n\t\t// If the limit wasn't reached, then we don't need to check for\n\t\t// more data after the EOF\n\t\tif tmpLR.N > 0 {\n\t\t\treturn true\n\t\t}\n\n\t\t// Use the internal Reader for checking for more data\n\t\tr = tmpLR.R\n\t} else {\n\t\tc.debugf(\"compareReader: A type assertion of LimitedReader unexpectedly failed\\n\")\n\t}\n\n\t// Attempt to read more bytes from the original readers, to determine\n\t// if we should return an error for exceeding the MaxSize read limit.\n\tn, _ := readPartial(c, r, buf, 0, len(buf))\n\treturn n == 0\n}", "reference": "// postEOFCheck returns false if there is more data in a LimitedReader after\n// hitting EOF", "generated": "// postEOFCheck checks that there's no remaining data in the reader before returning\n// an error when reading beyond the max size specified by the cmp object. This\n// ensures that any errors returned will be due to reaching the maximum allowed\n// amount of data rather than because it was truncated early (e.g.,"}
{"id": 5311, "code": "func exist(file string) (bool, error) {\n\t_, err := os.Stat(file)\n\tif err != nil {\n\t\tif err == os.ErrNotExist {\n\t\t\treturn false, nil\n\t\t}\n\t\treturn false, err\n\t}\n\treturn true, nil\n}", "reference": "// exist checks if the file exists.", "generated": "// exists checks if file is present in filesystem.\n//\n// If it's not there then returns false alongwith noerr. Otherwise,\n// returns true alongwith nil. The caller can decide whether to do something or nothing based on this result. It also handles errors that may occur while checking for existence. In case of"}
{"id": 5340, "code": "func (e *edit) Comment(reLine []string) error {\n\tallReSearch := make([]*regexp.Regexp, len(reLine))\n\n\tfor i, v := range reLine {\n\t\tif re, err := regexp.Compile(v); err != nil {\n\t\t\treturn err\n\t\t} else {\n\t\t\tallReSearch[i] = re\n\t\t}\n\t}\n\n\tif _, err := e.file.Seek(0, os.SEEK_SET); err != nil {\n\t\treturn err\n\t}\n\n\tchar := []byte(e.CommentChar + \" \")\n\tisNew := false\n\tbuf := new(bytes.Buffer)\n\n\t// Check every line.\n\tfor {\n\t\tline, err := e.buf.ReadBytes('\\n')\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\n\t\tfor _, v := range allReSearch {\n\t\t\tif v.Match(line) {\n\t\t\t\tline = append(char, line...)\n\n\t\t\t\tif !isNew {\n\t\t\t\t\tisNew = true\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif _, err = buf.Write(line); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif isNew {\n\t\treturn e.rewrite(buf.Bytes())\n\t}\n\treturn nil\n}", "reference": "// Comment inserts the comment character in lines that mach any regular expression\n// in reLine.", "generated": "// Comment adds comments to lines that match any pattern in reLine. The first\n// occurrence is marked by adding the comment char before it. If there's no\n// matching line then nothing happens. This method will only work if we're at\n// the start of the file or after editing has finished because otherwise"}
{"id": 5384, "code": "func Run(command string) (output []byte, err error) {\n\toutput, _, err = RunWithMatch(command)\n\treturn\n}", "reference": "// Run executes external commands just like RunWithMatch, but does not return\n// the boolean `match`.", "generated": "// Run runs command in shell. It returns output from stdout and stderr.\n// If there is no match for command then it will return nil for both output and errors. The only way to get this information back is by checking if either of them is nil after calling run() method. For example: var out bytes.Buffer"}
{"id": 5387, "code": "func (i *info) GroupHas(p ...perm) bool {\n\tmode := i.fi.Mode()\n\n\tfor _, v := range p {\n\t\tswitch v {\n\t\tcase R:\n\t\t\tif mode&modeRGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase W:\n\t\t\tif mode&modeWGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase X:\n\t\t\tif mode&modeXGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\treturn true\n}", "reference": "// GroupHas reports whether the group has all given permissions.", "generated": "// GroupHas returns whether this file has all the specified permissions for group.\n//\n// This is used to determine if we can use the file in a context where it's being read or written by another process,\n// but only when that other process will be writing to the same directory. If there isn't such a guarantee"}
{"id": 5393, "code": "func ChPasswd(user string, key []byte) error {\n\tshadow, err := LookupShadow(user)\n\tif err != nil {\n\t\treturn err\n\t}\n\tshadow.Passwd(key)\n\n\treturn edit(user, shadow)\n}", "reference": "// == Change passwd\n// ChPasswd updates passwd.\n// The passwd must be supplied in clear-text.", "generated": "// ChPasswd changes the password for user to key.\n//\n// This is similar to chpasswd but it uses the lookupShadow method instead,\n// which allows us to use the same code that we would normally call from\n// init() in order to avoid having to recompile our binary if we change\n// the"}
{"id": 5399, "code": "func parseGroup(row string) (*Group, error) {\n\tfields := strings.Split(row, \":\")\n\tif len(fields) != 4 {\n\t\treturn nil, rowError{_GROUP_FILE, row}\n\t}\n\n\tgid, err := strconv.Atoi(fields[2])\n\tif err != nil {\n\t\treturn nil, atoiError{_GROUP_FILE, row, \"GID\"}\n\t}\n\n\treturn &Group{\n\t\tName:     fields[0],\n\t\tpassword: fields[1],\n\t\tGID:      gid,\n\t\tUserList: strings.Split(fields[3], \",\"),\n\t}, nil\n}", "reference": "// parseGroup parses the row of a group.", "generated": "// ParseGroup parses group information from a line in the file.\n//\n// The format is <name>:<password>:<gid>:<userlist>\n// where userlist can be empty or contain multiple users separated by commas.\n//\n// If any field cannot be parsed to its expected type, it returns an error."}
{"id": 5450, "code": "func (c *CallService) Create(ctx context.Context, data url.Values) (*Call, error) {\n\tcall := new(Call)\n\terr := c.client.CreateResource(ctx, callsPathPart, data, call)\n\treturn call, err\n}", "reference": "// Initiate a new Call.", "generated": "// Create creates a Call resource in the server. The URL parameters must be provided by the client to create a valid request body for this method. This is done using the url.Values type which allows easy creation of query strings from key-value pairs. If any errors occur during the execution of this operation, they will be returned"}
{"id": 5453, "code": "func (c *CallService) GetNextCallsInRange(start time.Time, end time.Time, nextPageURI string) CallPageIterator {\n\tif nextPageURI == \"\" {\n\t\tpanic(\"nextpageuri is empty\")\n\t}\n\titer := NewNextPageIterator(c.client, callsPathPart)\n\titer.SetNextPageURI(types.NullString{Valid: true, String: nextPageURI})\n\treturn &callDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetNextCallsInRange retrieves the page at the nextPageURI and continues\n// retrieving pages until any results are found in the range given by start or\n// end, or we determine there are no more records to be found in that range.\n//\n// If CallPage is non-nil, it will have at least one result.", "generated": "// GetNextCallsInRange returns iterator for next page of call records\n// that were created between start and end times.\n//\n// If there's no more pages to iterate over, it will return nil. The caller must close this iterator when done using it. It also has a method to get the current date range if"}
{"id": 5455, "code": "func (c *CallService) GetRecordingsIterator(callSid string, data url.Values) *RecordingPageIterator {\n\tif data == nil {\n\t\tdata = url.Values{}\n\t}\n\t// Cheat - hit the Recordings list view with a filter instead of\n\t// GET /calls/CA123/Recordings. The former is probably more reliable\n\tdata.Set(\"CallSid\", callSid)\n\treturn c.client.Recordings.GetPageIterator(data)\n}", "reference": "// GetRecordings returns an iterator of recording pages for this Call.\n// Note there may be more than one Page of results.", "generated": "// GetRecordingsIterator returns an iterator for all recordings associated\n// with this Call service instance. This will return all records in one page.\n// If there's no recording to display then it will be empty. You can use\n// Next() or Last() methods to get next set of results if needed. Note"}
{"id": 5461, "code": "func (r *KeyService) Delete(ctx context.Context, sid string) error {\n\treturn r.client.DeleteResource(ctx, keyPathPart, sid)\n}", "reference": "// Delete the Key with the given sid. If the Key has already been\n// deleted, or does not exist, Delete returns nil. If another error or a\n// timeout occurs, the error is returned.", "generated": "// Delete deletes a resource by its ID. The client will automatically\n// handle any errors that occur during deletion. If there is no such\n// resource in the system then this method returns nil without raising\n// an exception. This can be useful for cleanup operations where we don't\n// care about whether or not"}
{"id": 5462, "code": "func (a *AlertService) GetAlertsInRange(start time.Time, end time.Time, data url.Values) AlertPageIterator {\n\tif start.After(end) {\n\t\tpanic(\"start date is after end date\")\n\t}\n\td := url.Values{}\n\tif data != nil {\n\t\tfor k, v := range data {\n\t\t\td[k] = v\n\t\t}\n\t}\n\td.Del(\"Page\") // just in case\n\tif start != Epoch {\n\t\tstartFormat := start.UTC().Format(time.RFC3339)\n\t\td.Set(\"StartDate\", startFormat)\n\t}\n\tif end != HeatDeath {\n\t\t// If you specify \"StartTime<=YYYY-MM-DD\", the *latest* result returned\n\t\t// will be midnight (the earliest possible second) on DD. We want all\n\t\t// of the results for DD so we need to specify DD+1 in the API.\n\t\t//\n\t\t// TODO validate midnight-instant math more closely, since I don't think\n\t\t// Twilio returns the correct results for that instant.\n\t\tendFormat := end.UTC().Format(time.RFC3339)\n\t\td.Set(\"EndDate\", endFormat)\n\t}\n\titer := NewPageIterator(a.client, d, alertPathPart)\n\treturn &alertDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetAlertsInRange gets an Iterator containing conferences in the range\n// [start, end), optionally further filtered by data. GetAlertsInRange\n// panics if start is not before end. Any date filters provided in data will\n// be ignored. If you have an end, but don't want to specify a start, use\n// twilio.Epoch for start. If you have a start, but don't want to specify an\n// end, use twilio.HeatDeath for end.\n//\n// Assumes that Twilio returns resources in chronological order, latest\n// first. If this assumption is incorrect, your results will not be correct.\n//\n// Returned AlertPages will have at most PageSize results, but may have fewer,\n// based on filtering.", "generated": "// GetAlertsInRange fetches alerts from the last 24 hours or less if no dates were specified. The\n// request includes only those alerts which occurred within this timeframe. This method can also\n// include any additional parameters passed into it via the 'data' parameter. It's up to the caller\n//"}
{"id": 5466, "code": "func (d Direction) Friendly() string {\n\tswitch d {\n\tcase DirectionOutboundReply:\n\t\treturn \"Reply\"\n\tcase DirectionOutboundCall:\n\t\treturn \"Outgoing (from call)\"\n\tcase DirectionOutboundAPI:\n\t\treturn \"Outgoing (from API)\"\n\tcase DirectionInbound:\n\t\treturn \"Incoming\"\n\tcase DirectionOutboundDial:\n\t\treturn \"Outgoing (via Dial)\"\n\tcase DirectionTrunkingTerminating:\n\t\treturn \"Trunking (terminating)\"\n\tcase DirectionTrunkingOriginating:\n\t\treturn \"Trunking (originating)\"\n\tdefault:\n\t\treturn string(d)\n\t}\n}", "reference": "// Friendly prints out a friendly version of the Direction, following the\n// example shown in the Twilio Dashboard.", "generated": "// Friendly returns a friendly name for this direction. This is used in\n// UIs to make it easier for users to understand which type of call they're making.\n// For example, instead of saying 'DirectionOutbound', we say 'Outbound'. The same goes for incoming calls,\n// where we use '"}
{"id": 5468, "code": "func (m *MessageService) GetPage(ctx context.Context, data url.Values) (*MessagePage, error) {\n\titer := m.GetPageIterator(data)\n\treturn iter.Next(ctx)\n}", "reference": "// GetPage returns a single page of resources. To retrieve multiple pages, use\n// GetPageIterator.", "generated": "// GetPage returns a page from Message service based on given query parameters.\n//\n// If no results found then it will return nil\n// if there is any errors in getting iterator or fetching result then it will be returned along with error message\n// if there is any other issues like network failure etc., then it will"}
{"id": 5470, "code": "func (c *MessageService) GetNextMessagesInRange(start time.Time, end time.Time, nextPageURI string) MessagePageIterator {\n\tif nextPageURI == \"\" {\n\t\tpanic(\"nextpageuri is empty\")\n\t}\n\titer := NewNextPageIterator(c.client, messagesPathPart)\n\titer.SetNextPageURI(types.NullString{Valid: true, String: nextPageURI})\n\treturn &messageDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetNextMessagesInRange retrieves the page at the nextPageURI and continues\n// retrieving pages until any results are found in the range given by start or\n// end, or we determine there are no more records to be found in that range.\n//\n// If MessagePage is non-nil, it will have at least one result.", "generated": "// GetNextMessagesInRange returns iterator for next page of messages in range\n// [start;end). If there's no more pages then it will return nil.\n//\n// Note that this method doesn't check if there are any messages at all before returning\n// iterator. It just checks if there's enough space to"}
{"id": 5486, "code": "func (r *ApplicationService) Delete(ctx context.Context, sid string) error {\n\treturn r.client.DeleteResource(ctx, applicationPathPart, sid)\n}", "reference": "// Delete the Application with the given sid. If the Application has already been\n// deleted, or does not exist, Delete returns nil. If another error or a\n// timeout occurs, the error is returned.", "generated": "// Delete deletes the specified resource from the service. The client will\n// automatically retry if it encounters any errors during deletion.\n//\n// If there is no such resource in the system then this method returns nil,\n// otherwise it returns an error indicating that the operation was successful but\n// the requested resource could not be found"}
{"id": 5490, "code": "func (ipn *IncomingNumberService) BuyNumber(phoneNumber string) (*IncomingPhoneNumber, error) {\n\tdata := url.Values{\"PhoneNumber\": []string{phoneNumber}}\n\treturn ipn.NumberPurchasingService.Create(context.Background(), data)\n}", "reference": "// BuyNumber attempts to buy the provided phoneNumber and returns it if\n// successful.", "generated": "// BuyNumber purchases a number for the given phone number.\n//\n// Returns nil if successful or an error otherwise. The returned\n// IncomingPhoneNumber will be updated to reflect that it is currently in use by this service. If there was no available number,\n// then the PhoneNumber field will remain empty. This method should only"}
{"id": 5517, "code": "func (m *Messenger) DeleteGetStartedButton() error {\n\tresult, err := m.changeThreadSettings(http.MethodDelete, &threadSettings{\n\t\tType:  settingTypeCallToActions,\n\t\tState: threadStateNew,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\tif result.Result != \"Successfully deleted all new_thread's CTAs\" {\n\t\treturn fmt.Errorf(\"Error occured while deleting get started button, invalid result: %s\", result.Result)\n\t}\n\treturn nil\n}", "reference": "// DeleteGetStartedButton delets a button set by SetGetStartedButton", "generated": "// DeleteGetStartedButton deletes the Get Started Button from Messenger. This is useful when testing or debugging purposes to ensure that no one can start conversations using this bot. The delete operation will only work if there are any threads in use by the bot. If there aren't any active threads then it returns an error. After"}
{"id": 5523, "code": "func pushNumberValue(L *lua.State, a interface{}, t1, t2 reflect.Type) {\n\tv := reflect.ValueOf(a)\n\tisComplex := unsizedKind(v) == reflect.Complex128\n\tmt := cNumberMeta\n\tif isComplex {\n\t\tmt = cComplexMeta\n\t}\n\tif t1 == t2 || isPredeclaredType(t2) {\n\t\tmakeValueProxy(L, v.Convert(t1), mt)\n\t} else if isPredeclaredType(t1) {\n\t\tmakeValueProxy(L, v.Convert(t2), mt)\n\t} else if isComplex {\n\t\tcomplexType := reflect.TypeOf(0i)\n\t\tmakeValueProxy(L, v.Convert(complexType), cComplexMeta)\n\t} else {\n\t\tL.PushNumber(valueToNumber(L, v))\n\t}\n}", "reference": "// pushNumberValue pushes the number resulting from an arithmetic operation.\n//\n// At least one operand must be a proxy for this function to be called. See the\n// main documentation for the conversion rules.", "generated": "// pushNumberValue pushes number value to Lua stack.\n//\n// If type of 'a' matches either t1 or t2 then it will be pushed directly,\n// otherwise complex version will be created first and then converted into\n// desired type before pushing onto the stack. This way we can avoid\n// unnecessary conversions"}
{"id": 5556, "code": "func (d *digest) Sum(in []byte) []byte {\n\ts := d.Sum64()\n\tin = append(in, byte(s))\n\tin = append(in, byte(s>>8))\n\tin = append(in, byte(s>>16))\n\tin = append(in, byte(s>>24))\n\tin = append(in, byte(s>>32))\n\tin = append(in, byte(s>>40))\n\tin = append(in, byte(s>>48))\n\tin = append(in, byte(s>>56))\n\treturn in\n}", "reference": "// Encode in little endian", "generated": "// Sum returns the digest for the given input data.\n//\n// The returned value is a slice containing two bytes: first 4 bytes represent\n// the sum of all previous values; second 4 bytes contain the actual hash\n// result. This allows to compute checksums without having to store the full\n// hash"}
{"id": 5562, "code": "func FindPerformancePrice(productPackage datatypes.Product_Package, priceCategory string) (datatypes.Product_Item_Price, error) {\n\tfor _, item := range productPackage.Items {\n\t\tfor _, price := range item.Prices {\n\t\t\t// Only collect prices from valid location groups.\n\t\t\tif price.LocationGroupId != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif !hasCategory(price.Categories, priceCategory) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn price, nil\n\t\t}\n\t}\n\treturn datatypes.Product_Item_Price{}, bosherr.Error(\"Unable to find price for performance storage\")\n}", "reference": "// Find the price in the given package that has the specified category", "generated": "// Finds the first available price in the given category that is associated with the specified package. If no such price exists,\n// returns an empty Product_Item_Price object along with an appropriate BOSH error message. The search only considers items where\n// there is at least one price entry. This method can be used when creating"}
{"id": 5571, "code": "func (o *OrderVMByFilterParams) WithBody(body *models.VMFilter) *OrderVMByFilterParams {\n\to.SetBody(body)\n\treturn o\n}", "reference": "// WithBody adds the body to the order Vm by filter params", "generated": "// SetBody sets the Body field's value. Create a copy of the received object to avoid mutating it directly.\n// To set multiple fields at once pass an empty map: `params.WithBody(map[string]interface{})`. Use Copy() method if you want create a deep copy. If you passed nil or used default pointer"}
{"id": 5572, "code": "func (c *FakeClient) Delete(instanceID string) error {\n\tc.DeleteCalled = true\n\treturn c.DeleteErr\n}", "reference": "// Delete deletes the instance settings for a given instance ID.", "generated": "// Delete is called when deleting an instance. It returns nil if no errors occurred.\n//\n// If there was an error during deletion it will return that instead. The caller can then check for this by calling IsError() to see if any error has been returned. This allows the caller to decide how they want to handle"}
{"id": 5599, "code": "func (o *UpdateVMWithStateParams) WithBody(body *models.VMState) *UpdateVMWithStateParams {\n\to.SetBody(body)\n\treturn o\n}", "reference": "// WithBody adds the body to the update Vm with state params", "generated": "// SetBody sets the Body field's value. Create a new UpdateVMWithStateParams if you don't want to modify o. Use method SetBody instead if o is not modifiable. // Package models imports this type directly; it has no fields. You can safely ignore this warning. // Code was generated by"}
{"id": 5601, "code": "func (o *AddVMParams) WithTimeout(timeout time.Duration) *AddVMParams {\n\to.SetTimeout(timeout)\n\treturn o\n}", "reference": "// WithTimeout adds the timeout to the add Vm params", "generated": "// SetTimeout sets the timeout for this request to be executed.\n//\n// The default value is 30 seconds. You can override it by setting it explicitly.\n// The maximum allowed value is 30000 milliseconds or 5 minutes. If set to zero,\n// it will use the system's default timeout. Setting it"}
{"id": 5606, "code": "func (o *ListVMParams) WithContext(ctx context.Context) *ListVMParams {\n\to.SetContext(ctx)\n\treturn o\n}", "reference": "// WithContext adds the context to the list Vm params", "generated": "// SetContext sets the Context field's value. See ListVMParams for method signature.\n//\n// Use this method to set the Context field's value after the object is created,\n// typically used when returing from a function. This avoids possible runtime errors\n// that may occur if the structure was passed via a pointer"}
{"id": 5626, "code": "func (pk PrivKeyLedgerSecp256k1) getPubKey() (key PubKey, err error) {\n\tdev, err := getLedger()\n\tif err != nil {\n\t\treturn key, fmt.Errorf(\"cannot connect to Ledger device - error: %v\", err)\n\t}\n\tkey, err = pubkeyLedgerSecp256k1(dev, pk.Path)\n\tif err != nil {\n\t\treturn key, fmt.Errorf(\"please open Cosmos app on the Ledger device - error: %v\", err)\n\t}\n\treturn key, err\n}", "reference": "// getPubKey reads the pubkey the ledger itself\n// since this involves IO, it may return an error, which is not exposed\n// in the PubKey interface, so this function allows better error handling", "generated": "// getPubKey returns public key from ledger device. If there is no private key associated with this path,\n// it will return an empty byte slice. The returned value can be used for signing transactions.\n//\n// Note that if the private key has been deleted or removed from the ledger device, calling this method may result"}
{"id": 5656, "code": "func (kb dbKeybase) ImportPubKey(name string, armor string) (err error) {\n\tbz := kb.db.Get(infoKey(name))\n\tif len(bz) > 0 {\n\t\treturn errors.New(\"Cannot overwrite data for name \" + name)\n\t}\n\tpubBytes, err := unarmorPubKeyBytes(armor)\n\tif err != nil {\n\t\treturn\n\t}\n\tpubKey, err := crypto.PubKeyFromBytes(pubBytes)\n\tif err != nil {\n\t\treturn\n\t}\n\tkb.writeOfflineKey(pubKey, name)\n\treturn\n}", "reference": "// ImportPubKey imports ASCII-armored public keys.\n// Store a new Info object holding a public key only, i.e. it will\n// not be possible to sign with it as it lacks the secret key.", "generated": "// ImportPubKey imports a public key into Keybase's database.\n//\n// This is used to import keys from other sources that don't have access to our\n// internal database or API. The key must be in PEM format, which can be obtained\n// by using tools like OpenSSL. If this fails, it"}
{"id": 5660, "code": "func CompareHashAndPassword(hashedPassword, password []byte) error {\n\tp, err := newFromHash(hashedPassword)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\totherHash, err := bcrypt(password, p.cost, p.salt)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\totherP := &hashed{otherHash, p.salt, p.cost, p.major, p.minor}\n\tif subtle.ConstantTimeCompare(p.Hash(), otherP.Hash()) == 1 {\n\t\treturn nil\n\t}\n\n\treturn ErrMismatchedHashAndPassword\n}", "reference": "// CompareHashAndPassword compares a bcrypt hashed password with its possible\n// plaintext equivalent. Returns nil on success, or an error on failure.", "generated": "// CompareHashAndPassword checks if hashed_password matches password.\n//\n// If they match then it returns no error otherwise it will return\n// ErrMismatchedHashAndPassword which is a custom error type for this package.\n//\n// This method uses constant time comparison to prevent timing attacks,\n// but still allows for fast lookup in case"}
{"id": 5696, "code": "func doDemangle(out *bufio.Writer, name string) {\n\tskip := 0\n\tif name[0] == '.' || name[0] == '$' {\n\t\tskip++\n\t}\n\tif *stripUnderscore && name[skip] == '_' {\n\t\tskip++\n\t}\n\tresult := demangle.Filter(name[skip:], options()...)\n\tif result == name[skip:] {\n\t\tout.WriteString(name)\n\t} else {\n\t\tif name[0] == '.' {\n\t\t\tout.WriteByte('.')\n\t\t}\n\t\tout.WriteString(result)\n\t}\n}", "reference": "// Demangle a string just as the GNU c++filt program does.", "generated": "// DoDemangle writes out the given symbol to the writer in its demangled form.\n//\n// The first character is skipped if it's either a dot or dollar sign,\n// unless stripUnderscores is true (in which case underscores are also stripped).\n// If the original symbol was already fully demangled then no"}
{"id": 5707, "code": "func (s *Sentinel) defaultPool(addr string) *redis.Pool {\n\treturn &redis.Pool{\n\t\tMaxIdle:     3,\n\t\tMaxActive:   10,\n\t\tWait:        true,\n\t\tIdleTimeout: 240 * time.Second,\n\t\tDial: func() (redis.Conn, error) {\n\t\t\treturn s.Dial(addr)\n\t\t},\n\t\tTestOnBorrow: func(c redis.Conn, t time.Time) error {\n\t\t\t_, err := c.Do(\"PING\")\n\t\t\treturn err\n\t\t},\n\t}\n}", "reference": "// defaultPool returns a connection pool to one Sentinel. This allows\n// us to call concurrent requests to Sentinel using connection Do method.", "generated": "// Default pool is used when no other pool has been set for this sentinel.\n//\n// This will create a new pool that uses the same connection settings as the\n// underlying Redis client. The number of idle connections can be adjusted by\n// calling SetDefaultPool(). If there's already a custom pool defined using"}
{"id": 5723, "code": "func (c *Client) CompareAndSwap(item *Item) error {\n\treturn c.populateOne(cmdSet, item, item.casid)\n}", "reference": "// CompareAndSwap writes the given item that was previously returned\n// by Get, if the value was neither modified or evicted between the\n// Get and the CompareAndSwap calls. The item's Key should not change\n// between calls but all other item fields may differ. ErrCASConflict\n// is returned if the value was modified in between the\n// calls. ErrNotStored is returned if the value was evicted in between\n// the calls.", "generated": "// CompareAndSwap is similar to Get but returns nil if no matching\n// Item exists or if it has been deleted since we last checked.\n//\n// This method will return an error if there was a CAS failure. If that happens,\n// then the Item may have been updated by another goroutine while this call was"}
{"id": 5736, "code": "func Ticker(ticker <-chan time.Time, procfunc gp.ProcessFunc) gp.Process {\n\treturn gp.Go(callOnTicker(ticker, procfunc))\n}", "reference": "// Ticker calls the given ProcessFunc every time the ticker fires.\n// This is sequentially rate limited, only one call will be in-flight at a time.", "generated": "// Ticker runs a goroutine that calls func every tick duration.\n//\n// The ticker is started when this process starts. It will continue to run\n// until it's stopped by calling Stop() or killed (e.g., via SIGINT).\n//\n// If the ticker is already running, its current state is preserved"}
{"id": 5746, "code": "func (a *API) FetchCheck(cid CIDType) (*Check, error) {\n\tif cid == nil || *cid == \"\" {\n\t\treturn nil, fmt.Errorf(\"Invalid check CID [none]\")\n\t}\n\n\tcheckCID := string(*cid)\n\n\tmatched, err := regexp.MatchString(config.CheckCIDRegex, checkCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !matched {\n\t\treturn nil, fmt.Errorf(\"Invalid check CID [%s]\", checkCID)\n\t}\n\n\tresult, err := a.Get(checkCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] fetch check, received JSON: %s\", string(result))\n\t}\n\n\tcheck := new(Check)\n\tif err := json.Unmarshal(result, check); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn check, nil\n}", "reference": "// FetchCheck retrieves check with passed cid.", "generated": "// FetchCheck returns Check object from API for given check ID.\n//\n// If no match is found in config, it will return nil along with appropriate\n// error message. It also logs debug information if enabled. The returned\n// result can be used to update or delete the check using UpdateCheck() method,\n//"}
{"id": 5747, "code": "func (a *API) FetchChecks() (*[]Check, error) {\n\tresult, err := a.Get(config.CheckPrefix)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar checks []Check\n\tif err := json.Unmarshal(result, &checks); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &checks, nil\n}", "reference": "// FetchChecks retrieves all checks available to the API Token.", "generated": "// Fetches all available check results from the API. Returns nil if there is no data to fetch or if fetching fails. The returned slice will be populated in-place by this method. If it's empty after calling this method, then either there was no data fetched or something went wrong during unmarshalling. You can"}
{"id": 5752, "code": "func (a *API) FetchGraph(cid CIDType) (*Graph, error) {\n\tif cid == nil || *cid == \"\" {\n\t\treturn nil, fmt.Errorf(\"Invalid graph CID [none]\")\n\t}\n\n\tgraphCID := string(*cid)\n\n\tmatched, err := regexp.MatchString(config.GraphCIDRegex, graphCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !matched {\n\t\treturn nil, fmt.Errorf(\"Invalid graph CID [%s]\", graphCID)\n\t}\n\n\tresult, err := a.Get(graphCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] fetch graph, received JSON: %s\", string(result))\n\t}\n\n\tgraph := new(Graph)\n\tif err := json.Unmarshal(result, graph); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn graph, nil\n}", "reference": "// FetchGraph retrieves graph with passed cid.", "generated": "// FetchGraph returns the Graph object for the given CID.\n//\n// If no matching CID is found in the database, it will return an empty Graph object.\n//\n// The returned value can be used to access all nodes within this graph by calling\n// GetNode() or GetEdge(). Note that if there was an"}
{"id": 5786, "code": "func (a *API) FetchAnnotations() (*[]Annotation, error) {\n\tresult, err := a.Get(config.AnnotationPrefix)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar annotations []Annotation\n\tif err := json.Unmarshal(result, &annotations); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &annotations, nil\n}", "reference": "// FetchAnnotations retrieves all annotations available to the API Token.", "generated": "// FetchAnnotations fetches all annotation data from the API server.\n//\n// This is used to populate the Annotation field in the Pod object when it's created or updated,\n// so that we can display them in the UI. The annotations should be stored under the key specified by config.AnnotationPrefix.\n//\n// If there was"}
{"id": 5815, "code": "func (m *CirconusMetrics) NewHistogram(metric string) *Histogram {\n\tm.hm.Lock()\n\tdefer m.hm.Unlock()\n\n\tif hist, ok := m.histograms[metric]; ok {\n\t\treturn hist\n\t}\n\n\thist := &Histogram{\n\t\tname: metric,\n\t\thist: circonusllhist.New(),\n\t}\n\n\tm.histograms[metric] = hist\n\n\treturn hist\n}", "reference": "// NewHistogram returns a histogram instance.", "generated": "// NewHistogram returns a new Histogram for the given metric name.\n//\n// If there is already a histogram registered under this metric name it will be returned instead of creating one. This can help to avoid unnecessary overhead when metrics have been previously recorded. The caller must ensure that all necessary cleanup happens before returning from their handler."}
{"id": 5847, "code": "func (a *API) CreateRuleSet(cfg *RuleSet) (*RuleSet, error) {\n\tif cfg == nil {\n\t\treturn nil, fmt.Errorf(\"Invalid rule set config [nil]\")\n\t}\n\n\tjsonCfg, err := json.Marshal(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] create rule set, sending JSON: %s\", string(jsonCfg))\n\t}\n\n\tresp, err := a.Post(config.RuleSetPrefix, jsonCfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\truleset := &RuleSet{}\n\tif err := json.Unmarshal(resp, ruleset); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn ruleset, nil\n}", "reference": "// CreateRuleSet creates a new rule set.", "generated": "// CreateRuleSet creates a new Rule Set in the API server.\n//\n// This method sends a POST request to the /ruleSets endpoint with the provided configuration.\n// The returned RuleSet object is populated from the received data. If there's any errors during this process,\n// it will be logged at debug level if"}
{"id": 5860, "code": "func (a *API) DeleteWorksheet(cfg *Worksheet) (bool, error) {\n\tif cfg == nil {\n\t\treturn false, fmt.Errorf(\"Invalid worksheet config [nil]\")\n\t}\n\treturn a.DeleteWorksheetByCID(CIDType(&cfg.CID))\n}", "reference": "// DeleteWorksheet deletes passed worksheet.", "generated": "// DeleteWorksheet deletes a worksheet by its CID.\n//\n// If no worksheet is found for this ID, it returns true without any errors\n// but also sets the return value to false. The caller should check that result before returning from their code. This can be useful if they want to avoid panicking in case something"}
{"id": 5865, "code": "func (a *API) CreateContactGroup(cfg *ContactGroup) (*ContactGroup, error) {\n\tif cfg == nil {\n\t\treturn nil, fmt.Errorf(\"Invalid contact group config [nil]\")\n\t}\n\n\tjsonCfg, err := json.Marshal(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] create contact group, sending JSON: %s\", string(jsonCfg))\n\t}\n\n\tresult, err := a.Post(config.ContactGroupPrefix, jsonCfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tgroup := &ContactGroup{}\n\tif err := json.Unmarshal(result, group); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn group, nil\n}", "reference": "// CreateContactGroup creates a new contact group.", "generated": "// CreateContactGroup creates a new Contact Group in the API server.\n//\n// This method is used to send a POST request to the /contactgroups endpoint,\n// which will return the newly created contact group object if successful.\n//\n// If there was any errors during this process it returns an error message along\n// with"}
{"id": 5890, "code": "func NewEllipticSigner(alg Algorithm, curve elliptic.Curve) func(Store, crypto.Hash) (Signer, error) {\n\tcurveBitSize := curve.Params().BitSize\n\n\t// precompute curve key len\n\tkeyLen := curveBitSize / 8\n\tif curveBitSize%8 > 0 {\n\t\tkeyLen++\n\t}\n\n\treturn func(store Store, hash crypto.Hash) (Signer, error) {\n\t\tvar ok bool\n\t\tvar privRaw, pubRaw interface{}\n\t\tvar priv *ecdsa.PrivateKey\n\t\tvar pub *ecdsa.PublicKey\n\n\t\t// check private key\n\t\tif privRaw, ok = store.PrivateKey(); ok {\n\t\t\tif priv, ok = privRaw.(*ecdsa.PrivateKey); !ok {\n\t\t\t\treturn nil, ErrInvalidPrivateKey\n\t\t\t}\n\n\t\t\t// check curve type matches private key curve type\n\t\t\tif curveBitSize != priv.Curve.Params().BitSize {\n\t\t\t\treturn nil, ErrInvalidPrivateKeySize\n\t\t\t}\n\t\t}\n\n\t\t// check public key\n\t\tif pubRaw, ok = store.PublicKey(); ok {\n\t\t\tif pub, ok = pubRaw.(*ecdsa.PublicKey); !ok {\n\t\t\t\treturn nil, ErrInvalidPublicKey\n\t\t\t}\n\t\t}\n\n\t\t// check that either a private or public key has been provided\n\t\tif priv == nil && pub == nil {\n\t\t\treturn nil, ErrMissingPrivateOrPublicKey\n\t\t}\n\n\t\treturn &EccSigner{\n\t\t\talg:    alg,\n\t\t\tcurve:  curve,\n\t\t\thash:   hash,\n\t\t\tpriv:   priv,\n\t\t\tpub:    pub,\n\t\t\tkeyLen: keyLen,\n\t\t}, nil\n\t}\n}", "reference": "// NewEllipticSigner creates an Elliptic Curve Signer for the specified curve.", "generated": "// NewEllipticSigner returns a new Elliptic signer for given algorithm and curve.\n//\n// The returned signer can be used to sign messages using the specified algorithm\n// and curve. If no keys have been set in the store then it will attempt to find\n// them based on their names. It"}
{"id": 5907, "code": "func FromFile(path string, opts ...Option) (*GServiceAccount, error) {\n\tbuf, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn FromJSON(buf, opts...)\n}", "reference": "// FromFile loads Google service account credentials from a reader.", "generated": "// Load service account from file path. The JSON data is expected to be in the format defined by GServiceAccount.\n//\n// If no options are provided, default values will be used for all fields except keyId,\n// which must match exactly one of the keys specified in the Options parameter.\n//\n// Returns nil if"}
{"id": 5932, "code": "func PostEZCountTime(statName, ezkey string, count int, timestamp int64) error {\n\treturn DefaultReporter.PostEZCountTime(statName, ezkey, count, timestamp)\n}", "reference": "// Using the EZ API, posts a count to a stat at a specific time using DefaultReporter.", "generated": "// PostEZCountTime is used to post EZ counts for a given time period.\n//\n// This method will be called by the reporter when it has finished processing\n// all events in the specified time range. The event must have been processed\n// before this call can occur. If there was no data collected during that"}
{"id": 5952, "code": "func (s Scan) AddHosts(hosts ...string) Scan {\n\ts.configHosts = append(s.configHosts, hosts...)\n\treturn s\n}", "reference": "// AddHosts adds a list of hosts to the list of hosts to be scanned", "generated": "// AddHosts adds multiple hostnames to scan. This is useful for adding all\n// subdomains or other related domains that should be scanned.\n//\n// Example: `scan.AddHosts(\"example.com\", \"sub.example.com\")` will add both\n// example.com and sub.example.com to the list of"}
{"id": 5955, "code": "func (s Scan) SetPorts(ports ...uint16) Scan {\n\ts.configPorts = ports\n\treturn s\n}", "reference": "// SetPorts sets the ports that wil be used", "generated": "// SetPorts sets the list of port numbers to scan for this scanner.\n//\n// The default is 1-1024 if no value was set by calling SetPortRange or\n// SetScanPortRange. If multiple values were passed in then they will be used\n// sequentially until all have been exhausted. For"}
{"id": 5964, "code": "func (otp HOTP) Counter() uint64 {\n\tcounter := binary.BigEndian.Uint64(otp.counter[:])\n\treturn counter\n}", "reference": "// Counter returns the HOTP's 8-byte counter as an unsigned 64-bit\n// integer.", "generated": "// Counter returns the current value of the OTP's internal counter.\n//\n// The counter is incremented every time the OTP is used to generate a new key,\n// which means that it will eventually overflow when all possible values have been generated.\n// This can be detected by checking if the counter has reached its maximum value or"}
{"id": 5967, "code": "func (otp *HOTP) URL(label string) string {\n\tsecret := base32.StdEncoding.EncodeToString(otp.Key)\n\tu := url.URL{}\n\tv := url.Values{}\n\tu.Scheme = \"otpauth\"\n\tu.Host = \"hotp\"\n\tu.Path = label\n\tv.Add(\"secret\", secret)\n\tv.Add(\"counter\", fmt.Sprintf(\"%d\", otp.Counter()))\n\tu.RawQuery = v.Encode()\n\treturn u.String()\n}", "reference": "// URL returns a suitable URL, such as for the Google Authenticator\n// app. The label is used by these apps to identify the service to\n// which this OTP belongs. The digits value is ignored by the Google\n// authenticator app, and is therefore elided in the resulting URL.", "generated": "// URL returns the URL for this HOTP instance. The counter is set to 0 by default.\n//\n// If you want to use a different counter value, pass it in as a parameter.\n// For example: hotp://example.com/label?secret=your_secret&counter=12345\n// You"}
{"id": 5975, "code": "func Marshal(otp *HOTP) ([]byte, error) {\n\tvar asnHOTP struct {\n\t\tKey     []byte\n\t\tCounter *big.Int\n\t\tDigits  int\n\t}\n\tasnHOTP.Key = otp.Key[:]\n\tasnHOTP.Counter = new(big.Int).SetUint64(otp.Counter())\n\tasnHOTP.Digits = otp.Digits\n\treturn asn1.Marshal(asnHOTP)\n}", "reference": "// Marshal serialises an HOTP key value as a DER-encoded byte slice.", "generated": "// Marshal converts HOTP to ASN.1 encoded byte slice.\n//\n// This is used for encoding in PEM format or other formats that require\n// ASN.1 encoding. The returned value can be decoded back into a HOTP object using\n// Unmarshal. Note: this method only works if the counter has been"}
{"id": 5981, "code": "func (pool *ReaderPool) Get(r io.Reader) (reader io.Reader, release func()) {\n\t// don't export a ThrottlerReader to prevent users changing the rate\n\t// and expecting their change to be respected, since we might modify\n\t// the rate under their feet\n\n\t// make the initial rate be 0, the actual rate is\n\t// set in the call to `setSharedRates`.\n\trd := ThrottledReader(r, 0, pool.maxBurst)\n\n\tpool.mu.Lock()\n\tpool.givenOut[rd] = struct{}{}\n\tpool.setSharedRates()\n\tpool.mu.Unlock()\n\n\treturn rd, func() {\n\t\tpool.mu.Lock()\n\t\tdelete(pool.givenOut, rd)\n\t\tpool.setSharedRates()\n\t\tpool.mu.Unlock()\n\t}\n}", "reference": "// Get a throttled reader that wraps r.", "generated": "// Get returns a throttled reader that will only read from r at most maxBurst times.\n//\n// The returned reader must be closed when it's no longer needed; this ensures\n// that all readers have been released back into the pool before any new ones can\n// be acquired. If there aren't enough"}
{"id": 6002, "code": "func JsonFile(path string) (Typed, error) {\n\tdata, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn Json(data)\n}", "reference": "// Create a Typed helper from the JSON within a file", "generated": "// JsonFile reads JSON from file path.\n//\n// Returns Typed if successful or nil otherwise. The data is read in binary format,\n// so it must be converted to json before being used by typed. If there's any issue\n// during conversion, return nil along with appropriate error message. This method\n// assumes"}
{"id": 6018, "code": "func (t Typed) TimeMust(key string) time.Time {\n\ttt, exists := t.TimeIf(key)\n\tif exists == false {\n\t\tpanic(\"expected time.Time value for \" + key)\n\t}\n\treturn tt\n}", "reference": "// Returns a time.Time or panics", "generated": "// TimeMust returns the typed time if it is present in the map.\n//\n// If no such entry exist then panic() will be called to indicate that there was\n// something wrong. This method should only be used when we know that this field\n// must always have been set by now or else some other error"}
{"id": 6025, "code": "func (t Typed) BoolsOr(key string, d []bool) []bool {\n\tn, ok := t.BoolsIf(key)\n\tif ok {\n\t\treturn n\n\t}\n\treturn d\n}", "reference": "// Returns an slice of boolean, or the specified slice", "generated": "// BoolsOr returns all values for key if they exist in typed,\n// otherwise it will return the provided default value.\n//\n// If there is only one value then that value will be returned instead of nil.\n// This can also be used to provide a default value when no other option exists. For example: b"}
{"id": 6037, "code": "func NewWorker(logger log.Logger, db *reform.DB, ethBack eth.Backend,\n\tgasConc *GasConf, pscAddr common.Address, payAddr string,\n\tpwdGetter data.PWDGetter, countryConf *country.Config,\n\tdecryptKeyFunc data.ToPrivateKeyFunc, eptConf *ept.Config,\n\ttorHostname string, somcClientBuilder somc.ClientBuilderInterface) (*Worker, error) {\n\n\tl := logger.Add(\"type\", \"proc/worker.Worker\")\n\n\tabi, err := abi.JSON(\n\t\tstrings.NewReader(contract.PrivatixServiceContractABI))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\teptService, err := ept.New(db, logger, payAddr, eptConf.Timeout)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &Worker{\n\t\tabi:               abi,\n\t\tlogger:            l,\n\t\tdb:                db,\n\t\tdecryptKeyFunc:    decryptKeyFunc,\n\t\tgasConf:           gasConc,\n\t\tept:               eptService,\n\t\tethBack:           ethBack,\n\t\tpscAddr:           pscAddr,\n\t\tpwdGetter:         pwdGetter,\n\t\tcountryConfig:     countryConf,\n\t\ttorHostName:       data.FromBytes([]byte(torHostname)),\n\t\tsomcClientBuilder: somcClientBuilder,\n\t}, nil\n}", "reference": "// NewWorker returns new instance of worker.", "generated": "// NewWorker creates new worker instance for Privatix service contract.\n//\n// It returns error if any part of initialization fails or if there is no\n// valid configuration provided to this constructor. Otherwise it returns\n// pointer to newly created Worker struct which can be used in further calls\n// like Start() method."}
{"id": 6089, "code": "func AddWithDelay(q Queue, tx *reform.TX,\n\tjobType, relatedType, relatedID, creator string,\n\tdelay time.Duration) error {\n\treturn AddWithDataAndDelay(q, tx,\n\t\tjobType, relatedType, relatedID, creator, &struct{}{}, delay)\n}", "reference": "// AddWithDelay is convenience method to add a job with given data delay.", "generated": "// AddWithDelay adds job to queue after specified delay.\n//\n// If there is no available slot in the queue for this type of transaction\n// then it will be added at the end of the list (i.e., last). This can help\n// prevent overloading when adding jobs from multiple sources concurrently.\n//"}
{"id": 6115, "code": "func NewFileLogger(conf *FileConfig) (Logger, io.Closer, error) {\n\tnow := time.Now()\n\tif conf.UTC {\n\t\tnow = now.UTC()\n\t}\n\n\tfile, err := os.OpenFile(\n\t\ttimeutil.Strftime(&now, conf.Filename),\n\t\tos.O_APPEND|os.O_CREATE|os.O_WRONLY, conf.FileMode)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tlogger, err := NewWriterLogger(conf.WriterConfig, file)\n\tif err != nil {\n\t\tfile.Close()\n\t\treturn nil, nil, err\n\t}\n\n\treturn logger, file, nil\n}", "reference": "// NewFileLogger creates a new file logger.", "generated": "// NewFileLogger returns a new FileLogger instance that writes to a log file.\n//\n// The filename is generated based on the current timestamp in UTC if specified by\n// config.Utc. If it's false then local timezone will be used for generating the\n// filename. The mode of the opened file can also"}
{"id": 6138, "code": "func (b *backendInstance) EthBalanceAt(ctx context.Context,\n\towner common.Address) (*big.Int, error) {\n\tctx2, cancel := b.addTimeout(ctx)\n\tdefer cancel()\n\n\treturn b.conn.ethClient().BalanceAt(ctx2, owner, nil)\n}", "reference": "// EthBalanceAt returns the wei balance of the given account.", "generated": "// EthBalanceAt returns the balance for the given address at block number\n// specified by ctx. The result is returned in wei units.\n//\n// If there's no such block available then it will return 0. This method can be used to get\n// the current balance if we don't know which block this"}
{"id": 6147, "code": "func (w *Worker) keyFromChannelData(logger log.Logger,\n\tchannel string) (data.Base64String, error) {\n\tch, err := w.channel(logger, channel)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\toffering, err := w.offering(logger, ch.Offering)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tkey, err := data.ChannelKey(ch.Client, ch.Agent,\n\t\tch.Block, offering.Hash)\n\t// internal\n\tif err != nil {\n\t\tlogger.Add(\"channel\", ch, \"offering\", offering).Error(err.Error())\n\t\treturn \"\", ErrInternal\n\t}\n\treturn data.FromBytes(key), nil\n}", "reference": "// keyFromChannelData returns the unique channel identifier\n// used in a Privatix Service Contract.", "generated": "// keyFromChannelData returns the base64 encoded key for the given channel.\n//\n// This is used to verify that we have received all blocks in the chain before\n// proceeding further. The returned value will be empty if there was no block\n// offered by this client or agent. If any other errors occur during"}
{"id": 6157, "code": "func (w *Worker) AgentAfterOfferingDelete(job *data.Job) error {\n\tlogger := w.logger.Add(\n\t\t\"method\", \"AgentAfterOfferingDelete\", \"job\", job)\n\n\toffering, err := w.relatedOffering(\n\t\tlogger, job, data.JobAgentAfterOfferingDelete)\n\tif err != nil {\n\t\treturn err\n\t}\n\toffering.Status = data.OfferRemoved\n\n\tif err := w.saveRecord(logger, w.db.Querier, offering); err != nil {\n\t\treturn err\n\t}\n\n\tagent, err := w.account(logger, offering.Agent)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn w.addJob(logger, nil,\n\t\tdata.JobAccountUpdateBalances, data.JobAccount, agent.ID)\n}", "reference": "// AgentAfterOfferingDelete set offering status to `remove`", "generated": "// AgentAfterOfferingDelete is called after deleting an offer from the worker's\n// database. It updates the related account balance to reflect that it has been\n// removed. The update will be done in two steps: first updating the offer status\n// then updating the balances for all accounts involved. This ensures that"}
{"id": 6177, "code": "func (m *Monitor) VerifyChannelsForInactivity() error {\n\tquery := `\n              SELECT channels.id::text\n\t\tFROM channels\n                     LEFT JOIN sessions ses\n                     ON channels.id = ses.channel\n                     LEFT JOIN offerings offer\n                     ON channels.offering = offer.id\n                     INNER JOIN accounts acc\n                     ON channels.agent = acc.eth_addr\n               WHERE channels.service_status IN ('pending', 'active', 'suspended')\n                 AND channels.channel_status NOT IN ('pending')\n                 AND acc.in_use\n               GROUP BY channels.id, offer.max_inactive_time_sec\n              HAVING GREATEST(MAX(ses.last_usage_time), channels.service_changed_time) +\n\t      (offer.max_inactive_time_sec * INTERVAL '1 second') < now();`\n\n\treturn m.processEachChannel(query, m.terminateService)\n}", "reference": "// VerifyChannelsForInactivity scans all channels, that are not terminated,\n// and terminates those of them, who are staying inactive too long.", "generated": "// VerifyChannelsForInactivity checks if any channel has been inactive for more than its maximum allowed time.\n//\n// This is done by joining all active services to their respective channels,\n// checking that there's no pending or suspended service in each channel,\n// and then verifying whether the last usage was before the max inactive period"}
{"id": 6235, "code": "func New(db *reform.DB, logger log.Logger, payAddr string,\n\ttimeout uint) (*Service, error) {\n\treturn &Service{\n\t\tdb:      db,\n\t\tmsgChan: make(chan *req),\n\t\tpayAddr: payAddr,\n\t\ttimeout: time.Duration(timeout) * time.Millisecond,\n\t\tlogger:  logger.Add(\"type\", \"messages/ept.Service\"),\n\t}, nil\n}", "reference": "// New function for initialize the service for generating\n// the Endpoint Message.", "generated": "// New creates new instance of Service. It is used to send messages from\n// different goroutines. The service will be closed when it's no longer needed.\n//\n// If there was any errors during initialization, they should be returned here.\n// Otherwise, nil is returned. This method can only be called once."}
{"id": 6244, "code": "func BytesToUint32(b []byte) (uint32, error) {\n\tif len(b) != 4 {\n\t\treturn 0, fmt.Errorf(\"wrong len\")\n\t}\n\treturn binary.BigEndian.Uint32(b), nil\n}", "reference": "// BytesToUint32 using big endian.", "generated": "// Convert bytes to uint32. If there is no valid data in b then return 0.\n//\n// This function assumes that input byte slice has exactly four elements,\n// otherwise it returns an error. The first element must be non-zero for this\n// conversion to work correctly. Otherwise, result will always be zero"}
{"id": 6251, "code": "func ChannelKey(client, agent HexString, block uint32,\n\tofferingHash HexString) ([]byte, error) {\n\tclientAddr, err := HexToAddress(client)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tagentAddr, err := HexToAddress(agent)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\thash, err := base64.URLEncoding.DecodeString(\n\t\tstrings.TrimSpace(string(offeringHash)))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tblockBytes := Uint32ToBytes(block)\n\n\treturn crypto.Keccak256(clientAddr.Bytes(),\n\t\tagentAddr.Bytes(), blockBytes[:],\n\t\tcommon.BytesToHash(hash).Bytes()), nil\n}", "reference": "// ChannelKey returns the unique channel identifier\n// used in a Privatix Service Contract.", "generated": "// ChannelKey returns a key for a channel given client address, agent hash,\n// block number and offering hash.\n//\n// The returned value is used to encrypt messages sent over this channel.\n// It's also used in the signature verification process when receiving\n// messages from other nodes. If there was no message received yet"}
{"id": 6280, "code": "func PanicHunter() {\n\tif panicIgnore {\n\t\treturn\n\t}\n\n\tif err := recover(); err != nil {\n\t\tif enable && notifier != nil {\n\t\t\tnotifier.NotifySync(\n\t\t\t\terrors.New(err, 3), true,\n\t\t\t\tmetadata([]data.HexString{defaultAccEth}))\n\t\t}\n\t\tpanic(err)\n\t}\n}", "reference": "// PanicHunter catches panic, in case of an enabled reporter.", "generated": "// PanicHunter is used to catch panics in the application.\n//\n// If it's set to false then no error will be reported if there was a panic.\n// It can also be disabled by setting panicIgnore to true. In this case all errors that occur during execution will be ignored. The default value for panic"}
{"id": 6291, "code": "func (m *Marshaller) MarshalRaw(bs []byte) {\n\tif m.Error != nil {\n\t\treturn\n\t}\n\tif len(m.Data) < m.offset+len(bs) {\n\t\tm.Error = io.ErrShortBuffer\n\t\treturn\n\t}\n\n\tm.offset += copy(m.Data[m.offset:], bs)\n}", "reference": "// MarshalRaw copies the raw bytes to the buffer, without a size prefix or\n// padding. This is suitable for appending data already in XDR format from\n// another source.", "generated": "// MarshalRaw writes raw data to the buffer. If there is no space left in the\n// buffer it returns an error. The offset will be updated after writing.\n//\n// This method should only be used when marshaling binary data that doesn't need\n// any additional formatting or encoding. It's intended for use"}
{"id": 6293, "code": "func (m *Marshaller) MarshalBytes(bs []byte) {\n\tif m.Error != nil {\n\t\treturn\n\t}\n\tif len(m.Data) < m.offset+4+len(bs)+Padding(len(bs)) {\n\t\tm.Error = io.ErrShortBuffer\n\t\treturn\n\t}\n\n\tm.MarshalUint32(uint32(len(bs)))\n\tm.offset += copy(m.Data[m.offset:], bs)\n\tm.offset += copy(m.Data[m.offset:], padBytes[:Padding(len(bs))])\n}", "reference": "// MarshalString appends the bytes to the buffer, with a size prefix and\n// correct padding.", "generated": "// MarshalBytes marshals bytes into the data buffer. The length is written to the\n// first 4 bytes after offset. If there's no space left in the buffer for this,\n// it returns an error. It also pads out any remaining space if necessary.\n//\n// This method should be called only when we"}
{"id": 6308, "code": "func Prefix(prefix string, p AssetPipeline) AssetPipeline {\n\tif prefix == \"\" {\n\t\treturn p\n\t}\n\n\treturn &prefixPipeline{\n\t\tprefix:        prefix,\n\t\tAssetPipeline: p,\n\t}\n}", "reference": "// Prefix returns an AssetPipeline that prefixes URLs with the\n// given string", "generated": "// Prefix returns a new pipeline that is prefixed by the given value.\n//\n// This can be used to create pipelines for assets in subdirectories or other\n// directories where we want to add some extra directory path before each asset's\n// name. For example, if we have a pipeline like this:\n//\n//"}
{"id": 6327, "code": "func Map(ss []string, callback func(string) string) []string {\n\tnewStrings := make([]string, len(ss))\n\tfor i, s := range ss {\n\t\tnewStrings[i] = callback(s)\n\t}\n\n\treturn newStrings\n}", "reference": "// Map returns a slice containing all the elements of ss\n// after applying the callback function to each one", "generated": "// Maps each element in the slice to its corresponding value from the map.\n//\n// The key is used for mapping purposes only; it's ignored when calling the callback.\n//\n// If there isn't a match in the map, the original string will be returned unchanged.\n//\n// This can also be thought of as \""}
{"id": 6383, "code": "func SelectMany(subject Enumerable, toMany Unfolder) Enumerable {\n\treturn selectManyer{\n\t\toriginal: subject,\n\t\ttoMany:   toMany,\n\t}\n}", "reference": "// SelectMany allows for unfolding of values.", "generated": "// SelectMany returns all elements in'subject' that match any element\n// from 'toMany'. The result is ordered by the original order of elements\n// in both lists.\n//\n// This method can be used when we need to find many items for each item\n// in another list (e.g., finding"}
{"id": 6400, "code": "func (stack *Stack) IsEmpty() bool {\n\tstack.key.RLock()\n\tdefer stack.key.RUnlock()\n\treturn stack.underlyer == nil || stack.underlyer.IsEmpty()\n}", "reference": "// IsEmpty tests the Stack to determine if it is populate or not.", "generated": "// IsEmpty returns true if there is no element in this Stack.\n//\n// This method will return false even when the underlying data structure\n// has been cleared because it still holds onto its internal state. If you want to check for empty,\n// use isEmpty instead. The difference between these two methods is that isEmpty checks"}
{"id": 6407, "code": "func (list *LinkedList) Enumerate(cancel <-chan struct{}) Enumerator {\n\tretval := make(chan interface{})\n\n\tgo func() {\n\t\tlist.key.RLock()\n\t\tdefer list.key.RUnlock()\n\t\tdefer close(retval)\n\n\t\tcurrent := list.first\n\t\tfor current != nil {\n\t\t\tselect {\n\t\t\tcase retval <- current.payload:\n\t\t\t\tbreak\n\t\t\tcase <-cancel:\n\t\t\t\treturn\n\t\t\t}\n\t\t\tcurrent = current.next\n\t\t}\n\t}()\n\n\treturn retval\n}", "reference": "// Enumerate creates a new instance of Enumerable which can be executed on.", "generated": "// Enumerate returns an enumerator that yields each item in this linked list.\n//\n// The returned channel is closed when all items have been yielded or if the\n// enumeration was cancelled by calling cancel().  This method will block until\n// cancellation occurs unless it has already completed.  If the caller wants to\n//"}
{"id": 6415, "code": "func (list *LinkedList) Sort(comparator Comparator) error {\n\tlist.key.Lock()\n\tdefer list.key.Unlock()\n\tvar err error\n\tlist.first, err = mergeSort(list.first, comparator)\n\tif err != nil {\n\t\treturn err\n\t}\n\tlist.last = findLast(list.first)\n\treturn err\n}", "reference": "// Sort rearranges the positions of the entries in this list so that they are\n// ascending.", "generated": "// Sort sorts this linked list in ascending order using the given comparator.\n//\n// The returned sorted list is owned by the caller; it must be freed when no longer needed.\n// If there was an error during sorting, that will also be returned to the caller.  In any case,\n// the original list remains unchanged"}
{"id": 6420, "code": "func merge(left, right *llNode, comparator Comparator) (first *llNode, err error) {\n\tcurLeft := left\n\tcurRight := right\n\n\tvar last *llNode\n\n\tappendResults := func(updated *llNode) {\n\t\tif last == nil {\n\t\t\tlast = updated\n\t\t} else {\n\t\t\tlast.next = updated\n\t\t\tlast = last.next\n\t\t}\n\t\tif first == nil {\n\t\t\tfirst = last\n\t\t}\n\t}\n\n\tfor curLeft != nil && curRight != nil {\n\t\tvar res int\n\t\tif res, err = comparator(curLeft.payload, curRight.payload); nil != err {\n\t\t\tbreak // Don't return, stitch the remaining elements back on.\n\t\t} else if res < 0 {\n\t\t\tappendResults(curLeft)\n\t\t\tcurLeft = curLeft.next\n\t\t} else {\n\t\t\tappendResults(curRight)\n\t\t\tcurRight = curRight.next\n\t\t}\n\t}\n\n\tif curLeft != nil {\n\t\tappendResults(curLeft)\n\t}\n\tif curRight != nil {\n\t\tappendResults(curRight)\n\t}\n\treturn\n}", "reference": "// merge takes two sorted lists and merges them into one sorted list.\n// Behavior is undefined when you pass a non-sorted list as `left` or `right`", "generated": "// Merge two sorted linked lists into one sorted list. The result is returned in ascending order. If there's any errors during merging,\n// they're propagated to the caller. This method doesn't modify either input list; it returns new nodes that represent merged results. It also\n// preserves original node values by copying them"}
{"id": 6439, "code": "func (l *List) Remove(pos uint) (interface{}, bool) {\n\tl.key.Lock()\n\tdefer l.key.Unlock()\n\n\tif pos > uint(len(l.underlyer)) {\n\t\treturn nil, false\n\t}\n\tretval := l.underlyer[pos]\n\tl.underlyer = append(l.underlyer[:pos], l.underlyer[pos+1:]...)\n\treturn retval, true\n}", "reference": "// Remove retreives a value from this List and shifts all other values.", "generated": "// remove removes item at given position from list.\n//\n// returns removed value or nil if there is no such element in list,\n// also return whether removal was successful. If it wasn't then\n// returned value will be nil. In case of success, this method\n// modifies original data structure. It's safe"}
{"id": 6484, "code": "func (h *Handler) Rule(r rule.Rule) *Handler {\n\tif r == nil {\n\t\t// if nothing passed then use the allow-everyting rule\n\t\tr = rule.Satisfied()\n\t}\n\th.rule = r\n\n\treturn h\n}", "reference": "// Rule sets the ruleset for this handler.\n//\n// returns itself.", "generated": "// Rule sets up the handler to only accept requests that match this rule.\n//\n// If no rule is set it will default to allowing all rules. This can be used in conjunction with other methods like\n// AllowAll() or Disallow(). The order matters here because later calls overrule earlier ones. For example,"}
{"id": 6515, "code": "func (c Client) CreateUser(email string, password string) (*user, error) {\n\tparams := map[string]interface{}{\n\t\t\"user[email]\":    email,\n\t\t\"user[password]\": password,\n\t}\n\tholder := userHolder{}\n\tif err := c.Post(\"users\", params, &holder); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := checkApiErrors(holder.response, \"CreateUser\"); err != nil {\n\t\treturn nil, err\n\t}\n\treturn &holder.User, nil\n}", "reference": "// CreateUser creates a new user given an email and password", "generated": "// CreateUser creates a new user account for the given email address.\n//\n// The provided password must be hashed before being passed to this method.\n// If no hash is provided it will default to using SHA256 from crypto/sha1.\n//\n// Returns *user if successful or an error otherwise.  It's up to"}
{"id": 6523, "code": "func (c Client) GetTransfers(page int) (*transfers, error) {\n\tparams := map[string]int{\n\t\t\"page\": page,\n\t}\n\tholder := transfersHolder{}\n\tif err := c.Get(\"transfers\", params, &holder); err != nil {\n\t\treturn nil, err\n\t}\n\ttransfers := transfers{\n\t\tpaginationStats: holder.paginationStats,\n\t}\n\t// Remove one layer of nesting\n\tfor _, t := range holder.Transfers {\n\t\ttransfers.Transfers = append(transfers.Transfers, t.Transfer)\n\t}\n\treturn &transfers, nil\n}", "reference": "// GetTransfers get transfers associated with an account", "generated": "// GetTransfers returns all transfer objects for this client.\n//\n// The result is paginated by default; if no pagination parameters were provided in the request,\n// then it will return only the first 10 results. If more than 1000 requests have been made to\n// getTransferObjects since the last time"}
{"id": 6531, "code": "func (d *SerialDispatcher) DispatchOptional(cmd interface{}) (err error) {\n\td.mutex.RLock()\n\tdefer d.mutex.RUnlock()\n\n\terr = d.Dispatch(cmd)\n\tswitch err.(type) {\n\tcase *NoHandlerFoundError:\n\t\treturn nil\n\tdefault:\n\t\treturn err\n\t}\n}", "reference": "// DispatchOptional implements `Dispatcher.DispatchOptional`", "generated": "// DispatchOptional dispatches cmd to appropriate handler if it exists.\n//\n// If no suitable handler is found then returns NoHandlerFoundError which will be ignored by default.\n// This method should only be used when there's some chance that the command might have been dispatched before,\n// but we don't care about its result"}
{"id": 6532, "code": "func NewParallelDispatcher(handlers []Handler) Dispatcher {\n\treturn &ParallelDispatcher{\n\t\thandlers: handlers,\n\t\tmutex:    sync.RWMutex{},\n\t}\n}", "reference": "// NewParallelDispatcher creates a new PrallelDispatcher with the given handlers", "generated": "// NewParallelDispatcher creates a new parallel dispatcher that dispatches\n// requests to all registered handlers concurrently.\n//\n// This is useful when there's no need for synchronization between handler\n// invocations since they're executed in separate goroutines anyway. The mutex\n// ensures safe access to the list of handlers even if it"}
{"id": 6537, "code": "func (l *listener) Accept() (transport.Conn, error) {\n\tif c, ok := <-l.incoming; ok {\n\t\treturn c.conn, c.err\n\t}\n\treturn nil, fmt.Errorf(\"listener is closed\")\n}", "reference": "// Accept waits for and returns the next connection to the listener.", "generated": "// Accept returns a new connection from the listener's queue or closes it if there isn't one available.\n//\n// If no connections are waiting in the incoming channel then this will return immediately,\n// even though the listener may still be accepting requests. This can happen when the\n// listener has been stopped but hasn't yet"}
{"id": 6557, "code": "func NewCommand(name string, args ...string) *Command {\n\treturn &Command{\n\t\tname: name,\n\t\targs: args,\n\t}\n}", "reference": "// NewCommand creates a new Livestatus command instance.", "generated": "// NewCommand creates new command instance.\n//\n// Command is used to create commands that can be executed by client or\n// server. It's also used for creating subcommands in case of nested\n// commands (e.g., \"client ls -a\").\n//\n// Args must contain at least one argument which will serve"}
{"id": 6564, "code": "func (r Record) GetSlice(column string) ([]interface{}, error) {\n\tv, err := r.getKey(reflect.Slice, column)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trv := reflect.ValueOf(v)\n\tn := rv.Len()\n\tout := make([]interface{}, n)\n\n\tfor i := 0; i < n; i++ {\n\t\tout[i] = rv.Index(i).Interface()\n\t}\n\n\treturn out, nil\n}", "reference": "// GetSlice returns a slice of interface value for a specific column.", "generated": "// GetSlice returns all values in slice field for given key.\n//\n// If value is empty it will return nil instead of panic() like other fields.\n//\n// Usage: record.GetSlice(\"column\") -> []value. Or if there's no such field,\n//         then it will return nil. You can also"}
{"id": 6588, "code": "func RemoveSvcAcknowledgement(\n\thost_name string,\n\tservice_description string,\n) *livestatus.Command {\n\treturn livestatus.NewCommand(\n\t\t\"REMOVE_SVC_ACKNOWLEDGEMENT\",\n\t\tstringifyArg(\"host_name\", \"string\", host_name),\n\t\tstringifyArg(\"service_description\", \"string\", service_description),\n\t)\n}", "reference": "// RemoveSvcAcknowledgement creates a new \"REMOVE_SVC_ACKNOWLEDGEMENT\" Nagios command.\n//\n// This removes the problem acknowledgement for a particular service.\n//\n// Once the acknowledgement has been removed, notifications can once again be sent out for the given service.", "generated": "// Removes acknowledgement for given service from Livestandby database.\n//\n// This command is used to remove acknowledgement for specific\n// service in livestandby database. It can be useful when\n// removing old services that were previously acknowledged by\n// other hosts. The removal will only happen if there's no active"}
{"id": 6615, "code": "func NewCmdWithRunner(cmdName string, runner func()) (*CmdWithRunner, error) {\n\tif cmdName == \"\" {\n\t\treturn nil, errors.New(\"cmdName cannot be blank\")\n\t}\n\n\tfor _, r := range cmdName {\n\t\tif unicode.IsSpace(r) {\n\t\t\treturn nil, errors.Errorf(\"cmdName cannot contain whitespace: %q\", cmdName)\n\t\t}\n\t}\n\n\treturn &CmdWithRunner{\n\t\tcmdName: cmdName,\n\t\trunner:  runner,\n\t}, nil\n}", "reference": "// NewCmdWithRunner creates a new CmdWithRunner for the provided name and runner. Returns an error if the provided name\n// is not a legal command name.", "generated": "// NewCmdWithRunner creates a new CmdWithRunner instance from a command name.\n//\n// The returned value is only valid for use within this goroutine. If used outside\n// of this goroutine it will panic when called. This is because the internal state\n// (the command name) may have been modified"}
{"id": 6617, "code": "func importBreakPaths(file *ast.File) []string {\n\tvar output []string\n\n\tfor _, decl := range file.Decls {\n\t\tif gen, ok := decl.(*ast.GenDecl); ok && gen.Tok == token.IMPORT {\n\t\t\tfor srcIndex, currSpec := range gen.Specs {\n\t\t\t\tif srcIndex > 0 {\n\t\t\t\t\t// if there was a previous element, check if the group has changed\n\t\t\t\t\tcurrGroup := importGroup(importPath(currSpec))\n\t\t\t\t\tprevGroup := importGroup(importPath(gen.Specs[srcIndex-1]))\n\t\t\t\t\tif currGroup != prevGroup {\n\t\t\t\t\t\t// if group has changed, add path to the output\n\t\t\t\t\t\toutput = append(output, importPath(gen.Specs[srcIndex]))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// assume that only one import token block exists\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn output\n}", "reference": "// importBreakPaths returns a slice that contains the import paths before which a line breaks should be inserted.", "generated": "// importBreakPaths returns all paths imported in this file.\n//\n// This is used by go build when it needs to know which files have been imported,\n// so it can determine whether or not we need to include them again for compilation.\n//\n// Note: We don't actually care about the imports themselves - just their"}
{"id": 6619, "code": "func SupplierWithPrependedArgs(s CmderSupplier, argsFunc func(cmd Cmd) []string) CmderSupplier {\n\treturn func(cmd Cmd) (Cmder, error) {\n\t\tr, err := s(cmd)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn CmderWithPrependedArgs(r, argsFunc(cmd)...), nil\n\t}\n}", "reference": "// SupplierWithPrependedArgs returns a new Supplier that invokes the provided supplier and returns the result of calling\n// RunnerWithPrependedArgs on the returned runner with the result of applying the provided \"argsFunc\" function to the\n// provided command.", "generated": "// SupplierWithPrependedArgs returns a supplier that prepends arguments to each command.\n//\n// This is useful when you want to add some common options or flags to every command,\n// but don't need them for all commands. The supplied `argsFunc` will be called once per\n// command to get any"}
{"id": 6633, "code": "func (t *Timer) ServeHTTP(w http.ResponseWriter, req *http.Request) {\n\n\treq.ParseForm()\n\tsortBy := req.Form.Get(\"sort\")\n\n\tstats := &Stats{}\n\tstats.SortBy = strings.ToLower(sortBy)\n\tstats.Generated = time.Now()\n\tstats.UpTime = fmt.Sprintf(\"%s\", stats.Generated.Sub(t.Since))\n\t// Read access OK for map?\n\tstats.Result = make([]*Stat, 0, len(t.routes))\n\tfor k, v := range t.routes {\n\t\tstat := &Stat{}\n\t\tstat.Route = k\n\t\tstat.Count = v.Count\n\t\tstat.Tot = v.Tot\n\t\tstat.Avg = time.Duration(int64(v.Tot) / v.Count)\n\t\tstat.AvgAfter = time.Duration(int64(v.AfterTot) / v.Count)\n\t\tstat.AvgBefore = time.Duration(int64(v.BeforeTot) / v.Count)\n\t\tstat.Max = v.Max\n\t\tstat.Min = v.Min\n\t\tstats.Result = append(stats.Result, stat)\n\t}\n\tsort.Sort(sort.Reverse(stats))\n\tjsonData, _ := json.Marshal(stats)\n\tw.Write(jsonData)\n}", "reference": "// For serving statistics", "generated": "// ServeHTTP is called by net/http to serve our timer.\n//\n// This method will return JSON data that contains all statistics about this server,\n// including route names, counts, averages, max/min values etc. The sort parameter\n// can be used to change how these statistics are sorted in descending order. If no"}
{"id": 6638, "code": "func RectFromSphere(c Vec3, r float32) Rectangle {\n\treturn RectWHD(c[0]-r, c[1]-r, c[2]-r, 2*r, 2*r, 2*r)\n}", "reference": "// RectFromSphere returns the minimum rectangle that contains the circle of\n// center c and radius r.", "generated": "// Returns rectangle that bounds sphere centered at given point.\n//\n// The radius is used to determine the size of the bounding box in all\n// dimensions (x,y,z). If the center coordinates are negative then the\n// corresponding dimension will be smaller than if they were positive,\n// but this should never happen for spheres"}
{"id": 6640, "code": "func (r Rectangle) Size() Vec3 {\n\treturn Vec3{\n\t\tr.Max[0] - r.Min[0],\n\t\tr.Max[1] - r.Min[1],\n\t\tr.Max[2] - r.Min[2],\n\t}\n}", "reference": "// Size returns r's width, height and depth.", "generated": "// Size returns the size of this rectangle in 3D space.\n//\n// The returned vector is normalized to have length equal to its magnitude,\n// so it can be used directly for scaling or other purposes that require\n// unit vectors. If you need unnormalized values instead, use SizeUnscaled().\n//\n// This"}
{"id": 6645, "code": "func (r Rectangle) In(s Rectangle) bool {\n\tif r.Empty() {\n\t\treturn true\n\t}\n\t// Note that r.Max is an exclusive bound for r, so that r.In(s)\n\t// does not require that r.Max.In(s).\n\treturn s.Min[0] <= r.Min[0] && r.Max[0] <= s.Max[0] &&\n\t\ts.Min[1] <= r.Min[1] && r.Max[1] <= s.Max[1]\n}", "reference": "// In reports whether Rectangle r is contained in s.", "generated": "// In returns whether rectangle contains another rectangle.\n//\n// The returned value will be false if either rectangles have empty area,\n// or one has zero width/height while other doesn't. Otherwise it's true.\n// This method can also return true when both rectangles overlap but do not contain each other. For example, two"}
{"id": 6647, "code": "func ApproxEpsilon(x, y float64, eps float64) bool {\n\treturn math.Abs(x-y) < eps*(1.0+math.Max(math.Abs(x), math.Abs(y)))\n}", "reference": "// ApproxEpsilon returns true if x ~= y, using provided epsilon value.", "generated": "// ApproxEpsilon checks if two floats x,y have difference less than\n// epsilon times max(abs(x),abs(y)). This is useful for comparing\n// floating point numbers that may be slightly different due to rounding errors.\n//\n// Usage: e.g., 2.000001 == 2.000002 using"}
{"id": 6650, "code": "func (v Vec3) Copy(dst Vec3) {\n\tdst[0] = v[0]\n\tdst[1] = v[1]\n\tdst[2] = v[2]\n}", "reference": "// Vec3 methods\n// Copy copies the 3 vector components into dst.", "generated": "// Copy copies all values from src to dst. This is more efficient than\n// calling Set() for each value individually. It's also faster because it\n// doesn't require any memory allocation or deallocation. The caller must ensure that\n// both vectors have the same length; otherwise this will panic. If they"}
{"id": 6703, "code": "func (c *Client) LoadBalancer(identifier string) (*LoadBalancer, error) {\n\tlb := new(LoadBalancer)\n\t_, err := c.MakeApiRequest(\"GET\", \"/1.0/load_balancers/\"+identifier, nil, lb)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn lb, err\n}", "reference": "// LoadBalancer retrieves a detailed view of one load balancer", "generated": "// LoadBalancer returns information about load balancer identifier.\n//\n// This method is used to retrieve information about a specific load balancer by its ID or name. The returned object contains all available fields for that particular load balancer. If no such load balancer exists in the system, it will return nil along with appropriate"}
{"id": 6730, "code": "func FromURL(src *url.URL, w io.Writer, options Options) error {\n\thttpClient := getHTTPClient(options)\n\tvar (\n\t\terr  error\n\t\tresp *http.Response\n\t)\n\tdownloader := func() error {\n\t\tresp, err = httpClient.Get(src.String())\n\t\tif err != nil {\n\t\t\treturn &retriableError{errors.Wrap(err, \"Temporary download error\")}\n\t\t}\n\t\tif resp.StatusCode != http.StatusOK {\n\t\t\tdefer func() { _ = resp.Body.Close() }() // #nosec\n\t\t\treturn errors.Errorf(\"received invalid status code: %d (expected %d)\", resp.StatusCode, http.StatusOK)\n\t\t}\n\t\treturn nil\n\t}\n\tretries := options.Retries\n\tif retries == 0 {\n\t\tretries = 5\n\t}\n\tif err = retryAfter(retries, downloader, options.RetryInterval); err != nil {\n\t\treturn errors.Wrap(err, \"download failed\")\n\t}\n\tdefer func() { _ = resp.Body.Close() }() // #nosec\n\n\tvar (\n\t\tvalidator checksumValidator\n\n\t\treader io.Reader = resp.Body\n\t)\n\n\tif options.ProgressBars != nil && resp.ContentLength > 0 {\n\t\tbar := newProgressBar(resp.ContentLength, options.ProgressBars.MaxWidth, options.ProgressBars.Writer)\n\t\tbar.Start()\n\t\treader = bar.NewProxyReader(reader)\n\t\tdefer func() {\n\t\t\t<-time.After(bar.RefreshRate)\n\t\t\tfmt.Println()\n\t\t}()\n\t}\n\n\tvalidator, reader, err = createValidatorReader(reader, options.ChecksumHash, httpClient, options.Checksum, path.Base(src.Path))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, err = io.Copy(w, reader); err != nil {\n\t\treturn errors.Wrap(err, \"failed to copy contents\")\n\t}\n\n\tif !validator.validate() {\n\t\treturn errors.New(\"checksum validation failed\")\n\t}\n\n\treturn nil\n}", "reference": "// FromURL downloads the specified `src` URL to `w` writer using\n// the specified `Options`.", "generated": "// DownloadFile downloads file from URL using HTTP client.\n//\n// The downloaded data is written into writer. If progress bars are enabled,\n// they will be displayed during downloading process. After successful\n// completion, it prints newline character for better readability.\n//\n// Returns error if there was any problem while downloading or validating"}
{"id": 6733, "code": "func RandomSecret(length int, rnd *rand.Rand) string {\n\tif 0 <= length {\n\t\tlength = 10\n\t}\n\tsecret := make([]byte, length)\n\tfor i, _ := range secret {\n\t\tsecret[i] = byte(rnd.Int31() % 256)\n\t}\n\treturn base32.StdEncoding.EncodeToString(secret)\n}", "reference": "// Generate a Random secret encoded as a b32 string\n// If the length is <= 0, a default length of 10 bytes will\n// be used, which will generate a secret of length 16.", "generated": "// Generate a random secret key for use in cryptographic applications.\n//\n// The generated keys will be at least 16 bytes long (128 bits), but may vary depending\n// upon the system's entropy pool. This is suitable for most purposes such as generating\n// encryption keys or signing data. If you need to generate"}
{"id": 6758, "code": "func (a *AddrBook) RemoveAddress(addr *NetAddress) {\n\ta.mtx.Lock()\n\tdefer a.mtx.Unlock()\n\tka := a.addrLookup[addr.String()]\n\tif ka == nil {\n\t\treturn\n\t}\n\tlog.Info(\"Remove address from book\", \"addr\", addr)\n\ta.removeFromAllBuckets(ka)\n}", "reference": "// RemoveAddress removes the address from the book.", "generated": "// RemoveAddress removes all addresses that match the given NetAddress.\n//\n// This is used to remove any duplicate entries in the Address Book when two\n// different programs use the same IP port number for their own services.  The\n// caller must ensure they have exclusive access to this method by locking the\n// mutex"}
{"id": 6767, "code": "func (na *NetAddress) Dial() (net.Conn, error) {\n\tconn, err := net.Dial(\"tcp\", na.String())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn conn, nil\n}", "reference": "// Dial calls net.Dial on the address.", "generated": "// Dial returns a connection to this address using TCP. The returned\n// connection is closed when it's garbage collected or if there's an I/O\n// error while reading from it. If dial fails for any reason other than\n// \"connection refused\" then that error will be propagated up.\n//\n// Note:"}
{"id": 6778, "code": "func LogOnPanic(id int64, err interface{}, stacktrace []string, _ *http.Request) {\n\tlogMutex.Lock()\n\tdefer logMutex.Unlock()\n\n\tlog.Printf(\"panic=%016x message=%v\\n\", id, err)\n\tfor _, line := range stacktrace {\n\t\tlog.Printf(\"panic=%016x %s\", id, line)\n\t}\n}", "reference": "// LogOnPanic logs the given panic and its stacktrace, prefixing each line with\n// the panic ID.", "generated": "// LogOnPanic logs panic information to stdout. This is used for debugging purposes only.\n//\n// The error will be logged along with its ID (if any), which can help identify\n// where in the code it occurred. If there's no request associated with this\n// call, then the caller must have"}
{"id": 6791, "code": "func (hub *hub) getChannel(name string) *channel {\n\thub.Lock()\n\tdefer hub.Unlock()\n\tcn, ok := hub.channels[name]\n\tif ok {\n\t\treturn cn\n\t}\n\tcn = makeChannel(hub, name)\n\thub.channels[name] = cn\n\tgo cn.start()\n\treturn cn\n}", "reference": "// GetChannel gets or creates new pubsub channel.", "generated": "// Get returns channel by its name or creates new one if it doesn't exist.\n//\n// If channel already exists in current run then returned is cached copy to avoid race when\n// multiple goroutines try to create same channel at the same time. This way we can be sure that\n// all channels will have correct"}
{"id": 6814, "code": "func (c *Client) Push(value interface{}, params map[string]string) (*Client, error) {\n\tbody, err := json.Marshal(value)\n\tif err != nil {\n\t\tlog.Printf(\"%v\\n\", err)\n\t\treturn nil, err\n\t}\n\n\tres, err := c.api.Call(\"POST\", c.Url, c.Auth, body, params)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar r map[string]string\n\n\terr = json.Unmarshal(res, &r)\n\tif err != nil {\n\t\tlog.Printf(\"%v\\n\", err)\n\t\treturn nil, err\n\t}\n\n\tret := &Client{\n\t\tapi:   c.api,\n\t\tAuth:  c.Auth,\n\t\tUrl:   c.Url + \"/\" + r[\"name\"],\n\t\tvalue: value}\n\n\treturn ret, nil\n}", "reference": "// Push creates a new value under the current root url.\n// A populated pointer with that value is also returned.", "generated": "// Push sends data to the server for storage in Redis. The returned client is used to retrieve the stored values.\n//\n// If there's no redis instance available then it will return an error. You can use this method only once per connection. After that you should close the connection using Close() or call Disconnect(). Otherwise"}
{"id": 6821, "code": "func (t *trace) Finish() {\n\tif t.err {\n\t\tincrError(t)\n\t}\n\tincr(t)\n\tduration(t)\n\tif t.err {\n\t\tincrError(t)\n\t}\n\tt.trace.Finish()\n}", "reference": "// Finish declares that this trace is complete.\n// The trace should not be used after calling this method.", "generated": "// Finish is called when tracing has finished. It will increment trace,\n// duration and error counters if necessary. If there was an error\n// during tracing it also increments the error counter. The trace object\n// should be closed after this call to prevent memory leaks. This method\n// can only be called once per"}
{"id": 6843, "code": "func (c *Client) PushLinkToChannel(tag, title, u, body string) error {\n\tdata := Link{\n\t\tTag:   tag,\n\t\tType:  \"link\",\n\t\tTitle: title,\n\t\tURL:   u,\n\t\tBody:  body,\n\t}\n\treturn c.Push(\"/pushes\", data)\n}", "reference": "// PushLinkToChannel pushes a link with a title and url to a specific PushBullet device.", "generated": "// Push link to channel. This will send a push notification to all users in\n// the specified channel when this message is sent. The URL must be valid.\n//\n// Returns nil if successful or an error otherwise. If there was no errors but\n// something unexpected happened then it returns an empty error. You can"}
{"id": 6852, "code": "func (c *cachedLoader) MustGetString(key string) string {\n\tb, err := c.Get(key)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"Could not fetch config (%s) %v\", key, err))\n\t}\n\n\tvar s string\n\terr = json.Unmarshal(b, &s)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"Could not unmarshal config (%s) %v\", key, err))\n\t}\n\n\treturn s\n}", "reference": "// MustGetString fetches the config and parses it into a string.  Panics on failure.", "generated": "// MustGetString returns the value for the given key from cache or loads it if necessary.\n//\n// If there is no cached version then this will panic because we have to load the data,\n// which may take some time depending on how long it takes to get the configuration file.\n//\n// This method should be used when"}
{"id": 6870, "code": "func (e *execStreamerBuilder) Exe(exe string) ExecStreamerBuilder {\n\te.d.Exe = exe\n\treturn e\n}", "reference": "//Exe sets the Exe", "generated": "// Set the executable to use for this streamer builder. If set,\n// it will be used instead of the default one specified in the\n// config file or passed via command line arguments.\n//\n// This is useful if you want to override the default executable that\n// would otherwise be chosen based on the operating system"}
{"id": 6884, "code": "func (w *Window) setCell(x, y int, c Cell) {\n\tc.dirty = true\n\tpos := x + (y * w.x)\n\tif pos < len(w.backingStore) {\n\t\tw.backingStore[pos] = c\n\t}\n}", "reference": "// setCell sets the content of the window cell at the x and y coordinate.\n// setCell shall be called from queue context.", "generated": "// Set cell at position in backing store to given value.\n//\n// This is used internally by Window when it needs to update its internal state,\n// but can be called directly if needed for debugging purposes.  Note that this\n// will only work correctly after all drawing operations have been completed;\n// otherwise, the window"}
{"id": 6896, "code": "func Deinit() {\n\twait := make(chan interface{})\n\tQueue(func() {\n\t\ttermbox.Close()\n\t\tfocus = nil\n\t\tprevFocus = nil\n\t\twindows = make(map[int]*Window) // toss all windows\n\n\t\trawMtx.Lock()\n\t\ttermRaw = false\n\t\trawMtx.Unlock()\n\n\t\twait <- true\n\t})\n\t<-wait\n}", "reference": "// Deinit switches the terminal back to cooked mode and it terminates managed\n// window mode.  Init must be called again if a switch is required again.\n// Deinit shall be called on application exit; failing to do so may leave the\n// terminal corrupted.  If that does happen typing \"reset\" on the shell usually\n// fixes this problem.", "generated": "// Deinit closes termbox and releases any resources it holds onto.\n// This should be called when exiting the program to ensure that everything is properly cleaned up before shutting down.  It will also reset focus to null so that no window can claim ownership after this point."}
{"id": 6933, "code": "func (d *Derive) Update(v float64) {\n\tp := atomic.SwapUint64(&d.value, math.Float64bits(v))\n\td.rate.Update(v - math.Float64frombits(p))\n}", "reference": "// Update update rate value based on the stored previous value.", "generated": "// Update updates the value in d by v. The rate is updated to reflect\n// that the new value has been reached. This should be called only when\n// updating from another source; otherwise it will cause incorrect rates.\n//\n// If this method fails for some reason, then the old values may still exist,"}
{"id": 6934, "code": "func (r *Reservoir) Snapshot() Distribution {\n\th := newHistogram(defaultHistogramSize)\n\tr.m.Lock()\n\th = r.hist.Copy(h)\n\tr.m.Unlock()\n\treturn h\n}", "reference": "// Snapshot returns a Distribution", "generated": "// Snapshot returns a copy of the current histogram in this reservoir.\n//\n// This is useful for debugging purposes or when we want to save some state,\n// but don't need to update it immediately after taking the snapshot. The\n// returned distribution will be updated automatically if any values arrive at\n// the reservoir while the"}
{"id": 6957, "code": "func (s *Set) RemoveAll(values ...interface{}) {\n\ts.Lock()\n\tdefer s.Unlock()\n\tfor _, value := range values {\n\t\tdelete(s.m, value)\n\t}\n}", "reference": "// RemoveAll removes all values from the set if they exist in the set.", "generated": "// Removes all elements from set that match any given value.\n//\n// This is similar to Set.Remove() but removes multiple\n// values at once instead of one by one. It's more efficient,\n// especially for large sets. However it doesn't preserve order.\n// If you need to remove items in sorted order use"}
{"id": 6980, "code": "func (s *Server) SendRequest(connID string, method string, params interface{}, resHandler func(ctx *ResCtx) error) (reqID string, err error) {\n\tif !s.running.Load().(bool) {\n\t\treturn \"\", errors.New(\"use of closed server\")\n\t}\n\n\tif conn, ok := s.conns.GetOk(connID); ok {\n\t\treqID, err = conn.(*Conn).SendRequest(method, params, resHandler)\n\t\t// todo: only log in debug mode?\n\t\tlog.Printf(\"server: send-request: connID: %v, reqID: %v, method: %v, params: %#v, err (if any): %v\", connID, reqID, method, params, err)\n\t\treturn\n\t}\n\n\treturn \"\", fmt.Errorf(\"connection with requested ID: %v does not exist\", connID)\n}", "reference": "// SendRequest sends a JSON-RPC request through the connection denoted by the connection ID with an auto generated request ID.\n// resHandler is called when a response is returned.", "generated": "// SendRequest sends request to specified connection.\n//\n// If there is no such connection then it returns error. Also if server has been stopped,\n// this will return \"use of closed server\" error. In case when server was running but\n// some other goroutine crashed or panicked while sending requests - we don't"}
{"id": 6996, "code": "func (r *Router) Request(route string, handler func(ctx *neptulon.ReqCtx) error) {\n\tr.routes[route] = handler\n}", "reference": "// Request adds a new request route registry.", "generated": "// Register a new route for this router. The route is used to identify which request should be handled by this handler.\n//\n// This method will add the given handler to the routers routes map under the key specified in the first argument.\n// If that key already exists then it will simply update its value to point at the"}
{"id": 7042, "code": "func (c *Conn) setConn(ws *websocket.Conn) error {\n\tc.ws.Store(ws)\n\tc.connected.Store(true)\n\tif err := ws.SetDeadline(time.Now().Add(c.deadline)); err != nil {\n\t\treturn fmt.Errorf(\"conn: error while setting websocket connection deadline: %v\", err)\n\t}\n\treturn nil\n}", "reference": "// Reuse an established websocket.Conn.", "generated": "// Set the conn to be used for this request. This will also enable the\n// WebSocket protocol if it is supported by the client.\n//\n// If there was already a Conn associated with this request then that one\n// should be closed before calling this method. The new conn must have its\n// deadline set correctly"}
{"id": 7046, "code": "func (r *MockReadWriteCloser) Read(p []byte) (n int, err error) {\n\n\tif err = r.ReadErr; err == nil {\n\t\tr.BytesRead = p\n\t\tn = len(p)\n\t}\n\treturn\n}", "reference": "//Read - satisfies reader interface", "generated": "// Mocked read method for testing purposes only. It will return any value that was set in ReadErr or BytesRead.\n//\n// This is used to mock out the real read operation when writing tests. The caller should never call this directly,\n// but rather use it through the interface provided by the test. If no"}
{"id": 7078, "code": "func (m *MACMaskArg) MarshalBinary() ([]byte, error) {\n\t// Must indicate correct number of directives\n\tif int(m.DirCount) != len(m.Directives) {\n\t\treturn nil, ErrorBadArgumentParameter\n\t}\n\n\t// Allocate byte slice for argument and all directives\n\tb := make([]byte, macMaskArgLen+(directiveLen*m.DirCount))\n\n\t// 1 byte reserved\n\n\tb[1] = uint8(m.Command)\n\tb[2] = uint8(m.Error)\n\tb[3] = m.DirCount\n\n\t// Marshal each directive into binary and copy into byte slice\n\t// after argument\n\tn := 4\n\tfor _, d := range m.Directives {\n\t\tdb, err := d.MarshalBinary()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tcopy(b[n:n+directiveLen], db)\n\t\tn += directiveLen\n\t}\n\n\treturn b, nil\n}", "reference": "// MarshalBinary allocates a byte slice containing the data from a MACMaskArg.\n//\n// If m.DirCount does not indicate the actual length of m.Directives, or\n// a Directive is malformed, ErrorBadArgumentParameter is returned.", "generated": "// MarshalBinary marshals MAC Mask Arg to bytes. It is used when sending\n// command over network or writing it to file. The returned value must be\n// unmarshaled using UnmarshalBinary method in order to get back original\n// struct. This marshal operation should only be done once since it's expensive"}
{"id": 7086, "code": "func (s *CORSHandler) CreatePreflight(routes Routes) Routes {\n\tlist := make(Routes, 0, len(routes))\n\thList := make(map[string]*CORSPreflight, len(routes))\n\tfor _, v := range routes {\n\t\tpreflight, ok := hList[v.Path]\n\t\tif !ok {\n\t\t\tpreflight = &CORSPreflight{\n\t\t\t\t*s,\n\t\t\t\tmake([]string, 0, 1),\n\t\t\t\tv.MustAuth,\n\t\t\t}\n\t\t\thList[v.Path] = preflight\n\t\t}\n\n\t\tpreflight.Methods = append(preflight.Methods, v.Method)\n\t\tif v.MustAuth {\n\t\t\tpreflight.UseCredentials = true\n\t\t}\n\t}\n\n\tfor k, v := range hList {\n\t\tlist = append(list, Route{\n\t\t\tName:       \"\",\n\t\t\tMethod:     DEFAULT_CORS_PREFLIGHT_METHOD,\n\t\t\tPath:       k,\n\t\t\tMustAuth:   v.UseCredentials,\n\t\t\tActionFunc: v.ServeHTTP,\n\t\t})\n\t}\n\treturn list\n}", "reference": "// CreatePreflight creates HTTP routes that handles pre-flight requests.", "generated": "// CreatePreflight returns all CORS Preflight handlers for this handler.\n//\n// This is used to create a new set of routes that can be added to the router.\n// The prefight route will only match requests from browsers which send the\n// \"Access-Control-Request-Headers\" header in their request headers. It"}
{"id": 7097, "code": "func (b *RefCountBox) Alloc() (DB, error) {\n\tb.Lock()\n\tdefer b.Unlock()\n\n\tif b.db.DB == nil {\n\t\tif b.DataPath == nil {\n\t\t\treturn DB{}, errorsp.WithStacks(ErrBoxDataPathNotSpecified)\n\t\t}\n\t\tvar db DB\n\t\tvar err error\n\t\tif b.OpenFunc == nil {\n\t\t\tdb, err = Open(b.DataPath(), 0644, nil)\n\t\t} else {\n\t\t\tdb, err = b.OpenFunc(b.DataPath())\n\t\t}\n\t\tif err != nil {\n\t\t\treturn DB{}, errorsp.WithStacks(err)\n\t\t}\n\t\tb.db, b.count = db, 0\n\t}\n\tb.count++\n\treturn b.db, nil\n}", "reference": "// Alloc opens a DB if not openned yet. It adds a reference if already openned.", "generated": "// Alloc returns a new database object that is associated to this box.\n//\n// The returned database will be closed when it goes out of scope or if its\n// underlying file descriptor closes. If there's already one open in the same\n// process, then no additional lock will be acquired for the allocation,\n// but"}
{"id": 7105, "code": "func ToSSN(theString, delimiter string) (string, error) {\n\tf := New(theString)\n\tf.removeNonDigits()\n\n\tif f.length != 9 {\n\t\treturn \"\", errors.New(\"string needs to be 9 digits for Social Security Numbers\")\n\t}\n\n\tvar buffer bytes.Buffer\n\tcount := 0\n\n\tfor _, i := range f.theString {\n\t\tcount++\n\n\t\tbuffer.WriteString(string(i))\n\n\t\tif count == 3 || count == 5 {\n\t\t\tbuffer.WriteString(delimiter)\n\t\t}\n\t}\n\treturn buffer.String(), nil\n}", "reference": "// ToSSN will format the provided string as a SSN.", "generated": "// ToSSN converts a given string into a valid SSN format.\n//\n// The input must contain exactly nine digits in order to form a valid social security number.\n//\n// If there is any other character present it will return an error message indicating that the string was invalid. It also removes all non-digit characters from"}
{"id": 7113, "code": "func (c *Config) OptionMap(section string) map[string]string {\n\toptions := make(map[string]string)\n\tfor _, sect := range c.sections {\n\t\tif sect.name == section {\n\t\t\tfor _, opt := range sect.options {\n\t\t\t\toptions[opt.name] = opt.value\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t}\n\treturn options\n}", "reference": "// OptionMap returns the map option => value for a given section.", "generated": "// OptionMap returns all option values for given config section name.\n//\n// This is useful when we need to get multiple configuration settings from one place,\n// like in case of command-line arguments or environment variables. It's also good\n// practice to avoid duplicated code that fetches same setting value from different places.\n//"}
{"id": 7121, "code": "func Convert(val interface{}, targetType reflect.Type) reflect.Value {\n\tvalue := reflect.ValueOf(val)\n\tif !value.IsValid() {\n\t\treturn reflect.Zero(targetType)\n\t}\n\n\tvalType := value.Type()\n\tif valType.ConvertibleTo(targetType) {\n\t\treturn value.Convert(targetType)\n\t}\n\n\t//fmt.Printf(\"Value type is %v, emptyInterfaceType is %v, equals %v\\n\", valType, emptyInterfaceType, valType == emptyInterfaceType)\n\tinterfaceVal := value.Interface()\n\n\tswitch realVal := interfaceVal.(type) {\n\tcase float64:\n\t\treturn reflect.ValueOf(realVal).Convert(targetType)\n\tcase []interface{}:\n\t\t// val is of type []interface{}, try to convert to typ\n\t\tsliceSize := len(realVal)\n\t\ttargetSlice := reflect.MakeSlice(targetType, 0, sliceSize)\n\t\telemType := targetType.Elem()\n\t\tfor i := 0; i < sliceSize; i++ {\n\t\t\ttargetSlice = reflect.Append(targetSlice, Convert(value.Index(i), elemType))\n\t\t}\n\t\treturn targetSlice\n\t}\n\n\tpanic(fmt.Errorf(\"convert from type %v to %v failed: %v\", valType, targetType, value))\n}", "reference": "// try to convert value to target type, panic if fail", "generated": "// Convert converts a given value into another type.\n//\n// If the types match or if they can be converted (e.g., int -> uint),\n// then it returns the original value wrapped in its new type.\n//\n// Otherwise, panic will occur because we cannot determine how to represent\n// this value in the other"}
{"id": 7123, "code": "func Filter(l LogBackend, r Ruler) LogBackend {\n\treturn &filter{\n\t\tLogBackend: l,\n\t\tr:          r,\n\t}\n}", "reference": "// Filter creates a new filter with rules r for l backend.", "generated": "// Filter returns a new log backend that filters logs based on\n// the given ruler's rules.\n//\n// The returned log backend will only forward messages to its underlying\n// logger if they match one or more of the specified conditions in the\n// provided rule set. If no matching message is found then it simply forwards"}
{"id": 7139, "code": "func (cn *ContentNegotiator) getEncoder(req *http.Request) Encoder {\n\tvar result = cn.DefaultEncoder\n\taccept := req.Header.Get(\"Accept\")\n\n\tfor k, v := range cn.encoderMap {\n\t\tif strings.Contains(accept, k) {\n\t\t\tresult = v\n\t\t\tbreak\n\t\t}\n\t}\n\treturn result\n}", "reference": "// getEncoder parses the Accept header an returns the appropriate encoder to use", "generated": "// getEncoder returns the encoder for the given request based on its accept header.\n// If no match is found in the map it will return the default one. The encoding type can be set using Content-Negotiation-Types header or Accept header. For example: \"application/json; charset=utf8\" or \"text"}
{"id": 7148, "code": "func DefaultServiceConfig() ServiceConfig {\n\treturn ServiceConfig{\n\t\t// Dependencies.\n\t\tBackoffFactory: func() Backoff {\n\t\t\treturn &backoff.StopBackOff{}\n\t\t},\n\t\tRandFactory: rand.Int,\n\n\t\t// Settings.\n\t\tRandReader: rand.Reader,\n\t\tTimeout:    1 * time.Second,\n\t}\n}", "reference": "// DefaultServiceConfig provides a default configuration to create a new random\n// service by best effort.", "generated": "// Returns default service config for new services created by NewService(). This\n// is used to set up initial settings such as back off factory, random number generator etc. It's also useful when creating test cases where we want to ensure that all tests use same configuration. The returned value should be updated before passing it into"}
{"id": 7222, "code": "func (logger *Logger) Log(level Level, a ...interface{}) {\n\tlogger.log(level, \"\", a...)\n}", "reference": "// Log logs provided message.", "generated": "// Log logs messages at different levels to stdout or stderr depending\n// on whether it's enabled for that level.\n//\n// If log is disabled then this will do nothing. The message can be formatted\n// using printf style formatting. It should start with \"log\" followed by the\n// logging level in uppercase letters"}
{"id": 7234, "code": "func (e *Entry) getChildEntry(pat string) *Entry {\n\tfor _, entry := range e.entries {\n\t\tif pat == entry.Pattern() {\n\t\t\treturn entry\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// getChildEntry returns a child Entry that matches the given pattern string.", "generated": "// Child returns child entries matching pattern.\n//\n// If no matches found then return nil. This is useful for testing purposes,\n// where we want to verify that there's only one match or none at all. In this case\n// it will be faster than iterating over all children in Entry. However, if multiple"}
{"id": 7263, "code": "func routeSplitFunc(data []byte, atEOF bool) (int, []byte, error) {\n\tif atEOF || data == nil {\n\t\treturn 0, nil, io.EOF\n\t}\n\n\tr, _ := utf8.DecodeRune(data)\n\n\t// matcher\n\tif r == '<' {\n\t\ti := bytes.IndexRune(data, '>')\n\t\tif i == -1 {\n\t\t\treturn 0, nil, NoClosingBracket\n\t\t}\n\t\treturn (i + 1), data[:(i + 1)], nil\n\t}\n\n\t// one char\n\tif len(data) == 1 {\n\t\treturn 1, data, nil\n\t}\n\n\t// should ignore first '/'\n\tslashIndex := bytes.IndexRune(data[1:], '/')\n\tif slashIndex != -1 {\n\t\tslashIndex++\n\t}\n\n\tmatchIndex := bytes.IndexRune(data, '<')\n\n\t// remaining string would be a static entry\n\tif slashIndex == -1 && matchIndex == -1 {\n\t\treturn len(data), data, nil\n\t}\n\n\t// split by '<'\n\t// return data before '<'\n\tif matchIndex != -1 && (slashIndex == -1 || slashIndex > matchIndex) {\n\t\treturn matchIndex, data[:matchIndex], nil\n\t}\n\n\t// split by '/'\n\t// return data before '/' including '/'\n\treturn slashIndex + 1, data[:(slashIndex + 1)], nil\n}", "reference": "// routeSplitFunc is the SplitFunc to scan url pattern.", "generated": "// routeSplitFunc is used to parse routes in the format \"static/<path>\" or \"/<path>\". It returns the index where the path starts,\n// the path itself, and any errors that occurred during parsing. If there's no closing bracket it will panic.\n//\n// The returned slice contains only up to the"}
{"id": 7282, "code": "func (s *Image) Run(cfg *RunConfig) (*Container, error) {\n\targs := make([]string, 0, len(cfg.Options)+len(cfg.Args)+1)\n\targs = append(args, cfg.Options...)\n\targs = append(args, s.name)\n\targs = append(args, cfg.Args...)\n\n\tout, err := s.docker.Run(\"run\", args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcontainer := &Container{\n\t\tdocker: s.docker,\n\t\tid:     strings.TrimSpace(out),\n\t}\n\tif container.id == \"\" {\n\t\treturn nil, UnexpectedOutputError(\n\t\t\t\"Unexpected empty output when running docker container\")\n\t}\n\n\treturn container, nil\n}", "reference": "// Run creates a new Docker container as defined by current image and container\n// template.\n//\n// Returns ExternalCmdError or UnexpectedOutputError on error.", "generated": "// Run runs the image in a new container using Docker's run command.\n//\n// The options passed to this method will be used for the container creation process.\n// If no arguments are provided, it is assumed that there were no additional options specified during the build process.\n//\n// Returns the ID of the newly created container"}
{"id": 7285, "code": "func (s NetworkSettings) PortAt(index int) (string, *HostPublish) {\n\tcounter := 0\n\tfor k, v := range s.Ports {\n\t\tif counter != index {\n\t\t\tcounter++\n\t\t\tcontinue\n\t\t}\n\n\t\treturn k, v\n\t}\n\n\treturn \"\", nil\n}", "reference": "// PortAt returns expose and publish port information at especified index.", "generated": "// PortAt returns port at given index in ports map.\n//\n// If there is no such port it will return empty string for key and nil value.\n// It's used to get host publish from network settings by its name. For example,\n// if we have two hosts: \"host1\" and \"host2"}
{"id": 7297, "code": "func (tx Tx) ForEachGob(folders [][]byte, f func(Bucket, bytesp.Slice, interface{}) error) error {\n\treturn tx.ForEach(folders, func(b Bucket, k, bs bytesp.Slice) error {\n\t\tvar v interface{}\n\t\tif err := gob.NewDecoder(&bs).Decode(&v); err != nil {\n\t\t\treturn errorsp.WithStacksAndMessage(err, \"decoding %d bytes value for key %q failed\", len(bs), string(k))\n\t\t}\n\t\treturn errorsp.WithStacks(f(b, k, v))\n\t})\n}", "reference": "// ForEach iterates over all key values of a folder, decode non-nil values using gob.", "generated": "// ForEachGob is similar to ForEach but uses Gob instead of JSON.\n//\n// It's used when we need to decode values from byte slices that were encoded\n// using Gob. This method will return errors if there was any problem decoding\n// or encoding the data. If it encounters an unknown"}
{"id": 7310, "code": "func (handler *WriteHandler) Handle(record *Record) error {\n\t_, err := handler.Writer.Write([]byte(handler.Formatter.Format(record) + \"\\n\"))\n\treturn err\n}", "reference": "// Handle writes all provided log records to writer provided during creation.", "generated": "// Write writes the record to stdout. This is used for debugging purposes only.\n// It's recommended that this be overridden in handlers where it makes sense,\n// such as when writing logs or other debug output. The default will print out\n// all records from the stream. If there was an error while trying to write"}
