{"id": 24, "code": "func (c *ServiceDiscoveryConfig) Validate() error {\n\tfor _, cfg := range c.AzureSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in azure_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.ConsulSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in consul_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.DNSSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in dns_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.EC2SDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in ec2_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.FileSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in file_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.GCESDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in gce_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.KubernetesSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in kubernetes_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.MarathonSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in marathon_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.NerveSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in nerve_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.OpenstackSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in openstack_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.ServersetSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in serverset_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.StaticConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in static_configs\")\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// Validate validates the ServiceDiscoveryConfig.", "generated": "//Validate checks if all required fields exist for each service discovery configuration type.\n//\n//If any field is missing it returns an error message indicating which config was invalid."}
{"id": 36, "code": "func NewDiscovery(conf SDConfig, logger log.Logger) (*Discovery, error) {\n\trt, err := config_util.NewRoundTripperFromConfig(conf.HTTPClientConfig, \"marathon_sd\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif len(conf.AuthToken) > 0 {\n\t\trt, err = newAuthTokenRoundTripper(conf.AuthToken, rt)\n\t} else if len(conf.AuthTokenFile) > 0 {\n\t\trt, err = newAuthTokenFileRoundTripper(conf.AuthTokenFile, rt)\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\td := &Discovery{\n\t\tclient:     &http.Client{Transport: rt},\n\t\tservers:    conf.Servers,\n\t\tappsClient: fetchApps,\n\t}\n\td.Discovery = refresh.NewDiscovery(\n\t\tlogger,\n\t\t\"marathon\",\n\t\ttime.Duration(conf.RefreshInterval),\n\t\td.refresh,\n\t)\n\treturn d, nil\n}", "reference": "// NewDiscovery returns a new Marathon Discovery.", "generated": "// Create a discovery client for Marathon service.\n//\n// This creates a round-trip transport to use in HTTP requests to marathon's API endpoint.\n// It also sets up authentication using either token or file based auth tokens from configuration options."}
{"id": 50, "code": "func (d *Discovery) shouldWatch(name string, tags []string) bool {\n\treturn d.shouldWatchFromName(name) && d.shouldWatchFromTags(tags)\n}", "reference": "// shouldWatch returns whether the service of the given name should be watched.", "generated": "// Should watch this name or tag? This is used to determine whether\n// we need to listen for changes in discovery.\n//\n// If true then it will be watched by all listeners that support watching names,\n// but only if there's at least one listener which supports watching tags.\n //\n// Note: We don't"}
{"id": 52, "code": "func (d *Discovery) getDatacenter() error {\n\t// If the datacenter was not set from clientConf, let's get it from the local Consul agent\n\t// (Consul default is to use local node's datacenter if one isn't given for a query).\n\tif d.clientDatacenter != \"\" {\n\t\treturn nil\n\t}\n\n\tinfo, err := d.client.Agent().Self()\n\tif err != nil {\n\t\tlevel.Error(d.logger).Log(\"msg\", \"Error retrieving datacenter name\", \"err\", err)\n\t\trpcFailuresCount.Inc()\n\t\treturn err\n\t}\n\n\tdc, ok := info[\"Config\"][\"Datacenter\"].(string)\n\tif !ok {\n\t\terr := errors.Errorf(\"invalid value '%v' for Config.Datacenter\", info[\"Config\"][\"Datacenter\"])\n\t\tlevel.Error(d.logger).Log(\"msg\", \"Error retrieving datacenter name\", \"err\", err)\n\t\treturn err\n\t}\n\n\td.clientDatacenter = dc\n\treturn nil\n}", "reference": "// Get the local datacenter if not specified.", "generated": "//\n// Get the DataCenter that this server uses.\n //\n// This method will return an empty string if no data center has been specified in either\n// Client config or by the Agent itself.  In such case we'll try to determine which\n// data center our Server should be using based on its configuration information."}
{"id": 64, "code": "func (ls Labels) HashForLabels(names ...string) uint64 {\n\tb := make([]byte, 0, 1024)\n\n\tfor _, v := range ls {\n\t\tfor _, n := range names {\n\t\t\tif v.Name == n {\n\t\t\t\tb = append(b, v.Name...)\n\t\t\t\tb = append(b, sep)\n\t\t\t\tb = append(b, v.Value...)\n\t\t\t\tb = append(b, sep)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn xxhash.Sum64(b)\n}", "reference": "// HashForLabels returns a hash value for the labels matching the provided names.", "generated": "// HashForLabel returns hash value for labels in name-value format.\n//\n// This is used to identify label sets that have same set of values but different order or keys,\n// which can be useful when storing them into database where key must be unique."}
{"id": 117, "code": "func ParseExpr(input string) (Expr, error) {\n\tp := newParser(input)\n\n\texpr, err := p.parseExpr()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = p.typecheck(expr)\n\treturn expr, err\n}", "reference": "// ParseExpr returns the expression parsed from the input.", "generated": "// ParseExpr parses input into expression object.\n//\n// If there is any syntax errors in input then it returns non-nil error.\n //\n// Input must be valid JSON text or empty string for null value."}
{"id": 129, "code": "func (p *parser) expectOneOf(exp1, exp2 ItemType, context string) item {\n\ttoken := p.next()\n\tif token.typ != exp1 && token.typ != exp2 {\n\t\tp.errorf(\"unexpected %s in %s, expected %s or %s\", token.desc(), context, exp1.desc(), exp2.desc())\n\t}\n\treturn token\n}", "reference": "// expectOneOf consumes the next token and guarantees it has one of the required types.", "generated": "// Expect one specific type to appear next.\n//\n// If it appears then continue parsing otherwise return error message."}
{"id": 133, "code": "func (p *parser) expectType(node Node, want ValueType, context string) {\n\tt := p.checkType(node)\n\tif t != want {\n\t\tp.errorf(\"expected type %s in %s, got %s\", documentedType(want), context, documentedType(t))\n\t}\n}", "reference": "// expectType checks the type of the node and raises an error if it\n// is not of the expected type.", "generated": "// Expect checks that node is correct value for given context.\n//\n// If it's incorrect then error will be printed to output stream\n// if there isn't any current error already set up by previous calls to\n// checkValue or checkNode types."}
{"id": 145, "code": "func New(minSize, maxSize int, factor float64, makeFunc func(int) interface{}) *Pool {\n\tif minSize < 1 {\n\t\tpanic(\"invalid minimum pool size\")\n\t}\n\tif maxSize < 1 {\n\t\tpanic(\"invalid maximum pool size\")\n\t}\n\tif factor < 1 {\n\t\tpanic(\"invalid factor\")\n\t}\n\n\tvar sizes []int\n\n\tfor s := minSize; s <= maxSize; s = int(float64(s) * factor) {\n\t\tsizes = append(sizes, s)\n\t}\n\n\tp := &Pool{\n\t\tbuckets: make([]sync.Pool, len(sizes)),\n\t\tsizes:   sizes,\n\t\tmake:    makeFunc,\n\t}\n\n\treturn p\n}", "reference": "// New returns a new Pool with size buckets for minSize to maxSize\n// increasing by the given factor.", "generated": "// Create new Pool instance.\n//\n// This creates pools for each specified bucket size from smallest to largest.\n// The last created pool will be larger than max if it is smaller or equal to max.\n //\n// If there's no specific factory provided then default Factory returns nil which means that\n// objects in this pool can"}
{"id": 165, "code": "func sendAlerts(s sender, externalURL string) rules.NotifyFunc {\n\treturn func(ctx context.Context, expr string, alerts ...*rules.Alert) {\n\t\tvar res []*notifier.Alert\n\n\t\tfor _, alert := range alerts {\n\t\t\ta := &notifier.Alert{\n\t\t\t\tStartsAt:     alert.FiredAt,\n\t\t\t\tLabels:       alert.Labels,\n\t\t\t\tAnnotations:  alert.Annotations,\n\t\t\t\tGeneratorURL: externalURL + strutil.TableLinkForExpression(expr),\n\t\t\t}\n\t\t\tif !alert.ResolvedAt.IsZero() {\n\t\t\t\ta.EndsAt = alert.ResolvedAt\n\t\t\t} else {\n\t\t\t\ta.EndsAt = alert.ValidUntil\n\t\t\t}\n\t\t\tres = append(res, a)\n\t\t}\n\n\t\tif len(alerts) > 0 {\n\t\t\ts.Send(res...)\n\t\t}\n\t}\n}", "reference": "// sendAlerts implements the rules.NotifyFunc for a Notifier.", "generated": "// Send sends all alerts to s for each expression that has been fired.\n//\n// This is used by the rule engine when it needs to notify about events in real-time.\n //\n// Note this method will be called from multiple goroutines at once so we need to make sure\n// our code can handle concurrent access safely"}
{"id": 166, "code": "func (g *RuleGroups) Validate() (errs []error) {\n\tset := map[string]struct{}{}\n\n\tfor _, g := range g.Groups {\n\t\tif g.Name == \"\" {\n\t\t\terrs = append(errs, errors.Errorf(\"Groupname should not be empty\"))\n\t\t}\n\n\t\tif _, ok := set[g.Name]; ok {\n\t\t\terrs = append(\n\t\t\t\terrs,\n\t\t\t\terrors.Errorf(\"groupname: \\\"%s\\\" is repeated in the same file\", g.Name),\n\t\t\t)\n\t\t}\n\n\t\tset[g.Name] = struct{}{}\n\n\t\tfor i, r := range g.Rules {\n\t\t\tfor _, err := range r.Validate() {\n\t\t\t\tvar ruleName string\n\t\t\t\tif r.Alert != \"\" {\n\t\t\t\t\truleName = r.Alert\n\t\t\t\t} else {\n\t\t\t\t\truleName = r.Record\n\t\t\t\t}\n\t\t\t\terrs = append(errs, &Error{\n\t\t\t\t\tGroup:    g.Name,\n\t\t\t\t\tRule:     i,\n\t\t\t\t\tRuleName: ruleName,\n\t\t\t\t\tErr:      err,\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t}\n\n\treturn errs\n}", "reference": "// Validate validates all rules in the rule groups.", "generated": "//Validate checks for invalid rules within each group.\n//\n//This method returns any error that occurs during validation. The result will contain all valid groups along side their corresponding errors if there were none found."}
{"id": 182, "code": "func (r *AlertingRule) SetHealth(health RuleHealth) {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\tr.health = health\n}", "reference": "// SetHealth sets the current health of the alerting rule.", "generated": "// SetHealth sets the rule's current status to specified value.\n//\n// This method is used for internal use only by Alertmanager itself,\n// it should never be called from outside. If this happens then alert manager will panic."}
{"id": 185, "code": "func (r *AlertingRule) SetEvaluationDuration(dur time.Duration) {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\tr.evaluationDuration = dur\n}", "reference": "// SetEvaluationDuration updates evaluationDuration to the duration it took to evaluate the rule on its last evaluation.", "generated": "// Evaluate duration is set to specify how long it takes for this rule's alert rules to be evaluated.\n//\n// This value should only change when setting up or tearing down alerts from these rules,\n// since changing during evaluation could cause unexpected results.  The default is one hour."}
{"id": 197, "code": "func (g *Group) GetEvaluationDuration() time.Duration {\n\tg.mtx.Lock()\n\tdefer g.mtx.Unlock()\n\treturn g.evaluationDuration\n}", "reference": "// GetEvaluationDuration returns the time in seconds it took to evaluate the rule group.", "generated": "// Evaluate duration is set when group starts running.\n//\n// This value can be used to calculate how long it takes for all tasks in this group to complete their evaluation phase,\n// which includes execution of task functions and calculation of results."}
{"id": 199, "code": "func (g *Group) GetEvaluationTimestamp() time.Time {\n\tg.mtx.Lock()\n\tdefer g.mtx.Unlock()\n\treturn g.evaluationTimestamp\n}", "reference": "// GetEvaluationTimestamp returns the time the last evaluation of the rule group took place.", "generated": "// Evaluate timestamp is set when group evaluation starts or ends.\n//\n// This value can be used to determine if there has been any change in the group's state since it was last evaluated,\n// which could indicate that some operations have failed but were still executed due to other reasons such as network issues."}
{"id": 212, "code": "func (w *WALWatcher) Start() {\n\tw.setMetrics()\n\tlevel.Info(w.logger).Log(\"msg\", \"starting WAL watcher\", \"queue\", w.name)\n\n\tgo w.loop()\n}", "reference": "// Start the WALWatcher.", "generated": "// Starts the WAL watch loop.\n//\n// This method starts the main loop that watches for changes to the database\n// file system. The loop runs in its own goroutine so it doesn't block other parts\n// of the application. It also sets up metrics which can be used by tools like\n// Prometheus or"}
{"id": 225, "code": "func (sd *StaticProvider) Run(ctx context.Context, ch chan<- []*targetgroup.Group) {\n\t// We still have to consider that the consumer exits right away in which case\n\t// the context will be canceled.\n\tselect {\n\tcase ch <- sd.TargetGroups:\n\tcase <-ctx.Done():\n\t}\n\tclose(ch)\n}", "reference": "// Run implements the Worker interface.", "generated": "//\n// This method is used by consumers who want to run their targetgroups directly,\n// without using our provider's API. The result should always contain all groups\n// regardless if they were created or deleted since we started running this process.\n //\n // Note: If there was any error while creating or deleting targets during execution"}
{"id": 228, "code": "func NewDiscovery(\n\tsrvs []string,\n\ttimeout time.Duration,\n\tpaths []string,\n\tlogger log.Logger,\n\tpf func(data []byte, path string) (model.LabelSet, error),\n) (*Discovery, error) {\n\tif logger == nil {\n\t\tlogger = log.NewNopLogger()\n\t}\n\n\tconn, _, err := zk.Connect(\n\t\tsrvs, timeout,\n\t\tfunc(c *zk.Conn) {\n\t\t\tc.SetLogger(treecache.NewZookeeperLogger(logger))\n\t\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tupdates := make(chan treecache.ZookeeperTreeCacheEvent)\n\tsd := &Discovery{\n\t\tconn:    conn,\n\t\tupdates: updates,\n\t\tsources: map[string]*targetgroup.Group{},\n\t\tparse:   pf,\n\t\tlogger:  logger,\n\t}\n\tfor _, path := range paths {\n\t\tsd.treeCaches = append(sd.treeCaches, treecache.NewZookeeperTreeCache(conn, path, updates, logger))\n\t}\n\treturn sd, nil\n}", "reference": "// NewDiscovery returns a new discovery along Zookeeper parses with\n// the given parse function.", "generated": "// Create new discovery instance for given zookeeper connection.\n//\n// This method creates tree cache instances based on provided list of paths to watch in ZooKeeper.\n// Each event from ZooKeeper is processed by this method which parses it into target group data using passed parser.\n// If there's no parser specified then default parsing logic"}
{"id": 244, "code": "func (q *querier) Select(p *storage.SelectParams, matchers ...*labels.Matcher) (storage.SeriesSet, storage.Warnings, error) {\n\tquery, err := ToQuery(q.mint, q.maxt, matchers, p)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tremoteReadGauge := remoteReadQueries.WithLabelValues(q.client.Name())\n\tremoteReadGauge.Inc()\n\tdefer remoteReadGauge.Dec()\n\n\tres, err := q.client.Read(q.ctx, query)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn FromQueryResult(res), nil, nil\n}", "reference": "// Select implements storage.Querier and uses the given matchers to read series\n// sets from the Client.", "generated": "// Select returns all data from the specified namespace for the given parameters.\n//\n// This method is used to retrieve data that can be stored in memory or written out to disk,\n// but it may also return results if they need to be retrieved remotely due to lack of local cache.\n //\n// If there's no result available"}
{"id": 298, "code": "func NewRegexp(s string) (Regexp, error) {\n\tregex, err := regexp.Compile(\"^(?:\" + s + \")$\")\n\treturn Regexp{\n\t\tRegexp:   regex,\n\t\toriginal: s,\n\t}, err\n}", "reference": "// NewRegexp creates a new anchored Regexp and returns an error if the\n// passed-in regular expression does not compile.", "generated": "// Create new RegExp from given regular expression.\n//\n// This is used to create Regexps that match only at start or end of line.\n //\n// Note: this method creates a compile-time pattern which can be more efficient than creating it dynamically in runtime code. However, if there's any chance that the input will change"}
{"id": 303, "code": "func (sp *scrapePool) reload(cfg *config.ScrapeConfig) error {\n\ttargetScrapePoolReloads.Inc()\n\tstart := time.Now()\n\n\tsp.mtx.Lock()\n\tdefer sp.mtx.Unlock()\n\n\tclient, err := config_util.NewClientFromConfig(cfg.HTTPClientConfig, cfg.JobName)\n\tif err != nil {\n\t\ttargetScrapePoolReloadsFailed.Inc()\n\t\treturn errors.Wrap(err, \"error creating HTTP client\")\n\t}\n\tsp.config = cfg\n\toldClient := sp.client\n\tsp.client = client\n\n\tvar (\n\t\twg              sync.WaitGroup\n\t\tinterval        = time.Duration(sp.config.ScrapeInterval)\n\t\ttimeout         = time.Duration(sp.config.ScrapeTimeout)\n\t\tlimit           = int(sp.config.SampleLimit)\n\t\thonorLabels     = sp.config.HonorLabels\n\t\thonorTimestamps = sp.config.HonorTimestamps\n\t\tmrc             = sp.config.MetricRelabelConfigs\n\t)\n\n\tfor fp, oldLoop := range sp.loops {\n\t\tvar (\n\t\t\tt       = sp.activeTargets[fp]\n\t\t\ts       = &targetScraper{Target: t, client: sp.client, timeout: timeout}\n\t\t\tnewLoop = sp.newLoop(scrapeLoopOptions{\n\t\t\t\ttarget:          t,\n\t\t\t\tscraper:         s,\n\t\t\t\tlimit:           limit,\n\t\t\t\thonorLabels:     honorLabels,\n\t\t\t\thonorTimestamps: honorTimestamps,\n\t\t\t\tmrc:             mrc,\n\t\t\t})\n\t\t)\n\t\twg.Add(1)\n\n\t\tgo func(oldLoop, newLoop loop) {\n\t\t\toldLoop.stop()\n\t\t\twg.Done()\n\n\t\t\tgo newLoop.run(interval, timeout, nil)\n\t\t}(oldLoop, newLoop)\n\n\t\tsp.loops[fp] = newLoop\n\t}\n\n\twg.Wait()\n\toldClient.CloseIdleConnections()\n\ttargetReloadIntervalLength.WithLabelValues(interval.String()).Observe(\n\t\ttime.Since(start).Seconds(),\n\t)\n\treturn nil\n}", "reference": "// reload the scrape pool with the given scrape configuration. The target state is preserved\n// but all scrape loops are restarted with the new scrape configuration.\n// This method returns after all scrape loops that were stopped have stopped scraping.", "generated": "//reload starts scraping again after interval seconds.\n//\n// This method is called when the scrape configuration changes or if there's been too many failed scrapes in a row. It will restart all targets that have had their intervals exceed the configured value for this job. The target scrappers run concurrently to minimize downtime. If any"}
{"id": 332, "code": "func NewDiscovery(conf *SDConfig, logger log.Logger) *Discovery {\n\tif logger == nil {\n\t\tlogger = log.NewNopLogger()\n\t}\n\n\tdisc := &Discovery{\n\t\tpaths:      conf.Files,\n\t\tinterval:   time.Duration(conf.RefreshInterval),\n\t\ttimestamps: make(map[string]float64),\n\t\tlogger:     logger,\n\t}\n\tfileSDTimeStamp.addDiscoverer(disc)\n\treturn disc\n}", "reference": "// NewDiscovery returns a new file discovery for the given paths.", "generated": "// Create new discovery instance from config file path list.\n//\n// If no configuration is provided then default values will be used for all options."}
{"id": 349, "code": "func (r *ewmaRate) tick() {\n\tnewEvents := atomic.LoadInt64(&r.newEvents)\n\tatomic.AddInt64(&r.newEvents, -newEvents)\n\tinstantRate := float64(newEvents) / r.interval.Seconds()\n\n\tr.mutex.Lock()\n\tdefer r.mutex.Unlock()\n\n\tif r.init {\n\t\tr.lastRate += r.alpha * (instantRate - r.lastRate)\n\t} else {\n\t\tr.init = true\n\t\tr.lastRate = instantRate\n\t}\n}", "reference": "// tick assumes to be called every r.interval.", "generated": "// Tick updates rate based on new events in last interval.\n//\n// This method is called once per second to update the current rate from the number\n// of recent events divided by time elapsed since last call. The initial value for this\n// field will be set when first initialized using SetInterval(). If there have been"}
{"id": 390, "code": "func (a *Args) GetBool(key string) bool {\n\tswitch b2s(a.Peek(key)) {\n\t// Support the same true cases as strconv.ParseBool\n\t// See: https://github.com/golang/go/blob/4e1b11e2c9bdb0ddea1141eed487be1a626ff5be/src/strconv/atob.go#L12\n\t// and Y and Yes versions.\n\tcase \"1\", \"t\", \"T\", \"true\", \"TRUE\", \"True\", \"y\", \"yes\", \"Y\", \"YES\", \"Yes\":\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}", "reference": "// GetBool returns boolean value for the given key.\n//\n// true is returned for \"1\", \"t\", \"T\", \"true\", \"TRUE\", \"True\", \"y\", \"yes\", \"Y\", \"YES\", \"Yes\",\n// otherwise false is returned.", "generated": "//\n// Parse boolean value from key in Args using standard conversion rules for\n// strconv.ParseBoolean. This is similar to stdlib's ParseBool but supports more\n// formats like 'y', 'n' etc which aren't supported by stdlib's version. The\n// format should be one of these strings or"}
{"id": 420, "code": "func (cc *LBClient) DoTimeout(req *Request, resp *Response, timeout time.Duration) error {\n\tdeadline := time.Now().Add(timeout)\n\treturn cc.get().DoDeadline(req, resp, deadline)\n}", "reference": "// DoTimeout calculates deadline and calls DoDeadline on the least loaded client", "generated": "// This method is similar to do but it adds a delay before returning if\n// there's no result from the server within the given duration.\n//\n// If this returns nil then we'll wait for another second and try again,\n// until either our timer runs out or we get a successful response back."}
{"id": 430, "code": "func (ctx *RequestCtx) TLSConnectionState() *tls.ConnectionState {\n\ttlsConn, ok := ctx.c.(connTLSer)\n\tif !ok {\n\t\treturn nil\n\t}\n\tstate := tlsConn.ConnectionState()\n\treturn &state\n}", "reference": "// TLSConnectionState returns TLS connection state.\n//\n// The function returns nil if the underlying connection isn't tls.Conn.\n//\n// The returned state may be used for verifying TLS version, client certificates,\n// etc.", "generated": "// Returns connection state for this request's TLS context if it exists.\n//\n// This is used to determine whether or not we need to perform any additional checks before returning from the handler,\n// such as checking that our client certificate matches the server's expected one.  If no TLS has been established yet then\n// return"}
{"id": 453, "code": "func (s *Server) Serve(ln net.Listener) error {\n\tvar lastOverflowErrorTime time.Time\n\tvar lastPerIPErrorTime time.Time\n\tvar c net.Conn\n\tvar err error\n\n\ts.mu.Lock()\n\t{\n\t\tif s.ln != nil {\n\t\t\ts.mu.Unlock()\n\t\t\treturn ErrAlreadyServing\n\t\t}\n\n\t\ts.ln = ln\n\t\ts.done = make(chan struct{})\n\t}\n\ts.mu.Unlock()\n\n\tmaxWorkersCount := s.getConcurrency()\n\ts.concurrencyCh = make(chan struct{}, maxWorkersCount)\n\twp := &workerPool{\n\t\tWorkerFunc:      s.serveConn,\n\t\tMaxWorkersCount: maxWorkersCount,\n\t\tLogAllErrors:    s.LogAllErrors,\n\t\tLogger:          s.logger(),\n\t\tconnState:       s.setState,\n\t}\n\twp.Start()\n\n\t// Count our waiting to accept a connection as an open connection.\n\t// This way we can't get into any weird state where just after accepting\n\t// a connection Shutdown is called which reads open as 0 because it isn't\n\t// incremented yet.\n\tatomic.AddInt32(&s.open, 1)\n\tdefer atomic.AddInt32(&s.open, -1)\n\n\tfor {\n\t\tif c, err = acceptConn(s, ln, &lastPerIPErrorTime); err != nil {\n\t\t\twp.Stop()\n\t\t\tif err == io.EOF {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\ts.setState(c, StateNew)\n\t\tatomic.AddInt32(&s.open, 1)\n\t\tif !wp.Serve(c) {\n\t\t\tatomic.AddInt32(&s.open, -1)\n\t\t\ts.writeFastError(c, StatusServiceUnavailable,\n\t\t\t\t\"The connection cannot be served because Server.Concurrency limit exceeded\")\n\t\t\tc.Close()\n\t\t\ts.setState(c, StateClosed)\n\t\t\tif time.Since(lastOverflowErrorTime) > time.Minute {\n\t\t\t\ts.logger().Printf(\"The incoming connection cannot be served, because %d concurrent connections are served. \"+\n\t\t\t\t\t\"Try increasing Server.Concurrency\", maxWorkersCount)\n\t\t\t\tlastOverflowErrorTime = time.Now()\n\t\t\t}\n\n\t\t\t// The current server reached concurrency limit,\n\t\t\t// so give other concurrently running servers a chance\n\t\t\t// accepting incoming connections on the same address.\n\t\t\t//\n\t\t\t// There is a hope other servers didn't reach their\n\t\t\t// concurrency limits yet :)\n\t\t\t//\n\t\t\t// See also: https://github.com/valyala/fasthttp/pull/485#discussion_r239994990\n\t\t\tif s.SleepWhenConcurrencyLimitsExceeded > 0 {\n\t\t\t\ttime.Sleep(s.SleepWhenConcurrencyLimitsExceeded)\n\t\t\t}\n\t\t}\n\t\tc = nil\n\t}\n}", "reference": "// Serve serves incoming connections from the given listener.\n//\n// Serve blocks until the given listener returns permanent error.", "generated": "// Serve starts serving new requests from given listener. If there's already\n// another instance listening for this port then return ErrorAlreadyServing.\n// Return nil if no errors occurred during start process or when shutting down.\n// Note that while calling this method all instances will stop working until\n// they're shut down manually"}
{"id": 480, "code": "func (req *Request) SetBodyString(body string) {\n\treq.RemoveMultipartFormFiles()\n\treq.closeBodyStream()\n\treq.bodyBuffer().SetString(body)\n}", "reference": "// SetBodyString sets request body.", "generated": "// Sets body to be sent in request using String type.\n//\n// Note: This method removes any multipart form data from the request,\n// so it should only be used for requests that do not contain\n// file uploads or other types of binary content.  If this is set then\n// all files will also be"}
{"id": 511, "code": "func (h *ResponseHeader) SetCookie(cookie *Cookie) {\n\th.cookies = setArgBytes(h.cookies, cookie.Key(), cookie.Cookie(), argsHasValue)\n}", "reference": "// SetCookie sets the given response cookie.\n//\n// It is save re-using the cookie after the function returns.", "generated": "// Sets cookies for this Response Header object.\n//\n// Args\n//   - Cookie: The Cookies to add or update in this header. If it's nil,\n//     then no changes will be made to any existing values."}
{"id": 513, "code": "func (h *ResponseHeader) DelCookie(key string) {\n\th.cookies = delAllArgs(h.cookies, key)\n}", "reference": "// DelCookie removes cookie under the given key from response header.\n//\n// Note that DelCookie doesn't remove the cookie from the client.\n// Use DelClientCookie instead.", "generated": "// Delete cookie from Response Header\n//\n// Args: \n//   - Key : Cookie name to delete.\n //\n// Returns :\n//   - None if no cookies found for given key,\n//     otherwise returns deleted value in return variable."}
{"id": 517, "code": "func (h *ResponseHeader) PeekBytes(key []byte) []byte {\n\th.bufKV.key = append(h.bufKV.key[:0], key...)\n\tnormalizeHeaderKey(h.bufKV.key, h.disableNormalizing)\n\treturn h.peek(h.bufKV.key)\n}", "reference": "// PeekBytes returns header value for the given key.\n//\n// Returned value is valid until the next call to ResponseHeader.\n// Do not store references to returned value. Make copies instead.", "generated": "// PeekBytes returns bytes from Response Header without consuming them.\n//\n// This method is used to peek at header values before they're consumed by\n// another part of code that needs it. It's useful when we need some data but don't want\n// consume all available headers yet. The returned value will be empty"}
{"id": 525, "code": "func (h *RequestHeader) WriteTo(w io.Writer) (int64, error) {\n\tn, err := w.Write(h.Header())\n\treturn int64(n), err\n}", "reference": "// WriteTo writes request header to w.\n//\n// WriteTo implements io.WriterTo interface.", "generated": "// Writes header to writer.\n//\n// Returns number written or zero if there was no data in this request's headers,\n// otherwise it is negative for errors that occurred while writing.  The return value\n// will be non-negative when reading from the output stream instead."}
{"id": 536, "code": "func (c *Cookie) Expire() time.Time {\n\texpire := c.expire\n\tif expire.IsZero() {\n\t\texpire = CookieExpireUnlimited\n\t}\n\treturn expire\n}", "reference": "// Expire returns cookie expiration time.\n//\n// CookieExpireUnlimited is returned if cookie doesn't expire", "generated": "// Expire returns cookie expiration date or zero if it's unlimited.\n//\n// Note: This method is used to get current value from stored data,\n// so this should be called only once when reading cookies for first time."}
{"id": 537, "code": "func (c *Cookie) SetValue(value string) {\n\tc.value = append(c.value[:0], value...)\n}", "reference": "// SetValue sets cookie value.", "generated": "// Set cookie values\n//\n// This method sets all cookies to be sent in the request.\n //\n// Note: The Cookie object is mutable after it's created,\n // so this can also set new values for existing cookies if needed."}
{"id": 577, "code": "func (mx *Mux) Patch(pattern string, handlerFn http.HandlerFunc) {\n\tmx.handle(mPATCH, pattern, handlerFn)\n}", "reference": "// Patch adds the route `pattern` that matches a PATCH http method to\n// execute the `handlerFn` http.HandlerFunc.", "generated": "// Handle patch requests to this endpoint.\n//\n// This is used for updating existing resources in the database,\n// which can be useful when working with APIs that support\n// partial updates or patches. The request body should contain\n// only the fields being updated; any missing values will remain unchanged."}
{"id": 579, "code": "func (mx *Mux) Put(pattern string, handlerFn http.HandlerFunc) {\n\tmx.handle(mPUT, pattern, handlerFn)\n}", "reference": "// Put adds the route `pattern` that matches a PUT http method to\n// execute the `handlerFn` http.HandlerFunc.", "generated": "// Add a new route to handle PUT requests.\n//\n// This method adds a single path for handling GET request. The value passed\n// is used in place of the default HTTP HandlerFunc type argument when calling\n// this method from within another MUX instance's Handle methods. If no values\n// are provided then"}
{"id": 600, "code": "func SearchArticles(w http.ResponseWriter, r *http.Request) {\n\trender.RenderList(w, r, NewArticleListResponse(articles))\n}", "reference": "// SearchArticles searches the Articles data for a matching article.\n// It's just a stub, but you get the idea.", "generated": "// Searches for articles based on query parameters.\n//\n// Args: searchQuery (string), page (int)\n //\n// Returns 200 if found otherwise returns 404\n//\n// Example request URL: /search?query=python&page=1"}
{"id": 603, "code": "func UpdateArticle(w http.ResponseWriter, r *http.Request) {\n\tarticle := r.Context().Value(\"article\").(*Article)\n\n\tdata := &ArticleRequest{Article: article}\n\tif err := render.Bind(r, data); err != nil {\n\t\trender.Render(w, r, ErrInvalidRequest(err))\n\t\treturn\n\t}\n\tarticle = data.Article\n\tdbUpdateArticle(article.ID, article)\n\n\trender.Render(w, r, NewArticleResponse(article))\n}", "reference": "// UpdateArticle updates an existing Article in our persistent store.", "generated": "// Updates existing Article in database.\n//\n// Args:\n//   w - HTTP Response Writer\n//   r  - Request object containing context value for current request's article instance\n //\n// Returns:\n//   Rendered HTML page if successful or error message otherwise"}
{"id": 605, "code": "func adminRouter() chi.Router {\n\tr := chi.NewRouter()\n\tr.Use(AdminOnly)\n\tr.Get(\"/\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(\"admin: index\"))\n\t})\n\tr.Get(\"/accounts\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(\"admin: list accounts..\"))\n\t})\n\tr.Get(\"/users/{userId}\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(fmt.Sprintf(\"admin: view user id %v\", chi.URLParam(r, \"userId\"))))\n\t})\n\treturn r\n}", "reference": "// A completely separate router for administrator routes", "generated": "// Admin router for administrative access to API endpoints.\n//\n// This is used by the server's internal administration interface,\n// which can be accessed via HTTP requests from within the container."}
{"id": 606, "code": "func AdminOnly(next http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tisAdmin, ok := r.Context().Value(\"acl.admin\").(bool)\n\t\tif !ok || !isAdmin {\n\t\t\thttp.Error(w, http.StatusText(http.StatusForbidden), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}", "reference": "// AdminOnly middleware restricts access to just administrators.", "generated": "// AdminOnly checks if user is admin before calling next handler.\n//\n// This can be used to protect routes that should only be accessible by admins,\n// while still allowing other handlers to run for non-admin users."}
{"id": 612, "code": "func DefaultCompress(next http.Handler) http.Handler {\n\treturn Compress(flate.DefaultCompression)(next)\n}", "reference": "// DefaultCompress is a middleware that compresses response\n// body of predefined content types to a data format based\n// on Accept-Encoding request header. It uses a default\n// compression level.\n// DEPRECATED", "generated": "// DefaultCompress returns a handler that compresses all responses using\n//\n// flate compression.\n //\n// This is used by default in go-http-server to reduce network bandwidth usage,\n// but can be overridden if needed for specific use cases (e.g., when serving static files)."}
{"id": 623, "code": "func canonicalHostedZone(hostname string) string {\n\tfor suffix, zone := range canonicalHostedZones {\n\t\tif strings.HasSuffix(hostname, suffix) {\n\t\t\treturn zone\n\t\t}\n\t}\n\n\treturn \"\"\n}", "reference": "// canonicalHostedZone returns the matching canonical zone for a given hostname.", "generated": "// Canonicalizes hostname to match one of our hosted zones.\n//\n// This is used for DNS lookups where we need to know which hoster's domain\n// it belongs to (e.g., when checking if someone has set up their own custom\n// DNS).  We don't want any random domains that aren"}
{"id": 629, "code": "func InMemoryWithLogging() InMemoryOption {\n\treturn func(p *InMemoryProvider) {\n\t\tp.OnApplyChanges = func(changes *plan.Changes) {\n\t\t\tfor _, v := range changes.Create {\n\t\t\t\tlog.Infof(\"CREATE: %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.UpdateOld {\n\t\t\t\tlog.Infof(\"UPDATE (old): %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.UpdateNew {\n\t\t\t\tlog.Infof(\"UPDATE (new): %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.Delete {\n\t\t\t\tlog.Infof(\"DELETE: %v\", v)\n\t\t\t}\n\t\t}\n\t}\n}", "reference": "// InMemoryWithLogging injects logging when ApplyChanges is called", "generated": "// With Logging adds logging to all operations in memory provider.\n//\n// This option is useful for debugging purposes or when testing\n// the database connection without actually writing any data to disk."}
{"id": 656, "code": "func (sc *serviceSource) filterByAnnotations(services []*v1.Service) ([]*v1.Service, error) {\n\tlabelSelector, err := metav1.ParseToLabelSelector(sc.annotationFilter)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tselector, err := metav1.LabelSelectorAsSelector(labelSelector)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// empty filter returns original list\n\tif selector.Empty() {\n\t\treturn services, nil\n\t}\n\n\tfilteredList := []*v1.Service{}\n\n\tfor _, service := range services {\n\t\t// convert the service's annotations to an equivalent label selector\n\t\tannotations := labels.Set(service.Annotations)\n\n\t\t// include service if its annotations match the selector\n\t\tif selector.Matches(annotations) {\n\t\t\tfilteredList = append(filteredList, service)\n\t\t}\n\t}\n\n\treturn filteredList, nil\n}", "reference": "// filterByAnnotations filters a list of services by a given annotation selector.", "generated": "// FilterServices filters out any Service that doesn't have the specified annotation.\n//\n// This is used when we're trying to find all Services in our cluster,\n// but some of them don't contain certain required information for us to use.\n //\n// If no AnnotationFilter has been set then this will return every Service."}
{"id": 658, "code": "func (p *Plan) Calculate() *Plan {\n\tt := newPlanTable()\n\n\tfor _, current := range filterRecordsForPlan(p.Current) {\n\t\tt.addCurrent(current)\n\t}\n\tfor _, desired := range filterRecordsForPlan(p.Desired) {\n\t\tt.addCandidate(desired)\n\t}\n\n\tchanges := &Changes{}\n\tchanges.Create = t.getCreates()\n\tchanges.Delete = t.getDeletes()\n\tchanges.UpdateNew, changes.UpdateOld = t.getUpdates()\n\tfor _, pol := range p.Policies {\n\t\tchanges = pol.Apply(changes)\n\t}\n\n\tplan := &Plan{\n\t\tCurrent: p.Current,\n\t\tDesired: p.Desired,\n\t\tChanges: changes,\n\t}\n\n\treturn plan\n}", "reference": "// Calculate computes the actions needed to move current state towards desired\n// state. It then passes those changes to the current policy for further\n// processing. It returns a copy of Plan with the changes populated.", "generated": "// Calculate returns a Plan that represents all possible outcomes for this change.\n//\n// This is used to calculate which policies should be applied in order to achieve the desired state from any given initial state."}
{"id": 662, "code": "func NewTargets(target ...string) Targets {\n\tt := make(Targets, 0, len(target))\n\tt = append(t, target...)\n\treturn t\n}", "reference": "// NewTargets is a convenience method to create a new Targets object from a vararg of strings", "generated": "// Create new targets from given strings.\n//\n// This is used to create initial set of targets for use in tests or other contexts where we need more than one target,\n// but don't want to pass them all at once when calling test.Run()."}
{"id": 721, "code": "func NewRfc2136Provider(host string, port int, zoneName string, insecure bool, keyName string, secret string, secretAlg string, axfr bool, domainFilter DomainFilter, dryRun bool, actions rfc2136Actions) (Provider, error) {\n\tsecretAlgChecked, ok := tsigAlgs[secretAlg]\n\tif !ok && !insecure {\n\t\treturn nil, errors.Errorf(\"%s is not supported TSIG algorithm\", secretAlg)\n\t}\n\n\tr := &rfc2136Provider{\n\t\tnameserver:   net.JoinHostPort(host, strconv.Itoa(port)),\n\t\tzoneName:     dns.Fqdn(zoneName),\n\t\tinsecure:     insecure,\n\t\tdomainFilter: domainFilter,\n\t\tdryRun:       dryRun,\n\t\taxfr:         axfr,\n\t}\n\tif actions != nil {\n\t\tr.actions = actions\n\t} else {\n\t\tr.actions = r\n\t}\n\n\tif !insecure {\n\t\tr.tsigKeyName = dns.Fqdn(keyName)\n\t\tr.tsigSecret = secret\n\t\tr.tsigSecretAlg = secretAlgChecked\n\t}\n\n\tlog.Infof(\"Configured RFC2136 with zone '%s' and nameserver '%s'\", r.zoneName, r.nameserver)\n\treturn r, nil\n}", "reference": "// NewRfc2136Provider is a factory function for OpenStack rfc2136 providers", "generated": "// Create new instance for/rfc2136 provider.\n//\n// Args:\n// host - name server to use in query.\n// port - port number used by name server.\n// zoneName - DNS FQDN of zone that we want to resolve.\n// insecure - if true then no authentication will be performed using TSIG"}
{"id": 734, "code": "func (p *AWSSDProvider) RegisterInstance(service *sd.Service, ep *endpoint.Endpoint) error {\n\tfor _, target := range ep.Targets {\n\t\tlog.Infof(\"Registering a new instance \\\"%s\\\" for service \\\"%s\\\" (%s)\", target, *service.Name, *service.Id)\n\n\t\tattr := make(map[string]*string)\n\n\t\tif ep.RecordType == endpoint.RecordTypeCNAME {\n\t\t\tif p.isAWSLoadBalancer(target) {\n\t\t\t\tattr[sdInstanceAttrAlias] = aws.String(target)\n\t\t\t} else {\n\t\t\t\tattr[sdInstanceAttrCname] = aws.String(target)\n\t\t\t}\n\t\t} else if ep.RecordType == endpoint.RecordTypeA {\n\t\t\tattr[sdInstanceAttrIPV4] = aws.String(target)\n\t\t} else {\n\t\t\treturn fmt.Errorf(\"invalid endpoint type (%v)\", ep)\n\t\t}\n\n\t\tif !p.dryRun {\n\t\t\t_, err := p.client.RegisterInstance(&sd.RegisterInstanceInput{\n\t\t\t\tServiceId:  service.Id,\n\t\t\t\tAttributes: attr,\n\t\t\t\tInstanceId: aws.String(p.targetToInstanceID(target)),\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "reference": "// RegisterInstance creates a new instance in given service.", "generated": "// RegisterInstance registers all endpoints in this provider to their respective services.\n//\n// This method is used by sd providers that support AWS SD instances. It will register each end point's IP address or CName into its corresponding service. If dry run mode has been enabled then it won't actually perform any operations but instead log"}
{"id": 769, "code": "func canonicalizeDomainName(d string) string {\n\tif !strings.HasSuffix(d, \".\") {\n\t\td += \".\"\n\t}\n\treturn strings.ToLower(d)\n}", "reference": "// converts domain name to FQDN", "generated": "// Canonicalizes domain names to lowercase.\n//\n// This is used for consistency in logging messages where we want\n// all domains to be written out consistently regardless of how they're\n// formatted when received from clients or other servers.  We don't need\n// this if it's already been sanitized by another part of"}
{"id": 772, "code": "func addEndpoint(ep *endpoint.Endpoint, recordSets map[string]*recordSet, delete bool) {\n\tkey := fmt.Sprintf(\"%s/%s\", ep.DNSName, ep.RecordType)\n\trs := recordSets[key]\n\tif rs == nil {\n\t\trs = &recordSet{\n\t\t\tdnsName:    canonicalizeDomainName(ep.DNSName),\n\t\t\trecordType: ep.RecordType,\n\t\t\tnames:      make(map[string]bool),\n\t\t}\n\t}\n\tif rs.zoneID == \"\" {\n\t\trs.zoneID = ep.Labels[designateZoneID]\n\t}\n\tif rs.recordSetID == \"\" {\n\t\trs.recordSetID = ep.Labels[designateRecordSetID]\n\t}\n\tfor _, rec := range strings.Split(ep.Labels[designateOriginalRecords], \"\\000\") {\n\t\tif _, ok := rs.names[rec]; !ok && rec != \"\" {\n\t\t\trs.names[rec] = true\n\t\t}\n\t}\n\ttargets := ep.Targets\n\tif ep.RecordType == endpoint.RecordTypeCNAME {\n\t\ttargets = canonicalizeDomainNames(targets)\n\t}\n\tfor _, t := range targets {\n\t\trs.names[t] = !delete\n\t}\n\trecordSets[key] = rs\n}", "reference": "// adds endpoint into recordset aggregation, loading original values from endpoint labels first", "generated": "// Add adds records to the zone for this DNS name.\n//\n// If there is already a set of records in the zone that match this DNS\n// name then they will be updated instead of added.  The names must exist\n// within the zones target list or else it will fail silently if no such\n//"}
{"id": 787, "code": "func (ms *dedupSource) Endpoints() ([]*endpoint.Endpoint, error) {\n\tresult := []*endpoint.Endpoint{}\n\tcollected := map[string]bool{}\n\n\tendpoints, err := ms.source.Endpoints()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ep := range endpoints {\n\t\tidentifier := ep.DNSName + \" / \" + ep.Targets.String()\n\n\t\tif _, ok := collected[identifier]; ok {\n\t\t\tlog.Debugf(\"Removing duplicate endpoint %s\", ep)\n\t\t\tcontinue\n\t\t}\n\n\t\tcollected[identifier] = true\n\t\tresult = append(result, ep)\n\t}\n\n\treturn result, nil\n}", "reference": "// Endpoints collects endpoints from its wrapped source and returns them without duplicates.", "generated": "// Ends returns all endpoints from source that have been added to this dedupe.\n//\n// This method is used when we're done adding new sources or ending existing ones,\n// but still want to keep track of any endpoints they've already sent us.  It's also\n// useful if someone wants to remove duplicates before"}
{"id": 791, "code": "func (sdr *AWSSDRegistry) ApplyChanges(changes *plan.Changes) error {\n\tfilteredChanges := &plan.Changes{\n\t\tCreate:    changes.Create,\n\t\tUpdateNew: filterOwnedRecords(sdr.ownerID, changes.UpdateNew),\n\t\tUpdateOld: filterOwnedRecords(sdr.ownerID, changes.UpdateOld),\n\t\tDelete:    filterOwnedRecords(sdr.ownerID, changes.Delete),\n\t}\n\n\tsdr.updateLabels(filteredChanges.Create)\n\tsdr.updateLabels(filteredChanges.UpdateNew)\n\tsdr.updateLabels(filteredChanges.UpdateOld)\n\tsdr.updateLabels(filteredChanges.Delete)\n\n\treturn sdr.provider.ApplyChanges(filteredChanges)\n}", "reference": "// ApplyChanges filters out records not owned the External-DNS, additionally it adds the required label\n// inserted in the AWS SD instance as a CreateID field", "generated": "// ApplyChanges applies all registered records to their current state.\n//\n// This method is used by AWSSD registry when it's initialized or updated\n// after registration. It should be called only once for each change set in order\n// to maintain consistency between different providers' states. If this method\n// fails then provider"}
{"id": 800, "code": "func createDiskImage(dest string, size int, r io.Reader) error {\n\t// Convert a raw image from stdin to the dest VMDK image.\n\tsizeBytes := int64(size) << 20 // usually won't fit in 32-bit int (max 2GB)\n\t// FIXME: why isn't this just using the vbm*() functions?\n\tcmd := exec.Command(vboxManageCmd, \"convertfromraw\", \"stdin\", dest,\n\t\tfmt.Sprintf(\"%d\", sizeBytes), \"--format\", \"VMDK\")\n\n\tlog.Debug(cmd)\n\n\tif os.Getenv(\"MACHINE_DEBUG\") != \"\" {\n\t\tcmd.Stdout = os.Stdout\n\t\tcmd.Stderr = os.Stderr\n\t}\n\n\tstdin, err := cmd.StdinPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Starting command\")\n\n\tif err := cmd.Start(); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Copying to stdin\")\n\n\tn, err := io.Copy(stdin, r)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Filling zeroes\")\n\n\t// The total number of bytes written to stdin must match sizeBytes, or\n\t// VBoxManage.exe on Windows will fail. Fill remaining with zeros.\n\tif left := sizeBytes - n; left > 0 {\n\t\tif err := zeroFill(stdin, left); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tlog.Debug(\"Closing STDIN\")\n\n\t// cmd won't exit until the stdin is closed.\n\tif err := stdin.Close(); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Waiting on cmd\")\n\n\treturn cmd.Wait()\n}", "reference": "// createDiskImage makes a disk image at dest with the given size in MB. If r is\n// not nil, it will be read as a raw disk image to convert from.", "generated": "//\n// Create a disk image by copying data into it via stdin. This can be used for\n// converting images created during virtual machine creation to other formats that\n// support more features than the original format supports. Note that if there's any\n// errors while writing to stdout then the output file may end up being"}
{"id": 802, "code": "func (n *hostOnlyNetwork) SaveIPv4(vbox VBoxManager) error {\n\tif n.IPv4.IP != nil && n.IPv4.Mask != nil {\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tlog.Warn(\"Windows might ask for the permission to configure a network adapter. Sometimes, such confirmation window is minimized in the taskbar.\")\n\t\t}\n\n\t\tif err := vbox.vbm(\"hostonlyif\", \"ipconfig\", n.Name, \"--ip\", n.IPv4.IP.String(), \"--netmask\", net.IP(n.IPv4.Mask).String()); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}", "reference": "// SaveIPv4 changes the ipv4 configuration of the host-only network.", "generated": "// Saves IPv4 configuration if it exists.\n//\n// Note: This method will only work when running inside VirtualBox,\n// because host-only networks can't be created or modified outside of VirtualBox."}
{"id": 821, "code": "func (d *Driver) Restart() error {\n\tcs := d.client()\n\t_, err := cs.RequestWithContext(context.TODO(), &egoscale.RebootVirtualMachine{\n\t\tID: d.ID,\n\t})\n\n\treturn err\n}", "reference": "// Restart reboots the existing VM instance.", "generated": "//Restart restarts this virtual machine in its current state.\n//\n//Note that if there is already another instance running for this VM then it will be stopped first before being restarted."}
{"id": 822, "code": "func (d *Driver) Remove() error {\n\tclient := d.client()\n\n\t// Destroy the SSH key from CloudStack\n\tif d.KeyPair != \"\" {\n\t\tkey := &egoscale.SSHKeyPair{Name: d.KeyPair}\n\t\tif err := client.DeleteWithContext(context.TODO(), key); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Destroy the virtual machine\n\tif d.ID != \"\" {\n\t\tvm := &egoscale.VirtualMachine{ID: d.ID}\n\t\tif err := client.DeleteWithContext(context.TODO(), vm); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tlog.Infof(\"The Anti-Affinity group and Security group were not removed\")\n\n\treturn nil\n}", "reference": "// Remove destroys the VM instance and the associated SSH key.", "generated": "//\n// Removes all resources created by this driver.\n //\n// This method is called when the resource has been deleted in cloudstack,\n// but it's also used to clean up any remaining resources that may have\n// been left behind if there was some kind of failure or other issue during\n// creation.  It should"}
{"id": 823, "code": "func (d *Driver) getCloudInit() ([]byte, error) {\n\tvar err error\n\tif d.UserDataFile != \"\" {\n\t\td.UserData, err = ioutil.ReadFile(d.UserDataFile)\n\t}\n\n\treturn d.UserData, err\n}", "reference": "// Build a cloud-init user data string that will install and run\n// docker.", "generated": "// Get cloud init data from user file or default to empty bytes if no UserDATA_FILE is set.\n//\n// This method should be called only once per instance when it starts up for first time,\n// otherwise this will return same result which was stored in previous call."}
{"id": 834, "code": "func deviceFlowAuth(oauthCfg azure.OAuthConfig, clientID, resource string) (*azure.ServicePrincipalToken, error) {\n\tcl := oauthClient()\n\tdeviceCode, err := azure.InitiateDeviceAuth(&cl, oauthCfg, clientID, resource)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to start device auth: %v\", err)\n\t}\n\tlog.Debug(\"Retrieved device code.\", logutil.Fields{\n\t\t\"expires_in\": to.Int64(deviceCode.ExpiresIn),\n\t\t\"interval\":   to.Int64(deviceCode.Interval),\n\t})\n\n\t// Example message: \u201cTo sign in, open https://aka.ms/devicelogin and enter\n\t// the code 0000000 to authenticate.\u201d\n\tlog.Infof(\"Microsoft Azure: %s\", to.String(deviceCode.Message))\n\n\ttoken, err := azure.WaitForUserCompletion(&cl, deviceCode)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to complete device auth: %v\", err)\n\t}\n\n\tspt, err := azure.NewServicePrincipalTokenFromManualToken(oauthCfg, clientID, resource, *token)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error constructing service principal token: %v\", err)\n\t}\n\treturn spt, nil\n}", "reference": "// deviceFlowAuth prints a message to the screen for user to take action to\n// consent application on a browser and in the meanwhile the authentication\n// endpoint is polled until user gives consent, denies or the flow times out.\n// Returned token must be saved.", "generated": "// Device flow authentication for Microsoft Azure using OAuth.\n//\n// This method is used when there's no existing access token available,\n// such as during initial setup or after user has logged out but before they've signed back in again.\n //\n// Note that this requires users have their browser opened at least once so it can prompt"}
{"id": 842, "code": "func (c *ComputeUtil) staticAddress() (string, error) {\n\t// is the address a name?\n\tisName, err := regexp.MatchString(\"[a-z]([-a-z0-9]*[a-z0-9])?\", c.address)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif !isName {\n\t\treturn c.address, nil\n\t}\n\n\t// resolve the address by name\n\texternalAddress, err := c.service.Addresses.Get(c.project, c.region(), c.address).Do()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn externalAddress.Address, nil\n}", "reference": "// staticAddress returns the external static IP address.", "generated": "//\n// Returns the IP or hostname for this compute instance's network interface.\n //\n// If it returns a hostnames then we assume that the user has specified a\n// hostname in their Compute Instance configuration file instead of specifying\n// an IP address directly when creating the Compute Instance.\n //\n// This method will return \"nil"}
{"id": 849, "code": "func (c *ComputeUtil) startInstance() error {\n\top, err := c.service.Instances.Start(c.project, c.zone, c.instanceName).Do()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Infof(\"Waiting for instance to start.\")\n\treturn c.waitForRegionalOp(op.Name)\n}", "reference": "// startInstance starts the instance.", "generated": "// Start starts the specified compute engine instance.\n//\n// This method waits until the operation is complete before returning,\n// or if there's any errors during this process it returns those instead."}
{"id": 867, "code": "func osDiskStorageContainerURL(account *storage.AccountProperties, vmName string) string {\n\treturn fmt.Sprintf(\"%s%s/\", to.String(account.PrimaryEndpoints.Blob), osDiskStorageContainerName(vmName))\n}", "reference": "// osDiskStorageContainerURL crafts a URL with a trailing slash pointing\n// to the full Azure Blob Container URL for given VM name.", "generated": "// Returns URL for container holding disk storage data associated\n// with given VM name.\n//\n// Note: This method is used only when using cloud provider's native\n// disks support (i.e., Azure Disk Storage). If this isn't supported,\n// it returns empty string."}
{"id": 892, "code": "func (d *Driver) Create() error {\n\tlog.Infof(\"Generating SSH Key\")\n\n\tif err := ssh.GenerateSSHKey(d.GetSSHKeyPath()); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Infof(\"Creating host...\")\n\n\tc, err := newComputeUtil(d)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := c.openFirewallPorts(d); err != nil {\n\t\treturn err\n\t}\n\n\tif d.UseExisting {\n\t\treturn c.configureInstance(d)\n\t}\n\treturn c.createInstance(d)\n}", "reference": "// Create creates a GCE VM instance acting as a docker host.", "generated": "// Creates a cloud instance using the provided config options.\n//\n// This method will create a firewalls to allow all incoming traffic for port 22,\n// which is required by default in most clouds. If this option isn't set then it's\n// assumed that there already exists some existing firewall rules configured. In such"}
{"id": 908, "code": "func (d *Driver) Restart() error {\n\tif err := d.checkLegacyDriver(true); err != nil {\n\t\treturn err\n\t}\n\n\t// NOTE(ahmetalpbalkan) Azure will always keep the VM in Running state\n\t// during the restart operation. Hence we rely on returned async operation\n\t// polling to make sure the reboot is waited upon.\n\tc, err := d.newAzureClient()\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn c.RestartVirtualMachine(d.ResourceGroup, d.naming().VM())\n}", "reference": "// Restart reboots the virtual machine instance.", "generated": "//\n// Start or stop the virtual machine based on its current status. This method returns\n// true if it was successful otherwise false. The driver should handle any errors that occur,\n// but they can be ignored by calling ignoreError for them. Note: this method only works when\n// running locally because azure requires authentication"}
{"id": 914, "code": "func (d *Driver) Start() error {\n\tif err := cmd(\"Hyper-V\\\\Start-VM\", d.MachineName); err != nil {\n\t\treturn err\n\t}\n\n\tip, err := d.waitForIP()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\td.IPAddress = ip\n\n\treturn nil\n}", "reference": "// Start starts an host", "generated": "// Starts the virtual machine in Hyper-V mode.\n//\n// This method starts the VM if it is already running or stops it otherwise,\n// then waits for its IP address to be available before returning. If there's any\n// errors during this process, they're returned by this method."}
{"id": 921, "code": "func (d *BaseDriver) GetSSHUsername() string {\n\tif d.SSHUser == \"\" {\n\t\td.SSHUser = DefaultSSHUser\n\t}\n\treturn d.SSHUser\n}", "reference": "// GetSSHUsername returns the ssh user name, root if not specified", "generated": "// Return SSH username to use for connection if it is set in driver config,\n// otherwise return default value from BaseDriver's configuration."}
{"id": 937, "code": "func NewDriver(machineName, storePath string) drivers.Driver {\n\tlog.Debug(\"Instantiating Rackspace driver.\", map[string]string{\"machineName\": machineName})\n\n\tinner := openstack.NewDerivedDriver(machineName, storePath)\n\tdriver := &Driver{\n\t\tDriver: inner,\n\t}\n\tinner.SetClient(&Client{\n\t\tdriver: driver,\n\t})\n\n\treturn driver\n}", "reference": "// NewDriver instantiates a Rackspace driver.", "generated": "// Create new instance of Driver for given Machine name and Store path.\n//\n// This method creates a client to interact with OpenStack cloud service using\n// provided credentials. The created Client is then used by Driver's methods."}
{"id": 945, "code": "func (d *Driver) GetCreateFlags() []mcnflag.Flag {\n\treturn []mcnflag.Flag{\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_CPU_COUNT\",\n\t\t\tName:   \"vmwarevsphere-cpu-count\",\n\t\t\tUsage:  \"vSphere CPU number for docker VM\",\n\t\t\tValue:  defaultCpus,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_MEMORY_SIZE\",\n\t\t\tName:   \"vmwarevsphere-memory-size\",\n\t\t\tUsage:  \"vSphere size of memory for docker VM (in MB)\",\n\t\t\tValue:  defaultMemory,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_DISK_SIZE\",\n\t\t\tName:   \"vmwarevsphere-disk-size\",\n\t\t\tUsage:  \"vSphere size of disk for docker VM (in MB)\",\n\t\t\tValue:  defaultDiskSize,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_BOOT2DOCKER_URL\",\n\t\t\tName:   \"vmwarevsphere-boot2docker-url\",\n\t\t\tUsage:  \"vSphere URL for boot2docker image\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER\",\n\t\t\tName:   \"vmwarevsphere-vcenter\",\n\t\t\tUsage:  \"vSphere IP/hostname for vCenter\",\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER_PORT\",\n\t\t\tName:   \"vmwarevsphere-vcenter-port\",\n\t\t\tUsage:  \"vSphere Port for vCenter\",\n\t\t\tValue:  defaultSDKPort,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_USERNAME\",\n\t\t\tName:   \"vmwarevsphere-username\",\n\t\t\tUsage:  \"vSphere username\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_PASSWORD\",\n\t\t\tName:   \"vmwarevsphere-password\",\n\t\t\tUsage:  \"vSphere password\",\n\t\t},\n\t\tmcnflag.StringSliceFlag{\n\t\t\tEnvVar: \"VSPHERE_NETWORK\",\n\t\t\tName:   \"vmwarevsphere-network\",\n\t\t\tUsage:  \"vSphere network where the docker VM will be attached\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATASTORE\",\n\t\t\tName:   \"vmwarevsphere-datastore\",\n\t\t\tUsage:  \"vSphere datastore for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATACENTER\",\n\t\t\tName:   \"vmwarevsphere-datacenter\",\n\t\t\tUsage:  \"vSphere datacenter for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_FOLDER\",\n\t\t\tName:   \"vmwarevsphere-folder\",\n\t\t\tUsage:  \"vSphere folder for the docker VM. This folder must already exist in the datacenter.\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_POOL\",\n\t\t\tName:   \"vmwarevsphere-pool\",\n\t\t\tUsage:  \"vSphere resource pool for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_HOSTSYSTEM\",\n\t\t\tName:   \"vmwarevsphere-hostsystem\",\n\t\t\tUsage:  \"vSphere compute resource where the docker VM will be instantiated. This can be omitted if using a cluster with DRS.\",\n\t\t},\n\t\tmcnflag.StringSliceFlag{\n\t\t\tEnvVar: \"VSPHERE_CFGPARAM\",\n\t\t\tName:   \"vmwarevsphere-cfgparam\",\n\t\t\tUsage:  \"vSphere vm configuration parameters (used for guestinfo)\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_CLOUDINIT\",\n\t\t\tName:   \"vmwarevsphere-cloudinit\",\n\t\t\tUsage:  \"vSphere cloud-init file or url to set in the guestinfo\",\n\t\t},\n\t}\n}", "reference": "// GetCreateFlags registers the flags this driver adds to\n// \"docker-machine create\"", "generated": "// Return all flags that need to be passed when creating a Docker container\n// from vSpere. The flag names match those used by the command line tool.\n//\n// Note: These values should always come from environment variables unless they're explicitly defined here.\n// If these aren't provided then it defaults to some reasonable"}
{"id": 963, "code": "func (v *View) Data() interface{} {\n\tv.dataLock.RLock()\n\tdefer v.dataLock.RUnlock()\n\treturn v.data\n}", "reference": "// Data returns the most-recently-received data from Consul for this View.", "generated": "// Data returns data stored in this view.\n//\n// This method is safe to call from multiple goroutines at once,\n// but it must be called while holding the lock for that view's\n// context.  If another thread calls Data before the current one has\n// finished reading its data, they will block until"}
{"id": 1020, "code": "func NewKVListQuery(s string) (*KVListQuery, error) {\n\tif s != \"\" && !KVListQueryRe.MatchString(s) {\n\t\treturn nil, fmt.Errorf(\"kv.list: invalid format: %q\", s)\n\t}\n\n\tm := regexpMatch(KVListQueryRe, s)\n\treturn &KVListQuery{\n\t\tstopCh: make(chan struct{}, 1),\n\t\tdc:     m[\"dc\"],\n\t\tprefix: m[\"prefix\"],\n\t}, nil\n}", "reference": "// NewKVListQuery parses a string into a dependency.", "generated": "// Create new KV list query from given command line argument.\n//\n// If no arguments is provided or if they don't match expected pattern,\n// return nil and non-nil error message respectively."}
{"id": 1021, "code": "func NewDedupManager(config *config.DedupConfig, clients *dep.ClientSet, brain *template.Brain, templates []*template.Template) (*DedupManager, error) {\n\td := &DedupManager{\n\t\tconfig:    config,\n\t\tclients:   clients,\n\t\tbrain:     brain,\n\t\ttemplates: templates,\n\t\tleader:    make(map[*template.Template]<-chan struct{}),\n\t\tlastWrite: make(map[*template.Template]uint64),\n\t\tupdateCh:  make(chan struct{}, 1),\n\t\tstopCh:    make(chan struct{}),\n\t}\n\treturn d, nil\n}", "reference": "// NewDedupManager creates a new Dedup manager", "generated": "// Create new Dedup manager instance from given configuration.\n//\n// This method creates all necessary channels for communication between components.\n //\n// If there is no leader in current cluster then it will be chosen automatically by first available template that has been created before this call to create dedup manager."}
{"id": 1045, "code": "func NewVaultReadQuery(s string) (*VaultReadQuery, error) {\n\ts = strings.TrimSpace(s)\n\ts = strings.Trim(s, \"/\")\n\tif s == \"\" {\n\t\treturn nil, fmt.Errorf(\"vault.read: invalid format: %q\", s)\n\t}\n\n\tsecretURL, err := url.Parse(s)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &VaultReadQuery{\n\t\tstopCh:      make(chan struct{}, 1),\n\t\trawPath:     secretURL.Path,\n\t\tqueryValues: secretURL.Query(),\n\t}, nil\n}", "reference": "// NewVaultReadQuery creates a new datacenter dependency.", "generated": "// Create new Vault read query from URL.\n//\n// This will create a vault.ReadQuery that can be used to get secrets from\n// Vault using this URL. The raw path is trimmed for any leading or trailing\n// slashes so it's safe to use in URLs like \"https://example.com/vault/\"."}
{"id": 1057, "code": "func (c *Child) Kill() {\n\tlog.Printf(\"[INFO] (child) killing process\")\n\tc.Lock()\n\tdefer c.Unlock()\n\tc.kill()\n}", "reference": "// Kill sends the kill signal to the child process and waits for successful\n// termination. If no kill signal is defined, the process is killed with the\n// most aggressive kill signal. If the process does not gracefully stop within\n// the provided KillTimeout, the process is force-killed. If a splay was\n// provided, this function will sleep for a random period of time between 0 and\n// the provided splay value to reduce the thundering herd problem. This function\n// does not return any errors because it guarantees the process will be dead by\n// the return of the function call.", "generated": "// kill kills this child's parent process.\n//\n// This is used to clean up after a failed start or when we're done\n// running our children for some other reason.  Note that if there's no\n// current parent then nothing happens - it just logs a message saying so."}
{"id": 1064, "code": "func NewRunner(config *config.Config, dry, once bool) (*Runner, error) {\n\tlog.Printf(\"[INFO] (runner) creating new runner (dry: %v, once: %v)\", dry, once)\n\n\trunner := &Runner{\n\t\tconfig: config,\n\t\tdry:    dry,\n\t\tonce:   once,\n\t}\n\n\tif err := runner.init(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn runner, nil\n}", "reference": "// NewRunner accepts a slice of TemplateConfigs and returns a pointer to the new\n// Runner and any error that occurred during creation.", "generated": "// Create a new Runner instance from given configuration options.\n//\n// This method initializes all necessary components for running tasks in parallel.\n //\n// If 'dry' is true then no actual task execution will occur but instead log messages\n// indicating that they would be executed if this option was set to false.\n //\n// The '"}
{"id": 1102, "code": "func base64URLDecode(s string) (string, error) {\n\tv, err := base64.URLEncoding.DecodeString(s)\n\tif err != nil {\n\t\treturn \"\", errors.Wrap(err, \"base64URLDecode\")\n\t}\n\treturn string(v), nil\n}", "reference": "// base64URLDecode decodes the given string as a URL-safe base64 string.", "generated": "// decode s using URL-safe Base64 encoding.\n//\n// This is used to convert URLs from Base64 encoded strings back into bytes,\n// which can then be decoded by url.Parse(). Decode() or other methods that expect\n// byte slices instead of strings.  Note: this will return any invalid characters in\n//"}
{"id": 1107, "code": "func in(l, v interface{}) (bool, error) {\n\tlv := reflect.ValueOf(l)\n\tvv := reflect.ValueOf(v)\n\n\tswitch lv.Kind() {\n\tcase reflect.Array, reflect.Slice:\n\t\t// if the slice contains 'interface' elements, then the element needs to be extracted directly to examine its type,\n\t\t// otherwise it will just resolve to 'interface'.\n\t\tvar interfaceSlice []interface{}\n\t\tif reflect.TypeOf(l).Elem().Kind() == reflect.Interface {\n\t\t\tinterfaceSlice = l.([]interface{})\n\t\t}\n\n\t\tfor i := 0; i < lv.Len(); i++ {\n\t\t\tvar lvv reflect.Value\n\t\t\tif interfaceSlice != nil {\n\t\t\t\tlvv = reflect.ValueOf(interfaceSlice[i])\n\t\t\t} else {\n\t\t\t\tlvv = lv.Index(i)\n\t\t\t}\n\n\t\t\tswitch lvv.Kind() {\n\t\t\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\t\t\tswitch vv.Kind() {\n\t\t\t\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\t\t\t\tif vv.Int() == lvv.Int() {\n\t\t\t\t\t\treturn true, nil\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase reflect.Float32, reflect.Float64:\n\t\t\t\tswitch vv.Kind() {\n\t\t\t\tcase reflect.Float32, reflect.Float64:\n\t\t\t\t\tif vv.Float() == lvv.Float() {\n\t\t\t\t\t\treturn true, nil\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase reflect.String:\n\t\t\t\tif vv.Type() == lvv.Type() && vv.String() == lvv.String() {\n\t\t\t\t\treturn true, nil\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tcase reflect.String:\n\t\tif vv.Type() == lv.Type() && strings.Contains(lv.String(), vv.String()) {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\n\treturn false, nil\n}", "reference": "// in searches for a given value in a given interface.", "generated": "//\n// In checks whether value is contained within another.\n //\n // This method returns true when the second argument's string or integer values match any part of the first argument's string or integers respectively.\n //\n // The comparison for floats uses floating point equality which may result in incorrect results due to rounding errors. If exact float matching"}
{"id": 1110, "code": "func parseBool(s string) (bool, error) {\n\tif s == \"\" {\n\t\treturn false, nil\n\t}\n\n\tresult, err := strconv.ParseBool(s)\n\tif err != nil {\n\t\treturn false, errors.Wrap(err, \"parseBool\")\n\t}\n\treturn result, nil\n}", "reference": "// parseBool parses a string into a boolean", "generated": "// Parse bool from string.\n//\n// If empty string is passed it returns 0 which means true in boolean context."}
{"id": 1111, "code": "func parseFloat(s string) (float64, error) {\n\tif s == \"\" {\n\t\treturn 0.0, nil\n\t}\n\n\tresult, err := strconv.ParseFloat(s, 10)\n\tif err != nil {\n\t\treturn 0, errors.Wrap(err, \"parseFloat\")\n\t}\n\treturn result, nil\n}", "reference": "// parseFloat parses a string into a base 10 float", "generated": "// Parse float from given string.\n//\n// If parsing fails it returns zero value for number."}
{"id": 1132, "code": "func (c *cache) Delete(k string) {\n\tc.mu.Lock()\n\tv, evicted := c.delete(k)\n\tc.mu.Unlock()\n\tif evicted {\n\t\tc.onEvicted(k, v)\n\t}\n}", "reference": "// Delete an item from the cache. Does nothing if the key is not in the cache.", "generated": "// delete removes key from cache if it exists.\n//\n// If k is found in cache then its value will be removed\n// otherwise no-op operation. The return values for k that exist\n// include the cached value which can be used to update another cache,\n// while non-existent keys have nil returned.  This"}
{"id": 1133, "code": "func (c *cache) DeleteExpired() {\n\tvar evictedItems []keyAndValue\n\tnow := time.Now().UnixNano()\n\tc.mu.Lock()\n\tfor k, v := range c.items {\n\t\t// \"Inlining\" of expired\n\t\tif v.Expiration > 0 && now > v.Expiration {\n\t\t\tov, evicted := c.delete(k)\n\t\t\tif evicted {\n\t\t\t\tevictedItems = append(evictedItems, keyAndValue{k, ov})\n\t\t\t}\n\t\t}\n\t}\n\tc.mu.Unlock()\n\tfor _, v := range evictedItems {\n\t\tc.onEvicted(v.key, v.value)\n\t}\n}", "reference": "// Delete all expired items from the cache.", "generated": "// Remove all items that have already passed their expiration date.\n//\n// This is called when cache expires or if there's been too many hits in one minute,\n// to prevent memory from growing indefinitely. The result will be stored for later use by\n// deleteExpiredWithTimeOut which can clean up any remaining expired"}
{"id": 1137, "code": "func djb33(seed uint32, k string) uint32 {\n\tvar (\n\t\tl = uint32(len(k))\n\t\td = 5381 + seed + l\n\t\ti = uint32(0)\n\t)\n\t// Why is all this 5x faster than a for loop?\n\tif l >= 4 {\n\t\tfor i < l-4 {\n\t\t\td = (d * 33) ^ uint32(k[i])\n\t\t\td = (d * 33) ^ uint32(k[i+1])\n\t\t\td = (d * 33) ^ uint32(k[i+2])\n\t\t\td = (d * 33) ^ uint32(k[i+3])\n\t\t\ti += 4\n\t\t}\n\t}\n\tswitch l - i {\n\tcase 1:\n\tcase 2:\n\t\td = (d * 33) ^ uint32(k[i])\n\tcase 3:\n\t\td = (d * 33) ^ uint32(k[i])\n\t\td = (d * 33) ^ uint32(k[i+1])\n\tcase 4:\n\t\td = (d * 33) ^ uint32(k[i])\n\t\td = (d * 33) ^ uint32(k[i+1])\n\t\td = (d * 33) ^ uint32(k[i+2])\n\t}\n\treturn d ^ (d >> 16)\n}", "reference": "// djb2 with better shuffling. 5x faster than FNV with the hash.Hash overhead.", "generated": "// This hash function was written by Daniel Bernstein in his paper \"Fast\n// Data Structures Using Hash Functions\". It's used to generate keys from strings.\n//\n// The key length must be between 1 and 8 characters long. If it exceeds that,\n// only the first n bytes will be hashed where n <="}
{"id": 1143, "code": "func (m *MockTaskEngine) MarshalJSON() ([]byte, error) {\n\tret := m.ctrl.Call(m, \"MarshalJSON\")\n\tret0, _ := ret[0].([]byte)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// MarshalJSON mocks base method", "generated": "// MockMethod calls mock.Method to simulate method call.\n//\n// This is used for testing purposes only. It should never be called in real code,\n// because it will panic if there's no controller set up yet or if the control group has been destroyed already."}
{"id": 1149, "code": "func (mr *MockImageManagerMockRecorder) AddAllImageStates(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"AddAllImageStates\", reflect.TypeOf((*MockImageManager)(nil).AddAllImageStates), arg0)\n}", "reference": "// AddAllImageStates indicates an expected call of AddAllImageStates", "generated": "// AddAllImageStates returns mock result for method call to ImageManager.AddAllImageStates\n//\n// Args: imageStateList - list of images states that should be added into database.\n //\n// Returns: MockedImageManager object which can be used to verify calls made by this method."}
{"id": 1150, "code": "func (m *MockImageManager) GetImageStateFromImageName(arg0 string) (*image.ImageState, bool) {\n\tret := m.ctrl.Call(m, \"GetImageStateFromImageName\", arg0)\n\tret0, _ := ret[0].(*image.ImageState)\n\tret1, _ := ret[1].(bool)\n\treturn ret0, ret1\n}", "reference": "// GetImageStateFromImageName mocks base method", "generated": "// MockedImageStateFromImageName - mock method for ImageStateFromImageName\n//\n// Args:\n//   name: image name to get state from\n//\n// Returns:\n//   return value if successful or nil otherwise\n //\n// Note that this is just a mocking tool so it doesn't actually do anything."}
{"id": 1181, "code": "func (mr *MockContainerMetadataResolverMockRecorder) ResolveContainer(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"ResolveContainer\", reflect.TypeOf((*MockContainerMetadataResolver)(nil).ResolveContainer), arg0)\n}", "reference": "// ResolveContainer indicates an expected call of ResolveContainer", "generated": "// RecordCallWithMethodType records that the given method call was made to this mock's controller\n//\n// Args:   args - The arguments passed into the method being recorded.\n//         returnTypes - The type returned from the method being recorded.\n //\n// Returns: A gomock.Call object representing the record call"}
{"id": 1183, "code": "func NewTaskResponse(taskARN string,\n\tstate dockerstate.TaskEngineState,\n\tecsClient api.ECSClient,\n\tcluster string,\n\taz string,\n\tcontainerInstanceArn string,\n\tpropagateTags bool) (*TaskResponse, error) {\n\ttask, ok := state.TaskByArn(taskARN)\n\tif !ok {\n\t\treturn nil, errors.Errorf(\"v2 task response: unable to find task '%s'\", taskARN)\n\t}\n\n\tresp := &TaskResponse{\n\t\tCluster:          cluster,\n\t\tTaskARN:          task.Arn,\n\t\tFamily:           task.Family,\n\t\tRevision:         task.Version,\n\t\tDesiredStatus:    task.GetDesiredStatus().String(),\n\t\tKnownStatus:      task.GetKnownStatus().String(),\n\t\tAvailabilityZone: az,\n\t}\n\n\ttaskCPU := task.CPU\n\ttaskMemory := task.Memory\n\tif taskCPU != 0 || taskMemory != 0 {\n\t\ttaskLimits := &LimitsResponse{}\n\t\tif taskCPU != 0 {\n\t\t\ttaskLimits.CPU = &taskCPU\n\t\t}\n\t\tif taskMemory != 0 {\n\t\t\ttaskLimits.Memory = &taskMemory\n\t\t}\n\t\tresp.Limits = taskLimits\n\t}\n\n\tif timestamp := task.GetPullStartedAt(); !timestamp.IsZero() {\n\t\tresp.PullStartedAt = aws.Time(timestamp.UTC())\n\t}\n\tif timestamp := task.GetPullStoppedAt(); !timestamp.IsZero() {\n\t\tresp.PullStoppedAt = aws.Time(timestamp.UTC())\n\t}\n\tif timestamp := task.GetExecutionStoppedAt(); !timestamp.IsZero() {\n\t\tresp.ExecutionStoppedAt = aws.Time(timestamp.UTC())\n\t}\n\tcontainerNameToDockerContainer, ok := state.ContainerMapByArn(task.Arn)\n\tif !ok {\n\t\tseelog.Warnf(\"V2 task response: unable to get container name mapping for task '%s'\",\n\t\t\ttask.Arn)\n\t\treturn resp, nil\n\t}\n\n\teni := task.GetTaskENI()\n\tfor _, dockerContainer := range containerNameToDockerContainer {\n\t\tcontainerResponse := newContainerResponse(dockerContainer, eni, state)\n\t\tresp.Containers = append(resp.Containers, containerResponse)\n\t}\n\n\tif propagateTags {\n\t\tpropagateTagsToMetadata(state, ecsClient, containerInstanceArn, taskARN, resp)\n\t}\n\n\treturn resp, nil\n}", "reference": "// NewTaskResponse creates a new response object for the task", "generated": "// Create Task Response from v2 task data.\n//\n// This method creates a TaskResponse object based off the provided v2 task data.\n// It also adds any necessary metadata such as limits or pull status information if available."}
{"id": 1195, "code": "func (m *MockTime) After(arg0 time.Duration) <-chan time.Time {\n\tret := m.ctrl.Call(m, \"After\", arg0)\n\tret0, _ := ret[0].(<-chan time.Time)\n\treturn ret0\n}", "reference": "// After mocks base method", "generated": "// After returns a channel that will be sent when this mock's timer fires after the specified amount of seconds.\n//\n// This method must only be called once; calling it more than once is illegal."}
{"id": 1200, "code": "func (mr *MockTimeMockRecorder) Sleep(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Sleep\", reflect.TypeOf((*MockTime)(nil).Sleep), arg0)\n}", "reference": "// Sleep indicates an expected call of Sleep", "generated": "// Sleep returns mock call for method Sleep\n//\n// Args: int64 - time to sleep in seconds"}
{"id": 1205, "code": "func (mr *MockTimerMockRecorder) Stop() *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Stop\", reflect.TypeOf((*MockTimer)(nil).Stop))\n}", "reference": "// Stop indicates an expected call of Stop", "generated": "// Stop returns call to Mock Timer's stop method\n//\n// Args: None\n //\n // Returns: gomock.Call - Call that was recorded by mock controller"}
{"id": 1216, "code": "func (imageState *ImageState) AddImageName(imageName string) {\n\timageState.lock.Lock()\n\tdefer imageState.lock.Unlock()\n\tif !imageState.HasImageName(imageName) {\n\t\tseelog.Infof(\"Adding image name- %v to Image state- %v\", imageName, imageState.Image.ImageID)\n\t\timageState.Image.Names = append(imageState.Image.Names, imageName)\n\t}\n}", "reference": "// AddImageName adds image name to image state", "generated": "// Adds new image names into existing images in this instance's states\n//\n// This method is used when adding multiple instances at once or after initial setup.\n //\n// If there already exists such image then it will be updated instead of creating one more time."}
{"id": 1254, "code": "func copyMetricsMetadata(metadata *ecstcs.MetricsMetadata, fin bool) *ecstcs.MetricsMetadata {\n\treturn &ecstcs.MetricsMetadata{\n\t\tCluster:           aws.String(*metadata.Cluster),\n\t\tContainerInstance: aws.String(*metadata.ContainerInstance),\n\t\tIdle:              aws.Bool(*metadata.Idle),\n\t\tMessageId:         aws.String(*metadata.MessageId),\n\t\tFin:               aws.Bool(fin),\n\t}\n}", "reference": "// copyMetricsMetadata creates a new MetricsMetadata object from a given MetricsMetadata object.\n// It copies all the fields from the source object to the new object and sets the 'Fin' field\n// as specified by the argument.", "generated": "// Copy metrics metadata to create new instance.\n//\n// This method creates a deep copy of the input metric metadata object,\n// which is then used for creating a new ecstcs MetricsMetadata\n// resource in AWS CloudWatch. The copied value will be set based on\n// whether or not it was provided by the"}
{"id": 1285, "code": "func (cgroup *CgroupResource) Create() error {\n\terr := cgroup.setupTaskCgroup()\n\tif err != nil {\n\t\tseelog.Criticalf(\"Cgroup resource [%s]: unable to setup cgroup root: %v\", cgroup.taskARN, err)\n\t\treturn err\n\t}\n\treturn nil\n}", "reference": "// Create creates cgroup root for the task", "generated": "// Creates a new CGroup for this task if it doesn't exist already.\n//\n// This method is called when creating or updating a Task instance that has no existing\n// Cgroups associated with it.  If there's another process using the same name,\n// then we'll return an error indicating why the creation failed"}
{"id": 1293, "code": "func NewECRFactory(acceptInsecureCert bool) ECRFactory {\n\treturn &ecrFactory{\n\t\thttpClient: httpclient.New(roundtripTimeout, acceptInsecureCert),\n\t}\n}", "reference": "// NewECRFactory returns an ECRFactory capable of producing ECRSDK clients", "generated": "// Create new instance for using Amazon Elastic Container Registry (ECR). This\n// factory is used to create instances that can be passed into other functions.\n//\n// The default value for accepting insecure certificates from ECR will always return true,\n// which means it won't check if they're valid or trusted by any certificate"}
{"id": 1313, "code": "func (err CannotStopContainerError) IsRetriableError() bool {\n\tif _, ok := err.FromError.(NoSuchContainerError); ok {\n\t\treturn false\n\t}\n\n\treturn true\n}", "reference": "// IsRetriableError returns a boolean indicating whether the call that\n// generated the error can be retried.\n// When stopping a container, most errors that we can get should be\n// considered retriable. However, in the case where the container is\n// already stopped or doesn't exist at all, there's no sense in\n// retrying.", "generated": "// Returns whether this error is retrievable or if it's due to some other reason that can't be recovered from.\n//\n// This method should return always true for errors which have been caused by user actions,\n// but may need to check against specific types in order to handle certain cases correctly."}
{"id": 1327, "code": "func (m *MockEC2MetadataClient) DefaultCredentials() (*ec2.RoleCredentials, error) {\n\tret := m.ctrl.Call(m, \"DefaultCredentials\")\n\tret0, _ := ret[0].(*ec2.RoleCredentials)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// DefaultCredentials mocks base method", "generated": "// Mock default credentials for testing purposes.\n//\n// This method is called when ec2.Default Credentials need to be retrieved from\n// environment variables or other sources before they can be used by any EC2 client.  It returns nil if no role exists,\n// otherwise it will return the Role object that was created in Set"}
{"id": 1340, "code": "func (mr *MockClientSDKMockRecorder) DescribeTags(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"DescribeTags\", reflect.TypeOf((*MockClientSDK)(nil).DescribeTags), arg0)\n}", "reference": "// DescribeTags indicates an expected call of DescribeTags", "generated": "// Describe Tags is called when client SDK calls describe tags method\n//\n// Args: tagKey - key to filter by; if nil then all tags will be returned.\n //\n// Returns: list of tags that match the given keys or null for no matching tags."}
{"id": 1352, "code": "func (agent *ecsAgent) setClusterInConfig(previousCluster string) error {\n\t// TODO Handle default cluster in a sane and unified way across the codebase\n\tconfiguredCluster := agent.cfg.Cluster\n\tif configuredCluster == \"\" {\n\t\tseelog.Debug(\"Setting cluster to default; none configured\")\n\t\tconfiguredCluster = config.DefaultClusterName\n\t}\n\tif previousCluster != configuredCluster {\n\t\terr := clusterMismatchError{\n\t\t\tfmt.Errorf(clusterMismatchErrorFormat, previousCluster, configuredCluster),\n\t\t}\n\t\tseelog.Criticalf(\"%v\", err)\n\t\treturn err\n\t}\n\tagent.cfg.Cluster = previousCluster\n\tseelog.Infof(\"Restored cluster '%s'\", agent.cfg.Cluster)\n\n\treturn nil\n}", "reference": "// setClusterInConfig sets the cluster name in the config object based on\n// previous state. It returns an error if there's a mismatch between the\n// the current cluster name with what's restored from the cluster state", "generated": "//\n// Set Cluster from configuration if it is different than current one.\n //\n// This method should be called when there's been some change that requires us to use\n// another cluster for our application. For example,\n// - When we're running inside Docker container where host cluster doesn't exist or isn't available.\n//"}
{"id": 1377, "code": "func handleInvalidParamException(err error, events *list.List, eventToSubmit *list.Element) {\n\tif utils.IsAWSErrorCodeEqual(err, ecs.ErrCodeInvalidParameterException) {\n\t\tevent := eventToSubmit.Value.(*sendableEvent)\n\t\tseelog.Warnf(\"TaskHandler: Event is sent with invalid parameters; just removing: %s\", event.toString())\n\t\tevents.Remove(eventToSubmit)\n\t}\n}", "reference": "// handleInvalidParamException removes the event from event queue when its parameters are\n// invalid to reduce redundant API call", "generated": "// Handle Invalid Parameter Exception by logging it to seelog if\n// there's any valid parameter in this request otherwise ignore.\n//\n// This method should be called from Task Handler when task receives\n// exception that indicates some incorrect or missing values were passed into its constructor."}
{"id": 1402, "code": "func NewJitteredTicker(ctx context.Context, start, end time.Duration) <-chan time.Time {\n\tticker := make(chan time.Time, 1)\n\n\tgo func() {\n\t\tdefer close(ticker)\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tdefault:\n\t\t\t\ttime.Sleep(randomDuration(start, end))\n\t\t\t\tsendNow(ticker)\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn ticker\n}", "reference": "// NewJitteredTicker works like a time.Ticker except with randomly distributed ticks\n// between start and end duration.", "generated": "// JitteredTickers returns a channel that sends every random duration between start and end.\n//\n// The jitter is chosen randomly from [0, max), where max = min(end-start,\n// int(100*start)). This means there's always some chance to get closer than this\n// minimum interval if we"}
{"id": 1411, "code": "func (m *MockECSClient) GetResourceTags(arg0 string) ([]*ecs.Tag, error) {\n\tret := m.ctrl.Call(m, \"GetResourceTags\", arg0)\n\tret0, _ := ret[0].([]*ecs.Tag)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// GetResourceTags mocks base method", "generated": "// MockMethod calls mock.ECSClient.GetResourceTag to simulate the method call.\n//\n// Args: None - argument is passed in by caller's args array\n //\n// Returns: []ecstags.EcsTag, Error - return values from ECSClients get_resource_tags method.  The first value returned"}
{"id": 1417, "code": "func (m *MockSaveableOption) AddSaveable(arg0 string, arg1 statemanager.Saveable) statemanager.Option {\n\tret := m.ctrl.Call(m, \"AddSaveable\", arg0, arg1)\n\tret0, _ := ret[0].(statemanager.Option)\n\treturn ret0\n}", "reference": "// AddSaveable mocks base method", "generated": "// AddSaveable is the mock for method Saveable.AddSaveable.\n//\n// Args:\n//   arg0: The argument passed to this method call.\n//   arg1: The return value from this method call.\n //\n // Returns:\n //   Return value returned by this method call."}
{"id": 1440, "code": "func (state *DockerTaskEngineState) TaskByArn(arn string) (*apitask.Task, bool) {\n\tstate.lock.RLock()\n\tdefer state.lock.RUnlock()\n\n\treturn state.taskByArn(arn)\n}", "reference": "// TaskByArn returns a task for a given ARN", "generated": "// Returns task by ARN if exists in Docker engine's internal store\n//\n// Note: This method is intended to be used only for testing purposes.\n //\n// If this method returns nil it means that there was no such task found or\n// some other error occurred while trying to retrieve task from storage. In any"}
{"id": 1448, "code": "func (state *DockerTaskEngineState) AddTaskIPAddress(addr string, taskARN string) {\n\tstate.lock.Lock()\n\tdefer state.lock.Unlock()\n\n\tstate.ipToTask[addr] = taskARN\n}", "reference": "// AddTaskIPAddress adds ip adddress for a task arn into the state", "generated": "// Adds IP address to Docker Task Engine State for use in tasks.\n//\n// This method is used by Docker Tasks when they need access to their own\n// container's network interface. The returned value will be valid until the\n// task completes or it goes into error status."}
{"id": 1457, "code": "func (c *Container) GetKnownStatus() apicontainerstatus.ContainerStatus {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.KnownStatusUnsafe\n}", "reference": "// GetKnownStatus returns the known status of the container", "generated": "// Returns known status for this container.\n//\n// This method is used to get the current state of the container from the host,\n// which can be different than its actual running state due to various reasons such\n// like network isolation or other system level issues. The returned value will always\n// reflect the last time it"}
{"id": 1458, "code": "func (c *Container) SetKnownStatus(status apicontainerstatus.ContainerStatus) {\n\tc.lock.Lock()\n\tdefer c.lock.Unlock()\n\n\tc.KnownStatusUnsafe = status\n\tc.updateAppliedStatusUnsafe(status)\n}", "reference": "// SetKnownStatus sets the known status of the container and update the container\n// applied status", "generated": "// Sets known container status for this instance.\n//\n// This method is used internally by the API server to set the initial state when creating or updating containers,\n// but it can also be called directly from client code if needed. Note that calling this method after setting the\n// applied status will result in unexpected results because they"}
{"id": 1466, "code": "func (c *Container) ShouldPullWithExecutionRole() bool {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.RegistryAuthentication != nil &&\n\t\tc.RegistryAuthentication.Type == AuthTypeECR &&\n\t\tc.RegistryAuthentication.ECRAuthData != nil &&\n\t\tc.RegistryAuthentication.ECRAuthData.UseExecutionRole\n}", "reference": "// ShouldPullWithExecutionRole returns whether this container has its own ECR credentials", "generated": "// Returns true if this container should pull using ECR's execution role.\n//\n// This is used to determine whether or not we need to use the default\n// authentication method for pulling from Amazon ECR when it has been configured\n// in the Docker configuration file.  If there isn't any config set up,"}
{"id": 1497, "code": "func (c *Container) GetV3EndpointID() string {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.V3EndpointID\n}", "reference": "// GetV3EndpointID returns the v3 endpoint id of container", "generated": "// Return V3 endpoint ID if set in container config or return empty string otherwise.\n//\n// This method is used to get current v2/v3 endpoint id from container configuration,\n// which can be changed by user when running containers using Docker command-line tool.\n //\n// Note: this value will only change after restart of"}
{"id": 1507, "code": "func (secret *ASMSecretResource) retrieveASMSecretValue(apiSecret apicontainer.Secret, iamCredentials credentials.IAMRoleCredentials, wg *sync.WaitGroup, errorEvents chan error) {\n\tdefer wg.Done()\n\n\tasmClient := secret.asmClientCreator.NewASMClient(apiSecret.Region, iamCredentials)\n\tseelog.Infof(\"ASM secret resource: retrieving resource for secret %v in region %s for task: [%s]\", apiSecret.ValueFrom, apiSecret.Region, secret.taskARN)\n\t//for asm secret, ValueFrom can be arn or name\n\tsecretValue, err := asm.GetSecretFromASM(apiSecret.ValueFrom, asmClient)\n\tif err != nil {\n\t\terrorEvents <- fmt.Errorf(\"fetching secret data from AWS Secrets Manager in region %s: %v\", apiSecret.Region, err)\n\t\treturn\n\t}\n\n\tsecret.lock.Lock()\n\tdefer secret.lock.Unlock()\n\n\t// put secret value in secretData\n\tsecretKey := apiSecret.GetSecretResourceCacheKey()\n\tsecret.secretData[secretKey] = secretValue\n}", "reference": "// retrieveASMSecretValue reads secret value from cache first, if not exists, call GetSecretFromASM to retrieve value\n// AWS secrets Manager", "generated": "//\n// Retrieve ASM Secret values.\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //"}
{"id": 1516, "code": "func handleInactivityTimeout(reader io.ReadCloser, timeout time.Duration, cancelRequest func(), canceled *uint32) (io.ReadCloser, chan<- struct{}) {\n\tdone := make(chan struct{})\n\tproxyReader := &proxyReader{ReadCloser: reader}\n\tgo func() {\n\t\tvar lastCallCount uint64\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-time.After(timeout):\n\t\t\tcase <-done:\n\t\t\t\treturn\n\t\t\t}\n\t\t\tcurCallCount := proxyReader.callCount()\n\t\t\tif curCallCount == lastCallCount {\n\t\t\t\tatomic.AddUint32(canceled, 1)\n\t\t\t\tcancelRequest()\n\t\t\t\treturn\n\t\t\t}\n\t\t\tlastCallCount = curCallCount\n\t\t}\n\t}()\n\treturn proxyReader, done\n}", "reference": "// When pulling an image, the docker api will pull and then subsequently unzip the downloaded artifacts. Docker does\n// not separate the \"pull\" from the \"unpack\" step. What this means is that this timeout doesn't 'tick' while unpacking\n// the downloaded files. This only causes noticeable impact with large files, but we should investigate improving this.", "generated": "// Handle inactivity timeouts for requests to proxies that support it.\n//\n// This will return when either the request times out or if there is no more\n// activity from the client after the specified amount of time has passed since\n// the previous call. The caller should use this channel to signal cancellation,\n// which can"}
{"id": 1519, "code": "func (imageManager *dockerImageManager) RemoveContainerReferenceFromImageState(container *apicontainer.Container) error {\n\t// the image state has been updated, save the new state\n\tdefer imageManager.saver.ForceSave()\n\t// this lock is for reading image states and finding the one that the container belongs to\n\timageManager.updateLock.RLock()\n\tdefer imageManager.updateLock.RUnlock()\n\tif container.ImageID == \"\" {\n\t\treturn fmt.Errorf(\"Invalid container reference: Empty image id\")\n\t}\n\n\t// Find image state that this container is part of, and remove the reference\n\timageState, ok := imageManager.getImageState(container.ImageID)\n\tif !ok {\n\t\treturn fmt.Errorf(\"Cannot find image state for the container to be removed\")\n\t}\n\t// Found matching ImageState\n\treturn imageState.RemoveContainerReference(container)\n}", "reference": "// RemoveContainerReferenceFromImageState removes container reference from the corresponding imageState object", "generated": "//\n// Removes the given Container from its corresponding ImageState.\n //\n // This method should only be called when there's no other way to access the image,\n // i.e., it can't happen in normal operation because we always try to keep images up-to-date by saving them after every update or removal. However, if"}
{"id": 1540, "code": "func (td *TransitionDependenciesMap) UnmarshalJSON(b []byte) error {\n\tdepMap := make(map[apicontainerstatus.ContainerStatus]TransitionDependencySet)\n\terr := json.Unmarshal(b, &depMap)\n\tif err == nil {\n\t\t*td = depMap\n\t\treturn nil\n\t}\n\tseelog.Debugf(\"Unmarshal 'TransitionDependencySet': %s, not a map: %v\", string(b), err)\n\t// Unmarshal to deprecated 'TransitionDependencySet' and then convert to a map\n\ttdSet := TransitionDependencySet{}\n\tif err := json.Unmarshal(b, &tdSet); err != nil {\n\t\treturn errors.Wrapf(err,\n\t\t\t\"Unmarshal 'TransitionDependencySet': does not comply with any of the dependency types\")\n\t}\n\tfor _, dep := range tdSet.ContainerDependencies {\n\t\tdependentStatus := dep.DependentStatus\n\t\t// no need for DependentStatus field anymore, since it becomes the map's key\n\t\tdep.DependentStatus = 0\n\t\tif _, ok := depMap[dependentStatus]; !ok {\n\t\t\tdepMap[dependentStatus] = TransitionDependencySet{}\n\t\t}\n\t\tdeps := depMap[dependentStatus]\n\t\tdeps.ContainerDependencies = append(deps.ContainerDependencies, dep)\n\t\tdepMap[dependentStatus] = deps\n\t}\n\t*td = depMap\n\treturn nil\n}", "reference": "// UnmarshalJSON decodes the TransitionDependencySet tag in the JSON encoded string\n// into the TransitionDependenciesMap object", "generated": "//\n// Unmarshals JSON data into transition dependencies.\n //\n // This is used when unserializing from a serialized version that was created by\n // MarshalJson(). The serialization format has changed over time so this method must be called in both directions.\n // Note that if there were multiple transitions dependent upon one container status,"}
{"id": 1543, "code": "func NewMockCgroup(ctrl *gomock.Controller) *MockCgroup {\n\tmock := &MockCgroup{ctrl: ctrl}\n\tmock.recorder = &MockCgroupMockRecorder{mock}\n\treturn mock\n}", "reference": "// NewMockCgroup creates a new mock instance", "generated": "// MockNew returns a new instance of CgroupsController that can be used for testing.\n//\n// This method is intended to be called from test code only. It should never be\n// called in production code. The returned controller will automatically shut down when it's done,\n// so there's no need to call Close"}
{"id": 1579, "code": "func (m *MockSecretsManagerAPI) DeleteResourcePolicyWithContext(arg0 aws.Context, arg1 *secretsmanager.DeleteResourcePolicyInput, arg2 ...request.Option) (*secretsmanager.DeleteResourcePolicyOutput, error) {\n\tvarargs := []interface{}{arg0, arg1}\n\tfor _, a := range arg2 {\n\t\tvarargs = append(varargs, a)\n\t}\n\tret := m.ctrl.Call(m, \"DeleteResourcePolicyWithContext\", varargs...)\n\tret0, _ := ret[0].(*secretsmanager.DeleteResourcePolicyOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// DeleteResourcePolicyWithContext mocks base method", "generated": "// DeleteResourcePolicyWithContext is used to delete resource policy from AWS Secrets Manager.\n//\n// Args:\n//   context - Context for this operation.\n//   input - Input parameters for DeleteResourcePolicy command.\n //\n// Returns: Output values returned by DeleteResourcePolicy command. Error code if there was any issue during execution."}
{"id": 1595, "code": "func (m *MockSecretsManagerAPI) ListSecretVersionIds(arg0 *secretsmanager.ListSecretVersionIdsInput) (*secretsmanager.ListSecretVersionIdsOutput, error) {\n\tret := m.ctrl.Call(m, \"ListSecretVersionIds\", arg0)\n\tret0, _ := ret[0].(*secretsmanager.ListSecretVersionIdsOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// ListSecretVersionIds mocks base method", "generated": "// MockMethod calls mock method named 'ListSecretVersionIds' which is defined inMocks for Secrets Manager API client. The first argument passed to this method should be input parameter, second one - output value.\n//\n// Args:\n//     arg0: Input parameters for Method call. In case of list secret version ids"}
{"id": 1612, "code": "func (m *MockSecretsManagerAPI) RotateSecret(arg0 *secretsmanager.RotateSecretInput) (*secretsmanager.RotateSecretOutput, error) {\n\tret := m.ctrl.Call(m, \"RotateSecret\", arg0)\n\tret0, _ := ret[0].(*secretsmanager.RotateSecretOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// RotateSecret mocks base method", "generated": "// MockMethod calls mock method named 'RotateSecret' which is passed to controller's constructor.\n//\n// Args: input - secret manager rotate secrets request object\n //\n // Returns: output - result of rotation operation or nil if it was failed; errors - any error that occurred during execution of this call"}
{"id": 1616, "code": "func (m *MockSecretsManagerAPI) TagResourceRequest(arg0 *secretsmanager.TagResourceInput) (*request.Request, *secretsmanager.TagResourceOutput) {\n\tret := m.ctrl.Call(m, \"TagResourceRequest\", arg0)\n\tret0, _ := ret[0].(*request.Request)\n\tret1, _ := ret[1].(*secretsmanager.TagResourceOutput)\n\treturn ret0, ret1\n}", "reference": "// TagResourceRequest mocks base method", "generated": "// MockMethod calls mock.Method to simulate method call.\n//\n// This is used for testing purposes only. It should never be called in real code,\n// because it will panic if there's no controller set up yet or if this isn't being\n// tested from within a test case.  If you need to use"}
{"id": 1628, "code": "func (manager *metadataManager) parseMetadataAtContainerCreate(task *apitask.Task, containerName string) Metadata {\n\treturn Metadata{\n\t\tcluster: manager.cluster,\n\t\ttaskMetadata: TaskMetadata{\n\t\t\tcontainerName:          containerName,\n\t\t\ttaskARN:                task.Arn,\n\t\t\ttaskDefinitionFamily:   task.Family,\n\t\t\ttaskDefinitionRevision: task.Version,\n\t\t},\n\t\tcontainerInstanceARN:  manager.containerInstanceARN,\n\t\tmetadataStatus:        MetadataInitial,\n\t\tavailabilityZone:      manager.availabilityZone,\n\t\thostPublicIPv4Address: manager.hostPublicIPv4Address,\n\t}\n}", "reference": "// parseMetadataAtContainerCreate gathers metadata from task and cluster configurations\n// then packages it for JSON Marshaling. We use this version to get data\n// available prior to container creation\n// Since we accept incomplete metadata fields, we should not return\n// errors here and handle them at this or the above stage.", "generated": "// Parse metadata at container create time for use in tasks created by\n// ContainerService. This is used to store information about each container's\n// creation when it starts running.\n//\n// Note that this method should be called only once per container instance; if\n// multiple containers start within the same container instance, they"}
{"id": 1649, "code": "func (m *MockTaskResource) Cleanup() error {\n\tret := m.ctrl.Call(m, \"Cleanup\")\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// Cleanup mocks base method", "generated": "// Mock cleanup method for testing purposes only.\n//\n// This is used to mock out the task resource's cleaning up process,\n// which can be useful when writing unit tests that need to test this\n// specific functionality in isolation from other factors such as network or disk I/O."}
{"id": 1669, "code": "func (f *factory) GetClient(version dockerclient.DockerVersion) (sdkclient.Client, error) {\n\tfor _, v := range getWindowsReplaceableVersions() {\n\t\tif v == version {\n\t\t\tversion = minDockerAPIVersion\n\t\t\tbreak\n\t\t}\n\t}\n\treturn f.getClient(version)\n}", "reference": "// GetClient will replace some versions of Docker on Windows. We need this because\n// agent assumes that it can always call older versions of the docker API.", "generated": "// GetClient returns client for given Docker API Version.\n//\n// If no matching version is found it will return default one which can be used to connect to any supported Docker server."}
{"id": 1739, "code": "func (task *Task) GetExecutionCredentialsID() string {\n\ttask.lock.RLock()\n\tdefer task.lock.RUnlock()\n\n\treturn task.ExecutionCredentialsID\n}", "reference": "// GetExecutionCredentialsID gets the credentials ID for the task", "generated": "// Returns execution credentials ID for this Task instance.\n//\n// This method is intended to be used by tasks that need access to their own execution\n// credentials in order to execute some operation. The default value returned will always\n// match the current Execution Credentials ID set for this task's owner user account,\n// which can"}
{"id": 1757, "code": "func (task *Task) RecordExecutionStoppedAt(container *apicontainer.Container) {\n\tif !container.Essential {\n\t\treturn\n\t}\n\tif container.GetKnownStatus() != apicontainerstatus.ContainerStopped {\n\t\treturn\n\t}\n\t// If the essential container is stopped, set the ExecutionStoppedAt timestamp\n\tnow := time.Now()\n\tok := task.SetExecutionStoppedAt(now)\n\tif !ok {\n\t\t// ExecutionStoppedAt was already recorded. Nothing to left to do here\n\t\treturn\n\t}\n\tseelog.Infof(\"Task [%s]: recording execution stopped time. Essential container [%s] stopped at: %s\",\n\t\ttask.Arn, container.Name, now.String())\n}", "reference": "// RecordExecutionStoppedAt checks if this is an essential container stopped\n// and set the task executionStoppedAt timestamps", "generated": "// RecordExecutionStoppedAt records when this task's execution has been stopped.\n//\n// This method will only be called if the container that started this task is non-essential,\n// because we don't want to record any timestamps for tasks whose executions have never actually run."}
{"id": 1767, "code": "func (task *Task) getPIDMode() string {\n\ttask.lock.RLock()\n\tdefer task.lock.RUnlock()\n\n\treturn task.PIDMode\n}", "reference": "// Retrieves a Task's PIDMode", "generated": "// Get PID mode for this Task instance.\n//\n// This method is safe to call from multiple goroutines at once,\n// but it will block if another thread has already locked the lock."}
{"id": 1793, "code": "func (healthStatus *ContainerHealthStatus) UnmarshalJSON(b []byte) error {\n\t*healthStatus = ContainerHealthUnknown\n\n\tif strings.ToLower(string(b)) == \"null\" {\n\t\treturn nil\n\t}\n\tif b[0] != '\"' || b[len(b)-1] != '\"' {\n\t\treturn errors.New(\"container health status unmarshal: status must be a string or null; Got \" + string(b))\n\t}\n\n\tstrStatus := string(b[1 : len(b)-1])\n\tswitch strStatus {\n\tcase \"UNKNOWN\":\n\t// The health status is already set to ContainerHealthUnknown initially\n\tcase \"HEALTHY\":\n\t\t*healthStatus = ContainerHealthy\n\tcase \"UNHEALTHY\":\n\t\t*healthStatus = ContainerUnhealthy\n\tdefault:\n\t\treturn errors.New(\"container health status unmarshal: unrecognized status: \" + string(b))\n\t}\n\treturn nil\n}", "reference": "// UnmarshalJSON overrides the logic for parsing the JSON-encoded container health data", "generated": "//\n// Unmarshals container health status from JSON.\n //\n // This method will return an error if it cannot parse the value into one of the valid values for this field,\n // which can happen when the input contains invalid data that was generated by another system's marshaling code."}
{"id": 1797, "code": "func (m *MockDockerClient) APIVersion() (dockerclient.DockerVersion, error) {\n\tret := m.ctrl.Call(m, \"APIVersion\")\n\tret0, _ := ret[0].(dockerclient.DockerVersion)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// APIVersion mocks base method", "generated": "// MockApiVersion mocks base method: DockerClient.APIVersion.\n//\n// Returns mock result for given call parameters. If you want to use real method,\n// remove this mocking call."}
{"id": 1807, "code": "func (m *MockDockerClient) ListContainers(arg0 context.Context, arg1 bool, arg2 time.Duration) dockerapi.ListContainersResponse {\n\tret := m.ctrl.Call(m, \"ListContainers\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(dockerapi.ListContainersResponse)\n\treturn ret0\n}", "reference": "// ListContainers mocks base method", "generated": "// MockMethod calls mock.DockerClient.Method to simulate method call.\n//\n// Args: name - Method name; args... - arguments passed in method call;\n//       return value - returned from method call.\n //\n// Returns: result of method call or error if failed."}
{"id": 1823, "code": "func (mtask *managedTask) waitForHostResources() {\n\tif mtask.StartSequenceNumber == 0 {\n\t\t// This is the first transition on this host. No need to wait\n\t\treturn\n\t}\n\tif mtask.GetDesiredStatus().Terminal() {\n\t\t// Task's desired status is STOPPED. No need to wait in this case either\n\t\treturn\n\t}\n\n\tseelog.Infof(\"Managed task [%s]: waiting for any previous stops to complete. Sequence number: %d\",\n\t\tmtask.Arn, mtask.StartSequenceNumber)\n\n\tothersStoppedCtx, cancel := context.WithCancel(mtask.ctx)\n\tdefer cancel()\n\n\tgo func() {\n\t\tmtask.taskStopWG.Wait(mtask.StartSequenceNumber)\n\t\tcancel()\n\t}()\n\n\tfor !mtask.waitEvent(othersStoppedCtx.Done()) {\n\t\tif mtask.GetDesiredStatus().Terminal() {\n\t\t\t// If we end up here, that means we received a start then stop for this\n\t\t\t// task before a task that was expected to stop before it could\n\t\t\t// actually stop\n\t\t\tbreak\n\t\t}\n\t}\n\tseelog.Infof(\"Managed task [%s]: wait over; ready to move towards status: %s\",\n\t\tmtask.Arn, mtask.GetDesiredStatus().String())\n}", "reference": "// waitForHostResources waits for host resources to become available to start\n// the task. This involves waiting for previous stops to complete so the\n// resources become free.", "generated": "// waits until all other tasks have stopped or if there were no others.\n//\n// Returns true when another event occurred which requires us to continue,\n// false otherwise. The return value will be used by the caller to decide whether\n// they should proceed further based on their own logic."}
{"id": 1857, "code": "func (m *MockWebsocketConn) ReadMessage() (int, []byte, error) {\n\tret := m.ctrl.Call(m, \"ReadMessage\")\n\tret0, _ := ret[0].(int)\n\tret1, _ := ret[1].([]byte)\n\tret2, _ := ret[2].(error)\n\treturn ret0, ret1, ret2\n}", "reference": "// ReadMessage mocks base method", "generated": "// Mock read message method call for testing purposes only.\n//\n// This is used to mock out the reading from the websocket connection in order\n// to test its functionality without actually connecting to it.  The return values\n// will be set by calling this method before making any calls that require it."}
{"id": 1890, "code": "func (engine *DockerTaskEngine) isTaskManaged(arn string) bool {\n\tengine.tasksLock.RLock()\n\tdefer engine.tasksLock.RUnlock()\n\t_, ok := engine.managedTasks[arn]\n\treturn ok\n}", "reference": "// isTaskManaged checks if task for the corresponding arn is present", "generated": "// Returns true if task was created by Docker Task Engine or managed tasks.\n//\n// This method should be used only for internal use within Docker Task Engine,\n// since it can lead to incorrect results in case when there's multiple instances\n// running at same time."}
{"id": 1896, "code": "func (engine *DockerTaskEngine) sweepTask(task *apitask.Task) {\n\tfor _, cont := range task.Containers {\n\t\terr := engine.removeContainer(task, cont)\n\t\tif err != nil {\n\t\t\tseelog.Debugf(\"Task engine [%s]: unable to remove old container [%s]: %v\",\n\t\t\t\ttask.Arn, cont.Name, err)\n\t\t}\n\t\t// Internal container(created by ecs-agent) state isn't recorded\n\t\tif cont.IsInternal() {\n\t\t\tcontinue\n\t\t}\n\t\terr = engine.imageManager.RemoveContainerReferenceFromImageState(cont)\n\t\tif err != nil {\n\t\t\tseelog.Errorf(\"Task engine [%s]: Unable to remove container [%s] reference from image state: %v\",\n\t\t\t\ttask.Arn, cont.Name, err)\n\t\t}\n\t}\n\n\t// Clean metadata directory for task\n\tif engine.cfg.ContainerMetadataEnabled {\n\t\terr := engine.metadataManager.Clean(task.Arn)\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Task engine [%s]: clean task metadata failed: %v\", task.Arn, err)\n\t\t}\n\t}\n\tengine.saver.Save()\n}", "reference": "// sweepTask deletes all the containers associated with a task", "generated": "// Sweep Task - Remove all containers that have been removed or completed.\n//\n// This method is called when there's no more tasks running in this cluster,\n// it removes any remaining containers which were created but never started."}
{"id": 1906, "code": "func (engine *DockerTaskEngine) updateTaskUnsafe(task *apitask.Task, update *apitask.Task) {\n\tmanagedTask, ok := engine.managedTasks[task.Arn]\n\tif !ok {\n\t\tseelog.Criticalf(\"Task engine [%s]: ACS message for a task we thought we managed, but don't!  Aborting.\",\n\t\t\ttask.Arn)\n\t\treturn\n\t}\n\t// Keep the lock because sequence numbers cannot be correct unless they are\n\t// also read in the order addtask was called\n\t// This does block the engine's ability to ingest any new events (including\n\t// stops for past tasks, ack!), but this is necessary for correctness\n\tupdateDesiredStatus := update.GetDesiredStatus()\n\tseelog.Debugf(\"Task engine [%s]: putting update on the acs channel: [%s] with seqnum [%d]\",\n\t\ttask.Arn, updateDesiredStatus.String(), update.StopSequenceNumber)\n\tmanagedTask.emitACSTransition(acsTransition{\n\t\tdesiredStatus: updateDesiredStatus,\n\t\tseqnum:        update.StopSequenceNumber,\n\t})\n\tseelog.Debugf(\"Task engine [%s]: update taken off the acs channel: [%s] with seqnum [%d]\",\n\t\ttask.Arn, updateDesiredStatus.String(), update.StopSequenceNumber)\n}", "reference": "// updateTaskUnsafe determines if a new transition needs to be applied to the\n// referenced task, and if needed applies it. It should not be called anywhere\n// but from 'AddTask' and is protected by the tasksLock lock there.", "generated": "// Update the status of a task from another instance using ACSCloud API.\n//\n// Note that if there has been more than one stop event since our last check then\n// it will fail due to invalid sequences."}
{"id": 1918, "code": "func (m *MockFileSystem) Copy(arg0 io.Writer, arg1 io.Reader) (int64, error) {\n\tret := m.ctrl.Call(m, \"Copy\", arg0, arg1)\n\tret0, _ := ret[0].(int64)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// Copy mocks base method", "generated": "// MockMethod calls the specified method on the controller object.\n//\n// This is used to mock out methods that we don't want to actually call in our test,\n// but still need to verify were called correctly.  The argument list should be exactly\n// one more than the number of arguments expected by the real method"}
{"id": 1919, "code": "func (m *MockFileSystem) Exit(arg0 int) {\n\tm.ctrl.Call(m, \"Exit\", arg0)\n}", "reference": "// Exit mocks base method", "generated": "// Mock method for fileSystem.Exit\n//\n// Args:\n//  - arg0: The exit code to return.\n //\n// Returns:\n//  - None"}
{"id": 1920, "code": "func (m *MockFileSystem) MkdirAll(arg0 string, arg1 os.FileMode) error {\n\tret := m.ctrl.Call(m, \"MkdirAll\", arg0, arg1)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// MkdirAll mocks base method", "generated": "// MockMethod calls method named 'MkdirAll' from controller's context.\n//\n// Args: \n //\n //   0 - path to create directory in\n //\n // Returns:\n //\n // Result is returned by mock control. If there was no actual call,\n // it returns nil else result of real method call."}
{"id": 1937, "code": "func (m *MockTaskEngineState) AllTasks() []*task.Task {\n\tret := m.ctrl.Call(m, \"AllTasks\")\n\tret0, _ := ret[0].([]*task.Task)\n\treturn ret0\n}", "reference": "// AllTasks mocks base method", "generated": "// Mock task engine state method to return all tasks in mock context."}
{"id": 1948, "code": "func (containerType ContainerType) String() string {\n\tfor str, contType := range stringToContainerType {\n\t\tif contType == containerType {\n\t\t\treturn str\n\t\t}\n\t}\n\n\treturn \"NORMAL\"\n}", "reference": "// String converts the container type enum to a string", "generated": "// Returns human-readable name for given type.\n//\n// If there is no matching value then returns NORMAL which means it's unknown or invalid."}
{"id": 1959, "code": "func (f *factory) GetClient(version dockerclient.DockerVersion) (sdkclient.Client, error) {\n\treturn f.getClient(version)\n}", "reference": "// GetClient on linux will simply return the cached client from the map", "generated": "// GetClient returns client for given Docker version.\n//\n// If there is no available client then it will return nil\n// if there isn't any available clients at all or first one found in order to get latest possible client."}
{"id": 2002, "code": "func (engine *DockerStatsEngine) removeContainer(dockerID string) {\n\tengine.lock.Lock()\n\tdefer engine.lock.Unlock()\n\n\t// Make sure that this container belongs to a task.\n\ttask, err := engine.resolver.ResolveTask(dockerID)\n\tif err != nil {\n\t\tseelog.Debugf(\"Could not map container to task, ignoring, err: %v, id: %s\", err, dockerID)\n\t\treturn\n\t}\n\n\t_, taskExists := engine.tasksToContainers[task.Arn]\n\tif !taskExists {\n\t\tseelog.Debugf(\"Container not being watched, id: %s\", dockerID)\n\t\treturn\n\t}\n\n\t// task arn exists in map.\n\tcontainer, containerExists := engine.tasksToContainers[task.Arn][dockerID]\n\tif !containerExists {\n\t\t// container arn does not exist in map.\n\t\tseelog.Debugf(\"Container not being watched, id: %s\", dockerID)\n\t\treturn\n\t}\n\n\tengine.doRemoveContainerUnsafe(container, task.Arn)\n}", "reference": "// removeContainer deletes the container from the map of containers being watched.\n// It also stops the periodic usage data collection for the container.", "generated": "// Remove a Docker stats container from our list of containers we're watching,\n// which is necessary if it's been removed by another process or has gone away due to some other reason."}
{"id": 2004, "code": "func (engine *DockerStatsEngine) taskContainerMetricsUnsafe(taskArn string) ([]*ecstcs.ContainerMetric, error) {\n\tcontainerMap, taskExists := engine.tasksToContainers[taskArn]\n\tif !taskExists {\n\t\treturn nil, fmt.Errorf(\"Task not found\")\n\t}\n\n\tvar containerMetrics []*ecstcs.ContainerMetric\n\tfor _, container := range containerMap {\n\t\tdockerID := container.containerMetadata.DockerID\n\t\t// Check if the container is terminal. If it is, make sure that it is\n\t\t// cleaned up properly. We might sometimes miss events from docker task\n\t\t// engine and this helps in reconciling the state. The tcs client's\n\t\t// GetInstanceMetrics probe is used as the trigger for this.\n\t\tif engine.stopTrackingContainerUnsafe(container, taskArn) {\n\t\t\tcontinue\n\t\t}\n\n\t\tif !container.statsQueue.enoughDatapointsInBuffer() &&\n\t\t\t!container.statsQueue.resetThresholdElapsed(queueResetThreshold) {\n\t\t\tseelog.Debugf(\"Stats not ready for container %s\", dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Container is not terminal. Get CPU stats set.\n\t\tcpuStatsSet, err := container.statsQueue.GetCPUStatsSet()\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Error getting cpu stats, err: %v, container: %v\", err, dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Get memory stats set.\n\t\tmemoryStatsSet, err := container.statsQueue.GetMemoryStatsSet()\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Error getting memory stats, err: %v, container: %v\", err, dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\tcontainerMetrics = append(containerMetrics, &ecstcs.ContainerMetric{\n\t\t\tCpuStatsSet:    cpuStatsSet,\n\t\t\tMemoryStatsSet: memoryStatsSet,\n\t\t})\n\n\t}\n\n\treturn containerMetrics, nil\n}", "reference": "// taskContainerMetricsUnsafe gets all container metrics for a task arn.", "generated": "//\n// This method returns metrics about all containers running within a given\n// Docker Task. It will return empty list when there are no tasks or containers\n// to report on. Note that we don't track any errors here because they can be\n// ignored by our consumers. However, note that some operations may fail"}
{"id": 2025, "code": "func NewNamedError(err error) *DefaultNamedError {\n\tif namedErr, ok := err.(NamedError); ok {\n\t\treturn &DefaultNamedError{Err: namedErr.Error(), Name: namedErr.ErrorName()}\n\t}\n\treturn &DefaultNamedError{Err: err.Error()}\n}", "reference": "// NewNamedError creates a NamedError.", "generated": "// Create new NamedError from any Error type.\n//\n// If there is no name in the given Err then it will be set to \"Unknown\"."}
{"id": 2037, "code": "func (r *eventLogReceiver) ReceiveMessage(message string, level seelog.LogLevel, context seelog.LogContextInterface) error {\n\tswitch level {\n\tcase seelog.DebugLvl, seelog.InfoLvl:\n\t\treturn eventLog.Info(eventLogID, message)\n\tcase seelog.WarnLvl:\n\t\treturn eventLog.Warning(eventLogID, message)\n\tcase seelog.ErrorLvl, seelog.CriticalLvl:\n\t\treturn eventLog.Error(eventLogID, message)\n\t}\n\treturn nil\n}", "reference": "// ReceiveMessage receives a log line from seelog and emits it to the Windows event log", "generated": "// ReceiveMessage is used to receive messages from events log receiver.\n//\n// This method will return errors if it can't handle any given logging levels,\n// otherwise it returns no-op result which means that received logs won't be written into file or console."}
{"id": 2051, "code": "func (m *MockIOUtil) WriteFile(arg0 string, arg1 []byte, arg2 os.FileMode) error {\n\tret := m.ctrl.Call(m, \"WriteFile\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// WriteFile mocks base method", "generated": "// MockMethod calls mock method named 'WriteFile' which is defined in parent class.\n//\n// Args:\n//     args: Method arguments passed from child to parent. In this case,\n//        there's only one argument - file path.\n //\n// Returns:\n//     Error returned by mock method or nil if no"}
{"id": 2052, "code": "func (mr *MockIOUtilMockRecorder) WriteFile(arg0, arg1, arg2 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"WriteFile\", reflect.TypeOf((*MockIOUtil)(nil).WriteFile), arg0, arg1, arg2)\n}", "reference": "// WriteFile indicates an expected call of WriteFile", "generated": "// RecordCallWithMethodType records that WriteFile was called with args\n//\n// Args:\n//   mock - Mock object to record call for.\n//   method - Method name being recorded.\n//   typeOfResult - Type of result expected from calling this method.\n// Returns: The recorded Call instance if successful;"}
{"id": 2060, "code": "func NewVolumesResponse(dockerContainer *apicontainer.DockerContainer) []VolumeResponse {\n\tcontainer := dockerContainer.Container\n\tvar resp []VolumeResponse\n\n\tvolumes := container.GetVolumes()\n\n\tfor _, volume := range volumes {\n\t\tvolResp := VolumeResponse{\n\t\t\tDockerName:  volume.Name,\n\t\t\tSource:      volume.Source,\n\t\t\tDestination: volume.Destination,\n\t\t}\n\n\t\tresp = append(resp, volResp)\n\t}\n\treturn resp\n}", "reference": "// NewVolumesResponse creates VolumeResponse for a container", "generated": "// Returns list of Docker containers' volumes in format that can be used by client's API.\n//\n// Note: This method is only available for version v1beta2 or higher. If this method returns nil it means that the requested resource was removed from server side."}
{"id": 2062, "code": "func NewPublishMetricsRequest(metadata *MetricsMetadata, taskMetrics []*TaskMetric) *PublishMetricsRequest {\n\treturn &PublishMetricsRequest{\n\t\tMetadata:    metadata,\n\t\tTaskMetrics: taskMetrics,\n\t\tTimestamp:   aws.Time(time.Now()),\n\t}\n}", "reference": "// NewPublishMetricsRequest creates a PublishMetricsRequest object.", "generated": "// Create new Publish Metrics Request object from given Metadata and Task metrics.\n//\n// This method creates new instance of PublishMetricsRequest which can be used to send\n// request for publishing tasks metric data into AWS CloudWatch service."}
{"id": 2092, "code": "func (m *MockCNI) AddNetworkList(arg0 *libcni.NetworkConfigList, arg1 *libcni.RuntimeConf) (types.Result, error) {\n\tret := m.ctrl.Call(m, \"AddNetworkList\", arg0, arg1)\n\tret0, _ := ret[0].(types.Result)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// AddNetworkList mocks base method", "generated": "// AddNetworkList is the mock for cni.AddNetworkList.\n//\n// Args:\n//   - arg0: Network config list to add network configuration from.\n//     This should be non-nil if this method was called by CNI's API,\n//     otherwise it will return nil.\n//   - arg1"}
{"id": 2094, "code": "func (mr *MockCNIMockRecorder) DelNetwork(arg0, arg1 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"DelNetwork\", reflect.TypeOf((*MockCNI)(nil).DelNetwork), arg0, arg1)\n}", "reference": "// DelNetwork indicates an expected call of DelNetwork", "generated": "// MockDELNETWORK - mock for DeleteNetwork method\n//\n// Args: [arg0] network name to delete; [arg1] option object containing options that will be passed to CNI's DeleteNetwork API call.\n //\n// Returns: gomock.Call representing the recorded Call to DeleteNetwork.  If no"}
{"id": 2114, "code": "func (v *StackSwitcher) native() *C.GtkStackSwitcher {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkStackSwitcher(p)\n}", "reference": "// native returns a pointer to the underlying GtkStackSwitcher.", "generated": "// Convert to native type for use in GTK code.\n//\n// Note: This is only used when using the GTK3 API,\n// so this should never be called from user-space code."}
{"id": 2116, "code": "func (v *ComboBoxText) native() *C.GtkComboBoxText {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkComboBoxText(p)\n}", "reference": "// native returns a pointer to the underlying GtkComboBoxText.", "generated": "// Native returns the underlying native widget for this combobox text.\n//\n// This is used to access properties or methods that can only be accessed from\n// C code.  Note: You must use caution when accessing these values directly,\n// since they may change in future versions of GTK+."}
{"id": 2124, "code": "func (v *Variant) GetString() string {\n\tvar len C.gsize\n\tgc := C.g_variant_get_string(v.native(), &len)\n\tdefer C.g_free(C.gpointer(gc))\n\treturn C.GoStringN((*C.char)(gc), (C.int)(len))\n}", "reference": "// GetString returns the string value of the variant.", "generated": "//GetString returns the value of this variant as a string.\n//\n// Note: This method is only valid for strings that have been created using\n// gvariant_new_from_str(). If it's used to get the result from another type,\n// then use GetInt64 or GetFloat instead."}
{"id": 2143, "code": "func (v *StyleContext) native() *C.GtkStyleContext {\n\tif v == nil || v.Object == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkStyleContext(p)\n}", "reference": "// native returns a pointer to the underlying GtkStyleContext.", "generated": "//native returns the underlying GTK style context for this Style Context object.\n//\n//Note: This is only valid if the Style Context was created using the new API,\n//i.e., from a StyleContext constructor that takes a GWindow or a StyleContext\n//object returned by gtk STYLE_CONTEXT_NEW(). If it's"}
{"id": 2148, "code": "func (m *Matrix) InitRotate(radians float64) {\n\tC.cairo_matrix_init_rotate(m.native(), C.double(radians))\n}", "reference": "// InitRotate initializes a matrix with the given rotation", "generated": "// Initialize matrix for rotation by radians degrees.\n//\n// Note: This is equivalent to calling ccairo_matrix_set_rotation(c cairo_t,\n// CairoRotationType(C.CAIRO Rotation), double radian)."}
{"id": 2165, "code": "func NewSurface(s uintptr, needsRef bool) *Surface {\n\tsurface := WrapSurface(s)\n\tif needsRef {\n\t\tsurface.reference()\n\t}\n\truntime.SetFinalizer(surface, (*Surface).destroy)\n\treturn surface\n}", "reference": "// NewSurface creates a gotk3 cairo Surface from a pointer to a\n// C cairo_surface_t.  This is primarily designed for use with other\n// gotk3 packages and should be avoided by applications.", "generated": "// Create new Surface object from given pointer to underlying memory.\n//\n// If s is nil or already has reference set then return error."}
{"id": 2167, "code": "func AddFont(fontPath string) {\n\tpath := (*C.uchar)(unsafe.Pointer(C.CString(fontPath)))\n\tC.addFont(path)\n}", "reference": "// AddFont adds the font to the configuration.", "generated": "// Adds font to list.\n//\n// This is used by C.go's addFont method for adding fonts from local files or\n// paths that can be accessed directly in C code (e.g., system directories). The path should end\n// with \".ttf\" if it contains only ASCII characters; otherwise, use"}
{"id": 2168, "code": "func (v *Label) native() *C.GtkLabel {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkLabel(p)\n}", "reference": "// native returns a pointer to the underlying GtkLabel.", "generated": "//native returns the underlying label object from this Label instance.\n//\n//Note: This method is only valid if the Label has been created using\n//newLabel or newLabelFromWidget. If it was constructed directly,\n//this will return nil."}
{"id": 2182, "code": "func (v *ActionGroup) ChangeActionState(actionName string, value *Variant) {\n\tC.g_action_group_change_action_state(v.native(), (*C.gchar)(C.CString(actionName)), value.native())\n}", "reference": "// ChangeActionState is a wrapper around g_action_group_change_action_state", "generated": "// Changes state for action group named by name.\n//\n// This is used to change the status or type of all actions in\n// this group at once.  The new values will be stored into memory,\n// but they won't actually take effect until next time gactiongroup_update()\n// is called."}
{"id": 2186, "code": "func (v *GLArea) native() *C.GtkGLArea {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkGLArea(p)\n}", "reference": "// native returns a pointer to the underlying GtkGLArea.", "generated": "// Native returns the underlying GLArea object from this interface.\n//\n// This is used internally by the GTK+ library to interact directly with the\n// OpenGL area widget.  It should never be called manually in user code,\n// except for when using the GLUT or WGL functions provided by the GTK+\n// library itself"}
{"id": 2188, "code": "func (v *TreeView) SetSearchEqualSubstringMatch() {\n\tC.gtk_tree_view_set_search_equal_func(\n\t\tv.native(),\n\t\t(C.GtkTreeViewSearchEqualFunc)(unsafe.Pointer(C.substring_match_equal_func)),\n\t\tnil,\n\t\tnil)\n}", "reference": "// SetSearchEqualSubstringMatch sets TreeView to search by substring match.", "generated": "// Set search equal substring match for tree view.\n//\n// This sets up the custom comparison function to be used when searching\n// in this TreeView using the \"equal\" option. The string is compared by\n// finding two matching substrings that start at each character position from\n// left-to-right or right-to"}
{"id": 2202, "code": "func (v *ShortcutsShortcut) native() *C.GtkShortcutsShortcut {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkShortcutsShortcut(p)\n}", "reference": "// native returns a pointer to the underlying GtkShortcutsShortcut.", "generated": "// Convert to native type.\n//\n// This is used by the GTK+ code when it needs access to this object's properties,\n// but doesn't need its interface or methods.  Note that if we're using a custom\n// shortcut class for our application, then this will return NULL because there\n// isn't"}
{"id": 2203, "code": "func SimpleActionGroupNew() *SimpleActionGroup {\n\tc := C.g_simple_action_group_new()\n\tif c == nil {\n\t\treturn nil\n\t}\n\treturn wrapSimpleActionGroup(wrapObject(unsafe.Pointer(c)))\n}", "reference": "// SimpleActionGroupNew is a wrapper around g_simple_action_group_new", "generated": "// New creates new simple action group object from zero values.\n//\n// Returns error if failed to create it."}
{"id": 2208, "code": "func (v *Action) GetParameterType() *VariantType {\n\tc := C.g_action_get_parameter_type(v.native())\n\tif c == nil {\n\t\treturn nil\n\t}\n\treturn newVariantType((*C.GVariantType)(c))\n}", "reference": "// GetParameterType is a wrapper around g_action_get_parameter_type", "generated": "// Return type for g_action_get-parameter-type().  This is used to indicate that this action requires one parameter.\n//\n// The variant returned by this method will be valid until it goes out of scope or its parent object's native pointer becomes invalid,\n// whichever happens first."}
{"id": 2218, "code": "func (v *Bin) native() *C.GtkBin {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkBin(p)\n}", "reference": "// native returns a pointer to the underlying GtkBin.", "generated": "//native returns the underlying GTK+ Bin object for this widget.\n//\n//Note: This is only valid if the current context has been initialized,\n//and it's safe to call after setting up all necessary widgets in the window."}
{"id": 2221, "code": "func (v *CellRendererSpinner) native() *C.GtkCellRendererSpinner {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkCellRendererSpinner(p)\n}", "reference": "// native returns a pointer to the underlying GtkCellRendererSpinner.", "generated": "// Native returns the underlying GTK+ cell renderer object for this Cell Renderer Spinner.\n//\n// This is typically used when working directly with GTK+. However,\n// it's generally recommended to use the provided methods instead."}
{"id": 2247, "code": "func (v *FileChooserDialog) native() *C.GtkFileChooserDialog {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkFileChooserDialog(p)\n}", "reference": "// native returns a pointer to the underlying GtkFileChooserDialog.", "generated": "// Native returns the underlying GTK+ filechooser dialog object.\n//\n// This is only used internally by golangkit's GUI codebase,\n// so this method should never be called directly from user-space code."}
{"id": 2267, "code": "func (v *Paned) native() *C.GtkPaned {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkPaned(p)\n}", "reference": "// native returns a pointer to the underlying GtkPaned.", "generated": "// Native returns the underlying GTK+ paned object.\n//\n// This is only used internally by golang-gtk to avoid creating unnecessary\n// references in our codebase.  It's also possible that this could be made into\n// a method if we ever need it for some reason outside of internal use."}
{"id": 2303, "code": "func (v *TreePath) GetIndices() []int {\n\tvar depth C.gint\n\tvar goindices []int\n\tvar ginthelp C.gint\n\tindices := uintptr(unsafe.Pointer(C.gtk_tree_path_get_indices_with_depth(v.native(), &depth)))\n\tsize := unsafe.Sizeof(ginthelp)\n\tfor i := 0; i < int(depth); i++ {\n\t\tgoind := int(*((*C.gint)(unsafe.Pointer(indices))))\n\t\tgoindices = append(goindices, goind)\n\t\tindices += size\n\t}\n\treturn goindices\n}", "reference": "// GetIndices is a wrapper around gtk_tree_path_get_indices_with_depth", "generated": "// Returns indices for path elements in reverse order.\n//\n// Note: This method is only available if this treepath was created using\n// gtk_tree_path_new_from_string()."}
{"id": 2313, "code": "func (v *Window) native() *C.GtkWindow {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkWindow(p)\n}", "reference": "// native returns a pointer to the underlying GtkWindow.", "generated": "// Native returns the underlying GTK window object for this Window.\n//\n// This is only valid if the Window was created using NewFromNative or from a Glib\n// widget that has been converted to a Windows GUI component by gwinbase's ConvertToWindowsGUIComponent method.  If it wasn't,\n// then"}
{"id": 2348, "code": "func hideConsoleWindowOnWindows() {\n\tpid, err := getCurrentProcessId()\n\tif err != nil {\n\t\t// Ignore errors because:\n\t\t// 1. It is not critical if the console can't be hid.\n\t\t// 2. There is nothing to do when errors happen.\n\t\treturn\n\t}\n\tw, err := getConsoleWindow()\n\tif err != nil {\n\t\t// Ignore errors\n\t\treturn\n\t}\n\t// Get the process ID of the console's creator.\n\tcpid, err := getWindowThreadProcessId(w)\n\tif err != nil {\n\t\t// Ignore errors\n\t\treturn\n\t}\n\tif pid == cpid {\n\t\t// The current process created its own console. Hide this.\n\t\tshowWindowAsync(w, windows.SW_HIDE)\n\t}\n}", "reference": "// hideConsoleWindowOnWindows will hide the console window that is showing when\n// compiling on Windows without specifying the '-ldflags \"-Hwindowsgui\"' flag.", "generated": "// hides the window for the main application in Windows environment,\n// which should have been started by our program itself (i.e., it has same PID)."}
{"id": 2349, "code": "func DepthMask(flag bool) {\n\tC.glowDepthMask(gpDepthMask, (C.GLboolean)(boolToInt(flag)))\n}", "reference": "// enable or disable writing into the depth buffer", "generated": "// Set or clear depth mask flag.\n//\n// The GL_DEPTH_MASK is used to specify which components\n// should be considered when testing for whether any part\n// of this matrix affects the current pixel's depth value.\n //\n// If glDepthMask returns true then all subsequent calls to\n// glDrawArrays/glu"}
{"id": 2354, "code": "func scaleUpdater() {\n\tfor {\n\t\ts := getscale(0, 0)\n\t\tatomic.StoreUint64(&cachedScale, math.Float64bits(s))\n\t\ttime.Sleep(cacheUpdateWait)\n\t}\n}", "reference": "// run as goroutine. Will keep the desktop scale up to date.\n// This can be removed once the scale change event is implemented in GLFW 3.3", "generated": "// scales updates cached values for scaling factor.\n//\n// This is called every cache update interval to ensure that\n// caching remains valid in case of changes to the scaling factors."}
{"id": 2359, "code": "func (b *Board) Draw(boardImage *ebiten.Image) {\n\tboardImage.Fill(frameColor)\n\tfor j := 0; j < b.size; j++ {\n\t\tfor i := 0; i < b.size; i++ {\n\t\t\tv := 0\n\t\t\top := &ebiten.DrawImageOptions{}\n\t\t\tx := i*tileSize + (i+1)*tileMargin\n\t\t\ty := j*tileSize + (j+1)*tileMargin\n\t\t\top.GeoM.Translate(float64(x), float64(y))\n\t\t\tr, g, b, a := colorToScale(tileBackgroundColor(v))\n\t\t\top.ColorM.Scale(r, g, b, a)\n\t\t\tboardImage.DrawImage(tileImage, op)\n\t\t}\n\t}\n\tanimatingTiles := map[*Tile]struct{}{}\n\tnonAnimatingTiles := map[*Tile]struct{}{}\n\tfor t := range b.tiles {\n\t\tif t.IsMoving() {\n\t\t\tanimatingTiles[t] = struct{}{}\n\t\t} else {\n\t\t\tnonAnimatingTiles[t] = struct{}{}\n\t\t}\n\t}\n\tfor t := range nonAnimatingTiles {\n\t\tt.Draw(boardImage)\n\t}\n\tfor t := range animatingTiles {\n\t\tt.Draw(boardImage)\n\t}\n}", "reference": "// Draw draws the board to the given boardImage.", "generated": "// Draw draws all tiles onto board image.\n//\n// This is called by ebiten's draw loop to render our game state into the screen."}
{"id": 2441, "code": "func (i *Image) makeStale() {\n\ti.basePixels = nil\n\ti.drawTrianglesHistory = nil\n\ti.stale = true\n\n\t// Don't have to call makeStale recursively here.\n\t// Restoring is done after topological sorting is done.\n\t// If an image depends on another stale image, this means that\n\t// the former image can be restored from the latest state of the latter image.\n}", "reference": "// makeStale makes the image stale.", "generated": "//\n// Make all images in i base pixels or draw triangles history stale,\n// so they don't depend on any other images anymore. This should only be called once per frame.\n //\n// Note: if there's some dependency between two images which was already made stale before calling this method,\n// then it will still work"}
{"id": 2498, "code": "func (u *UserInterface) setScreenSize(width, height int, scale float64, fullscreen bool, vsync bool) bool {\n\tif u.width == width && u.height == height && u.scale == scale && u.isFullscreen() == fullscreen && u.vsync == vsync {\n\t\treturn false\n\t}\n\tu.forceSetScreenSize(width, height, scale, fullscreen, vsync)\n\treturn true\n}", "reference": "// setScreenSize must be called from the main thread.", "generated": "// Set screen size if it has changed or is forced to change by user request.\n//\n// Returns whether any changes were made in this call.  If no changes,\n// then return False immediately without calling forceSetScreenSize."}
{"id": 2504, "code": "func (q *commandQueue) Flush() {\n\tif q.err != nil {\n\t\treturn\n\t}\n\n\tes := q.indices\n\tvs := q.vertices\n\tif recordLog() {\n\t\tfmt.Println(\"--\")\n\t}\n\n\ttheGraphicsDriver.Begin()\n\tfor len(q.commands) > 0 {\n\t\tnv := 0\n\t\tne := 0\n\t\tnc := 0\n\t\tfor _, c := range q.commands {\n\t\t\tif c.NumIndices() > graphics.IndicesNum {\n\t\t\t\tpanic(fmt.Sprintf(\"graphicscommand: c.NumIndices() must be <= graphics.IndicesNum but not at Flush: c.NumIndices(): %d, graphics.IndicesNum: %d\", c.NumIndices(), graphics.IndicesNum))\n\t\t\t}\n\t\t\tif ne+c.NumIndices() > graphics.IndicesNum {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tnv += c.NumVertices()\n\t\t\tne += c.NumIndices()\n\t\t\tnc++\n\t\t}\n\t\tif 0 < ne {\n\t\t\ttheGraphicsDriver.SetVertices(vs[:nv], es[:ne])\n\t\t\tes = es[ne:]\n\t\t\tvs = vs[nv:]\n\t\t}\n\t\tindexOffset := 0\n\t\tfor _, c := range q.commands[:nc] {\n\t\t\tif err := c.Exec(indexOffset); err != nil {\n\t\t\t\tq.err = err\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif recordLog() {\n\t\t\t\tfmt.Printf(\"%s\\n\", c)\n\t\t\t}\n\t\t\t// TODO: indexOffset should be reset if the command type is different\n\t\t\t// from the previous one. This fix is needed when another drawing command is\n\t\t\t// introduced than drawTrianglesCommand.\n\t\t\tindexOffset += c.NumIndices()\n\t\t}\n\t\tif 0 < nc {\n\t\t\t// Call glFlush to prevent black flicking (especially on Android (#226) and iOS).\n\t\t\ttheGraphicsDriver.Flush()\n\t\t}\n\t\tq.commands = q.commands[nc:]\n\t}\n\ttheGraphicsDriver.End()\n\tq.commands = nil\n\tq.nvertices = 0\n\tq.nindices = 0\n\tq.tmpNumIndices = 0\n\tq.nextIndex = 0\n}", "reference": "// Flush flushes the command queue.", "generated": "//\n// Flush all commands in queue into OpenGL context. If there's any error,\n// it will stop flushing immediately after that. The result can't be used for anything else until next call to flush or start again by calling Reset()."}
{"id": 2534, "code": "func flattenClusterHostGroup(d *schema.ResourceData, obj *types.ClusterHostGroup) error {\n\tvar hostIDs []string\n\tfor _, v := range obj.Host {\n\t\thostIDs = append(hostIDs, v.Value)\n\t}\n\n\treturn structure.SetBatch(d, map[string]interface{}{\n\t\t\"host_system_ids\": hostIDs,\n\t})\n}", "reference": "// flattenClusterHostGroup saves a ClusterHostGroup into the supplied ResourceData.", "generated": "// Flatten Cluster Host Group resource to JSON format for serialization.\n//\n// This method is used by schema's code generator process when serializing data into json or yaml formats. It returns nil if there was no change made in the original object. Otherwise it returns any errors that occurred during this operation."}
{"id": 2535, "code": "func resourceVSphereComputeClusterHostGroupFlattenID(cluster *object.ClusterComputeResource, name string) (string, error) {\n\tclusterID := cluster.Reference().Value\n\treturn strings.Join([]string{clusterID, name}, \":\"), nil\n}", "reference": "// resourceVSphereComputeClusterHostGroupFlattenID makes an ID for the\n// vsphere_cluster_host_group resource.", "generated": "// Flatten ID for Compute Cluster Host Group object type. This is used to generate unique IDs when creating new host groups in Cloud Provider API.\n//\n// The format will be <compute_cluster_id>:<host_group_name>. For example: \"cloud-12345:host-group-1\"."}
{"id": 2590, "code": "func MoveToFolder(client *govmomi.Client, vm *object.VirtualMachine, relative string) error {\n\tlog.Printf(\"[DEBUG] Moving virtual %q to VM path %q\", vm.InventoryPath, relative)\n\tf, err := folder.VirtualMachineFolderFromObject(client, vm, relative)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn folder.MoveObjectTo(vm.Reference(), f)\n}", "reference": "// MoveToFolder moves a virtual machine to the specified folder.", "generated": "// Moves a Virtual Machine into its corresponding Folder in the directory structure.\n//\n// This is used when creating or updating a new Virtual Machine that should be stored under a specific parent folder,\n// such as for cloud-based machines where they need to live within their respective provider's directories."}
{"id": 2611, "code": "func FromPath(client *govmomi.Client, name string, dc *object.Datacenter) (*object.VirtualApp, error) {\n\tfinder := find.NewFinder(client.Client, false)\n\n\tctx, cancel := context.WithTimeout(context.Background(), provider.DefaultAPITimeout)\n\tdefer cancel()\n\tif dc != nil {\n\t\tfinder.SetDatacenter(dc)\n\t}\n\treturn finder.VirtualApp(ctx, name)\n}", "reference": "// FromPath returns a VirtualApp via its supplied path.", "generated": "// Find virtual app by path\n//\n// This method returns VirtualApp if found in data center or its parent.\n //\n// If no DataCenter is provided it will search for all available data centers first,\n// then look into their children (virtual apps). The default timeout value can be changed using\n// SetDefaultAPI"}
{"id": 2643, "code": "func resourceVSphereComputeClusterApplyCreate(d *schema.ResourceData, meta interface{}) (*object.ClusterComputeResource, error) {\n\tlog.Printf(\"[DEBUG] %s: Processing compute cluster creation\", resourceVSphereComputeClusterIDString(d))\n\tclient, err := resourceVSphereComputeClusterClient(meta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdc, err := datacenterFromID(client, d.Get(\"datacenter_id\").(string))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot locate datacenter: %s\", err)\n\t}\n\n\t// Find the folder based off the path to the datacenter. This is where we\n\t// create the datastore cluster.\n\tf, err := folder.FromPath(client, d.Get(\"folder\").(string), folder.VSphereFolderTypeHost, dc)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot locate folder: %s\", err)\n\t}\n\n\t// Create the cluster. We use an empty config spec so that we can move the\n\t// necessary hosts into the cluster *before* we send the full configuration,\n\t// ensuring that any host-dependent configuration does not break.\n\tcluster, err := clustercomputeresource.Create(f, d.Get(\"name\").(string), types.ClusterConfigSpecEx{})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error creating cluster: %s\", err)\n\t}\n\n\t// Set the ID now before proceeding any further. Any other operation past\n\t// this point is recoverable.\n\td.SetId(cluster.Reference().Value)\n\n\treturn cluster, nil\n}", "reference": "// resourceVSphereComputeClusterApplyCreate processes the creation part of\n// resourceVSphereComputeClusterCreate.", "generated": "//\n// Apply creates or updates a Compute Cluster in vCenter Server. The name must be unique within its parent container (i.e., it cannot exist already). If no value exists for \"Name\" then the default will be used which defaults to the Data Center's Name followed by \"_compute_cluster\"."}
{"id": 2650, "code": "func resourceVSphereComputeClusterSaveDatacenter(\n\td *schema.ResourceData,\n\tmeta interface{},\n\tcluster *object.ClusterComputeResource,\n) error {\n\tlog.Printf(\"[DEBUG] %s: Saving datacenter\", resourceVSphereComputeClusterIDString(d))\n\tclient, err := resourceVSphereComputeClusterClient(meta)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tp, err := folder.RootPathParticleHost.SplitDatacenter(cluster.InventoryPath)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error parsing datacenter path from cluster: %s\", err)\n\t}\n\n\tdc, err := getDatacenter(client, p)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error fetching datacenter for cluster: %s\", err)\n\t}\n\n\treturn d.Set(\"datacenter_id\", dc.Reference().Value)\n}", "reference": "// resourceVSphereComputeClusterSaveDatacenter saves the datacenter that the\n// cluster is a member of for correctness on imports.", "generated": "// SaveDatacenter saves the DataCenter object to vSphere server.\n//\n// This method is used when updating or creating a new Cluster Compute Resource in vCloud Director. The Data Center must be created before saving it using this method. If the Data Center has already been saved then calling this method will result in an error"}
{"id": 2677, "code": "func expandClusterDrsConfigInfo(d *schema.ResourceData) *types.ClusterDrsConfigInfo {\n\tobj := &types.ClusterDrsConfigInfo{\n\t\tDefaultVmBehavior:         types.DrsBehavior(d.Get(\"drs_automation_level\").(string)),\n\t\tEnabled:                   structure.GetBool(d, \"drs_enabled\"),\n\t\tEnableVmBehaviorOverrides: structure.GetBool(d, \"drs_enable_vm_overrides\"),\n\t\tVmotionRate:               int32(d.Get(\"drs_migration_threshold\").(int)),\n\t\tOption:                    expandResourceVSphereComputeClusterDrsAdvancedOptions(d),\n\t}\n\n\treturn obj\n}", "reference": "// expandClusterDrsConfigInfo reads certain ResourceData keys and returns a\n// ClusterDrsConfigInfo.", "generated": "// Expand ClusterDRS config info resource data to its corresponding type object.\n//\n// This method is used by schema.Read() when reading resources from the API server,\n// or for user-provided values in the Resource Data format. It returns nil if there's no value set."}
{"id": 2689, "code": "func Rename(pod *object.StoragePod, name string) error {\n\tlog.Printf(\"[DEBUG] Renaming storage pod %q to %s\", pod.InventoryPath, name)\n\tctx, cancel := context.WithTimeout(context.Background(), provider.DefaultAPITimeout)\n\tdefer cancel()\n\ttask, err := pod.Rename(ctx, name)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn task.Wait(ctx)\n}", "reference": "// Rename renames a StoragePod.", "generated": "// Rename renames the given Storage Pod by its Inventory Path.\n//\n// This method is used when we need to rename a Storage Pod that was created from\n// another container's inventory path (e.g., during migration). The newInventoryPath\n// should be set in the Container object before calling this method. If"}
{"id": 2727, "code": "func createHardDisk(client *govmomi.Client, size int, diskPath string, diskType string, adapterType string, dc string) error {\n\tvar vDiskType string\n\tswitch diskType {\n\tcase \"thin\":\n\t\tvDiskType = \"thin\"\n\tcase \"eagerZeroedThick\":\n\t\tvDiskType = \"eagerZeroedThick\"\n\tcase \"lazy\":\n\t\tvDiskType = \"preallocated\"\n\t}\n\n\tvirtualDiskManager := object.NewVirtualDiskManager(client.Client)\n\tspec := &types.FileBackedVirtualDiskSpec{\n\t\tVirtualDiskSpec: types.VirtualDiskSpec{\n\t\t\tAdapterType: adapterType,\n\t\t\tDiskType:    vDiskType,\n\t\t},\n\t\tCapacityKb: int64(1024 * 1024 * size),\n\t}\n\tdatacenter, err := getDatacenter(client, dc)\n\tif err != nil {\n\t\treturn err\n\t}\n\tlog.Printf(\"[DEBUG] Disk spec: %v\", spec)\n\n\ttask, err := virtualDiskManager.CreateVirtualDisk(context.TODO(), diskPath, datacenter, spec)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = task.WaitForResult(context.TODO(), nil)\n\tif err != nil {\n\t\tlog.Printf(\"[INFO] Failed to create disk:  %v\", err)\n\t\treturn err\n\t}\n\tlog.Printf(\"[INFO] Created disk.\")\n\n\treturn nil\n}", "reference": "// createHardDisk creates a new Hard Disk.", "generated": "// Create harddisk creates a new file-backed thin or eager-zeroed-thick virtual disk.\n//\n// Args:\n//   client - govmomi Client instance used for connection to ESX server.\n//   size     - Size in KB that should be allocated by the VirtualMachine.\n//               If zero then no allocation"}
{"id": 2729, "code": "func (p *nasDatastoreMountProcessor) processMountOperations() (*object.Datastore, error) {\n\thosts := p.diffNewOld()\n\tif len(hosts) < 1 {\n\t\t// Nothing to do\n\t\treturn p.ds, nil\n\t}\n\t// Validate we are vCenter if we are working with multiple hosts\n\tif len(hosts) > 1 {\n\t\tif err := viapi.ValidateVirtualCenter(p.client); err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"cannot mount on multiple hosts: %s\", err)\n\t\t}\n\t}\n\tfor _, hsID := range hosts {\n\t\tdss, err := hostDatastoreSystemFromHostSystemID(p.client, hsID)\n\t\tif err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\t\tdefer cancel()\n\t\tds, err := dss.CreateNasDatastore(ctx, *p.volSpec)\n\t\tif err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t\tif err := p.validateDatastore(ds); err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"datastore validation error on host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t}\n\treturn p.ds, nil\n}", "reference": "// processMountOperations processes all pending mount operations by diffing old\n// and new and adding any hosts that were not found in old. The datastore is\n// returned, along with any error.", "generated": "// Process all datastores for this volume's mounts.\n//\n// This method is called after every change in the volumes' configuration,\n// so it can be used by users who want their application code to react when\n// they see changes made outside of their control. However, since this method\n// runs under the same"}
{"id": 2733, "code": "func tagByName(client *tags.RestClient, name, categoryID string) (string, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\ttags, err := client.GetTagByNameForCategory(ctx, name, categoryID)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"could not get tag for name %q: %s\", name, err)\n\t}\n\n\tif len(tags) < 1 {\n\t\treturn \"\", fmt.Errorf(\"tag name %q not found in category ID %q\", name, categoryID)\n\t}\n\tif len(tags) > 1 {\n\t\t// This situation is very similar to the one in tagCategoryByName. The API\n\t\t// docs even say that tags need to be unique in categories, yet\n\t\t// GetTagByNameForCategory still returns multiple results.\n\t\treturn \"\", fmt.Errorf(vSphereTagSearchErrMultiple, name)\n\t}\n\n\treturn tags[0].ID, nil\n}", "reference": "// tagByName locates a tag by it supplied name and category ID. Use\n// tagCategoryByName to get the tag category ID if require the category ID as\n// well.", "generated": "//\n// TagNameByCatId - Returns the first matching tag by its name within given Category-ID.\n //\n // Args:\n //   Name    - Name of the tag to find.\n //   CatId    - Id of the category where this tag should exist.\n //\n // Return value:\n //   If there's no"}
{"id": 2752, "code": "func expandVMwareDVSConfigSpec(d *schema.ResourceData) *types.VMwareDVSConfigSpec {\n\tobj := &types.VMwareDVSConfigSpec{\n\t\tDVSConfigSpec: types.DVSConfigSpec{\n\t\t\tName:                                d.Get(\"name\").(string),\n\t\t\tConfigVersion:                       d.Get(\"config_version\").(string),\n\t\t\tDefaultPortConfig:                   expandVMwareDVSPortSetting(d),\n\t\t\tHost:                                expandSliceOfDistributedVirtualSwitchHostMemberConfigSpec(d),\n\t\t\tDescription:                         d.Get(\"description\").(string),\n\t\t\tContact:                             expandDVSContactInfo(d),\n\t\t\tSwitchIpAddress:                     d.Get(\"ipv4_address\").(string),\n\t\t\tInfrastructureTrafficResourceConfig: expandSliceOfDvsHostInfrastructureTrafficResource(d),\n\t\t\tNetworkResourceControlVersion:       d.Get(\"network_resource_control_version\").(string),\n\t\t\tUplinkPortPolicy:                    expandDVSNameArrayUplinkPortPolicy(d),\n\t\t},\n\t\tMaxMtu:                      int32(d.Get(\"max_mtu\").(int)),\n\t\tLinkDiscoveryProtocolConfig: expandLinkDiscoveryProtocolConfig(d),\n\t\tIpfixConfig:                 expandVMwareIpfixConfig(d),\n\t\tLacpApiVersion:              d.Get(\"lacp_api_version\").(string),\n\t\tMulticastFilteringMode:      d.Get(\"multicast_filtering_mode\").(string),\n\t}\n\treturn obj\n}", "reference": "// expandVMwareDVSConfigSpec reads certain ResourceData keys and\n// returns a VMwareDVSConfigSpec.", "generated": "// Expand VMware DVS Config Spec resource data to create new object instance.\n//\n// This method expands all fields in Resource Data into their corresponding properties within the VMWare DVS config spec object."}
{"id": 2765, "code": "func expandVirtualMachineResourceAllocation(d *schema.ResourceData, key string) *types.ResourceAllocationInfo {\n\tshareLevelKey := fmt.Sprintf(\"%s_share_level\", key)\n\tshareCountKey := fmt.Sprintf(\"%s_share_count\", key)\n\tlimitKey := fmt.Sprintf(\"%s_limit\", key)\n\treservationKey := fmt.Sprintf(\"%s_reservation\", key)\n\n\tobj := &types.ResourceAllocationInfo{\n\t\tLimit:       structure.GetInt64PtrEmptyZero(d, limitKey),\n\t\tReservation: structure.GetInt64PtrEmptyZero(d, reservationKey),\n\t}\n\tshares := &types.SharesInfo{\n\t\tLevel:  types.SharesLevel(d.Get(shareLevelKey).(string)),\n\t\tShares: int32(d.Get(shareCountKey).(int)),\n\t}\n\tobj.Shares = shares\n\treturn obj\n}", "reference": "// expandVirtualMachineResourceAllocation reads the VM resource allocation\n// resource data keys for the type supplied by key and returns an appropriate\n// types.ResourceAllocationInfo reference.", "generated": "// Expand virtual machine resource allocation into its components for use in schema validation.\n//\n// This expands all keys that start with \"virtual_machine_\" to their corresponding sub-keys,\n// which can then be used by the validator to validate against specific requirements or constraints."}
{"id": 2781, "code": "func expandClusterDasVMConfigInfo(\n\td *schema.ResourceData,\n\tmeta interface{},\n\tvm *object.VirtualMachine,\n) (*types.ClusterDasVmConfigInfo, error) {\n\tclient, err := resourceVSphereHAVMOverrideClient(meta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tversion := viapi.ParseVersionFromClient(client)\n\n\tobj := &types.ClusterDasVmConfigInfo{\n\t\tDasSettings: expandClusterDasVMSettings(d, version),\n\t\tKey:         vm.Reference(),\n\t}\n\n\t// Expand ha_vm_monitoring_use_cluster_defaults here as it's not included in\n\t// the base vsphere_compute_cluster resource.\n\tobj.DasSettings.VmToolsMonitoringSettings.ClusterSettings = structure.GetBool(d, \"ha_vm_monitoring_use_cluster_defaults\")\n\n\treturn obj, nil\n}", "reference": "// expandClusterDasVMConfigInfo reads certain ResourceData keys and returns a\n// ClusterDasVmConfigInfo.", "generated": "//\n// Expands cluster das VM config info from d to object type. This is used by\n// resources that need access to this information for their own operations (e.g.,\n// create or update). The result will be returned directly without any additional\n// processing required by the caller. If there was no match found"}
{"id": 2819, "code": "func expandVmwareUplinkPortTeamingPolicy(d *schema.ResourceData) *types.VmwareUplinkPortTeamingPolicy {\n\tobj := &types.VmwareUplinkPortTeamingPolicy{\n\t\tPolicy:          structure.GetStringPolicy(d, \"teaming_policy\"),\n\t\tNotifySwitches:  structure.GetBoolPolicy(d, \"notify_switches\"),\n\t\tRollingOrder:    structure.GetBoolPolicyReverse(d, \"failback\"),\n\t\tFailureCriteria: expandDVSFailureCriteria(d),\n\t\tUplinkPortOrder: expandVMwareUplinkPortOrderPolicy(d),\n\t}\n\n\tif structure.AllFieldsEmpty(obj) {\n\t\treturn nil\n\t}\n\treturn obj\n}", "reference": "// expandVmwareUplinkPortTeamingPolicy reads certain ResourceData keys and\n// returns a VmwareUplinkPortTeamingPolicy.", "generated": "// Expand vmware_uplink_port_team policy to its underlying types.\n//\n// This is used by resource provider's expansion functions for conversion from schema data to type objects,\n// which can then be passed into other expansions or directly created using newType()."}
{"id": 2824, "code": "func flattenVMwareUplinkLacpPolicy(d *schema.ResourceData, obj *types.VMwareUplinkLacpPolicy) error {\n\tif obj == nil {\n\t\treturn nil\n\t}\n\n\tstructure.SetBoolPolicy(d, \"lacp_enabled\", obj.Enable)\n\tstructure.SetStringPolicy(d, \"lacp_mode\", obj.Mode)\n\treturn nil\n}", "reference": "// flattenVMwareUplinkLacpPolicy reads various fields from a\n// VMwareUplinkLacpPolicy into the passed in ResourceData.", "generated": "// Flatten VMware UPLINK_LACP Policy to resource data format.\n//\n// This method is used by schema.ReadFromResource() when reading from resources,\n// which returns this value in its Response object.  It should be called after\n// any necessary validation has been performed for security reasons."}
{"id": 2841, "code": "func (r *CdromSubresource) ValidateDiff() error {\n\tlog.Printf(\"[DEBUG] %s: Beginning CDROM configuration validation\", r)\n\tdsID := r.Get(\"datastore_id\").(string)\n\tpath := r.Get(\"path\").(string)\n\tclientDevice := r.Get(\"client_device\").(bool)\n\tswitch {\n\tcase clientDevice && (dsID != \"\" || path != \"\"):\n\t\treturn fmt.Errorf(\"Cannot have both client_device parameter and ISO file parameters (datastore_id, path) set\")\n\tcase !clientDevice && (dsID == \"\" || path == \"\"):\n\t\treturn fmt.Errorf(\"Either client_device or datastore_id and path must be set\")\n\t}\n\tlog.Printf(\"[DEBUG] %s: Config validation complete\", r)\n\treturn nil\n}", "reference": "// ValidateDiff performs any complex validation of an individual\n// cdrom sub-resource that can't be done in schema alone.", "generated": "// Validates that all required fields for this resource type exist in the request.\n//\n// This method is used to validate data before it's written out to disk,\n// so we can catch any errors early if there was something wrong about our input."}
{"id": 2848, "code": "func verifyVAppCdromIso(d *schema.ResourceData, device *types.VirtualCdrom, l object.VirtualDeviceList, c *govmomi.Client) (bool, error) {\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: Checking if CDROM is using a vApp ISO\")\n\t// If the CDROM is using VirtualCdromIsoBackingInfo and matches the ISO\n\t// naming pattern, it has been used as a vApp CDROM, and we can move on to\n\t// checking if the parent VM supports ISO transport.\n\tif backing, ok := device.Backing.(*types.VirtualCdromIsoBackingInfo); ok {\n\t\tdp := &object.DatastorePath{}\n\t\tif ok := dp.FromString(backing.FileName); !ok {\n\t\t\t// If the ISO path can not be read, we can't tell if a vApp ISO is\n\t\t\t// connected.\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: Cannot read ISO path, cannot determine if CDROM is used for vApp\")\n\t\t\treturn false, nil\n\t\t}\n\t\t// The pattern used for vApp ISO naming is\n\t\t// \"<vmname>/_ovfenv-<vmname>.iso\"\n\t\tre := regexp.MustCompile(\".*/_ovfenv-.*.iso\")\n\t\tif !re.MatchString(dp.Path) {\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: ISO is name does not match vApp ISO naming pattern (<vmname>/_ovfenv-<vmname>.iso): %s\", dp.Path)\n\t\t\treturn false, nil\n\t\t}\n\t} else {\n\t\t// vApp CDROMs must be backed by an ISO.\n\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: CDROM is not backed by an ISO\")\n\t\treturn false, nil\n\t}\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: CDROM has a vApp ISO inserted\")\n\t// Set the vApp transport methods\n\ttm := d.Get(\"vapp_transport\").([]interface{})\n\tfor _, t := range tm {\n\t\tif t.(string) == \"iso\" {\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: vApp ISO transport is supported\")\n\t\t\treturn true, nil\n\t\t}\n\t}\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: vApp ISO transport is not required\")\n\treturn false, nil\n}", "reference": "// verifyVAppCdromIso takes VirtualCdrom and determines if it is needed for\n// vApp ISO transport. It does this by first checking if it has an ISO inserted\n// that matches the vApp ISO naming pattern. If it does, then the next step is\n// to see if vApp ISO transport is supported on the VM. If both of those\n// conditions are met, then the CDROM is considered in use for vApp transport.", "generated": "//\n// Verify that this virtual cdrom uses a valid vApp iso file.  This checks\n// whether or not there exists a matching vApp Iso in the data store,\n// which would indicate that the virtual machine was created from a vApp.\n //\n// Note that even though the.iso may exist, it's"}
{"id": 2853, "code": "func soapFault(err error) (*soap.Fault, bool) {\n\tif soap.IsSoapFault(err) {\n\t\treturn soap.ToSoapFault(err), true\n\t}\n\treturn nil, false\n}", "reference": "// soapFault extracts the SOAP fault from an error fault, if it exists. Check\n// the returned boolean value to see if you have a SoapFault.", "generated": "// soapFault returns a Soap Fault if err is a SOAP fault or null otherwise.\n//\n// This should be used when calling functions that return errors but do not have any information about whether they were caused by a SOAP fault."}
{"id": 2860, "code": "func isConcurrentAccessError(err error) bool {\n\t// ConcurrentAccess comes from a task more than it usually does from a direct\n\t// SOAP call, so we need to handle both here.\n\tvar f types.AnyType\n\tvar ok bool\n\tf, ok = vimSoapFault(err)\n\tif !ok {\n\t\tf, ok = taskFault(err)\n\t}\n\tif ok {\n\t\tswitch f.(type) {\n\t\tcase types.ConcurrentAccess, *types.ConcurrentAccess:\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "reference": "// isConcurrentAccessError checks an error to see if it's of the\n// ConcurrentAccess type.", "generated": "//\n// Is this some kind of concurrent access?  This should be used when checking for errors that come in due to tasks being run concurrently,\n// rather than directly through soap calls (which would typically result in a Fault)."}
{"id": 2882, "code": "func validateCloneSnapshots(props *mo.VirtualMachine) error {\n\tif props.Snapshot == nil {\n\t\treturn fmt.Errorf(\"virtual machine or template %s must have a snapshot to be used as a linked clone\", props.Config.Uuid)\n\t}\n\t// Root snapshot list can only have a singular element\n\tif len(props.Snapshot.RootSnapshotList) != 1 {\n\t\treturn fmt.Errorf(\"virtual machine or template %s must have exactly one root snapshot (has: %d)\", props.Config.Uuid, len(props.Snapshot.RootSnapshotList))\n\t}\n\t// Check to make sure the root snapshot has no children\n\tif len(props.Snapshot.RootSnapshotList[0].ChildSnapshotList) > 0 {\n\t\treturn fmt.Errorf(\"virtual machine or template %s's root snapshot must not have children\", props.Config.Uuid)\n\t}\n\t// Current snapshot must match root snapshot (this should be the case anyway)\n\tif props.Snapshot.CurrentSnapshot.Value != props.Snapshot.RootSnapshotList[0].Snapshot.Value {\n\t\treturn fmt.Errorf(\"virtual machine or template %s's current snapshot must match root snapshot\", props.Config.Uuid)\n\t}\n\treturn nil\n}", "reference": "// validateCloneSnapshots checks a VM to make sure it has a single snapshot\n// with no children, to make sure there is no ambiguity when selecting a\n// snapshot for linked clones.", "generated": "// Validate that virtual machines or templates which use snapshots for cloning,\n// do so correctly.\n//\n// This checks if there is at least one root snapshot in the virtual machine or\n// template, and then verifies it doesn't contain any child snapshots. It also\n// ensures that the current snapshot matches the root snapshot value"}
{"id": 2893, "code": "func dvsProperties(dvs *object.VmwareDistributedVirtualSwitch) (*mo.VmwareDistributedVirtualSwitch, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\tvar props mo.VmwareDistributedVirtualSwitch\n\tif err := dvs.Properties(ctx, dvs.Reference(), nil, &props); err != nil {\n\t\treturn nil, err\n\t}\n\treturn &props, nil\n}", "reference": "// dvsProperties is a convenience method that wraps fetching the DVS MO from\n// its higher-level object.", "generated": "// dvsProperties returns properties for given DVS object.\n//\n// If there is no property available then it will return nil along with any errors that occurred during execution."}
{"id": 2907, "code": "func (r *Subresource) Hash() int {\n\thf := schema.HashResource(&schema.Resource{Schema: r.schema})\n\treturn hf(r.data)\n}", "reference": "// Hash calculates a set hash for the current data. If you want a hash for\n// error reporting a device address, it's probably a good idea to run this at\n// the beginning of a run as any set calls will change the value this\n// ultimately calculates.", "generated": "// Hash returns hash value for this resource instance\n//\n// This is used to identify resources in cache or store them by their unique values.\n //\n// Note that it's possible to get different hashes if data changes but doesn't change type,\n// because types can be changed without changing structure of object itself. For example,"}
{"id": 2919, "code": "func createSCSIController(l *object.VirtualDeviceList, ct string, st string) ([]types.BaseVirtualDeviceConfigSpec, error) {\n\tnc, err := l.CreateSCSIController(ct)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnc.(types.BaseVirtualSCSIController).GetVirtualSCSIController().SharedBus = types.VirtualSCSISharing(st)\n\tcspec, err := object.VirtualDeviceList{nc}.ConfigSpec(types.VirtualDeviceConfigSpecOperationAdd)\n\t*l = applyDeviceChange(*l, cspec)\n\treturn cspec, err\n}", "reference": "// createSCSIController creates a new SCSI controller of the specified type and\n// sharing mode.", "generated": "// CreateSCSIController creates new virtual SCSI controller in specified device list.\n//\n// Args: \n//   - l (virtual Device List): Virtual Device List to add the SCSCI Controller into.\n//   - ct (string): Name for the virtual SCSI controller.\n//   - st (string): Shared bus name"}
{"id": 2933, "code": "func resourceVSphereComputeClusterVMDependencyRuleFetchObjects(\n\tmeta interface{},\n\tclusterID string,\n\tkey int32,\n) (*object.ClusterComputeResource, int32, error) {\n\tclient, err := resourceVSphereComputeClusterVMDependencyRuleClient(meta)\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\n\tcluster, err := clustercomputeresource.FromID(client, clusterID)\n\tif err != nil {\n\t\treturn nil, 0, fmt.Errorf(\"cannot locate cluster: %s\", err)\n\t}\n\n\treturn cluster, key, nil\n}", "reference": "// resourceVSphereComputeClusterVMDependencyRuleFetchObjects fetches the \"objects\"\n// for a cluster rule. This is currently just the cluster object as the rule\n// key a static value and a pass-through - this is to keep its workflow\n// consistent with other cluster-dependent resources that derive from\n// ArrayUpdateSpec that have managed object as keys, such as VM and host\n// overrides.", "generated": "// Fetch objects for dependency rule based on given metadata.\n//\n// This method is used to fetch required resources from vSphere client when creating or updating a compute resource in order to create dependencies between them. The result will be returned along with its index which can be passed back into this method if needed. If there's any"}
{"id": 2938, "code": "func resourceVSphereDatastoreClusterReadCustomAttributes(d *schema.ResourceData, meta interface{}, pod *object.StoragePod) error {\n\tclient := meta.(*VSphereClient).vimClient\n\t// Read custom attributes\n\tif customattribute.IsSupported(client) {\n\t\tlog.Printf(\"[DEBUG] %s: Reading custom attributes\", resourceVSphereDatastoreClusterIDString(d))\n\t\tprops, err := storagepod.Properties(pod)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcustomattribute.ReadFromResource(client, props.Entity(), d)\n\t} else {\n\t\tlog.Printf(\"[DEBUG] %s: Custom attributes unsupported on this connection, skipping\", resourceVSphereDatastoreClusterIDString(d))\n\t}\n\n\treturn nil\n}", "reference": "// resourceVSphereDatastoreClusterReadCustomAttributes reads the custom\n// attributes for vsphere_datastore_cluster.", "generated": "//\n// Reads any additional properties from Storage Pod that may be stored in its entity.\n //\n// This is used to support storing extra data about each Storage Pod for later use,\n// such as when we need to store it along side other objects or retrieve specific values.\n //\n// Note: The client must have supported custom attribute"}
{"id": 2958, "code": "func flattenStorageDrsOptionSpec(d *schema.ResourceData, opts []types.BaseOptionValue) error {\n\tm := make(map[string]interface{})\n\tfor _, opt := range opts {\n\t\tm[opt.GetOptionValue().Key] = opt.GetOptionValue().Value\n\t}\n\n\treturn d.Set(\"sdrs_advanced_options\", m)\n}", "reference": "// flattenStorageDrsOptionSpec saves a StorageDrsOptionSpec into the supplied\n// ResourceData.", "generated": "// Flatten StorageDRS option spec to resource data format.\n//\n// This method is used when creating or updating resources from API calls,\n// where we need to convert options into JSON object that can be serialized by\n// client library. It returns nil if there's no storage drs advanced options set in\n// api"}
{"id": 2965, "code": "func diskApplyOperationDelete(\n\tindex int,\n\toldData map[string]interface{},\n\tnewDataSet []interface{},\n\tc *govmomi.Client,\n\td *schema.ResourceData,\n\tl *object.VirtualDeviceList,\n\tspec *[]types.BaseVirtualDeviceConfigSpec,\n) error {\n\tdidx := -1\n\tfor ni, ne := range newDataSet {\n\t\tnewData := ne.(map[string]interface{})\n\t\tvar name string\n\t\tvar err error\n\t\tif name, err = diskLabelOrName(newData); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif (name == diskDeletedName || name == diskDetachedName) && oldData[\"uuid\"] == newData[\"uuid\"] {\n\t\t\tdidx = ni\n\t\t\tbreak\n\t\t}\n\t}\n\tif didx < 0 {\n\t\t// Deleted entry not found\n\t\treturn nil\n\t}\n\tr := NewDiskSubresource(c, d, oldData, nil, index)\n\tdspec, err := r.Delete(*l)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"%s: %s\", r.Addr(), err)\n\t}\n\t*l = applyDeviceChange(*l, dspec)\n\t*spec = append(*spec, dspec...)\n\treturn nil\n}", "reference": "// diskApplyOperationDelete is an inner-loop helper for disk deletion\n// operations.", "generated": "// Apply operation to delete virtual device from list. This is used when we need to remove it after deleting its parent resource.\n//\n// Args:\n//   c     client instance for connection to vCenter server\n//   d    current data object that contains information about deleted item\n//   l      existing Virtual Device List"}
{"id": 2974, "code": "func (r *DiskSubresource) Delete(l object.VirtualDeviceList) ([]types.BaseVirtualDeviceConfigSpec, error) {\n\tlog.Printf(\"[DEBUG] %s: Beginning delete\", r)\n\tdisk, err := r.findVirtualDisk(l, false)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot find disk device: %s\", err)\n\t}\n\tdeleteSpec, err := object.VirtualDeviceList{disk}.ConfigSpec(types.VirtualDeviceConfigSpecOperationRemove)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(deleteSpec) != 1 {\n\t\treturn nil, fmt.Errorf(\"incorrect number of config spec items returned - expected 1, got %d\", len(deleteSpec))\n\t}\n\tif r.Get(\"keep_on_remove\").(bool) || r.Get(\"attach\").(bool) {\n\t\t// Clear file operation so that the disk is kept on remove.\n\t\tdeleteSpec[0].GetVirtualDeviceConfigSpec().FileOperation = \"\"\n\t}\n\tlog.Printf(\"[DEBUG] %s: Device config operations from update: %s\", r, DeviceChangeString(deleteSpec))\n\tlog.Printf(\"[DEBUG] %s: Delete completed\", r)\n\treturn deleteSpec, nil\n}", "reference": "// Delete deletes a vsphere_virtual_machine disk sub-resource.", "generated": "//\n// This method deletes all virtual disks in this list if they have been removed by their parent VirtualMachine or other devices. The DiskSubresources must be configured to keep them when deleted for this to work correctly. If there's more than one item then it will return only the first one because we don't know which"}
{"id": 2979, "code": "func (r *DiskSubresource) String() string {\n\tp := diskPathOrName(r.data)\n\tif p == \"\" {\n\t\tp = \"<unknown>\"\n\t}\n\treturn fmt.Sprintf(\"%s (%s)\", r.Subresource.String(), p)\n}", "reference": "// String prints out the disk sub-resource's information including the ID at\n// time of instantiation, the path of the disk, and the current device\n// key and address.", "generated": "// DiskSubresource returns human-readable representation for this sub-resource.\n//\n// This is used in error messages to provide more context about which\n// resource was affected by the operation.  The value returned will be\n// empty if there's no specific path or name associated with this sub-\n// resource."}
{"id": 2993, "code": "func hostNetworkSystemFromHostSystem(hs *object.HostSystem) (*object.HostNetworkSystem, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\treturn hs.ConfigManager().NetworkSystem(ctx)\n}", "reference": "// hostNetworkSystemFromHostSystem locates a HostNetworkSystem from a specified\n// HostSystem.", "generated": "// Host Network System from Host system\n//\n// This method returns network configuration for given host system.\n //\n// If there is no config manager available then it will return nil,\n// if there is any other errors that can be returned by Config Manager's methods - they should be passed to caller directly."}
{"id": 3011, "code": "func (b *EnvironmentBrowser) QueryConfigOptionDescriptor(ctx context.Context) ([]types.VirtualMachineConfigOptionDescriptor, error) {\n\treq := types.QueryConfigOptionDescriptor{\n\t\tThis: b.Reference(),\n\t}\n\tres, err := methods.QueryConfigOptionDescriptor(ctx, b.Client(), &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn res.Returnval, nil\n}", "reference": "// QueryConfigOptionDescriptor returns a list the list of ConfigOption keys\n// available on the environment that this browser targets. The keys can be used\n// as query options for DefaultDevices and other functions, facilitating the\n// specification of results specific to a certain VM version.", "generated": "// Queries configuration options for virtual machines in this environment.\n//\n// Returns all available config option descriptors or returns nil if there is no such support."}
{"id": 3033, "code": "func lookupAddrs(svc *compute.Service, project, zone, tag string) ([]string, error) {\n\tvar addrs []string\n\tf := func(page *compute.InstanceList) error {\n\t\tfor _, v := range page.Items {\n\t\t\tif len(v.NetworkInterfaces) == 0 || v.NetworkInterfaces[0].NetworkIP == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor _, t := range v.Tags.Items {\n\t\t\t\tif t == tag {\n\t\t\t\t\taddrs = append(addrs, v.NetworkInterfaces[0].NetworkIP)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tcall := svc.Instances.List(project, zone)\n\tif err := call.Pages(oauth2.NoContext, f); err != nil {\n\t\treturn nil, err\n\t}\n\treturn addrs, nil\n}", "reference": "// lookupAddrs retrieves the private ip addresses of all instances in a given\n// project and zone which have a matching tag value.", "generated": "//lookupAddrs returns all instances in the given zone that have this network interface tagged.\n//\n//This is used to find which instance has the desired IP address assigned,\n//and then get its name from Compute API's Instance List method. This can be useful when using Cloud SDK for Google APIs client library because it doesn"}
{"id": 3055, "code": "func virtualMachinesForTag(ctx context.Context, client *vSphereClient, id string) ([]*object.VirtualMachine, error) {\n\tlogger.Printf(\"[DEBUG] Locating all virtual machines under tag ID %q\", id)\n\n\tvar vms []*object.VirtualMachine\n\n\tobjs, err := client.TagsClient.ListAttachedObjects(ctx, id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor i, obj := range objs {\n\t\tswitch {\n\t\tcase obj.Type == nil || obj.ID == nil:\n\t\t\tlogger.Printf(\"[WARN] Discovered object at index %d has either no ID or type\", i)\n\t\t\tcontinue\n\t\tcase *obj.Type != \"VirtualMachine\":\n\t\t\tlogger.Printf(\"[DEBUG] Discovered object ID %q is not a virutal machine\", *obj.ID)\n\t\t\tcontinue\n\t\t}\n\t\tvm, err := virtualMachineFromMOID(ctx, client.VimClient, *obj.ID)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error locating virtual machine with ID %q: %s\", *obj.ID, err)\n\t\t}\n\t\tvms = append(vms, vm)\n\t}\n\n\tlogger.Printf(\"[DEBUG] Discovered virtual machines: %s\", virtualMachineNames(vms))\n\treturn vms, nil\n}", "reference": "// virtualMachinesForTag discovers all of the virtual machines that match a\n// specific tag ID and returns their higher level helper objects.", "generated": "// Find all Virtual Machines that have been attached to this Tag.\n//\n// This method returns any number of VM's which may be zero if there are none,\n// but it will never return more than one per request due to the limit set by\n// List Attached Objects API call.  The result list contains only those"}
{"id": 3071, "code": "func (ctx *Context) RemoteAddr() string {\n\taddr := ctx.Req.Header.Get(\"X-Real-IP\")\n\tif len(addr) == 0 {\n\t\taddr = ctx.Req.Header.Get(\"X-Forwarded-For\")\n\t\tif addr == \"\" {\n\t\t\taddr = ctx.Req.RemoteAddr\n\t\t\tif i := strings.LastIndex(addr, \":\"); i > -1 {\n\t\t\t\taddr = addr[:i]\n\t\t\t}\n\t\t}\n\t}\n\treturn addr\n}", "reference": "// RemoteAddr returns more real IP address.", "generated": "// Return remote address from header or request if it is empty.\n//\n// Note: This method returns IP addresses in format \"192.168.2.3\" for local requests,\n// while returning \"127.0.0.1\" when running behind proxy server."}
{"id": 3085, "code": "func (ctx *Context) GetCookie(name string) string {\n\tcookie, err := ctx.Req.Cookie(name)\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\tval, _ := url.QueryUnescape(cookie.Value)\n\treturn val\n}", "reference": "// GetCookie returns given cookie value from request header.", "generated": "// Returns cookie value for given name or empty if it is missing in cookies.\n//\n// Note: This method returns unescaped query parameter values which may be different from original URL parameters due to security reasons."}
{"id": 3090, "code": "func (ctx *Context) GetSecureCookie(key string) (string, bool) {\n\treturn ctx.GetSuperSecureCookie(defaultCookieSecret, key)\n}", "reference": "// GetSecureCookie returns given cookie value from request header with default secret string.", "generated": "// Returns secure cookie value for given name or returns empty if it's\n// unknown.\n//\n// If there is no such cookie in context then return false to indicate that\n// this method was called incorrectly."}
{"id": 3092, "code": "func (ctx *Context) GetSuperSecureCookie(secret, name string) (string, bool) {\n\tval := ctx.GetCookie(name)\n\tif val == \"\" {\n\t\treturn \"\", false\n\t}\n\n\ttext, err := hex.DecodeString(val)\n\tif err != nil {\n\t\treturn \"\", false\n\t}\n\n\tkey := pbkdf2.Key([]byte(secret), []byte(secret), 1000, 16, sha256.New)\n\ttext, err = com.AESGCMDecrypt(key, text)\n\treturn string(text), err == nil\n}", "reference": "// GetSuperSecureCookie returns given cookie value from request header with secret string.", "generated": "// Returns cookie value if it is encrypted using secret key.\n//\n// If encryption fails or decryption error occurs then returns empty string,\n// true indicating that there was some errors during processing."}
{"id": 3127, "code": "func (app *App) ReloadConfig() error {\n\tapp.Lock()\n\tdefer app.Unlock()\n\n\tvar err error\n\tif err = app.configure(); err != nil {\n\t\treturn err\n\t}\n\n\truntime.GOMAXPROCS(app.Config.Common.MaxCPU)\n\n\tapp.Cache.SetMaxSize(app.Config.Cache.MaxSize)\n\tapp.Cache.SetWriteStrategy(app.Config.Cache.WriteStrategy)\n\tapp.Cache.SetTagsEnabled(app.Config.Tags.Enabled)\n\n\tif app.Persister != nil {\n\t\tapp.Persister.Stop()\n\t\tapp.Persister = nil\n\t}\n\n\tif app.Tags != nil {\n\t\tapp.Tags.Stop()\n\t\tapp.Tags = nil\n\t}\n\n\tapp.startPersister()\n\n\tif app.Collector != nil {\n\t\tapp.Collector.Stop()\n\t\tapp.Collector = nil\n\t}\n\n\tapp.Collector = NewCollector(app)\n\n\treturn nil\n}", "reference": "// ReloadConfig reloads some settings from config", "generated": "//ReloadConfig reloads all configuration options for this application.\n//\n//This method is intended to be used when changing any option that can't be changed at runtime,\n//such as setting max CPU or cache size.  It will stop any existing collector/persister if they exist,\n//and then restart them after reloading"}
{"id": 3133, "code": "func (d *Duration) UnmarshalText(text []byte) error {\n\tvar err error\n\td.Duration, err = time.ParseDuration(string(text))\n\treturn err\n}", "reference": "// UnmarshalText from TOML", "generated": "// Unmarshals text into duration value.\n//\n// This is used to un marshal string values from JSON or YAML data that represent durations in seconds,\n// milliseconds, microseconds, nanoseconds, etc. The format should be one of \"Xs\", \"Yms\",\n// \"Zus\" where X, Y,"}
{"id": 3147, "code": "func (p *Points) Eq(other *Points) bool {\n\tif other == nil {\n\t\treturn false\n\t}\n\tif p.Metric != other.Metric {\n\t\treturn false\n\t}\n\tif p.Data == nil && other.Data == nil {\n\t\treturn true\n\t}\n\tif (p.Data == nil || other.Data == nil) && (p.Data != nil || other.Data != nil) {\n\t\treturn false\n\t}\n\tif len(p.Data) != len(other.Data) {\n\t\treturn false\n\t}\n\tfor i := 0; i < len(p.Data); i++ {\n\t\tif p.Data[i].Value != other.Data[i].Value {\n\t\t\treturn false\n\t\t}\n\t\tif p.Data[i].Timestamp != other.Data[i].Timestamp {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}", "reference": "// Eq points check", "generated": "//Eq checks if two points have equal values for all metrics.\n//\n//This is used to check whether two Points objects represent the same data point,\n//or at least that they share the exact same metric names and value sets. This can be useful in cases where we need to compare multiple Point instances without having access to"}
{"id": 3152, "code": "func (app *App) Restore(storeFunc func(*points.Points), path string, rps int) {\n\tif rps > 0 {\n\t\tticker := persister.NewThrottleTicker(rps)\n\t\tdefer ticker.Stop()\n\n\t\tthrottledStoreFunc := func(p *points.Points) {\n\t\t\tfor i := 0; i < len(p.Data); i++ {\n\t\t\t\t<-ticker.C\n\t\t\t}\n\t\t\tstoreFunc(p)\n\t\t}\n\n\t\tapp.RestoreFromDir(path, throttledStoreFunc)\n\t} else {\n\t\tapp.RestoreFromDir(path, storeFunc)\n\t}\n}", "reference": "// Restore from dump.path", "generated": "// Restores points from directory using given storage functions for each point.\n//\n// If rps is greater than zero then it will throttle storing to that rate per second,\n// otherwise no throtling occurs. The default value is 1 which means there's no\n// restriction at all."}
{"id": 3183, "code": "func (client *Client) CreateComment(handle, message string) (*Comment, error) {\n\tvar out reqComment\n\tcomment := Comment{Message: String(message)}\n\tif len(handle) > 0 {\n\t\tcomment.Handle = String(handle)\n\t}\n\tif err := client.doJsonRequest(\"POST\", \"/v1/comments\", &comment, &out); err != nil {\n\t\treturn nil, err\n\t}\n\treturn out.Comment, nil\n}", "reference": "// CreateComment adds a new comment to the system.", "generated": "// Creates new comments for given handle or handles if provided.\n//\n// Returns created comment object in case it was successfully created,\n// otherwise returns nil along with any errors that occurred during creation process."}
{"id": 3185, "code": "func (client *Client) EditComment(id int, handle, message string) error {\n\tcomment := Comment{Message: String(message)}\n\tif len(handle) > 0 {\n\t\tcomment.Handle = String(handle)\n\t}\n\treturn client.doJsonRequest(\"PUT\", fmt.Sprintf(\"/v1/comments/%d\", id),\n\t\t&comment, nil)\n}", "reference": "// EditComment changes the message and possibly handle of a particular comment.", "generated": "// edit comments for given user\n//\n// Args:\n//   - id    ID of comment to be edited.\n//   - handle Handle name or email address that is associated with this comment.\n//     If empty then all users can see it.\n//   - message Message text which will replace existing one if exists,"}
{"id": 3254, "code": "func (c *Check) GetTimestampOk() (string, bool) {\n\tif c == nil || c.Timestamp == nil {\n\t\treturn \"\", false\n\t}\n\treturn *c.Timestamp, true\n}", "reference": "// GetTimestampOk returns a tuple with the Timestamp field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Get Timestamp Ok returns whether it is okay to get timestamp from check's internal state.\n//\n// If this method return false then there might be some issues in checking process,\n// such as missing or invalid data for example. In that case user should handle error themselves."}
{"id": 3256, "code": "func (c *Comment) GetRelatedId() int {\n\tif c == nil || c.RelatedId == nil {\n\t\treturn 0\n\t}\n\treturn *c.RelatedId\n}", "reference": "// GetRelatedId returns the RelatedId field if non-nil, zero value otherwise.", "generated": "// Return related id if exists else return zero.\n//\n// Note: This method is used to get relationship between comments in same thread,\n// but it's only valid for threads where there is at least one parent or child comment."}
{"id": 3292, "code": "func (d *Downtime) GetRecurrence() Recurrence {\n\tif d == nil || d.Recurrence == nil {\n\t\treturn Recurrence{}\n\t}\n\treturn *d.Recurrence\n}", "reference": "// GetRecurrence returns the Recurrence field if non-nil, zero value otherwise.", "generated": "// GetRecurrence returns recurrence for this downtime if it exists.\n//\n// If no recurrence is set then return default value which will be empty string in case of Downtimes without any recurrences."}
{"id": 3293, "code": "func (d *Downtime) GetRecurrenceOk() (Recurrence, bool) {\n\tif d == nil || d.Recurrence == nil {\n\t\treturn Recurrence{}, false\n\t}\n\treturn *d.Recurrence, true\n}", "reference": "// GetRecurrenceOk returns a tuple with the Recurrence field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetRecurrence returns whether this downtime has recurrence set,\n// along with its value.\n//\n// If there is no recurrence then it will return false for both values."}
{"id": 3310, "code": "func (g *Graph) GetDefinition() GraphDefinition {\n\tif g == nil || g.Definition == nil {\n\t\treturn GraphDefinition{}\n\t}\n\treturn *g.Definition\n}", "reference": "// GetDefinition returns the Definition field if non-nil, zero value otherwise.", "generated": "// Return graph definition if it exists or empty otherwise.\n//\n// This method is used to get default value for graph definitions in case they were set after creation."}
{"id": 3320, "code": "func (g *GraphDefinitionMarker) GetValOk() (json.Number, bool) {\n\tif g == nil || g.Val == nil {\n\t\treturn \"\", false\n\t}\n\treturn *g.Val, true\n}", "reference": "// GetValOk returns a tuple with the Val field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Return value if this marker is valid or empty otherwise.\n//\n// This method returns json.Number for values that can be serialized to JSON,\n// but it will return zero string in case there's no number at all."}
{"id": 3325, "code": "func (g *GraphDefinitionRequest) GetStacked() bool {\n\tif g == nil || g.Stacked == nil {\n\t\treturn false\n\t}\n\treturn *g.Stacked\n}", "reference": "// GetStacked returns the Stacked field if non-nil, zero value otherwise.", "generated": "// Returns whether this graph definition is stacked or flat.\n//\n// This method returns true if stackable graphs have been defined for all nodes in the graph,\n// otherwise it will return false.  If there's any uncertainty about whether a node should be\n// considered stackable then set Stack to False explicitly."}
{"id": 3343, "code": "func (h *HostActionMute) GetEndTime() string {\n\tif h == nil || h.EndTime == nil {\n\t\treturn \"\"\n\t}\n\treturn *h.EndTime\n}", "reference": "// GetEndTime returns the EndTime field if non-nil, zero value otherwise.", "generated": "// GetEndtime returns end time for host action mute in format 'YYYY-MM-DD HH:MM'. If there is no end date set then it will return empty string.\n//\n// Note that this method should be called only after HostAction has been created or updated successfully to ensure correct result."}
{"id": 3366, "code": "func (i *IntegrationGCPCreateRequest) GetClientX509CertURL() string {\n\tif i == nil || i.ClientX509CertURL == nil {\n\t\treturn \"\"\n\t}\n\treturn *i.ClientX509CertURL\n}", "reference": "// GetClientX509CertURL returns the ClientX509CertURL field if non-nil, zero value otherwise.", "generated": "// ClientX509CertURL returns URL to download client X.509 certificate from GCP.\n//\n// Note: This method is deprecated since v1.0.2. Use get_client_x509_cert_url instead."}
{"id": 3375, "code": "func (i *IntegrationGCPCreateRequest) HasPrivateKeyID() bool {\n\tif i != nil && i.PrivateKeyID != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasPrivateKeyID returns a boolean if a field has been set.", "generated": "// Returns whether this integration has private key ID set in its configuration.\n//\n// This is used to determine if we need to create or use existing keys for authentication purposes."}
{"id": 3394, "code": "func (m *MetricMetadata) HasStatsdInterval() bool {\n\tif m != nil && m.StatsdInterval != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasStatsdInterval returns a boolean if a field has been set.", "generated": "// Returns whether this metric has StatsD interval information available.\n//\n// This is used to determine if statsd metrics should be collected or sent,\n// regardless of other metadata that may also indicate they can't be collected."}
{"id": 3423, "code": "func (o *Options) GetLockedOk() (bool, bool) {\n\tif o == nil || o.Locked == nil {\n\t\treturn false, false\n\t}\n\treturn *o.Locked, true\n}", "reference": "// GetLockedOk returns a tuple with the Locked field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns whether this option is locked or unlocked.\n//\n// This method returns two values: first it indicates if the options object itself has been locked,\n// second it also provides information about its parent lock status in case there's one set for all\n// Options objects that implement Lockable interface."}
{"id": 3431, "code": "func (o *Options) GetQueryConfig() QueryConfig {\n\tif o == nil || o.QueryConfig == nil {\n\t\treturn QueryConfig{}\n\t}\n\treturn *o.QueryConfig\n}", "reference": "// GetQueryConfig returns the QueryConfig field if non-nil, zero value otherwise.", "generated": "// GetQueryConfig returns query config from options if it exists or default one otherwise.\n//\n// If no query configuration is set in Options then this method will return empty QueryConfig object."}
{"id": 3444, "code": "func (o *Options) GetThresholdWindowsOk() (ThresholdWindows, bool) {\n\tif o == nil || o.ThresholdWindows == nil {\n\t\treturn ThresholdWindows{}, false\n\t}\n\treturn *o.ThresholdWindows, true\n}", "reference": "// GetThresholdWindowsOk returns a tuple with the ThresholdWindows field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetThresholdWindows returns threshold windows if it exists in options else return zero value for Threshold Windows along with False status indicating that option is missing from Options object."}
{"id": 3465, "code": "func (r *Recurrence) GetUntilDateOk() (int, bool) {\n\tif r == nil || r.UntilDate == nil {\n\t\treturn 0, false\n\t}\n\treturn *r.UntilDate, true\n}", "reference": "// GetUntilDateOk returns a tuple with the UntilDate field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetUntilDate returns whether it is possible to get until date from this recurrence rule.\n//\n// If return value indicates that there was no error then returning values will be valid for next call to SetUntilDate or UpdateUntilDate methods."}
{"id": 3475, "code": "func (r *reqComment) HasComment() bool {\n\tif r != nil && r.Comment != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasComment returns a boolean if a field has been set.", "generated": "// Returns whether this request has any comments attached to it.\n//\n// This is used by clients when they need to know if there's anything for them\n// to handle in their callback handler.  If no comments exist then nothing will be passed into the client's callback."}
{"id": 3483, "code": "func (r *reqGetTags) GetTagsOk() (TagMap, bool) {\n\tif r == nil || r.Tags == nil {\n\t\treturn TagMap{}, false\n\t}\n\treturn *r.Tags, true\n}", "reference": "// GetTagsOk returns a tuple with the Tags field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Get Tags Ok returns tags if they exist or empty tag map otherwise.\n//\n// This method is used to check whether there were any errors during request processing,\n// but it doesn't return error message in case of success. If no tags have been found then\n// this method will always succeed without returning anything except for"}
{"id": 3485, "code": "func (r *Rule) GetThreshold() json.Number {\n\tif r == nil || r.Threshold == nil {\n\t\treturn \"\"\n\t}\n\treturn *r.Threshold\n}", "reference": "// GetThreshold returns the Threshold field if non-nil, zero value otherwise.", "generated": "// GetThreshold returns threshold value for this rule if it exists.\n//\n// If there is no Threshold set then return empty string."}
{"id": 3492, "code": "func (s *Screenboard) GetSharedOk() (bool, bool) {\n\tif s == nil || s.Shared == nil {\n\t\treturn false, false\n\t}\n\treturn *s.Shared, true\n}", "reference": "// GetSharedOk returns a tuple with the Shared field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Shared returns whether this screen is shared or not.\n//\n// This will return true if it's being used by another process,\n// otherwise it'll be false.  However, even when sharing isn't in use,\n// there may still be some residual state left behind from previous usage.\n //\n// Note that while this"}
{"id": 3495, "code": "func (s *Series) GetAggrOk() (string, bool) {\n\tif s == nil || s.Aggr == nil {\n\t\treturn \"\", false\n\t}\n\treturn *s.Aggr, true\n}", "reference": "// GetAggrOk returns a tuple with the Aggr field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetAggrOk returns whether this series has any aggregation functions applied to it.\n//\n// This is used by some clients when they need to know if there's anything that needs\n// doing before sending their query request.  If no aggs have been set then return False,\n// otherwise return True along with the"}
{"id": 3518, "code": "func (s *SyntheticsDevice) GetIsMobileOk() (bool, bool) {\n\tif s == nil || s.IsMobile == nil {\n\t\treturn false, false\n\t}\n\treturn *s.IsMobile, true\n}", "reference": "// GetIsMobileOk returns a tuple with the IsMobile field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// IsMobile returns whether this device is mobile or not.\n//\n// Returns error if there's no data available for this property."}
{"id": 3522, "code": "func (s *SyntheticsDevice) HasUserAgent() bool {\n\tif s != nil && s.UserAgent != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasUserAgent returns a boolean if a field has been set.", "generated": "// Returns whether this device has user agent information set.\n//\n// This is used to determine if we need to add any additional headers when making requests for synthetic devices that have no User-Agent header."}
{"id": 3534, "code": "func (s *SyntheticsOptions) HasMinLocationFailed() bool {\n\tif s != nil && s.MinLocationFailed != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasMinLocationFailed returns a boolean if a field has been set.", "generated": "// HasMinLocationFailed returns whether Min Location failed or not.\n//\n// This is used to determine if we need to retry the location request for this synthetic,\n// which can help avoid unnecessary retries in case it's already been done successfully."}
{"id": 3541, "code": "func (s *SyntheticsRequest) GetMethod() string {\n\tif s == nil || s.Method == nil {\n\t\treturn \"\"\n\t}\n\treturn *s.Method\n}", "reference": "// GetMethod returns the Method field if non-nil, zero value otherwise.", "generated": "// Method returns method for this request.\n//\n// If set to null or empty then no HTTP methods will be sent in the header,\n// otherwise it is included without any modification.  This can only contain one character which must be 'GET', 'POST',\n// 'PUT' or 'DELETE'."}
{"id": 3548, "code": "func (s *SyntheticsTest) GetConfigOk() (SyntheticsConfig, bool) {\n\tif s == nil || s.Config == nil {\n\t\treturn SyntheticsConfig{}, false\n\t}\n\treturn *s.Config, true\n}", "reference": "// GetConfigOk returns a tuple with the Config field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetConfig returns config if it exists or is set to default value.\n//\n// Returns error when there's no configuration available for this test."}
{"id": 3551, "code": "func (s *SyntheticsTest) GetDeletedAtOk() (string, bool) {\n\tif s == nil || s.DeletedAt == nil {\n\t\treturn \"\", false\n\t}\n\treturn *s.DeletedAt, true\n}", "reference": "// GetDeletedAtOk returns a tuple with the DeletedAt field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Get DeletedAt returns data about deleted resource.\n//\n// Use this method to get the deletion time for the given synthetics test,\n// if it has been deleted. If no such synthetic exists or is still active then\n// return error status code 404. The returned value will be in ISO format."}
{"id": 3577, "code": "func (t *ThresholdCount) GetTimeAggregator() string {\n\tif t == nil || t.TimeAggregator == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.TimeAggregator\n}", "reference": "// GetTimeAggregator returns the TimeAggregator field if non-nil, zero value otherwise.", "generated": "// Return time aggregator for this threshold count if it exists else return empty string.\n//\n// This is used to determine how often we should check the value in order to get accurate results,\n// especially when using rate limits or other types that have variable intervals between checks."}
{"id": 3579, "code": "func (t *ThresholdCount) HasTimeAggregator() bool {\n\tif t != nil && t.TimeAggregator != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasTimeAggregator returns a boolean if a field has been set.", "generated": "// Returns whether this Threshold has time aggregator or not.\n//\n// Time aggregators can be used to calculate statistics over intervals,\n// such as average values for each minute in a day. This is useful when\n// calculating thresholds that depend on historical data. However, it's also\n// more expensive than using simple counters"}
{"id": 3582, "code": "func (t *ThresholdCount) HasUnknown() bool {\n\tif t != nil && t.Unknown != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasUnknown returns a boolean if a field has been set.", "generated": "// Returns whether this Threshold is unknown or if it has been set to be known.\n//\n// This method should only return true when there's no other way for us to know that we're dealing with an unknown threshold,\n// such as in case where the user hasn't specified any value at all.  In general,"}
{"id": 3583, "code": "func (t *ThresholdCount) GetWarning() json.Number {\n\tif t == nil || t.Warning == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.Warning\n}", "reference": "// GetWarning returns the Warning field if non-nil, zero value otherwise.", "generated": "//Get Warning returns warning value if exists else return empty string.\n//\n//Note: This method is used to get threshold count warnings which can be set in ThresholdConfig object."}
{"id": 3589, "code": "func (t *ThresholdWindows) GetRecoveryWindow() string {\n\tif t == nil || t.RecoveryWindow == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.RecoveryWindow\n}", "reference": "// GetRecoveryWindow returns the RecoveryWindow field if non-nil, zero value otherwise.", "generated": "// GetRecoverWindow returns recovery window for threshold windows.\n//\n// If there is no Recovery Window set then it will return empty string."}
{"id": 3597, "code": "func (t *TileDefRequest) HasQueryType() bool {\n\tif t != nil && t.QueryType != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasQueryType returns a boolean if a field has been set.", "generated": "// Returns whether this request has query type set.\n//\n// This method is used to check if there's any query in the tile definition,\n// which can be useful when checking for valid requests or parsing them from\n// HTTP headers. However it doesn't guarantee that the query will actually work\n// because some queries may"}
{"id": 3598, "code": "func (t *TileDefRequest) GetTextFilter() string {\n\tif t == nil || t.TextFilter == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.TextFilter\n}", "reference": "// GetTextFilter returns the TextFilter field if non-nil, zero value otherwise.", "generated": "// Text filter is used to search for tiles by text content.\n//\n// This field can be set using SetTextFilter method or through constructor's parameter. It will override any previous value that was provided. If no value is given it returns empty string."}
{"id": 3604, "code": "func (t *TimeRange) GetLive() bool {\n\tif t == nil || t.Live == nil {\n\t\treturn false\n\t}\n\treturn *t.Live\n}", "reference": "// GetLive returns the Live field if non-nil, zero value otherwise.", "generated": "// Returns whether this time range is live or not.\n//\n// This method returns true if it's possible to get real-time data from this\n// TimeRange object. If there isn't any available data for this time range,\n// then Live will be set to False by default when created. However, some users may"}
{"id": 3606, "code": "func (t *TimeRange) HasLive() bool {\n\tif t != nil && t.Live != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasLive returns a boolean if a field has been set.", "generated": "// Returns whether this time range has live data available.\n//\n// This is always False for historical times ranges because they don't have any\n// real-time values to return. However it can be True if there's some other way\n// that we're getting our hands on current or near-realtime data from another source"}
{"id": 3613, "code": "func (t *TimeseriesRequestStyle) GetLineType() string {\n\tif t == nil || t.LineType == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.LineType\n}", "reference": "// GetLineType returns the LineType field if non-nil, zero value otherwise.", "generated": "// Return line type for this style if it exists otherwise return empty string.\n//\n// This method is used to get value from TimeserieDB request object which represents line type in timeseries data format. If there's no such field then returns empty string."}
{"id": 3626, "code": "func (t *TraceServiceDefinition) GetShowBreakdownOk() (bool, bool) {\n\tif t == nil || t.ShowBreakdown == nil {\n\t\treturn false, false\n\t}\n\treturn *t.ShowBreakdown, true\n}", "reference": "// GetShowBreakdownOk returns a tuple with the ShowBreakdown field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetShowBreakdown returns whether or if this service definition should show breakdowns in its output.\n//\n// This is used to determine how much data will be returned from the API call for each request,\n// which can help reduce network usage when dealing with large requests that have many subrequests."}
{"id": 3631, "code": "func (t *TraceServiceDefinition) GetShowErrors() bool {\n\tif t == nil || t.ShowErrors == nil {\n\t\treturn false\n\t}\n\treturn *t.ShowErrors\n}", "reference": "// GetShowErrors returns the ShowErrors field if non-nil, zero value otherwise.", "generated": "// GetShowErrors returns whether to show errors in this service's logs.\n//\n// This is used by default when logging services using loggers that support\n// showing error messages.  If set to true then all errors will be logged,\n// including those from child processes or other external components."}
{"id": 3702, "code": "func (w *Widget) HasMustShowHits() bool {\n\tif w != nil && w.MustShowHits != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasMustShowHits returns a boolean if a field has been set.", "generated": "// Returns whether this widget must show hits or not.\n//\n// This is used to determine if we need to display any hit data in our UI,\n// even when there aren't actually any results returned from the search query."}
{"id": 3703, "code": "func (w *Widget) GetMustShowLatency() bool {\n\tif w == nil || w.MustShowLatency == nil {\n\t\treturn false\n\t}\n\treturn *w.MustShowLatency\n}", "reference": "// GetMustShowLatency returns the MustShowLatency field if non-nil, zero value otherwise.", "generated": "// Returns whether this widget must show latency information or not.\n//\n// This is used to determine if we need to display any latency data in our UI,\n// such as when displaying network statistics for a specific connection.  If it's true,\n// then all widgets that have MustShowLatency set will be displayed;"}
{"id": 3726, "code": "func (w *Widget) HasTileDef() bool {\n\tif w != nil && w.TileDef != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasTileDef returns a boolean if a field has been set.", "generated": "// Returns whether this widget has defined tile definition or not.\n//\n// This method is used to check if there's any valid tiles in the widget,\n// which can be useful when checking for widgets that have been created from templates."}
{"id": 3747, "code": "func (w *WidgetConditionalFormat) HasImageUrl() bool {\n\tif w != nil && w.ImageUrl != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasImageUrl returns a boolean if a field has been set.", "generated": "// Returns whether this widget has image URL set or not.\n//\n// This method is used to check if there's any condition that requires image url in order to display it."}
{"id": 3762, "code": "func (t *templateData) addArrayType(x *ast.ArrayType, receiverType, fieldName string) {\n\t// TODO: should we make this dynamic? Could handle more cases than string only\n\tvar eltType string\n\tswitch elt := x.Elt.(type) {\n\tcase *ast.Ident:\n\t\teltType = elt.String()\n\tdefault:\n\t\tlogf(\"addArrayType: type %q, field %q: unknown element type: %T %+v; skipping.\", receiverType, fieldName, elt, elt)\n\t\treturn\n\t}\n\n\tt.Accessors = append(t.Accessors, newAccessor(receiverType, fieldName, \"[]\"+eltType, \"nil\"))\n}", "reference": "// addArrayType adds an accessor for a array type for a given receiver and field", "generated": "//\n// Add array access to template data.\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //\n //"}
{"id": 3764, "code": "func (client *Client) UpdateDowntime(downtime *Downtime) error {\n\treturn client.doJsonRequest(\"PUT\", fmt.Sprintf(\"/v1/downtime/%d\", *downtime.Id),\n\t\tdowntime, nil)\n}", "reference": "// UpdateDowntime takes a downtime that was previously retrieved through some method\n// and sends it back to the server.", "generated": "// Updates downtime information for given ID.\n//\n// Returns error if update fails or returns 400 status code from server\n// otherwise it will return empty error value."}
{"id": 3768, "code": "func (k *APIKey) UnmarshalJSON(data []byte) error {\n\ttype Alias APIKey\n\taux := &struct {\n\t\tCreated *string `json:\"created,omitempty\"`\n\t\t*Alias\n\t}{\n\t\tAlias: (*Alias)(k),\n\t}\n\tif err := json.Unmarshal(data, &aux); err != nil {\n\t\treturn err\n\t}\n\n\tif created, err := time.Parse(createdTimeLayout, *aux.Created); err != nil {\n\t\treturn err\n\t} else {\n\t\tk.Created = &created\n\t}\n\n\treturn nil\n}", "reference": "// UnmarshalJSON is a custom method for handling datetime unmarshalling", "generated": "// Unmarshals JSON data into ApiKey object.\n//\n// Note that this method is used to unmarhsal from string format which contains date in ISO 8601 format,\n// so it's necessary to parse it using specific layout for correct conversion."}
{"id": 3770, "code": "func (client *Client) GetAPIKey(key string) (*APIKey, error) {\n\tvar out reqAPIKey\n\tif err := client.doJsonRequest(\"GET\", fmt.Sprintf(\"/v1/api_key/%s\", key), nil, &out); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn out.APIKey, nil\n}", "reference": "// GetAPIKey returns a single API key or error on failure", "generated": "// Returns API Key for given name or ID.\n//\n// If no result is found then returns nil."}
{"id": 3791, "code": "func (t *bufferedObjectStream) WriteObject(obj interface{}) error {\n\tt.mu.Lock()\n\tdefer t.mu.Unlock()\n\tif err := t.codec.WriteObject(t.w, obj); err != nil {\n\t\treturn err\n\t}\n\treturn t.w.Flush()\n}", "reference": "// WriteObject implements ObjectStream.", "generated": "// WriteObject writes object to output stream.\n//\n// Returns any errors that occurred during writing or flushing."}
{"id": 3794, "code": "func (r *Request) SetMeta(v interface{}) error {\n\tb, err := json.Marshal(v)\n\tif err != nil {\n\t\treturn err\n\t}\n\tr.Meta = (*json.RawMessage)(&b)\n\treturn nil\n}", "reference": "// SetMeta sets r.Meta to the JSON representation of v. If JSON\n// marshaling fails, it returns an error.", "generated": "// SetMeta sets meta data for this request.\n//\n// This method is used to set metadata that can be accessed by other components,\n// such as logging or authentication services. The value must implement JSONUnmarshalable.\n //\n// If there's already some Meta in r, it will overwrite any existing values."}
{"id": 3795, "code": "func (r *Response) SetResult(v interface{}) error {\n\tb, err := json.Marshal(v)\n\tif err != nil {\n\t\treturn err\n\t}\n\tr.Result = (*json.RawMessage)(&b)\n\treturn nil\n}", "reference": "// SetResult sets r.Result to the JSON representation of v. If JSON\n// marshaling fails, it returns an error.", "generated": "// SetResult sets result to v which is serialized into JSON format.\n//\n// If there's already data in Result then this will overwrite it,\n// otherwise if there was no previous value for Result, this method returns nil.\n //\n// This should be used when setting values that can't be set directly from the API call"}
{"id": 3804, "code": "func PickID(id ID) CallOption {\n\treturn callOptionFunc(func(r *Request) error {\n\t\tr.ID = id\n\t\treturn nil\n\t})\n}", "reference": "// PickID returns a call option which sets the ID on a request. Care must be\n// taken to ensure there are no conflicts with any previously picked ID, nor\n// with the default sequence ID.", "generated": "//PickID sets the request's ID to use for this option.\n//\n//This is used when calling API methods that require IDs,\n//such as CreateResource or UpdateResource.  If no ID has been set using\n//SetIDs then it will be ignored by any method which requires one."}
{"id": 3863, "code": "func (c *Cursor) Backspace() {\n\ta := c.input\n\ti := c.Position\n\tif i == 0 {\n\t\t// Shrug\n\t\treturn\n\t}\n\tif i == len(a) {\n\t\tc.input = a[:i-1]\n\t} else {\n\t\tc.input = append(a[:i-1], a[i:]...)\n\t}\n\t// now it's pointing to the i+1th element\n\tc.Move(-1)\n}", "reference": "// Backspace removes the rune that precedes the cursor\n//\n// It handles being at the beginning or end of the row, and moves the cursor to\n// the appropriate position.", "generated": "//\n// Move back one character in input string.\n //\n // If we're at start position then nothing happens because there is no previous char.\n //\n // This method moves cursor backwards by one step from current position,\n // so if we were before first letter - after this call our new pos will be zero.\n //\n // Note"}
{"id": 3870, "code": "func (p *Package) Type(name string) (t *Type) {\n\tt, _ = p.Members[name].(*Type)\n\treturn\n}", "reference": "// Type returns the package-level type of the specified name,\n// or nil if not found.\n//", "generated": "// Returns type for given name in package's namespace.\n//\n// If no member is found then nil will be returned."}
{"id": 3892, "code": "func (b *builder) switchStmt(fn *Function, s *ast.SwitchStmt, label *lblock) {\n\t// We treat SwitchStmt like a sequential if-else chain.\n\t// Multiway dispatch can be recovered later by ssautil.Switches()\n\t// to those cases that are free of side effects.\n\tif s.Init != nil {\n\t\tb.stmt(fn, s.Init)\n\t}\n\tvar tag Value = vTrue\n\tif s.Tag != nil {\n\t\ttag = b.expr(fn, s.Tag)\n\t}\n\tdone := fn.newBasicBlock(\"switch.done\")\n\tif label != nil {\n\t\tlabel._break = done\n\t}\n\t// We pull the default case (if present) down to the end.\n\t// But each fallthrough label must point to the next\n\t// body block in source order, so we preallocate a\n\t// body block (fallthru) for the next case.\n\t// Unfortunately this makes for a confusing block order.\n\tvar dfltBody *[]ast.Stmt\n\tvar dfltFallthrough *BasicBlock\n\tvar fallthru, dfltBlock *BasicBlock\n\tncases := len(s.Body.List)\n\tfor i, clause := range s.Body.List {\n\t\tbody := fallthru\n\t\tif body == nil {\n\t\t\tbody = fn.newBasicBlock(\"switch.body\") // first case only\n\t\t}\n\n\t\t// Preallocate body block for the next case.\n\t\tfallthru = done\n\t\tif i+1 < ncases {\n\t\t\tfallthru = fn.newBasicBlock(\"switch.body\")\n\t\t}\n\n\t\tcc := clause.(*ast.CaseClause)\n\t\tif cc.List == nil {\n\t\t\t// Default case.\n\t\t\tdfltBody = &cc.Body\n\t\t\tdfltFallthrough = fallthru\n\t\t\tdfltBlock = body\n\t\t\tcontinue\n\t\t}\n\n\t\tvar nextCond *BasicBlock\n\t\tfor _, cond := range cc.List {\n\t\t\tnextCond = fn.newBasicBlock(\"switch.next\")\n\t\t\t// TODO(adonovan): opt: when tag==vTrue, we'd\n\t\t\t// get better code if we use b.cond(cond)\n\t\t\t// instead of BinOp(EQL, tag, b.expr(cond))\n\t\t\t// followed by If.  Don't forget conversions\n\t\t\t// though.\n\t\t\tcond := emitCompare(fn, token.EQL, tag, b.expr(fn, cond), cond.Pos())\n\t\t\temitIf(fn, cond, body, nextCond)\n\t\t\tfn.currentBlock = nextCond\n\t\t}\n\t\tfn.currentBlock = body\n\t\tfn.targets = &targets{\n\t\t\ttail:         fn.targets,\n\t\t\t_break:       done,\n\t\t\t_fallthrough: fallthru,\n\t\t}\n\t\tb.stmtList(fn, cc.Body)\n\t\tfn.targets = fn.targets.tail\n\t\temitJump(fn, done)\n\t\tfn.currentBlock = nextCond\n\t}\n\tif dfltBlock != nil {\n\t\temitJump(fn, dfltBlock)\n\t\tfn.currentBlock = dfltBlock\n\t\tfn.targets = &targets{\n\t\t\ttail:         fn.targets,\n\t\t\t_break:       done,\n\t\t\t_fallthrough: dfltFallthrough,\n\t\t}\n\t\tb.stmtList(fn, *dfltBody)\n\t\tfn.targets = fn.targets.tail\n\t}\n\temitJump(fn, done)\n\tfn.currentBlock = done\n}", "reference": "// switchStmt emits to fn code for the switch statement s, optionally\n// labelled by label.\n//", "generated": "//\n// This is similar to buildSwitch but it doesn't handle multi-way\n// switches yet. It also handles the special \"default\" branch which\n// should always come last. The result will have all its branches\n// sorted according to their position in the original statement's list.\n //\n// Note: For now"}
{"id": 3913, "code": "func yaml_emitter_flush(emitter *yaml_emitter_t) bool {\n\tif emitter.write_handler == nil {\n\t\tpanic(\"write handler not set\")\n\t}\n\n\t// Check if the buffer is empty.\n\tif emitter.buffer_pos == 0 {\n\t\treturn true\n\t}\n\n\tif err := emitter.write_handler(emitter, emitter.buffer[:emitter.buffer_pos]); err != nil {\n\t\treturn yaml_emitter_set_writer_error(emitter, \"write error: \"+err.Error())\n\t}\n\temitter.buffer_pos = 0\n\treturn true\n}", "reference": "// Flush the output buffer.", "generated": "// Flush writes any remaining data to its writer. If there's no more data,\n// it returns immediately without doing anything else."}
{"id": 3930, "code": "func TCPDialCheck(addr string, timeout time.Duration) Check {\n\treturn func() error {\n\t\tconn, err := net.DialTimeout(\"tcp\", addr, timeout)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn conn.Close()\n\t}\n}", "reference": "// TCPDialCheck returns a Check that checks TCP connectivity to the provided\n// endpoint.", "generated": "//TCPDialCheck checks if there is any connection to given address.\n//\n//This check can be used in case when we need some kind of health checking for network connections,\n//but it's also possible that this method will return false positive result (i.e., even if no one\n//is connected). This"}
{"id": 3934, "code": "func NewMetricsHandler(registry prometheus.Registerer, namespace string) Handler {\n\treturn &metricsHandler{\n\t\thandler:   NewHandler(),\n\t\tregistry:  registry,\n\t\tnamespace: namespace,\n\t}\n}", "reference": "// NewMetricsHandler returns a healthcheck Handler that also exposes metrics\n// into the provided Prometheus registry.", "generated": "// New Metrics handler returns new metrics handler instance.\n//\n// This method creates new instances for each metric type that is registered in\n// provided registerer. Each instance has its own name prefix based on specified\n// namespace parameter. If there's no namespace then default one will be used.\n //\n// Note: this method"}
{"id": 3938, "code": "func (p *Pinger) AddIP(ipaddr string) error {\n\taddr := net.ParseIP(ipaddr)\n\tif addr == nil {\n\t\treturn fmt.Errorf(\"%s is not a valid textual representation of an IP address\", ipaddr)\n\t}\n\tp.mu.Lock()\n\tp.addrs[addr.String()] = &net.IPAddr{IP: addr}\n\tif isIPv4(addr) {\n\t\tp.hasIPv4 = true\n\t} else if isIPv6(addr) {\n\t\tp.hasIPv6 = true\n\t}\n\tp.mu.Unlock()\n\treturn nil\n}", "reference": "// AddIP adds an IP address to Pinger. ipaddr arg should be a string like\n// \"192.0.2.1\".", "generated": "// Adds an IPv4 or IPv6 address to p's list of addresses that it will attempt to ping.\n//\n// If there already exists such an entry for this address in p,\n// then no action occurs; otherwise, one new entry is added.  The return value indicates whether any operation occurred."}
{"id": 3943, "code": "func Substitute(s string, sub map[string]string) (buf string) {\n\tbuf = s\n\tvar keys []string\n\tfor k := range sub {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)\n\n\tfor _, key := range keys {\n\t\tbuf = strings.Replace(buf, key, sub[key], -1)\n\t}\n\treturn\n}", "reference": "// Substitute returns string with superseded all substrings from\n// provided substitution map. Substitution map will be applied in alphabetic\n// order. Many passes, on one substitution another one could apply.", "generated": "// Substitute replaces all occurrences in s for each value given by sub.\n//\n// The values must be unique to avoid infinite recursion when there is more than one replacement needed per substitution."}
{"id": 3945, "code": "func Parse() error {\n\targs := os.Args\n\tif len(args) == 1 {\n\t\treturn nil\n\t}\n\n\t// Global flags.\n\tfset := flag.CommandLine\n\tfset.Usage = Usage\n\tout := fsetOutput(fset)\n\n\tif err := fset.Parse(args[1:]); err != nil {\n\t\treturn err\n\t}\n\n\t// Handle version request.\n\tif f := fset.Lookup(VersionBoolFlag); f != nil {\n\t\tif v, ok := f.Value.(flag.Getter); ok {\n\t\t\t// All values implemented by the flag package implement the flag.Getter interface.\n\t\t\tif b, ok := v.Get().(bool); ok && b {\n\t\t\t\t// The flag was defined as a bool and is set.\n\t\t\t\tprogram := programName(args[0])\n\t\t\t\tfmt.Fprintf(out, \"%s version %s %s/%s\\n\",\n\t\t\t\t\tprogram, buildinfo(),\n\t\t\t\t\truntime.GOOS, runtime.GOARCH)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n\n\t// No cmdflag.\n\tif fset.NArg() == 0 {\n\t\treturn nil\n\t}\n\n\t// Subcommand.\n\tidx := len(args) - fset.NArg()\n\ts := args[idx]\n\targs = args[idx+1:]\n\tfor _, sub := range subs {\n\t\tif sub.name != s {\n\t\t\tcontinue\n\t\t}\n\n\t\tfs, handler := sub.init(out)\n\t\tif err := fs.Parse(args); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn handler(args[len(args)-fs.NArg():]...)\n\t}\n\n\treturn fmt.Errorf(\"%s is not a valid cmdflag\", s)\n}", "reference": "// Parse parses the command line arguments including the global flags and, if any, the cmdflag and its flags.\n//\n// If the VersionBoolFlag is defined as a global boolean flag, then the program version is displayed and the program stops.", "generated": "//\n// Initialize command line parser for go tool commands. This parses all arguments,\n// including any options that may be specified after the main command name (e.g.,\n// \"go run\"). If there's no option or if it doesn't match one in this list then\n// return errors.New(\"invalid argument\") which"}
{"id": 3946, "code": "func (xxh XXHZero) Sum(b []byte) []byte {\n\th32 := xxh.Sum32()\n\treturn append(b, byte(h32), byte(h32>>8), byte(h32>>16), byte(h32>>24))\n}", "reference": "// Sum appends the current hash to b and returns the resulting slice.\n// It does not change the underlying hash state.", "generated": "// Sum returns summing bytes in b to 64-bit hash value.\n//\n// This is similar to xxs.XXHSum but it uses zero initialization for\n// initial values instead of zeros from memory location 0x10000000. It also\n// adds extra bits at end which can be used by other"}
{"id": 3949, "code": "func (xxh *XXHZero) Sum32() uint32 {\n\th32 := uint32(xxh.totalLen)\n\tif h32 >= 16 {\n\t\th32 += rol1(xxh.v1) + rol7(xxh.v2) + rol12(xxh.v3) + rol18(xxh.v4)\n\t} else {\n\t\th32 += prime32_5\n\t}\n\n\tp := 0\n\tn := xxh.bufused\n\tbuf := xxh.buf\n\tfor n := n - 4; p <= n; p += 4 {\n\t\th32 += binary.LittleEndian.Uint32(buf[p:p+4]) * prime32_3\n\t\th32 = rol17(h32) * prime32_4\n\t}\n\tfor ; p < n; p++ {\n\t\th32 += uint32(buf[p]) * prime32_5\n\t\th32 = rol11(h32) * prime32_1\n\t}\n\n\th32 ^= h32 >> 15\n\th32 *= prime32_2\n\th32 ^= h32 >> 13\n\th32 *= prime32_3\n\th32 ^= h32 >> 16\n\n\treturn h32\n}", "reference": "// Sum32 returns the 32 bits Hash value.", "generated": "//Sum32 returns the sum for this XXH object in bytes.\n//\n//Note: This is only valid if totalLength has been set to zero before calling\n//this method. If it's already set then there will be no effect from using this\n//method. The result can also have unexpected values after setting"}
{"id": 3956, "code": "func (z *Writer) Write(buf []byte) (int, error) {\n\tif !z.Header.done {\n\t\tif err := z.writeHeader(); err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t}\n\tif debugFlag {\n\t\tdebug(\"input buffer len=%d index=%d\", len(buf), z.idx)\n\t}\n\n\tzn := len(z.data)\n\tvar n int\n\tfor len(buf) > 0 {\n\t\tif z.idx == 0 && len(buf) >= zn {\n\t\t\t// Avoid a copy as there is enough data for a block.\n\t\t\tif err := z.compressBlock(buf[:zn]); err != nil {\n\t\t\t\treturn n, err\n\t\t\t}\n\t\t\tn += zn\n\t\t\tbuf = buf[zn:]\n\t\t\tcontinue\n\t\t}\n\t\t// Accumulate the data to be compressed.\n\t\tm := copy(z.data[z.idx:], buf)\n\t\tn += m\n\t\tz.idx += m\n\t\tbuf = buf[m:]\n\t\tif debugFlag {\n\t\t\tdebug(\"%d bytes copied to buf, current index %d\", n, z.idx)\n\t\t}\n\n\t\tif z.idx < len(z.data) {\n\t\t\t// Buffer not filled.\n\t\t\tif debugFlag {\n\t\t\t\tdebug(\"need more data for compression\")\n\t\t\t}\n\t\t\treturn n, nil\n\t\t}\n\n\t\t// Buffer full.\n\t\tif err := z.compressBlock(z.data); err != nil {\n\t\t\treturn n, err\n\t\t}\n\t\tz.idx = 0\n\t}\n\n\treturn n, nil\n}", "reference": "// Write compresses data from the supplied buffer into the underlying io.Writer.\n// Write does not return until the data has been written.", "generated": "Write writes out all remaining input into blocks until it's empty or we've reached our limit. The output will always contain at least one complete block if possible. If no other errors occur then this method returns zero indicating that nothing was written."}
{"id": 3959, "code": "func (z *Writer) Close() error {\n\tif !z.Header.done {\n\t\tif err := z.writeHeader(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := z.Flush(); err != nil {\n\t\treturn err\n\t}\n\n\tif debugFlag {\n\t\tdebug(\"writing last empty block\")\n\t}\n\tif err := z.writeUint32(0); err != nil {\n\t\treturn err\n\t}\n\tif !z.NoChecksum {\n\t\tchecksum := z.checksum.Sum32()\n\t\tif debugFlag {\n\t\t\tdebug(\"stream checksum %x\", checksum)\n\t\t}\n\t\tif err := z.writeUint32(checksum); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// Close closes the Writer, flushing any unwritten data to the underlying io.Writer, but does not close the underlying io.Writer.", "generated": "// Write all data to stream then close it.\n//\n// This method writes any remaining bytes in buffer before closing,\n// so that they can be flushed out if there is more writing done after this call.\n //\n// If no errors occur during flushing or checking sum we return nil otherwise."}
{"id": 4014, "code": "func (d *FileSelectDialog) detectPath() {\n\tp := d.currPath\n\tif p == \"\" {\n\t\td.currPath, _ = os.Getwd()\n\t\treturn\n\t}\n\n\tp = filepath.Clean(p)\n\tfor {\n\t\t_, err := os.Stat(p)\n\t\tif err == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tdirUp := filepath.Dir(p)\n\t\tif dirUp == p {\n\t\t\tp, _ = os.Getwd()\n\t\t\tbreak\n\t\t}\n\n\t\tp = dirUp\n\t}\n\td.currPath = p\n}", "reference": "// Tries to find the best fit for the given path.\n// It goes up until it gets into the existing directory.\n// If all fails it returns working directory.", "generated": "//detectPath returns current path if it is empty or doesn't exist,\n//else return cleaned up version of current directory.\n//\n//Note: this method should be called only once in lifetime of FileSelectDialog instance."}
{"id": 4018, "code": "func (d *dbCache) preload(firstRow, rowCount int) {\n\tif firstRow == d.firstRow && rowCount == d.rowCount {\n\t\t// fast path: view area is the same, return immediately\n\t\treturn\n\t}\n\n\t// slow path: refill cache\n\tfNames := []string{\"Jack\", \"Alisa\", \"Richard\", \"Paul\", \"Nicole\", \"Steven\", \"Jane\"}\n\tlNames := []string{\"Smith\", \"Catcher\", \"Stone\", \"White\", \"Black\"}\n\tposts := []string{\"Engineer\", \"Manager\", \"Janitor\", \"Driver\"}\n\tdeps := []string{\"IT\", \"Financial\", \"Support\"}\n\tsalary := []int{40000, 38000, 41000, 32000}\n\n\td.data = make([][]string, rowCount, rowCount)\n\tfor i := 0; i < rowCount; i++ {\n\t\tabsIndex := firstRow + i\n\t\td.data[i] = make([]string, columnInTable, columnInTable)\n\t\td.data[i][0] = fNames[absIndex%len(fNames)]\n\t\td.data[i][1] = lNames[absIndex%len(lNames)]\n\t\td.data[i][2] = fmt.Sprintf(\"%08d\", 100+absIndex)\n\t\td.data[i][3] = posts[absIndex%len(posts)]\n\t\td.data[i][4] = deps[absIndex%len(deps)]\n\t\td.data[i][5] = fmt.Sprintf(\"%d k/year\", salary[absIndex%len(salary)]/1000)\n\t}\n\n\t// do not forget to save the last values\n\td.firstRow = firstRow\n\td.rowCount = rowCount\n}", "reference": "// cache data from a new row span\n// It imitates a random data by selecting values from predefined arrays. Sizes\n// of all arrays should be different to make TableView data look more random", "generated": "//\n// Preload data into database for faster query execution.\n// This method should be called before any queries that use this table,\n// otherwise it will have no effect because there's already some cached rows in memory.\n// The preloaded row count must match the number of columns defined by the SQL statement.\n// If the"}
{"id": 4037, "code": "func PopClip() {\n\tif len(canvas.clipStack) == 0 {\n\t\treturn\n\t}\n\tc := canvas.clipStack[len(canvas.clipStack)-1]\n\tcanvas.clipStack = canvas.clipStack[:len(canvas.clipStack)-1]\n\tSetClipRect(c.x, c.y, c.w, c.h)\n}", "reference": "// PopClip restores saved with PushClip clipping window", "generated": "// PopClip removes last clip from stack if it exists otherwise leaves current state unchanged.\n//\n// This is used to undo clipping operations when needed."}
{"id": 4038, "code": "func InClipRect(x, y int) bool {\n\treturn x >= canvas.clipX && y >= canvas.clipY &&\n\t\tx < canvas.clipX+canvas.clipW &&\n\t\ty < canvas.clipY+canvas.clipH\n}", "reference": "// InClipRect returns true if x and y position is inside current clipping\n// rectangle", "generated": "// Returns true if point is in clip rectangle.\n//\n// This method can be used to check whether drawing or painting should happen inside\n// clipping region defined by canvas.clipX, canvas.clipY,\n// canvas.clippingWidth and canvas.clippingHeight fields."}
{"id": 4049, "code": "func FillRect(x, y, w, h int, r rune) {\n\tx, y, w, h = clip(x, y, w, h)\n\tif w < 1 || y < -1 {\n\t\treturn\n\t}\n\n\tfor yy := y; yy < y+h; yy++ {\n\t\tfor xx := x; xx < x+w; xx++ {\n\t\t\tputCharUnsafe(xx, yy, r)\n\t\t}\n\t}\n}", "reference": "// FillRect paints the area with r character using the current colors", "generated": "// FillRect fills in all pixels within this rectangle.\n//\n// The coordinates (x,y,w,h) must be valid for fillrect to work correctly,\n// but they don't need to match any actual pixel positions if we're filling\n// from outside the screen boundaries. If there's no space left at that point"}
{"id": 4058, "code": "func (l *ListBox) SelectedItemText() string {\n\tif l.currSelection == -1 {\n\t\treturn \"\"\n\t}\n\n\treturn l.items[l.currSelection]\n}", "reference": "// SelectedItemText returns text of currently selected item or empty sting if nothing is\n// selected or ListBox is empty.", "generated": "// Returns text for selected item in listbox if it exists otherwise returns empty string\n//\n// Note: This method is used to get current selection from list box when user interacts with GUI.\n //\n// If there's no active selection then this will return empty string."}
{"id": 4070, "code": "func ColorToString(attr term.Attribute) string {\n\tvar out string\n\n\trawClr := attr & 15\n\tif rawClr < 8 {\n\t\tfor k, v := range colorMap {\n\t\t\tif v == rawClr {\n\t\t\t\tout += k + \" \"\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tif attr&term.AttrBold != 0 {\n\t\tout += \"bold \"\n\t}\n\tif attr&term.AttrUnderline != 0 {\n\t\tout += \"underline \"\n\t}\n\tif attr&term.AttrReverse != 0 {\n\t\tout += \"reverse \"\n\t}\n\n\treturn strings.TrimSpace(out)\n}", "reference": "// ColorToString returns string representation of the attribute", "generated": "// Convert attribute to human-readable format for printing.\n//\n// Note: This is just a simple translation from CLR's attributes,\n// which may be more complex than this conversion suggests."}
{"id": 4074, "code": "func DeactivateControls(parent Control) {\n\tfor _, ctrl := range parent.Children() {\n\t\tif ctrl.Active() {\n\t\t\tctrl.SetActive(false)\n\t\t\tctrl.ProcessEvent(Event{Type: EventActivate, X: 0})\n\t\t}\n\n\t\tDeactivateControls(ctrl)\n\t}\n}", "reference": "// DeactivateControls makes all children of parent inactive", "generated": "// Deactivates all controls in this control group.\n//\n// This method is used to deactivate any child controls when their\n// parents become inactive themselves (i.e., they have been removed from\n// the layout). It also sends out an event for each active child,\n// indicating that it has now lost its activation"}
{"id": 4089, "code": "func (c *CheckBox) SetAllow3State(enable bool) {\n\tif !enable && c.state == 2 {\n\t\tc.state = 0\n\t}\n\tc.allow3state = enable\n}", "reference": "// SetAllow3State sets if ComboBox should use 3 states. If the current\n// state is unknown and one disables Allow3State option then the current\n// value resets to off", "generated": "// Allow3State sets whether this checkbox can be in state 3 or not.\n//\n// If set to true then it is possible for this checkbox to have its value changed from false to true,\n// but if set to false then changing the box's value will always result in one of two states: 1 or"}
{"id": 4109, "code": "func (b *ProgressBar) SecondaryColors() (term.Attribute, term.Attribute) {\n\treturn b.emptyFg, b.emptyBg\n}", "reference": "// SecondaryColors returns text and background colors for empty\n// part of the ProgressBar", "generated": "// Returns secondary colors for use in terminal attributes.\n//\n// This is used to highlight progress bars that have multiple columns or rows,\n// such as when displaying both primary and secondary values at once. The default\n// color scheme uses green for background and yellow for foreground; these can be\n// swapped by calling SetSecondary"}
{"id": 4219, "code": "func NewMemoryKeyCacher(maxKeyAge time.Duration, maxCacheSize int) KeyCacher {\n\treturn &memoryKeyCacher{\n\t\tentries:      map[string]keyCacherEntry{},\n\t\tmaxKeyAge:    maxKeyAge,\n\t\tmaxCacheSize: maxCacheSize,\n\t}\n}", "reference": "// NewMemoryKeyCacher creates a new Keycacher interface with option\n// to set max age of cached keys and max size of the cache.", "generated": "// Create new memory key cachers.\n//\n// This is used to create a simple in-memory cache for keys that don't need\n// persistent storage or caching across multiple nodes. The maximum number\n// of entries will be limited by `maxCacheSize`. If this limit is reached then\n// older items will start"}
{"id": 4226, "code": "func validColor(c string) bool {\n\tvalid := false\n\tif validColors[c] {\n\t\tvalid = true\n\t}\n\treturn valid\n}", "reference": "// validColor will make sure the given color is actually allowed", "generated": "// Valid returns whether c is a color name.\n//\n// This method checks if c matches any known colors in its argument list,\n// but it doesn't check for validity according to CSS specifications or other\n// standards; just that they're recognized by this library's codebase.  It\n// also allows users to"}
{"id": 4230, "code": "func (s *Spinner) Reverse() {\n\ts.lock.Lock()\n\tdefer s.lock.Unlock()\n\tfor i, j := 0, len(s.chars)-1; i < j; i, j = i+1, j-1 {\n\t\ts.chars[i], s.chars[j] = s.chars[j], s.chars[i]\n\t}\n}", "reference": "// Reverse will reverse the order of the slice assigned to the indicator", "generated": "// Reverse reverses all characters in spinner's chars slice.\n//\n// This is used to reverse spinning direction when user wants it\n// for some reason. Note that this will only work if there was ever any spin going on,\n// otherwise calling this method has no effect at all."}
{"id": 4237, "code": "func NewMultiplex(con net.Conn, initiator bool) *Multiplex {\n\tmp := &Multiplex{\n\t\tcon:       con,\n\t\tinitiator: initiator,\n\t\tbuf:       bufio.NewReader(con),\n\t\tchannels:  make(map[streamID]*Stream),\n\t\tclosed:    make(chan struct{}),\n\t\tshutdown:  make(chan struct{}),\n\t\twrTkn:     make(chan struct{}, 1),\n\t\tnstreams:  make(chan *Stream, 16),\n\t}\n\n\tgo mp.handleIncoming()\n\n\tmp.wrTkn <- struct{}{}\n\n\treturn mp\n}", "reference": "// NewMultiplex creates a new multiplexer session.", "generated": "// Create new multiplexer instance.\n//\n// This method creates Multiplex object which is used to handle multiple connections in one go routine.\n //\n// The connection must be non-blocking for this constructor because it will block until first message from client or when all channels are closed.\n //\n// If true then_multiplexer starts itself"}
{"id": 4242, "code": "func (b Box) Round() (lat, lng float64) {\n\tx := maxDecimalPower(b.MaxLat - b.MinLat)\n\tlat = math.Ceil(b.MinLat/x) * x\n\tx = maxDecimalPower(b.MaxLng - b.MinLng)\n\tlng = math.Ceil(b.MinLng/x) * x\n\treturn\n}", "reference": "// Round returns a point inside the box, making an effort to round to minimal\n// precision.", "generated": "//Round returns rounded values for lat and lng.\n//\n//The rounding is done using ceiling to round up if necessary,\n//and then multiplying by 1/10^x where x is the number of decimal places in the input value.\n //\n//This means that when there's only one digit after the decimal point it"}
{"id": 4327, "code": "func (c *Client) DeleteCheckoutKey(account, repo, fingerprint string) error {\n\treturn c.request(\"DELETE\", fmt.Sprintf(\"project/%s/%s/checkout-key/%s\", account, repo, fingerprint), nil, nil, nil)\n}", "reference": "// DeleteCheckoutKey fetches the checkout key for the given project by fingerprint", "generated": "// Deletes checkout key for given repository in specified project.\n//\n// Returns error if request fails or check out key is already deleted\n //\n// Args: \n//   Account - Project owner's username\n//   Repo     - Repository name\n//   Fingerprint - Check-out key hash value\n//\n// Return: Error"}
{"id": 4332, "code": "func (c *Client) Timing(bucket string, value interface{}) {\n\tif c.skip() {\n\t\treturn\n\t}\n\tc.conn.metric(c.prefix, bucket, value, \"ms\", c.rate, c.tags)\n}", "reference": "// Timing sends a timing value to a bucket.", "generated": "// Time metrics for this client.\n//\n// This method is used to record timing metric values in milliseconds,\n// which can be useful when debugging performance issues or monitoring system load."}
{"id": 4333, "code": "func (t Timing) Send(bucket string) {\n\tt.c.Timing(bucket, int(t.Duration()/time.Millisecond))\n}", "reference": "// Send sends the time elapsed since the creation of the Timing.", "generated": "// Sends timing data to the given bucket.\n//\n// This is used for logging purposes only. The timer will be reset when\n// this method returns. If t Duration() > 0ms then it's considered that time has passed since last call,\n// otherwise no log message would have been generated in case of repeated"}
{"id": 4348, "code": "func SpatialEntropy(match match.Match, turns int, shiftCount int) float64 {\n\tvar s, d float64\n\tif match.DictionaryName == \"qwerty\" || match.DictionaryName == \"dvorak\" {\n\t\t//todo: verify qwerty and dvorak have the same length and degree\n\t\ts = float64(len(adjacency.BuildQwerty().Graph))\n\t\td = adjacency.BuildQwerty().CalculateAvgDegree()\n\t} else {\n\t\ts = float64(keyPadStartingPositions)\n\t\td = keyPadAvgDegree\n\t}\n\n\tpossibilities := float64(0)\n\n\tlength := float64(len(match.Token))\n\n\t//TODO: Should this be <= or just < ?\n\t//Estimate the number of possible patterns w/ length L or less with t turns or less\n\tfor i := float64(2); i <= length+1; i++ {\n\t\tpossibleTurns := math.Min(float64(turns), i-1)\n\t\tfor j := float64(1); j <= possibleTurns+1; j++ {\n\t\t\tx := zxcvbnmath.NChoseK(i-1, j-1) * s * math.Pow(d, j)\n\t\t\tpossibilities += x\n\t\t}\n\t}\n\n\tentropy := math.Log2(possibilities)\n\t//add extra entropu for shifted keys. ( % instead of 5 A instead of a)\n\t//Math is similar to extra entropy for uppercase letters in dictionary matches.\n\n\tif S := float64(shiftCount); S > float64(0) {\n\t\tpossibilities = float64(0)\n\t\tU := length - S\n\n\t\tfor i := float64(0); i < math.Min(S, U)+1; i++ {\n\t\t\tpossibilities += zxcvbnmath.NChoseK(S+U, i)\n\t\t}\n\n\t\tentropy += math.Log2(possibilities)\n\t}\n\n\treturn entropy\n}", "reference": "// SpatialEntropy calculates the entropy for spatial matches", "generated": "//SpatialEntropy returns the estimated spatial entropy given a token,\n//number of turns allowed, and maximum shifts.\n//\n//Note that it's assumed here that all dictionaries will use the standard\n//keypad layout which has equal probability of each letter being pressed at any time.\n //\n//The result should only be used when"}
{"id": 4354, "code": "func Null(in []byte, pos int) (int, error) {\n\tswitch in[pos] {\n\tcase 'n':\n\t\treturn expect(in, pos, n...)\n\t\treturn pos + 4, nil\n\tdefault:\n\t\treturn 0, errUnexpectedValue\n\t}\n}", "reference": "// Null verifies the contents of bytes provided is a null starting as pos", "generated": "// Null returns null value if it is present otherwise return position where next character should be expected.\n//\n// This method checks for \"null\" or any other valid characters that can represent null values according to IANA specification,\n// which includes all ASCII letters from A-Z and numbers 1-9. If none of these"}
{"id": 4404, "code": "func (b *Base64) SetBSON(raw bson.Raw) error {\n\tvar m bson.M\n\tif err := raw.Unmarshal(&m); err != nil {\n\t\treturn err\n\t}\n\n\tif data, ok := m[\"data\"].(string); ok {\n\t\t*b = Base64(data)\n\t\treturn nil\n\t}\n\n\treturn errors.New(\"couldn't unmarshal bson raw value as Base64\")\n}", "reference": "// SetBSON sets the Base64 from raw bson data", "generated": "// SetBSON sets base64 encoded string in BSON document to b's content.\n//\n// If it can be decoded frombson Raw then nothing is returned,\n// otherwise an error will be given back."}
{"id": 4413, "code": "func (e *Email) UnmarshalEasyJSON(in *jlexer.Lexer) {\n\tif data := in.String(); in.Ok() {\n\t\t*e = Email(data)\n\t}\n}", "reference": "// UnmarshalEasyJSON sets the Email from a easyjson.Lexer", "generated": "// Unmarshals easy JSON into email object\n//\n// This is used for unmarshaling from string to struct directly.\n// It's faster than using json.Unmarshal but it doesn't support all types,\n// so use this only when possible."}
{"id": 4422, "code": "func (u *IPv6) DeepCopy() *IPv6 {\n\tif u == nil {\n\t\treturn nil\n\t}\n\tout := new(IPv6)\n\tu.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new IPv6.", "generated": "// Deepcopy implements deep copy for IPv6. It is used by default when\n// creating a new instance from another IPv4 or IPv6 object.\n//\n// This method creates a shallow copy of s to create a new IPv6 that shares\n// its underlying data structure but has independent references to all fields."}
{"id": 4452, "code": "func (h *HexColor) DeepCopy() *HexColor {\n\tif h == nil {\n\t\treturn nil\n\t}\n\tout := new(HexColor)\n\th.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new HexColor.", "generated": "// Deepcopy implements deep copy for HexColor. It is used when we need to create\n// multiple copies from one object.\n//\n// Note: This method uses reflection so it may be slower than other methods."}
{"id": 4466, "code": "func (t DateTime) MarshalJSON() ([]byte, error) {\n\tvar w jwriter.Writer\n\tt.MarshalEasyJSON(&w)\n\treturn w.BuildBytes()\n}", "reference": "// MarshalJSON returns the DateTime as JSON", "generated": "// Marshal JSON to binary format for serialization.\n//\n// This method is used when serializing datetime objects into bytes that can be written or stored in files,\n// databases etc. The result will always contain at least one byte which indicates its type."}
{"id": 4474, "code": "func (d *Duration) Scan(raw interface{}) error {\n\tswitch v := raw.(type) {\n\t// TODO: case []byte: // ?\n\tcase int64:\n\t\t*d = Duration(v)\n\tcase float64:\n\t\t*d = Duration(int64(v))\n\tcase nil:\n\t\t*d = Duration(0)\n\tdefault:\n\t\treturn fmt.Errorf(\"cannot sql.Scan() strfmt.Duration from: %#v\", v)\n\t}\n\n\treturn nil\n}", "reference": "// Scan reads a Duration value from database driver type.", "generated": "//\n// Scanner for duration type.\n //\n // This is used to convert values read in by SQL into our internal format,\n // which can be converted back out using Unscan().  The value must already have been\n // parsed correctly so that it's valid integer or string representation."}
{"id": 4491, "code": "func (d *Date) DeepCopy() *Date {\n\tif d == nil {\n\t\treturn nil\n\t}\n\tout := new(Date)\n\td.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new Date.", "generated": "// Deepcopy implements deep copy for Date. It is used by default when\n// creating copies from slices or arrays.\n//\n// Note: This method uses reflection to create a deep copy so it may be slower than\n// using a custom deepcopy function. However, since this is only called internally,\n// we don't"}
{"id": 4522, "code": "func GrepNot(r string) Filter {\n\tre, err := regexp.Compile(r)\n\tif err != nil {\n\t\treturn FilterFunc(func(Arg) error { return err })\n\t}\n\treturn If(func(s string) bool { return !re.MatchString(s) })\n}", "reference": "// GrepNot emits every input x that does not match the regular expression r.", "generated": "// Return filter that returns true if s is NOT in r.\n//\n// This will match any strings which do *not* contain re's pattern,\n// regardless of case or position within the string.  The result\n// should be used to select only those arguments for further processing."}
{"id": 4537, "code": "func FetchVersion(v discovery.ServerVersionInterface) (ret ServerVersion, err error) {\n\tversion, err := v.ServerVersion()\n\tif err != nil {\n\t\treturn ServerVersion{}, err\n\t}\n\treturn ParseVersion(version)\n}", "reference": "// FetchVersion fetches version information from discovery client, and parses", "generated": "// FetchServerVersion returns server version from given interface.\n//\n// This method is used to get current server version in case when it's needed for some reason,\n// but we don't have any specific request or context that requires this information. In such cases,\n// client should use default value which can be set using Set"}
{"id": 4543, "code": "func (n ImageName) RegistryRepoName() string {\n\trepo := n.Repository\n\tif repo == \"\" {\n\t\trepo = \"library\"\n\t}\n\treturn fmt.Sprintf(\"%s/%s\", repo, n.Name)\n}", "reference": "// RegistryRepoName returns the \"repository\" as used in the registry URL", "generated": "// RegisterRepository returns registry repository name for given image.\n//\n// If no Repository is specified in the image then it defaults to library."}
{"id": 4556, "code": "func MarkdownHelper(body string, help HelperContext) (template.HTML, error) {\n\tvar err error\n\tif help.HasBlock() {\n\t\tbody, err = help.Block()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\tb := github_flavored_markdown.Markdown([]byte(body))\n\treturn template.HTML(b), err\n}", "reference": "// Markdown converts the string into HTML using GitHub flavored markdown.", "generated": "//MarkdownHelp returns HTML for markdown text if it exists in body.\n//\n//If there is no block then return empty html or any other valid value that can be used by templates.\n //\n//This helper should always handle errors so they don't propagate to caller."}
{"id": 4565, "code": "func (t *Template) Exec(ctx hctx.Context) (string, error) {\n\terr := t.Parse()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tev := compiler{\n\t\tctx:     ctx,\n\t\tprogram: t.program,\n\t}\n\n\ts, err := ev.compile()\n\treturn s, err\n}", "reference": "// Exec the template using the content and return the results", "generated": "// Execute template using given context.\n//\n// Returns string if execution was successful or any error that occurred during compilation."}
{"id": 4576, "code": "func hasPathPrefix(p string, s map[string]string) bool {\n\tfor prefix := range s {\n\t\tif strings.HasPrefix(p, prefix+\"/\") {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "reference": "// hasPathPrefix returns true if any of s is the prefix of p.", "generated": "// HasPathPrefix checks if p is in any path prefixed by another.\n//\n// This can be used to check for paths that have been added after this object was created,\n// but before it's removed from memory or written out to disk.  It will return true even if\n// there are multiple prefixes (e"}
{"id": 4588, "code": "func (a *Args) similar(r *Args, similar Similarity) bool {\n\tif a.Elided != r.Elided || len(a.Values) != len(r.Values) {\n\t\treturn false\n\t}\n\tif similar == AnyValue {\n\t\treturn true\n\t}\n\tfor i, l := range a.Values {\n\t\tswitch similar {\n\t\tcase ExactFlags, ExactLines:\n\t\t\tif l != r.Values[i] {\n\t\t\t\treturn false\n\t\t\t}\n\t\tdefault:\n\t\t\tif l.IsPtr() != r.Values[i].IsPtr() || (!l.IsPtr() && l != r.Values[i]) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\treturn true\n}", "reference": "// similar returns true if the two Args are equal or almost but not quite\n// equal.", "generated": "// Args returns whether two arguments have values that match each other.\n//\n// This is used to determine if there's any similarity between two args,\n// which can be useful for filtering out duplicate or redundant operations.\n //\n// If both args contain pointers then they must point at exactly the same value in order to return True."}
{"id": 4597, "code": "func (s *Stack) merge(r *Stack) *Stack {\n\t// Assumes similar stacks have the same length.\n\tout := &Stack{\n\t\tCalls:  make([]Call, len(s.Calls)),\n\t\tElided: s.Elided,\n\t}\n\tfor i := range s.Calls {\n\t\tout.Calls[i] = s.Calls[i].merge(&r.Calls[i])\n\t}\n\treturn out\n}", "reference": "// merge merges two similar Stack, zapping out differences.", "generated": "//\n// Merge two stack traces into one. This assumes that both stacks were created from calls to this method in sequence.\n //\n // The resulting stack trace will be longer than either input if they overlap at all. If there is no overlap then it should be equal to each individual stack."}
{"id": 4624, "code": "func (b *base57) stringToNum(s string) (string, error) {\n\tn := big.NewInt(0)\n\n\tfor i := len(s) - 1; i >= 0; i-- {\n\t\tn.Mul(n, big.NewInt(b.alphabet.Length()))\n\n\t\tindex, err := b.alphabet.Index(string(s[i]))\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\n\t\tn.Add(n, big.NewInt(index))\n\t}\n\n\tx := fmt.Sprintf(\"%x\", n)\n\n\tif len(x) < 32 {\n\t\t// Pad the most significant bit (MSG) with 0 (zero) if the string is too short.\n\t\tx = strings.Repeat(\"0\", 32-len(x)) + x\n\t} else if len(x) > 32 {\n\t\treturn \"\", fmt.Errorf(\"UUID length overflow for %q\", s)\n\t}\n\n\treturn fmt.Sprintf(\"%s-%s-%s-%s-%s\", x[0:8], x[8:12], x[12:16], x[16:20], x[20:32]), nil\n}", "reference": "// stringToNum converts a string a number using the given alpabet.", "generated": "//\n// Convert base58 encoded UUID to number format. The result will be padded with zeros from left side until it reaches 64 characters in total,\n// which corresponds to standard Base58 encoding scheme used by Bitcoin network. If there's any errors during conversion process, they'll return along with original input value."}
{"id": 4644, "code": "func (geoIndex *geoIndex) AddEntryAt(point Point) interface{} {\n\tsquare := cellOf(point, geoIndex.resolution)\n\n\tif _, ok := geoIndex.index[square]; !ok {\n\t\tgeoIndex.index[square] = geoIndex.newEntry()\n\t}\n\n\treturn geoIndex.index[square]\n}", "reference": "// AddEntryAt adds an entry if missing, returns the entry at specific position.", "generated": "// Adds point to index at specified resolution level.\n//\n// Returns entry for added square or nil if it already exists in same\n// resolution level. If there is no such entry then returns new one created by\n//.geoIndex.newEntry(). This method should be used when adding points from outside\n// this package."}
{"id": 4662, "code": "func BearingTo(p1, p2 Point) float64 {\n\tdLon := toRadians(p2.Lon() - p1.Lon())\n\n\tlat1 := toRadians(p1.Lat())\n\tlat2 := toRadians(p2.Lat())\n\n\ty := math.Sin(dLon) * math.Cos(lat2)\n\tx := math.Cos(lat1)*math.Sin(lat2) -\n\t\tmath.Sin(lat1)*math.Cos(lat2)*math.Cos(dLon)\n\tbrng := toDegrees(math.Atan2(y, x))\n\n\treturn brng\n}", "reference": "// BearingTo returns the bearing from p1 to p2", "generated": "// Calculate bearing from point 1 to point 2 in degrees.\n//\n// Note: This is based off of the formula for calculating bearings between two points,\n// which assumes that both coordinates have equal weight (i.e., they're equally important).\n //\n// The result will be positive if it's clockwise from north,"}
{"id": 4720, "code": "func AddRelayTransport(ctx context.Context, h host.Host, upgrader *tptu.Upgrader, opts ...RelayOpt) error {\n\tn, ok := h.Network().(tpt.Network)\n\tif !ok {\n\t\treturn fmt.Errorf(\"%v is not a transport network\", h.Network())\n\t}\n\n\tr, err := NewRelay(ctx, h, upgrader, opts...)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// There's no nice way to handle these errors as we have no way to tear\n\t// down the relay.\n\t// TODO\n\tif err := n.AddTransport(r.Transport()); err != nil {\n\t\tlog.Error(\"failed to add relay transport:\", err)\n\t} else if err := n.Listen(r.Listener().Multiaddr()); err != nil {\n\t\tlog.Error(\"failed to listen on relay transport:\", err)\n\t}\n\treturn nil\n}", "reference": "// AddRelayTransport constructs a relay and adds it as a transport to the host network.", "generated": "//\n// Adds a new Relay instance for this Host. This method will return any\n// errors that occur while adding or listening on the relay transport,\n// but it won't attempt to remove the listener from the Transport once\n// added.  The caller must ensure they clean up after themselves when\n// removing listeners in"}
{"id": 4731, "code": "func NewServer() http.Handler {\n\tr := mux.NewRouter()\n\tr.Path(\"/hello\").Methods(\"GET\").HandlerFunc(handleHello)\n\treturn r\n}", "reference": "// NewServer makes a new example server.", "generated": "// Create new server handler for hello endpoint.\n//\n// This returns HTTP router that handles GET request to \"/hello\" path,\n// which calls handleHello method when received."}
{"id": 4742, "code": "func StringFindBetween(s, start, stop string) (between, remainder string, found bool) {\n\tbegin := strings.Index(s, start)\n\tif begin == -1 {\n\t\treturn \"\", s, false\n\t}\n\tbetween = s[begin+len(start):]\n\tend := strings.Index(between, stop)\n\tif end == -1 {\n\t\treturn \"\", s, false\n\t}\n\treturn between[:end], s[begin+len(start)+end+len(stop):], true\n}", "reference": "// StringFindBetween returns the string between the first occurrences of the tokens start and stop.\n// The remainder of the string after the stop token will be returned if found.\n// If the tokens couldn't be found, then the whole string will be returned as remainder.", "generated": "// Find Between returns all text after'start' until before or at'stop'. If neither is present,\n// it will return everything from'start', if only one is given.\n//\n// This can be used to find any substring in another string that contains certain characters.\n //\n// Example: \"Hello world\" ->"}
{"id": 4755, "code": "func HTTPPostJSON(url string, data interface{}) error {\n\tb, err := json.MarshalIndent(data, \"\", \"  \")\n\tif err != nil {\n\t\treturn err\n\t}\n\tresponse, err := http.Post(url, \"application/json\", bytes.NewBuffer(b))\n\tif err == nil && (response.StatusCode < 200 || response.StatusCode > 299) {\n\t\terr = errors.New(response.Status)\n\t}\n\treturn err\n}", "reference": "// HTTPPostJSON marshalles data as JSON\n// and sends it as HTTP POST request to url.\n// If the response status code is not 200 OK,\n// then the status is returned as an error.", "generated": "// POST JSON to url.\n//\n// Returns any error that occurred during the request or if it was successful but had status code outside range [200-399]."}
{"id": 4764, "code": "func FileSize(filename string) int64 {\r\n\tinfo, err := os.Stat(filename)\r\n\tif err != nil {\r\n\t\treturn 0\r\n\t}\r\n\treturn info.Size()\r\n}", "reference": "// FileSize returns the size of a file or zero in case of an error.", "generated": "// Returns file size in bytes\n//\n// If filename is empty or doesn't exist then returns zero.\n //\n// This method can be used to calculate total data sent by client when sending files using HTTP upload."}
{"id": 4781, "code": "func LoadTOMLBytes(conf interface{}, src []byte) error {\n\treturn loadConfigBytes(conf, src, nil, toml.Unmarshal)\n}", "reference": "// LoadTOMLBytes loads TOML bytes", "generated": "// Load TOML bytes into config.\n//\n// This is similar to Load but loads from byte slice instead\n// than string.  The source must be valid TOML data or this will return\n// an error."}
{"id": 4787, "code": "func Crop(img image.Image, c Config) (image.Image, error) {\n\tmaxBounds := c.maxBounds(img.Bounds())\n\tsize := c.computeSize(maxBounds, image.Point{c.Width, c.Height})\n\tcr := c.computedCropArea(img.Bounds(), size)\n\tcr = img.Bounds().Intersect(cr)\n\n\tif c.Options&Copy == Copy {\n\t\treturn cropWithCopy(img, cr)\n\t}\n\tif dImg, ok := img.(subImageSupported); ok {\n\t\treturn dImg.SubImage(cr), nil\n\t}\n\treturn cropWithCopy(img, cr)\n}", "reference": "// Crop retrieves an image that is a\n// cropped copy of the original img.\n//\n// The crop is made given the informations provided in config.", "generated": "// Crop returns a cropped version of the input image.\n//\n// The output is created using either copy or sub-image if possible,\n// otherwise it's copied directly from the original image to avoid memory usage issues for large images.\n //\n// If no options were specified then default values will be used: Copy=copy, Sub"}
{"id": 4788, "code": "func (c Config) computeSize(bounds image.Rectangle, ratio image.Point) (p image.Point) {\n\tif c.Options&Ratio == Ratio {\n\t\t// Ratio option is on, so we take the biggest size available that fit the given ratio.\n\t\tif float64(ratio.X)/float64(bounds.Dx()) > float64(ratio.Y)/float64(bounds.Dy()) {\n\t\t\tp = image.Point{bounds.Dx(), (bounds.Dx() / ratio.X) * ratio.Y}\n\t\t} else {\n\t\t\tp = image.Point{(bounds.Dy() / ratio.Y) * ratio.X, bounds.Dy()}\n\t\t}\n\t} else {\n\t\tp = image.Point{ratio.X, ratio.Y}\n\t}\n\treturn\n}", "reference": "// computeSize retrieve the effective size of the cropped image.\n// It is defined by Height, Width, and Ratio option.", "generated": "//\n// Compute the maximum possible point for the specified rectangle,\n// taking into account any options set in this config object.\n //\n// If no specific ratios have been defined then it will return the full\n// resolution of the input image.  The default value if none has been\n// provided is to use the largest area"}
{"id": 4790, "code": "func NewThen(command string, args ...string) Then {\n\treturn &gitCmd{command: command, args: args}\n}", "reference": "// NewThen creates a new Then command.", "generated": "// Create new then statement.\n//\n// This is used to create a chainable way for commands that need\n// multiple steps in order (like commit).  The first argument will be passed directly,\n// while any additional arguments after it should contain strings representing other git\n// commands or options."}
{"id": 4792, "code": "func (g *gitCmd) Command() string {\n\treturn g.command + \" \" + strings.Join(g.args, \" \")\n}", "reference": "// Command returns the full command as configured in Caddyfile.", "generated": "// Return command to execute\n//\n// This method returns the complete command that will be executed when this cmd is run.\n //\n// The args parameter should contain any arguments passed in from the user's input,\n// which can include options like --help or -v for more information about how to use gitcmd."}
{"id": 4812, "code": "func (r *Repo) pull() error {\n\n\t// if not pulled, perform clone\n\tif !r.pulled {\n\t\treturn r.clone()\n\t}\n\n\t// if latest tag config is set\n\tif r.Branch == latestTag {\n\t\treturn r.checkoutLatestTag()\n\t}\n\n\tparams := append([]string{\"pull\"}, append(r.PullArgs, \"origin\", r.Branch)...)\n\tvar err error\n\tif err = r.gitCmd(params, r.Path); err == nil {\n\t\tr.pulled = true\n\t\tr.lastPull = time.Now()\n\t\tLogger().Printf(\"%v pulled.\\n\", r.URL)\n\t\tr.lastCommit, err = r.mostRecentCommit()\n\t}\n\treturn err\n}", "reference": "// pull performs git pull, or git clone if repository does not exist.", "generated": "//\n// Perform a git pull operation.\n //\n // If this repository has been cloned but hasn't yet had its branch checked out,\n // it will be done here.  Otherwise, only updates to that specific branch's commit hash\n // will trigger another call to check for new commits in this method."}
{"id": 4815, "code": "func (r *Repo) Prepare() error {\n\t// check if directory exists or is empty\n\t// if not, create directory\n\tfs, err := gos.ReadDir(r.Path)\n\tif err != nil || len(fs) == 0 {\n\t\treturn gos.MkdirAll(r.Path, os.FileMode(0755))\n\t}\n\n\t// validate git repo\n\tisGit := false\n\tfor _, f := range fs {\n\t\tif f.IsDir() && f.Name() == \".git\" {\n\t\t\tisGit = true\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif isGit {\n\t\t// check if same repository\n\t\tvar repoURL string\n\t\tif repoURL, err = r.originURL(); err == nil {\n\t\t\tif strings.TrimSuffix(repoURL, \".git\") == strings.TrimSuffix(r.URL.Val(), \".git\") {\n\t\t\t\tr.pulled = true\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"cannot retrieve repo url for %v Error: %v\", r.Path, err)\n\t\t}\n\t\treturn fmt.Errorf(\"another git repo '%v' exists at %v\", repoURL, r.Path)\n\t}\n\treturn fmt.Errorf(\"cannot git clone into %v, directory not empty\", r.Path)\n}", "reference": "// Prepare prepares for a git pull\n// and validates the configured directory", "generated": "//\n// prepare checks that there's no other Git repositories in this path,\n// then creates one if necessary.\n //\n // If another Git repository already exists here it will return an error message indicating which one to use instead."}
{"id": 4819, "code": "func (g *gitCmd) Stdin(stdin io.Reader) {\n\tg.Cmd.Stdin = stdin\n}", "reference": "// Stdin sets the process's standard input.", "generated": "// Set stdio for command to read from stdin.\n//\n// This is used when running commands that don't have any input or output,\n// such as git config --list.  If no reader has been set then it will be ignored."}
{"id": 4831, "code": "func (t TravisHook) handleSignature(r *http.Request, secret string) error {\n\tsignature := r.Header.Get(\"Authorization\")\n\tif signature == \"\" {\n\t\treturn errors.New(\"request sent no authorization signature\")\n\t}\n\tif secret == \"\" {\n\t\tLogger().Print(\"Unable to verify request signature. Secret not set in caddyfile!\\n\")\n\t\treturn nil\n\t}\n\n\tcontent := r.Header.Get(\"Travis-Repo-Slug\") + secret\n\thash := sha256.Sum256([]byte(content))\n\texpectedMac := hex.EncodeToString(hash[:])\n\tif signature != expectedMac {\n\t\tfmt.Println(signature, expectedMac)\n\t\treturn errors.New(\"Invalid authorization header\")\n\t}\n\treturn nil\n}", "reference": "// Check for an authorization signature in the request. Reject if not present. If validation required, check the sha", "generated": "// Handle the authentication for this hook by verifying that it is signed correctly.\n//\n// This method checks if there was any content or headers provided,\n// then verifies whether they were properly authenticated using SHA1 hashing.\n //\n// If everything looks good, return nothing; otherwise, print out some information about why we failed verification."}
{"id": 4833, "code": "func hookName(h hookHandler) string {\n\tfor name, handler := range handlers {\n\t\tif handler == h {\n\t\t\treturn name\n\t\t}\n\t}\n\treturn \"\"\n}", "reference": "// hookName returns the name of the hookHanlder h.", "generated": "// hookName returns the name for given hook if it exists in the list,\n// otherwise return empty string.\n//\n// This is used to avoid duplicate hooks when using multiple plugins at once."}
{"id": 4861, "code": "func (u *URL) Short() string {\n\tif u.Scheme == \"\" {\n\t\treturn \"\"\n\t}\n\n\ts := schemeMap[u.Scheme].Aliases[0]\n\n\tif u.Scheme == \"odbc\" || u.Scheme == \"oleodbc\" {\n\t\tn := u.Proto\n\t\tif v, ok := schemeMap[n]; ok {\n\t\t\tn = v.Aliases[0]\n\t\t}\n\t\ts += \"+\" + n\n\t} else if u.Proto != \"tcp\" {\n\t\ts += \"+\" + u.Proto\n\t}\n\n\ts += \":\"\n\n\tif u.User != nil {\n\t\tif un := u.User.Username(); un != \"\" {\n\t\t\ts += un + \"@\"\n\t\t}\n\t}\n\n\tif u.Host != \"\" {\n\t\ts += u.Host\n\t}\n\n\tif u.Path != \"\" && u.Path != \"/\" {\n\t\ts += u.Path\n\t}\n\n\tif u.Opaque != \"\" {\n\t\ts += u.Opaque\n\t}\n\n\treturn s\n}", "reference": "// Short provides a short description of the user, host, and database.", "generated": "//Short returns short version of URL in format'scheme://host:port/path'. If host or port is empty,\n//the corresponding part will be omitted from result.\n//\n//If user name exists it's added to start of path before colon. The rest of the url remains unchanged."}
{"id": 4873, "code": "func (e *hdbError) Error() string {\n\tif e.stmtNo != -1 {\n\t\treturn fmt.Sprintf(\"SQL %s %d - %s (statement no: %d)\", e.errorLevel, e.errorCode, e.errorText, e.stmtNo)\n\t}\n\treturn fmt.Sprintf(\"SQL %s %d - %s\", e.errorLevel, e.errorCode, e.errorText)\n}", "reference": "// Error implements the Error interface.", "generated": "// Return error message for this hdbError instance\n//\n// If there is more than one statement in the query that caused the error,\n// then return \"Statement number X\" where X is the first non-zero value.\n //\n// This method should be called only once per call to hdb.Error()."}
{"id": 4883, "code": "func StringSize(s string) int {\n\tn := 0\n\tfor _, r := range s {\n\t\tn += RuneLen(r)\n\t}\n\treturn n\n}", "reference": "// StringSize is like Size with a string as parameter.", "generated": "// Return size in bytes for given string.\n//\n// This is used to calculate length when storing strings in binary format,\n// which requires encoding each character into its byte representation before adding up their lengths."}
{"id": 4887, "code": "func On() bool {\n\ttracer.mu.RLock()\n\ton := tracer.on\n\ttracer.mu.RUnlock()\n\treturn on\n}", "reference": "// On returns if tracing methods output is active.", "generated": "// Returns whether tracing is currently enabled or not.\n//\n// This should be used to determine if any operations will result in logging,\n// rather than attempting to log directly which would cause panic when disabled."}
{"id": 4913, "code": "func (r *Reader) ReadUint32() uint32 {\n\tif r.err != nil {\n\t\treturn 0\n\t}\n\tvar n int\n\tn, r.err = io.ReadFull(r.rd, r.b[:4])\n\tr.cnt += n\n\tif r.err != nil {\n\t\treturn 0\n\t}\n\treturn binary.LittleEndian.Uint32(r.b[:4])\n}", "reference": "// ReadUint32 reads and returns an uint32.", "generated": "// Reads a Uint32 from the reader's buffer. If there is no more data to read,\n// returns zero.\n//\n// This method will return any error that occurs while reading into its err field."}
{"id": 4918, "code": "func (r *Reader) ReadCesu8(size int) []byte {\n\tif r.err != nil {\n\t\treturn nil\n\t}\n\tp := make([]byte, size)\n\tvar n int\n\tn, r.err = io.ReadFull(r.rd, p)\n\tr.cnt += n\n\tif r.err != nil {\n\t\treturn nil\n\t}\n\tr.tr.Reset()\n\tif n, _, r.err = r.tr.Transform(p, p, true); r.err != nil { // inplace transformation\n\t\treturn nil\n\t}\n\treturn p[:n]\n}", "reference": "// ReadCesu8 reads a size CESU-8 encoded byte sequence and returns an UTF-8 byte slice.", "generated": "// Reads up to'size' bytes from reader into buffer.\n//\n// Returns error if there is no more data in stream or any other I/O errors occur during reading process."}
{"id": 4923, "code": "func (w *Writer) Write(p []byte) {\n\tif w.err != nil {\n\t\treturn\n\t}\n\tw.wr.Write(p)\n}", "reference": "// Write writes the contents of p.", "generated": "// Writes p to writer's output buffer.\n//\n// If err is set then writes will be ignored until it is reset by calling\n// Reset().  This allows writing while error occurs for example when reading from\n// network connection that has been closed or disconnected."}
{"id": 4938, "code": "func (c *Connector) Locale() string {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\treturn c.locale\n}", "reference": "// Locale returns the locale of the connector.", "generated": "//Locale returns locale name for this connector instance.\n//\n//Note: This method is thread-safe because it always locks the mutex when called,\n//and never releases it until after returning."}
{"id": 4942, "code": "func (c *Connector) SetTLSConfig(tlsConfig *tls.Config) error {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.tlsConfig = tlsConfig\n\treturn nil\n}", "reference": "// SetTLSConfig sets the TLS configuration of the connector.", "generated": "// Sets TLS config for this connector.\n//\n// This method is used to set custom TLS configuration that will be applied when connecting using this Connector instance."}
{"id": 4958, "code": "func Slice(arr []byte, count int) [][]byte {\n\n\tsliceCount := len(arr) / count\n\tresult := make([][]byte, sliceCount)\n\n\tfor i := 0; i < sliceCount; i++ {\n\t\tstart := i * count\n\t\tend := i*count + count\n\n\t\tresult[i] = arr[start:end]\n\t}\n\n\treturn result\n}", "reference": "// Slice is splitting input byte array into slice of subarrays. Each of count length.", "generated": "// Slice splits array into slices based on given length.\n//\n// Args: \n//   - arr : input byte array to be split\n//   - count : number of bytes per each resulting slice\n//\n// Returns: \n//   - Array of sliced arrays (each is size 'count' in length)\n//"}
{"id": 4965, "code": "func Decode(data string) ([]byte,error) {\n\tdata = strings.Replace(data, \"-\", \"+\", -1) // 62nd char of encoding\n\tdata = strings.Replace(data, \"_\", \"/\", -1) // 63rd char of encoding\n\t\n\tswitch(len(data) % 4) { // Pad with trailing '='s\n\t\tcase 0:             // no padding\n\t\tcase 2: data+=\"==\"  // 2 pad chars\n\t\tcase 3:\tdata+=\"=\"   // 1 pad char\t\t\n\t}\n\t\t\n\treturn base64.StdEncoding.DecodeString(data)\n}", "reference": "// Decode decodes base64url string to byte array", "generated": "//Decode decodes encoded bytes to raw byte slice.\n//\n//Note that this is only valid for Base64-encoded text,\n//not binary or other encodings like URL-safe bases64."}
{"id": 4969, "code": "func DerivePBKDF2(password, salt []byte, iterationCount, keyBitLength int, h hash.Hash) []byte {\n\n\tprf := hmac.New(func() hash.Hash { return h }, password)\n\thLen := prf.Size()\n\tdkLen := keyBitLength >> 3 //size of derived key in bytes\n\n\tl := int(math.Ceil(float64(dkLen) / float64(hLen))) // l = CEIL (dkLen / hLen)\n\tr := dkLen - (l-1)*hLen\n\n\t// 1. If dkLen > (2^32 - 1) * hLen, output \"derived key too long\" and stop.\n\tif dkLen > MaxInt {\n\t\tpanic(fmt.Sprintf(\"kdf.DerivePBKDF2: expects derived key size to be not more that (2^32-1) bits, but was requested %v bits.\", keyBitLength))\n\t}\n\n\tdk := make([]byte, 0, dkLen)\n\n\tfor i := 0; i < l; i++ {\n\n\t\tt := f(salt, iterationCount, i+1, prf) // T_l = F (P, S, c, l)\n\n\t\tif i == (l - 1) {\n\t\t\tt = t[:r]\n\t\t} // truncate last block to r bits\n\n\t\tdk = append(dk, t...) // DK = T_1 || T_2 ||  ...  || T_l<0..r-1>\n\t}\n\n\treturn dk\n}", "reference": "// DerivePBKDF2 implements Password Based Key Derivation Function 2, RFC 2898. Derives key of keyBitLength size, given password, salt, iteration count and hash function", "generated": "//\n// Derives a PBKDF2-derived-key from given parameters using HMAC-SHA256 for hashing,\n// which is specified by RFC 2898 section 5.4. This method returns a byte slice representing\n// the resulting derivative key length times number of iterations count times one bit per round.\n //\n //"}
{"id": 4970, "code": "func ReadPrivate(raw []byte) (key *ecdsa.PrivateKey,err error) {\n\tvar encoded *pem.Block\n\n\tif encoded, _ = pem.Decode(raw); encoded == nil {\n\t\treturn nil, errors.New(\"Ecc.ReadPrivate(): Key must be PEM encoded PKCS1 or PKCS8 EC private key\")\n\t}\n\n\tvar parsedKey interface{}\n\n\tif parsedKey,err=x509.ParseECPrivateKey(encoded.Bytes);err!=nil {\n\t\tif parsedKey, err = x509.ParsePKCS8PrivateKey(encoded.Bytes);err!=nil {\n\t\t\treturn nil,err\n\t\t}\n\t}\n\n\tvar ok bool\n\t\t\n\tif key,ok=parsedKey.(*ecdsa.PrivateKey);!ok {\n\t\treturn nil, errors.New(\"Ecc.ReadPrivate(): Key is not valid *ecdsa.PrivateKey\")\n\t}\n\t\n\treturn key,nil\n}", "reference": "// ReadPrivate loads ecdsa.PrivateKey from given PKCS1 or PKCS8 blobs", "generated": "// Reads ecDSA keys from raw bytes in base64-encoded format.\n//\n// The input should contain only one block per file; otherwise,\n// this will return incorrect results for each additional block found.\n //\n// This method returns nil if it was able to parse the data correctly;\n// else, it returns non-nil Err"}
{"id": 4978, "code": "func (c *Consumer) TailingLogs(appGuid, authToken string) (<-chan *events.LogMessage, <-chan error) {\n\treturn c.tailingLogs(appGuid, authToken, true)\n}", "reference": "// TailingLogs listens indefinitely for log messages only; other event types\n// are dropped.\n// Whenever an error is encountered, the error will be sent down the error\n// channel and TailingLogs will attempt to reconnect up to 5 times.  After\n// five failed reconnection attempts, TailingLogs will give up and close the\n// error and LogMessage channels.\n//\n// If c is closed, the returned channels will both be closed.\n//\n// Errors must be drained from the returned error channel for it to continue\n// retrying; if they are not drained, the connection attempts will hang.", "generated": "// Tailing logs for all events from appGuid in authToken.\n//\n// Returns two channels: one containing log messages,\n// another containing errors that occur while reading\n// these logs. The channel will be closed when it is no longer needed to avoid memory leaks."}
{"id": 4980, "code": "func (c *Consumer) Stream(appGuid string, authToken string) (outputChan <-chan *events.Envelope, errorChan <-chan error) {\n\treturn c.runStream(appGuid, authToken, true)\n}", "reference": "// Stream listens indefinitely for all log and event messages.\n//\n// Messages are presented in the order received from the loggregator server.\n// Chronological or other ordering is not guaranteed. It is the responsibility\n// of the consumer of these channels to provide any desired sorting mechanism.\n//\n// Whenever an error is encountered, the error will be sent down the error\n// channel and Stream will attempt to reconnect indefinitely.", "generated": "// Streams events from this consumer to another application.\n//\n// This method returns two channels: one for outputting envelopes,\n// which will be consumed by the target app; and one\n// containing any errors that occur during streaming.  The caller is responsible\n// for closing these channels when they're done using them."}
{"id": 5001, "code": "func (d *Dataset) Snapshot(name string, recursive bool) (*Dataset, error) {\n\targs := make([]string, 1, 4)\n\targs[0] = \"snapshot\"\n\tif recursive {\n\t\targs = append(args, \"-r\")\n\t}\n\tsnapName := fmt.Sprintf(\"%s@%s\", d.Name, name)\n\targs = append(args, snapName)\n\t_, err := zfs(args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn GetDataset(snapName)\n}", "reference": "// Snapshot creates a new ZFS snapshot of the receiving dataset, using the\n// specified name.  Optionally, the snapshot can be taken recursively, creating\n// snapshots of all descendent filesystems in a single, atomic operation.", "generated": "// Snapshots this dataset to create a new snapshot named after it.\n//\n// Args: Name - The name for the snapshot; if empty then use the current time,\n//        or 'now' which is equivalent to now but without any timestamp information;\n//         '-r' will recursively apply snapshots from parent directories in"}
{"id": 5017, "code": "func DialWithTimeout(url string, timeout time.Duration) (*Session, error) {\n\tinfo, err := ParseURL(url)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tinfo.Timeout = timeout\n\treturn DialWithInfo(info)\n}", "reference": "// DialWithTimeout works like Dial, but uses timeout as the amount of time to\n// wait for a server to respond when first connecting and also on follow up\n// operations in the session. If timeout is zero, the call may block\n// forever waiting for a connection to be made.\n//\n// See SetSyncTimeout for customizing the timeout for the session.", "generated": "//.DialWithTimeOut returns a new Session object that will be used to make requests.\n//\n//The url parameter should contain all necessary information about how to connect to the server,\n//such as host name or IP address, port number etc.\n //\n//If there is any problem connecting to the URL then it will return"}
{"id": 5025, "code": "func (s *Session) LogoutAll() {\n\ts.m.Lock()\n\tfor _, cred := range s.creds {\n\t\tif s.masterSocket != nil {\n\t\t\ts.masterSocket.Logout(cred.Source)\n\t\t}\n\t\tif s.slaveSocket != nil {\n\t\t\ts.slaveSocket.Logout(cred.Source)\n\t\t}\n\t}\n\ts.creds = s.creds[0:0]\n\ts.m.Unlock()\n}", "reference": "// LogoutAll removes all established authentication credentials for the session.", "generated": "// LogoutAll logs out all users connected to this session's master\n// socket or slave sockets.  This is used when logging in multiple\n// clients at once from one user account.\n//\n// Note that if there was only ever one client logged in then it will be\n// removed here too."}
{"id": 5048, "code": "func (q *Query) LogReplay() *Query {\n\tq.m.Lock()\n\tq.op.flags |= flagLogReplay\n\tq.m.Unlock()\n\treturn q\n}", "reference": "// LogReplay enables an option that optimizes queries that are typically\n// made on the MongoDB oplog for replaying it. This is an internal\n// implementation aspect and most likely uninteresting for other uses.\n// It has seen at least one use case, though, so it's exposed via the API.", "generated": "// Logs all queries that were replayed from disk to memory for debugging purposes.\n//\n// This is only used when logging is enabled in query configuration.  It's also\n// disabled if we're running under a debugger or testing framework because it can\n// cause problems by writing out every single operation ever performed during a"}
{"id": 5071, "code": "func tokenFor(t *transaction) token {\n\tnonce := t.Nonce\n\tif nonce == \"\" {\n\t\tnonce = newNonce()\n\t}\n\treturn token(t.Id.Hex() + \"_\" + nonce)\n}", "reference": "// tokenFor returns a unique transaction token that\n// is composed by t's id and a nonce. If t already has\n// a nonce assigned to it, it will be used, otherwise\n// a new nonce will be generated.", "generated": "// Token returns unique identifier for transaction.\n//\n// If no nonces have been set yet then it will generate one now."}
{"id": 5073, "code": "func (r *Runner) Run(ops []Op, id bson.ObjectId, info interface{}) (err error) {\n\tconst efmt = \"error in transaction op %d: %s\"\n\tfor i := range ops {\n\t\top := &ops[i]\n\t\tif op.C == \"\" || op.Id == nil {\n\t\t\treturn fmt.Errorf(efmt, i, \"C or Id missing\")\n\t\t}\n\t\tchanges := 0\n\t\tif op.Insert != nil {\n\t\t\tchanges++\n\t\t}\n\t\tif op.Update != nil {\n\t\t\tchanges++\n\t\t}\n\t\tif op.Remove {\n\t\t\tchanges++\n\t\t}\n\t\tif changes > 1 {\n\t\t\treturn fmt.Errorf(efmt, i, \"more than one of Insert/Update/Remove set\")\n\t\t}\n\t\tif changes == 0 && op.Assert == nil {\n\t\t\treturn fmt.Errorf(efmt, i, \"none of Assert/Insert/Update/Remove set\")\n\t\t}\n\t}\n\tif id == \"\" {\n\t\tid = bson.NewObjectId()\n\t}\n\n\t// Insert transaction sooner rather than later, to stay on the safer side.\n\tt := transaction{\n\t\tId:    id,\n\t\tOps:   ops,\n\t\tState: tpreparing,\n\t\tInfo:  info,\n\t}\n\tif err = r.tc.Insert(&t); err != nil {\n\t\treturn err\n\t}\n\tif err = flush(r, &t); err != nil {\n\t\treturn err\n\t}\n\tif t.State == taborted {\n\t\treturn ErrAborted\n\t} else if t.State != tapplied {\n\t\tpanic(fmt.Errorf(\"invalid state for %s after flush: %q\", &t, t.State))\n\t}\n\treturn nil\n}", "reference": "// Run creates a new transaction with ops and runs it immediately.\n// The id parameter specifies the transaction id, and may be written\n// down ahead of time to later verify the success of the change and\n// resume it, when the procedure is interrupted for any reason. If\n// empty, a random id will be generated.\n// The info parameter, if not nil, is included under the \"i\"\n// field of the transaction document.\n//\n// Operations across documents are not atomically applied, but are\n// guaranteed to be eventually all applied in the order provided or\n// all aborted, as long as the affected documents are only modified\n// through transactions. If documents are simultaneously modified\n// by transactions and out of transactions the behavior is undefined.\n//\n// If Run returns no errors, all operations were applied successfully.\n// If it returns ErrAborted, one or more operations can't be applied\n// and the transaction was entirely aborted with no changes performed.\n// Otherwise, if the transaction is interrupted while running for any\n// reason, it may be resumed explicitly or by attempting to apply\n// another transaction on any of the documents targeted by ops, as\n// long as the interruption was made after the transaction document\n// itself was inserted. Run Resume with the obtained transaction id\n// to confirm whether the transaction was applied or not.\n//\n// Any number of transactions may be run concurrently, with one\n// runner or many.", "generated": "Run runs all operations specified by ops within this runner's database connection. The result is stored in the provided ID field which will be updated when successful. If any errors occur during execution then they are returned immediately without running other transactions. This allows us to catch errors early before we start committing anything."}
{"id": 5076, "code": "func SetChaos(c Chaos) {\n\tchaosSetting = c\n\tchaosEnabled = c.KillChance > 0 || c.SlowdownChance > 0\n}", "reference": "// SetChaos sets the failure injection parameters to c.", "generated": "// Sets chaos settings for this client.\n//\n// This should be called before any requests to ensure that all subsequent calls will use these values."}
{"id": 5099, "code": "func NewObjectIdWithTime(t time.Time) ObjectId {\n\tvar b [12]byte\n\tbinary.BigEndian.PutUint32(b[:4], uint32(t.Unix()))\n\treturn ObjectId(string(b[:]))\n}", "reference": "// NewObjectIdWithTime returns a dummy ObjectId with the timestamp part filled\n// with the provided number of seconds from epoch UTC, and all other parts\n// filled with zeroes. It's not safe to insert a document with an id generated\n// by this method, it is useful only for queries to find documents with ids\n// generated before or after the specified timestamp.", "generated": "// Create new Object ID from Unix timestamp.\n//\n// This is used to create unique IDs for objects created at specific times,\n// which can be useful in certain scenarios where object creation needs to\n// happen within a particular timeframe or window.  Note that this method will\n// always return a valid UUID regardless of whether"}
{"id": 5102, "code": "func (id ObjectId) Time() time.Time {\n\t// First 4 bytes of ObjectId is 32-bit big-endian seconds from epoch.\n\tsecs := int64(binary.BigEndian.Uint32(id.byteSlice(0, 4)))\n\treturn time.Unix(secs, 0)\n}", "reference": "// Time returns the timestamp part of the id.\n// It's a runtime error to call this method with an invalid id.", "generated": "//\n// Returns the timestamp in UTC for this object's creation date\n// when it was created. The result will be zero if there has been no change to the Object ID since its initial generation,\n// which would have occurred at some point after the first second following the system clock reset or reboot. This value can also"}
{"id": 5107, "code": "func hasMinOf(top interface{}, current interface{}, field interface{}, param string) bool {\n\n\treturn isGte(top, current, field, param)\n}", "reference": "// min tests whether a variable value is larger or equal to a given\n// number. For number types, it's a simple lesser-than test; for\n// strings it tests the number of characters whereas for maps\n// and slices it tests the number of items.", "generated": "// check if top value can be less than or equal to min\n//\n// return true when it's possible for top to have minimum value.\n //\n// This method should only use in case where we need more strict validation,\n// otherwise always call isLessOrEqual instead."}
{"id": 5109, "code": "func Connect() {\n\turi := os.Getenv(\"MONGODB_URL\")\n\n\tif len(uri) == 0 {\n\t\turi = MongoDBUrl\n\t}\n\n\tmongo, err := mgo.ParseURL(uri)\n\ts, err := mgo.Dial(uri)\n\tif err != nil {\n\t\tfmt.Printf(\"Can't connect to mongo, go error %v\\n\", err)\n\t\tpanic(err.Error())\n\t}\n\ts.SetSafe(&mgo.Safe{})\n\tfmt.Println(\"Connected to\", uri)\n\tSession = s\n\tMongo = mongo\n}", "reference": "// Connect connects to mongodb", "generated": "// Connect connects to mongodb using environment variable or default url.\n//\n// If connection fails it panics. You can set MONGODB_URI environment variables for custom URL,\n// if there is no value then use default one from config file."}
{"id": 5112, "code": "func (file *GridFile) SetChunkSize(bytes int) {\n\tfile.assertMode(gfsWriting)\n\tdebugf(\"GridFile %p: setting chunk size to %d\", file, bytes)\n\tfile.m.Lock()\n\tfile.doc.ChunkSize = bytes\n\tfile.m.Unlock()\n}", "reference": "// SetChunkSize sets size of saved chunks.  Once the file is written to, it\n// will be split in blocks of that size and each block saved into an\n// independent chunk document.  The default chunk size is 256kb.\n//\n// It is a runtime error to call this function once the file has started\n// being written to.", "generated": "// Sets the grid file's chunk size for writing operations.\n//\n// This method is only valid when in gfsWrite mode.  The default value will be used if this call fails due to lack of permissions or other reasons."}
{"id": 5120, "code": "func (file *GridFile) Read(b []byte) (n int, err error) {\n\tfile.assertMode(gfsReading)\n\tfile.m.Lock()\n\tdebugf(\"GridFile %p: reading at offset %d into buffer of length %d\", file, file.offset, len(b))\n\tdefer file.m.Unlock()\n\tif file.offset == file.doc.Length {\n\t\treturn 0, io.EOF\n\t}\n\tfor err == nil {\n\t\ti := copy(b, file.rbuf)\n\t\tn += i\n\t\tfile.offset += int64(i)\n\t\tfile.rbuf = file.rbuf[i:]\n\t\tif i == len(b) || file.offset == file.doc.Length {\n\t\t\tbreak\n\t\t}\n\t\tb = b[i:]\n\t\tfile.rbuf, err = file.getChunk()\n\t}\n\treturn n, err\n}", "reference": "// Read reads into b the next available data from the file and\n// returns the number of bytes written and an error in case\n// something wrong happened.  At the end of the file, n will\n// be zero and err will be set to os.EOF.\n//\n// The parameters and behavior of this function turn the file\n// into an io.Reader.", "generated": "// Reads from this GridFile's underlying stream into the given byte slice.\n//\n// Returns zero for any amount read if there is no more data to be read,\n// or non-zero otherwise. If it returns negative then some other I/O error occurred."}
{"id": 5123, "code": "func invertAttributes(windowsMode uint16) uint16 {\n\treturn (COMMON_LVB_MASK & windowsMode) | ((FOREGROUND_MASK & windowsMode) << 4) | ((BACKGROUND_MASK & windowsMode) >> 4)\n}", "reference": "// invertAttributes inverts the foreground and background colors of a Windows attributes value", "generated": "// Inverts attributes for Windows mode.\n//\n// This is used to convert from common attribute values into\n// specific window-specific attribute values that can be passed directly\n// to SetWindowAttribute or GetWindowAttribute in Win32 API calls."}
{"id": 5157, "code": "func (s *SegmentStack) Peek() int64 {\n\tif s.Len() == 0 {\n\t\treturn rootSegment\n\t}\n\treturn s.s[s.Len()-1]\n}", "reference": "// Peek returns id from the top of the stack. It returns rootSegment if the stack is empty.", "generated": "// Peek returns the value at index n-1 in stack segment array.\n//\n// Note: This method is only valid if there's no more than one element left in the stack,\n// otherwise it will return default SegmentValue for last added item which has zero length."}
{"id": 5171, "code": "func (t *tx) StartExternal(host, name string) error {\n\tt.mtx.Lock()\n\tdefer t.mtx.Unlock()\n\n\tid, err := t.Tracer.BeginExternalSegment(t.id, t.ss.Peek(), host, name)\n\tif err != nil {\n\t\treturn err\n\t}\n\tt.ss.Push(id)\n\treturn nil\n}", "reference": "// StartExternal starts an external segment.", "generated": "// Starts external tracing for this transaction's segment.\n//\n// This method is used to start new segments that will be traced externally,\n// such as when calling remote services or making network requests from outside\n// the application container.  The returned ID can then be passed back into\n// Tracing.StartTransaction() in order"}
{"id": 5186, "code": "func NewClusterWithHost(hosts ...*URI) *Cluster {\n\tcluster := DefaultCluster()\n\tfor _, host := range hosts {\n\t\tcluster.AddHost(host)\n\t}\n\treturn cluster\n}", "reference": "// NewClusterWithHost returns a cluster with the given URIs.", "generated": "// Create new Cluster instance from list of URI's.\n//\n// This method creates default cluster if no arguments is given,\n// otherwise it adds all provided URIs to existing one."}
{"id": 5206, "code": "func (idx *Index) BatchQuery(queries ...PQLQuery) *PQLBatchQuery {\n\tstringQueries := make([]string, 0, len(queries))\n\thasKeys := false\n\tfor _, query := range queries {\n\t\tserializedQuery := query.Serialize()\n\t\thasKeys = hasKeys || serializedQuery.HasWriteKeys()\n\t\tstringQueries = append(stringQueries, serializedQuery.String())\n\t}\n\treturn &PQLBatchQuery{\n\t\tindex:   idx,\n\t\tqueries: stringQueries,\n\t\thasKeys: hasKeys,\n\t}\n}", "reference": "// BatchQuery creates a batch query with the given queries.", "generated": "// BatchQuery returns a new PQLBatchQuery that can be used to execute multiple\n// queries in one go.\n//\n// This method is useful when executing many small queries at once or if there's\n// some other reason why we need all these queries executed together for performance reasons."}
{"id": 5218, "code": "func OptFieldTypeMutex(cacheType CacheType, cacheSize int) FieldOption {\n\treturn func(options *FieldOptions) {\n\t\toptions.fieldType = FieldTypeMutex\n\t\toptions.cacheType = cacheType\n\t\toptions.cacheSize = cacheSize\n\t}\n}", "reference": "// OptFieldTypeMutex adds a mutex field.", "generated": "// Option for setting field type to Mutex.\n//\n// This option is used when creating fields that should be cached in memory,\n// but need synchronization between threads (e.g., mutexes). The value must be\n// greater than 0. If it's zero or negative then caching will be disabled.\n //\n// Options"}
{"id": 5230, "code": "func (f *Field) Rows() *PQLRowsQuery {\n\ttext := fmt.Sprintf(\"Rows(field='%s')\", f.name)\n\treturn NewPQLRowsQuery(text, f.index, nil)\n}", "reference": "// Rows creates a Rows query with defaults", "generated": "// Returns PQL query for rows in this field. This is used to get all\n// values from this column that match some condition.\n//\n// Note: The index parameter should be set if there's any indexing going\n// on this table or it will result in incorrect results because we're using\n// full scan"}
{"id": 5261, "code": "func OptClientConnectTimeout(timeout time.Duration) ClientOption {\n\treturn func(options *ClientOptions) error {\n\t\toptions.ConnectTimeout = timeout\n\t\treturn nil\n\t}\n}", "reference": "// OptClientConnectTimeout is the maximum time to connect in nanoseconds.", "generated": "// Set client connection timeouts for all connections to this server.\n//\n// This option is used by default when creating clients using new()\n// or createConnection().  If set after creation it will be applied only if\n// there are no existing active connections that need attention from the current thread."}
{"id": 5271, "code": "func OptImportThreadCount(count int) ImportOption {\n\treturn func(options *ImportOptions) error {\n\t\toptions.threadCount = count\n\t\treturn nil\n\t}\n}", "reference": "// OptImportThreadCount is the number of goroutines allocated for import.", "generated": "// Set thread-count option for import operation.\n//\n// This option is used to specify number of threads that should be used by\n// importer during execution. If set it will override default value which can\n// vary depending on platform architecture (32-bit or 64-bit). Note,\n// setting this option requires additional memory"}
{"id": 5282, "code": "func NewValueIterator(format Format, reader io.Reader) *Iterator {\n\treturn NewIterator(reader, FieldValueUnmarshaller(format))\n}", "reference": "// NewValueIterator creates a new iterator for value data.", "generated": "// Create new iterator for reading values from given format.\n//\n// This method creates new instance which reads all fields in specified\n// format until it encounters end-of-file or error while parsing field value.\n //\n// If there is no errors during iteration then return empty slice at the end,\n// otherwise returns list of parsed values"}
{"id": 5287, "code": "func elementsFromLine(config *Config, line string) []interface{} {\n\tseparated := strings.Split(line, config.Delim)\n\telements := make([]interface{}, len(separated))\n\tfor i, field := range separated {\n\t\tvalue := field\n\t\tif !config.NoTrim {\n\t\t\tvalue = strings.TrimSpace(field)\n\t\t}\n\n\t\t// Apply the empty value, if configured.\n\t\tif value == \"\" && config.Empty != \"\" {\n\t\t\tvalue = config.Empty\n\t\t}\n\t\telements[i] = value\n\t}\n\treturn elements\n}", "reference": "// elementsFromLine returns a list of elements, each representing a single\n// item which will belong to a column of output.", "generated": "//\n// Parse lines from configuration file into slices of interface{}\n// values. The delimiter is specified in Config.Delim; it defaults to ','\n// when left unset or set to''.  Empty fields will be replaced by the\n// default for that key (if any).\n //\n// This method returns nil if there"}
{"id": 5306, "code": "func postEOFCheck(c *Cmp, r io.Reader, buf []byte) bool {\n\ttmpLR, isLR := r.(*io.LimitedReader)\n\tif isLR {\n\t\t// If the limit wasn't reached, then we don't need to check for\n\t\t// more data after the EOF\n\t\tif tmpLR.N > 0 {\n\t\t\treturn true\n\t\t}\n\n\t\t// Use the internal Reader for checking for more data\n\t\tr = tmpLR.R\n\t} else {\n\t\tc.debugf(\"compareReader: A type assertion of LimitedReader unexpectedly failed\\n\")\n\t}\n\n\t// Attempt to read more bytes from the original readers, to determine\n\t// if we should return an error for exceeding the MaxSize read limit.\n\tn, _ := readPartial(c, r, buf, 0, len(buf))\n\treturn n == 0\n}", "reference": "// postEOFCheck returns false if there is more data in a LimitedReader after\n// hitting EOF", "generated": "//\n// Compare reader's remaining buffer size against max allowed value,\n// returning false when it exceeds that threshold or no further reading can be done."}
{"id": 5311, "code": "func exist(file string) (bool, error) {\n\t_, err := os.Stat(file)\n\tif err != nil {\n\t\tif err == os.ErrNotExist {\n\t\t\treturn false, nil\n\t\t}\n\t\treturn false, err\n\t}\n\treturn true, nil\n}", "reference": "// exist checks if the file exists.", "generated": "// exists checks if file is present or not.\n//\n// Returns true for existing files only. If there's any other type of error,\n// it returns false along with that error message."}
{"id": 5340, "code": "func (e *edit) Comment(reLine []string) error {\n\tallReSearch := make([]*regexp.Regexp, len(reLine))\n\n\tfor i, v := range reLine {\n\t\tif re, err := regexp.Compile(v); err != nil {\n\t\t\treturn err\n\t\t} else {\n\t\t\tallReSearch[i] = re\n\t\t}\n\t}\n\n\tif _, err := e.file.Seek(0, os.SEEK_SET); err != nil {\n\t\treturn err\n\t}\n\n\tchar := []byte(e.CommentChar + \" \")\n\tisNew := false\n\tbuf := new(bytes.Buffer)\n\n\t// Check every line.\n\tfor {\n\t\tline, err := e.buf.ReadBytes('\\n')\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\n\t\tfor _, v := range allReSearch {\n\t\t\tif v.Match(line) {\n\t\t\t\tline = append(char, line...)\n\n\t\t\t\tif !isNew {\n\t\t\t\t\tisNew = true\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif _, err = buf.Write(line); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif isNew {\n\t\treturn e.rewrite(buf.Bytes())\n\t}\n\treturn nil\n}", "reference": "// Comment inserts the comment character in lines that mach any regular expression\n// in reLine.", "generated": "//\n// Write comments to file at specified position in buffer.  The first character is added before each comment,\n// so that it can be removed when reading back into the editor."}
{"id": 5384, "code": "func Run(command string) (output []byte, err error) {\n\toutput, _, err = RunWithMatch(command)\n\treturn\n}", "reference": "// Run executes external commands just like RunWithMatch, but does not return\n// the boolean `match`.", "generated": "// Runs command in shell.\n//\n// Returns output from running command if it is successful,\n// otherwise returns nil for both output and errors.\n //\n// If there's any error while executing command then return false to indicate that\n// execution was unsuccessful. Output will be empty when this happens.\n//\n// This method runs commands"}
{"id": 5387, "code": "func (i *info) GroupHas(p ...perm) bool {\n\tmode := i.fi.Mode()\n\n\tfor _, v := range p {\n\t\tswitch v {\n\t\tcase R:\n\t\t\tif mode&modeRGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase W:\n\t\t\tif mode&modeWGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase X:\n\t\t\tif mode&modeXGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\treturn true\n}", "reference": "// GroupHas reports whether the group has all given permissions.", "generated": "// GroupHas returns whether this file has all specified permissions for group.\n//\n// This is used to determine if we need to create or modify the group's permission set,\n// rather than just checking each individual bit individually in Mode()."}
{"id": 5393, "code": "func ChPasswd(user string, key []byte) error {\n\tshadow, err := LookupShadow(user)\n\tif err != nil {\n\t\treturn err\n\t}\n\tshadow.Passwd(key)\n\n\treturn edit(user, shadow)\n}", "reference": "// == Change passwd\n// ChPasswd updates passwd.\n// The passwd must be supplied in clear-text.", "generated": "// Set password for user.\n//\n// This is similar to chpass(1), but it uses go's built-in file system,\n// which means that this will only work if we have permission to modify\n// files in /etc/passwd (and its associated shadows).  It also doesn't\n// handle any"}
{"id": 5399, "code": "func parseGroup(row string) (*Group, error) {\n\tfields := strings.Split(row, \":\")\n\tif len(fields) != 4 {\n\t\treturn nil, rowError{_GROUP_FILE, row}\n\t}\n\n\tgid, err := strconv.Atoi(fields[2])\n\tif err != nil {\n\t\treturn nil, atoiError{_GROUP_FILE, row, \"GID\"}\n\t}\n\n\treturn &Group{\n\t\tName:     fields[0],\n\t\tpassword: fields[1],\n\t\tGID:      gid,\n\t\tUserList: strings.Split(fields[3], \",\"),\n\t}, nil\n}", "reference": "// parseGroup parses the row of a group.", "generated": "// Parse group from file line.\n//\n// Returns *nil if there is no valid data in this field or it's invalid format."}
{"id": 5450, "code": "func (c *CallService) Create(ctx context.Context, data url.Values) (*Call, error) {\n\tcall := new(Call)\n\terr := c.client.CreateResource(ctx, callsPathPart, data, call)\n\treturn call, err\n}", "reference": "// Initiate a new Call.", "generated": "// Creates a Call resource in the server.\n//\n// Args: ctx - Context for this operation.\n//      Data - URL values to be used when creating the resource.\n//\n// Returns: The created Call object or nil if creation failed. Error is returned instead of nil if there was any issue during creation process."}
{"id": 5453, "code": "func (c *CallService) GetNextCallsInRange(start time.Time, end time.Time, nextPageURI string) CallPageIterator {\n\tif nextPageURI == \"\" {\n\t\tpanic(\"nextpageuri is empty\")\n\t}\n\titer := NewNextPageIterator(c.client, callsPathPart)\n\titer.SetNextPageURI(types.NullString{Valid: true, String: nextPageURI})\n\treturn &callDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetNextCallsInRange retrieves the page at the nextPageURI and continues\n// retrieving pages until any results are found in the range given by start or\n// end, or we determine there are no more records to be found in that range.\n//\n// If CallPage is non-nil, it will have at least one result.", "generated": "// Returns next page iterator for call dates in range [start;end)."}
{"id": 5455, "code": "func (c *CallService) GetRecordingsIterator(callSid string, data url.Values) *RecordingPageIterator {\n\tif data == nil {\n\t\tdata = url.Values{}\n\t}\n\t// Cheat - hit the Recordings list view with a filter instead of\n\t// GET /calls/CA123/Recordings. The former is probably more reliable\n\tdata.Set(\"CallSid\", callSid)\n\treturn c.client.Recordings.GetPageIterator(data)\n}", "reference": "// GetRecordings returns an iterator of recording pages for this Call.\n// Note there may be more than one Page of results.", "generated": "//\n// Returns iterator for all recordings associated to this Call.\n //\n// Note: This method returns only records that have been created by our service,\n // so it will never return any record from another provider or user's recording."}
{"id": 5461, "code": "func (r *KeyService) Delete(ctx context.Context, sid string) error {\n\treturn r.client.DeleteResource(ctx, keyPathPart, sid)\n}", "reference": "// Delete the Key with the given sid. If the Key has already been\n// deleted, or does not exist, Delete returns nil. If another error or a\n// timeout occurs, the error is returned.", "generated": "// Deletes resource from service.\n//\n// Args: ctx - Context\n//      side - Side to delete from\n//\n// Returns: Error if failed or nil otherwise\n //\n// Note: This method is used for testing purposes only. In production,\n//       this should be done using client's API directly instead of calling"}
{"id": 5462, "code": "func (a *AlertService) GetAlertsInRange(start time.Time, end time.Time, data url.Values) AlertPageIterator {\n\tif start.After(end) {\n\t\tpanic(\"start date is after end date\")\n\t}\n\td := url.Values{}\n\tif data != nil {\n\t\tfor k, v := range data {\n\t\t\td[k] = v\n\t\t}\n\t}\n\td.Del(\"Page\") // just in case\n\tif start != Epoch {\n\t\tstartFormat := start.UTC().Format(time.RFC3339)\n\t\td.Set(\"StartDate\", startFormat)\n\t}\n\tif end != HeatDeath {\n\t\t// If you specify \"StartTime<=YYYY-MM-DD\", the *latest* result returned\n\t\t// will be midnight (the earliest possible second) on DD. We want all\n\t\t// of the results for DD so we need to specify DD+1 in the API.\n\t\t//\n\t\t// TODO validate midnight-instant math more closely, since I don't think\n\t\t// Twilio returns the correct results for that instant.\n\t\tendFormat := end.UTC().Format(time.RFC3339)\n\t\td.Set(\"EndDate\", endFormat)\n\t}\n\titer := NewPageIterator(a.client, d, alertPathPart)\n\treturn &alertDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetAlertsInRange gets an Iterator containing conferences in the range\n// [start, end), optionally further filtered by data. GetAlertsInRange\n// panics if start is not before end. Any date filters provided in data will\n// be ignored. If you have an end, but don't want to specify a start, use\n// twilio.Epoch for start. If you have a start, but don't want to specify an\n// end, use twilio.HeatDeath for end.\n//\n// Assumes that Twilio returns resources in chronological order, latest\n// first. If this assumption is incorrect, your results will not be correct.\n//\n// Returned AlertPages will have at most PageSize results, but may have fewer,\n// based on filtering.", "generated": "// Returns alerts from this service within the specified dates. The return value\n// implements PageIterator which can iterate over multiple pages if there's many\n// alerts available. Note that it doesn't implement Slice or Array because each page\n// may contain different number of items due to pagination limits set by the server."}
{"id": 5466, "code": "func (d Direction) Friendly() string {\n\tswitch d {\n\tcase DirectionOutboundReply:\n\t\treturn \"Reply\"\n\tcase DirectionOutboundCall:\n\t\treturn \"Outgoing (from call)\"\n\tcase DirectionOutboundAPI:\n\t\treturn \"Outgoing (from API)\"\n\tcase DirectionInbound:\n\t\treturn \"Incoming\"\n\tcase DirectionOutboundDial:\n\t\treturn \"Outgoing (via Dial)\"\n\tcase DirectionTrunkingTerminating:\n\t\treturn \"Trunking (terminating)\"\n\tcase DirectionTrunkingOriginating:\n\t\treturn \"Trunking (originating)\"\n\tdefault:\n\t\treturn string(d)\n\t}\n}", "reference": "// Friendly prints out a friendly version of the Direction, following the\n// example shown in the Twilio Dashboard.", "generated": "// Friendly returns friendly name for direction type.\n//\n// This is used in UI to display directions without showing raw values\n// which could be confusing or hard to understand. For example,\n// when displaying calls from user's phonebook it would show outgoing\n// instead of 0x0001."}
{"id": 5468, "code": "func (m *MessageService) GetPage(ctx context.Context, data url.Values) (*MessagePage, error) {\n\titer := m.GetPageIterator(data)\n\treturn iter.Next(ctx)\n}", "reference": "// GetPage returns a single page of resources. To retrieve multiple pages, use\n// GetPageIterator.", "generated": "// Get page returns next message from database based on provided query parameters.\n//\n// Args\n// ctx - current request context\n// params - URL encoded query string to filter messages by name or date range.\n //\n// Returns\n// Page object containing list of Message objects matching given criteria,\n// along with total count for pagination"}
{"id": 5470, "code": "func (c *MessageService) GetNextMessagesInRange(start time.Time, end time.Time, nextPageURI string) MessagePageIterator {\n\tif nextPageURI == \"\" {\n\t\tpanic(\"nextpageuri is empty\")\n\t}\n\titer := NewNextPageIterator(c.client, messagesPathPart)\n\titer.SetNextPageURI(types.NullString{Valid: true, String: nextPageURI})\n\treturn &messageDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetNextMessagesInRange retrieves the page at the nextPageURI and continues\n// retrieving pages until any results are found in the range given by start or\n// end, or we determine there are no more records to be found in that range.\n//\n// If MessagePage is non-nil, it will have at least one result.", "generated": "// GetNextMessagesInRange returns next page iterator for message\n// which were received between given date range.\n//\n// If there's no more pages available it will return nil."}
{"id": 5486, "code": "func (r *ApplicationService) Delete(ctx context.Context, sid string) error {\n\treturn r.client.DeleteResource(ctx, applicationPathPart, sid)\n}", "reference": "// Delete the Application with the given sid. If the Application has already been\n// deleted, or does not exist, Delete returns nil. If another error or a\n// timeout occurs, the error is returned.", "generated": "// Deletes the specified Application resource.\n//\n// Args: ctx - Context\n//      sid - ID of the Application to delete\n//\n// Returns: Error if there was any issue deleting the Applicaiton or its resources."}
{"id": 5490, "code": "func (ipn *IncomingNumberService) BuyNumber(phoneNumber string) (*IncomingPhoneNumber, error) {\n\tdata := url.Values{\"PhoneNumber\": []string{phoneNumber}}\n\treturn ipn.NumberPurchasingService.Create(context.Background(), data)\n}", "reference": "// BuyNumber attempts to buy the provided phoneNumber and returns it if\n// successful.", "generated": "// Buy number for phone number\n//\n// Returns new Incoming PhoneNumber if successful or nil otherwise.\n //\n// Note: This method is asynchronous so it will return immediately after sending request to server,\n// but result may be available later when calling GetPhoneNumbers() method."}
{"id": 5517, "code": "func (m *Messenger) DeleteGetStartedButton() error {\n\tresult, err := m.changeThreadSettings(http.MethodDelete, &threadSettings{\n\t\tType:  settingTypeCallToActions,\n\t\tState: threadStateNew,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\tif result.Result != \"Successfully deleted all new_thread's CTAs\" {\n\t\treturn fmt.Errorf(\"Error occured while deleting get started button, invalid result: %s\", result.Result)\n\t}\n\treturn nil\n}", "reference": "// DeleteGetStartedButton delets a button set by SetGetStartedButton", "generated": "// Deletes Get Started Button from Messenger Thread Settings for New Threads.\n//\n// Returns any errors that occur during this operation. If successful returns nil."}
{"id": 5523, "code": "func pushNumberValue(L *lua.State, a interface{}, t1, t2 reflect.Type) {\n\tv := reflect.ValueOf(a)\n\tisComplex := unsizedKind(v) == reflect.Complex128\n\tmt := cNumberMeta\n\tif isComplex {\n\t\tmt = cComplexMeta\n\t}\n\tif t1 == t2 || isPredeclaredType(t2) {\n\t\tmakeValueProxy(L, v.Convert(t1), mt)\n\t} else if isPredeclaredType(t1) {\n\t\tmakeValueProxy(L, v.Convert(t2), mt)\n\t} else if isComplex {\n\t\tcomplexType := reflect.TypeOf(0i)\n\t\tmakeValueProxy(L, v.Convert(complexType), cComplexMeta)\n\t} else {\n\t\tL.PushNumber(valueToNumber(L, v))\n\t}\n}", "reference": "// pushNumberValue pushes the number resulting from an arithmetic operation.\n//\n// At least one operand must be a proxy for this function to be called. See the\n// main documentation for the conversion rules.", "generated": "// Push number value to Lua state.\n//\n// This method pushes complex or real numbers into lua State using their corresponding meta types,\n// which can be used for further operations in lua code. The type must match one of the following: float32, int64, uint8, bool, double (complex). If it"}
{"id": 5556, "code": "func (d *digest) Sum(in []byte) []byte {\n\ts := d.Sum64()\n\tin = append(in, byte(s))\n\tin = append(in, byte(s>>8))\n\tin = append(in, byte(s>>16))\n\tin = append(in, byte(s>>24))\n\tin = append(in, byte(s>>32))\n\tin = append(in, byte(s>>40))\n\tin = append(in, byte(s>>48))\n\tin = append(in, byte(s>>56))\n\treturn in\n}", "reference": "// Encode in little endian", "generated": "//Sum returns sum of input bytes.\n//\n//Note: This method is used to calculate hash value for data that can be stored or sent over network,\n//because it's more efficient than calculating hash from scratch when receiving data back. However,\n//this means this method should only be called once per chunk of data being"}
{"id": 5562, "code": "func FindPerformancePrice(productPackage datatypes.Product_Package, priceCategory string) (datatypes.Product_Item_Price, error) {\n\tfor _, item := range productPackage.Items {\n\t\tfor _, price := range item.Prices {\n\t\t\t// Only collect prices from valid location groups.\n\t\t\tif price.LocationGroupId != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif !hasCategory(price.Categories, priceCategory) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn price, nil\n\t\t}\n\t}\n\treturn datatypes.Product_Item_Price{}, bosherr.Error(\"Unable to find price for performance storage\")\n}", "reference": "// Find the price in the given package that has the specified category", "generated": "//\n// Finds the first available price category in the given package that matches the specified name.\n //\n // If no matching price is found then it returns an empty Product Item Price object along with an error message indicating why this was unable to be done.  This can happen if there isn't any data stored or because all items"}
{"id": 5571, "code": "func (o *OrderVMByFilterParams) WithBody(body *models.VMFilter) *OrderVMByFilterParams {\n\to.SetBody(body)\n\treturn o\n}", "reference": "// WithBody adds the body to the order Vm by filter params", "generated": "// SetBody sets Body field's value for this object\n//\n// Note: This is a shallow copy operation. Deep copying operations would require\n// serializing to JSON or another format, storing it to memory, then deserializing\n// back into a new Object.\n //\n// Returns the current instance of model to"}
{"id": 5572, "code": "func (c *FakeClient) Delete(instanceID string) error {\n\tc.DeleteCalled = true\n\treturn c.DeleteErr\n}", "reference": "// Delete deletes the instance settings for a given instance ID.", "generated": "// FakeDelete is called when delete operation fails.\n//\n// This method should be used to simulate errors in client operations for testing purposes only. It's recommended that this method never returns from real clients,\n// since it can cause unexpected behavior if implemented incorrectly."}
{"id": 5599, "code": "func (o *UpdateVMWithStateParams) WithBody(body *models.VMState) *UpdateVMWithStateParams {\n\to.SetBody(body)\n\treturn o\n}", "reference": "// WithBody adds the body to the update Vm with state params", "generated": "// SetBody sets the Body field's value. Use this method to set the values for fields that should be used during serialization into JSON strings ending in...[] or...Map[].  To get the mutable reference to base Value use o.Body()."}
{"id": 5601, "code": "func (o *AddVMParams) WithTimeout(timeout time.Duration) *AddVMParams {\n\to.SetTimeout(timeout)\n\treturn o\n}", "reference": "// WithTimeout adds the timeout to the add Vm params", "generated": "// Set Timeout sets timeout for add vm operation.\n//\n// Args:\n//   timeout - Time to wait before giving up while adding VMs. If zero,\n//     then there is no limit set by user or default value will be used.\n //\n// Returns:\n//   AddVMParams instance itself so that method call"}
{"id": 5606, "code": "func (o *ListVMParams) WithContext(ctx context.Context) *ListVMParams {\n\to.SetContext(ctx)\n\treturn o\n}", "reference": "// WithContext adds the context to the list Vm params", "generated": "// SetContext sets the Context to be used for this ListVMParams object.\n//\n// Args:\n//   ctx - The context to use.\n //\n// Returns:\n//   This list VM params instance which can be used after setting the context using SetContext()."}
{"id": 5626, "code": "func (pk PrivKeyLedgerSecp256k1) getPubKey() (key PubKey, err error) {\n\tdev, err := getLedger()\n\tif err != nil {\n\t\treturn key, fmt.Errorf(\"cannot connect to Ledger device - error: %v\", err)\n\t}\n\tkey, err = pubkeyLedgerSecp256k1(dev, pk.Path)\n\tif err != nil {\n\t\treturn key, fmt.Errorf(\"please open Cosmos app on the Ledger device - error: %v\", err)\n\t}\n\treturn key, err\n}", "reference": "// getPubKey reads the pubkey the ledger itself\n// since this involves IO, it may return an error, which is not exposed\n// in the PubKey interface, so this function allows better error handling", "generated": "// gets public keys from ledger devices using secp256k1 algorithm.\n//\n// Returns errors if there is no valid private key or if it cannot be read from theledger device."}
{"id": 5656, "code": "func (kb dbKeybase) ImportPubKey(name string, armor string) (err error) {\n\tbz := kb.db.Get(infoKey(name))\n\tif len(bz) > 0 {\n\t\treturn errors.New(\"Cannot overwrite data for name \" + name)\n\t}\n\tpubBytes, err := unarmorPubKeyBytes(armor)\n\tif err != nil {\n\t\treturn\n\t}\n\tpubKey, err := crypto.PubKeyFromBytes(pubBytes)\n\tif err != nil {\n\t\treturn\n\t}\n\tkb.writeOfflineKey(pubKey, name)\n\treturn\n}", "reference": "// ImportPubKey imports ASCII-armored public keys.\n// Store a new Info object holding a public key only, i.e. it will\n// not be possible to sign with it as it lacks the secret key.", "generated": "// ImportPublicKey imports public key from armored format to database.\n//\n// If there is already entry in database named by given name,\n// it will return error message saying that cannot overrite existing value."}
{"id": 5660, "code": "func CompareHashAndPassword(hashedPassword, password []byte) error {\n\tp, err := newFromHash(hashedPassword)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\totherHash, err := bcrypt(password, p.cost, p.salt)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\totherP := &hashed{otherHash, p.salt, p.cost, p.major, p.minor}\n\tif subtle.ConstantTimeCompare(p.Hash(), otherP.Hash()) == 1 {\n\t\treturn nil\n\t}\n\n\treturn ErrMismatchedHashAndPassword\n}", "reference": "// CompareHashAndPassword compares a bcrypt hashed password with its possible\n// plaintext equivalent. Returns nil on success, or an error on failure.", "generated": "// CompareHashAndPassword checks if hashed_password matches password.\n//\n// This is used to verify passwords stored in database against user-provided\n// password during login process. The hash must be generated using same cost,\n// salt and hashing algorithm (bcrypt). If any part changes then this will return\n// ErrorMismatchedHash"}
{"id": 5696, "code": "func doDemangle(out *bufio.Writer, name string) {\n\tskip := 0\n\tif name[0] == '.' || name[0] == '$' {\n\t\tskip++\n\t}\n\tif *stripUnderscore && name[skip] == '_' {\n\t\tskip++\n\t}\n\tresult := demangle.Filter(name[skip:], options()...)\n\tif result == name[skip:] {\n\t\tout.WriteString(name)\n\t} else {\n\t\tif name[0] == '.' {\n\t\t\tout.WriteByte('.')\n\t\t}\n\t\tout.WriteString(result)\n\t}\n}", "reference": "// Demangle a string just as the GNU c++filt program does.", "generated": "// Do Demangling - Write out the given symbol to the output stream.\n//\n// This is used by go build when building binary code from source files,\n// it will print symbols in their original form if they have been compiled\n// without being mangled (i.e., no prefix). If the first character was"}
{"id": 5707, "code": "func (s *Sentinel) defaultPool(addr string) *redis.Pool {\n\treturn &redis.Pool{\n\t\tMaxIdle:     3,\n\t\tMaxActive:   10,\n\t\tWait:        true,\n\t\tIdleTimeout: 240 * time.Second,\n\t\tDial: func() (redis.Conn, error) {\n\t\t\treturn s.Dial(addr)\n\t\t},\n\t\tTestOnBorrow: func(c redis.Conn, t time.Time) error {\n\t\t\t_, err := c.Do(\"PING\")\n\t\t\treturn err\n\t\t},\n\t}\n}", "reference": "// defaultPool returns a connection pool to one Sentinel. This allows\n// us to call concurrent requests to Sentinel using connection Do method.", "generated": "// Default pool is used when no custom pool has been set for this sentinel.\n//\n// This will create a new pool that uses Redis's built-in connection pooling to manage connections from the client. The number of active connections can be adjusted by setting MaxActive in Sentinel."}
{"id": 5723, "code": "func (c *Client) CompareAndSwap(item *Item) error {\n\treturn c.populateOne(cmdSet, item, item.casid)\n}", "reference": "// CompareAndSwap writes the given item that was previously returned\n// by Get, if the value was neither modified or evicted between the\n// Get and the CompareAndSwap calls. The item's Key should not change\n// between calls but all other item fields may differ. ErrCASConflict\n// is returned if the value was modified in between the\n// calls. ErrNotStored is returned if the value was evicted in between\n// the calls.", "generated": "// CompareAndSwap is similar to Set but returns whether or not\n// it was successful.\n//\n// If this method succeeds then all changes made by this call will be lost if they occur again in the future,\n// because another process has set the same value for that key before we did.  This means that any"}
{"id": 5736, "code": "func Ticker(ticker <-chan time.Time, procfunc gp.ProcessFunc) gp.Process {\n\treturn gp.Go(callOnTicker(ticker, procfunc))\n}", "reference": "// Ticker calls the given ProcessFunc every time the ticker fires.\n// This is sequentially rate limited, only one call will be in-flight at a time.", "generated": "// CallProcessWithTick calls func for each tick in ticker.\n//\n// This is similar to callProcess but it will be called every second,\n// regardless if there was any change or not.  It's useful when\n// calling process functions that need to run at regular intervals,\n// such as logging or monitoring processes"}
{"id": 5746, "code": "func (a *API) FetchCheck(cid CIDType) (*Check, error) {\n\tif cid == nil || *cid == \"\" {\n\t\treturn nil, fmt.Errorf(\"Invalid check CID [none]\")\n\t}\n\n\tcheckCID := string(*cid)\n\n\tmatched, err := regexp.MatchString(config.CheckCIDRegex, checkCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !matched {\n\t\treturn nil, fmt.Errorf(\"Invalid check CID [%s]\", checkCID)\n\t}\n\n\tresult, err := a.Get(checkCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] fetch check, received JSON: %s\", string(result))\n\t}\n\n\tcheck := new(Check)\n\tif err := json.Unmarshal(result, check); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn check, nil\n}", "reference": "// FetchCheck retrieves check with passed cid.", "generated": "// Fetch checks for given ID or name from API server.\n//\n// Returns result if found otherwise returns nil and any errors that occurred during fetching."}
{"id": 5747, "code": "func (a *API) FetchChecks() (*[]Check, error) {\n\tresult, err := a.Get(config.CheckPrefix)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar checks []Check\n\tif err := json.Unmarshal(result, &checks); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &checks, nil\n}", "reference": "// FetchChecks retrieves all checks available to the API Token.", "generated": "// Fetch Checks returns all available check results from API server.\n//\n// Returns errors if there is any issue fetching data or unmarshaling JSON result."}
{"id": 5752, "code": "func (a *API) FetchGraph(cid CIDType) (*Graph, error) {\n\tif cid == nil || *cid == \"\" {\n\t\treturn nil, fmt.Errorf(\"Invalid graph CID [none]\")\n\t}\n\n\tgraphCID := string(*cid)\n\n\tmatched, err := regexp.MatchString(config.GraphCIDRegex, graphCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !matched {\n\t\treturn nil, fmt.Errorf(\"Invalid graph CID [%s]\", graphCID)\n\t}\n\n\tresult, err := a.Get(graphCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] fetch graph, received JSON: %s\", string(result))\n\t}\n\n\tgraph := new(Graph)\n\tif err := json.Unmarshal(result, graph); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn graph, nil\n}", "reference": "// FetchGraph retrieves graph with passed cid.", "generated": "// Fetch Graph returns the specified graph from storage.\n//\n// If no valid graph is found in database or if there's any other errors,\n// it will return nil along with corresponding error message."}
{"id": 5786, "code": "func (a *API) FetchAnnotations() (*[]Annotation, error) {\n\tresult, err := a.Get(config.AnnotationPrefix)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar annotations []Annotation\n\tif err := json.Unmarshal(result, &annotations); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &annotations, nil\n}", "reference": "// FetchAnnotations retrieves all annotations available to the API Token.", "generated": "// Fetch Annotations returns all available annotation data for this API instance.\n//\n// This method is used to retrieve any additional metadata that may be provided by the server,\n// such as custom or user-defined annotations. The result will contain only Annotation objects which have been registered in the current configuration."}
{"id": 5815, "code": "func (m *CirconusMetrics) NewHistogram(metric string) *Histogram {\n\tm.hm.Lock()\n\tdefer m.hm.Unlock()\n\n\tif hist, ok := m.histograms[metric]; ok {\n\t\treturn hist\n\t}\n\n\thist := &Histogram{\n\t\tname: metric,\n\t\thist: circonusllhist.New(),\n\t}\n\n\tm.histograms[metric] = hist\n\n\treturn hist\n}", "reference": "// NewHistogram returns a histogram instance.", "generated": "// Create new Histogram for given name or create existing one if it already exists in metrics map.\n//\n// This method is used to get instance of histogram which can be then added into meter using Add() method."}
{"id": 5847, "code": "func (a *API) CreateRuleSet(cfg *RuleSet) (*RuleSet, error) {\n\tif cfg == nil {\n\t\treturn nil, fmt.Errorf(\"Invalid rule set config [nil]\")\n\t}\n\n\tjsonCfg, err := json.Marshal(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] create rule set, sending JSON: %s\", string(jsonCfg))\n\t}\n\n\tresp, err := a.Post(config.RuleSetPrefix, jsonCfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\truleset := &RuleSet{}\n\tif err := json.Unmarshal(resp, ruleset); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn ruleset, nil\n}", "reference": "// CreateRuleSet creates a new rule set.", "generated": "// Creates new Rule Set in API.\n//\n// Args:\n//   - cfg : RuleSet to be created.\n//\n// Returns :\n//   - Ruleset if creation is successful or any other errors that occurred during execution."}
{"id": 5860, "code": "func (a *API) DeleteWorksheet(cfg *Worksheet) (bool, error) {\n\tif cfg == nil {\n\t\treturn false, fmt.Errorf(\"Invalid worksheet config [nil]\")\n\t}\n\treturn a.DeleteWorksheetByCID(CIDType(&cfg.CID))\n}", "reference": "// DeleteWorksheet deletes passed worksheet.", "generated": "// Deletes a Worksheet by its CID\n//\n// Args: None\n//\n// Returns: True if successful or False otherwise.\n //\n// Errors: If invalid configuration is provided then returns an Error message indicating that."}
{"id": 5865, "code": "func (a *API) CreateContactGroup(cfg *ContactGroup) (*ContactGroup, error) {\n\tif cfg == nil {\n\t\treturn nil, fmt.Errorf(\"Invalid contact group config [nil]\")\n\t}\n\n\tjsonCfg, err := json.Marshal(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] create contact group, sending JSON: %s\", string(jsonCfg))\n\t}\n\n\tresult, err := a.Post(config.ContactGroupPrefix, jsonCfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tgroup := &ContactGroup{}\n\tif err := json.Unmarshal(result, group); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn group, nil\n}", "reference": "// CreateContactGroup creates a new contact group.", "generated": "// Creates new Contact Group using API call to server.\n//\n// Args:\n//   - cfg : ContactGroup object that will be created in database.\n//\n// Returns :\n//   - result : Response from server containing updated data for newly added contact group,\n//     or any errors encountered during creation process."}
{"id": 5890, "code": "func NewEllipticSigner(alg Algorithm, curve elliptic.Curve) func(Store, crypto.Hash) (Signer, error) {\n\tcurveBitSize := curve.Params().BitSize\n\n\t// precompute curve key len\n\tkeyLen := curveBitSize / 8\n\tif curveBitSize%8 > 0 {\n\t\tkeyLen++\n\t}\n\n\treturn func(store Store, hash crypto.Hash) (Signer, error) {\n\t\tvar ok bool\n\t\tvar privRaw, pubRaw interface{}\n\t\tvar priv *ecdsa.PrivateKey\n\t\tvar pub *ecdsa.PublicKey\n\n\t\t// check private key\n\t\tif privRaw, ok = store.PrivateKey(); ok {\n\t\t\tif priv, ok = privRaw.(*ecdsa.PrivateKey); !ok {\n\t\t\t\treturn nil, ErrInvalidPrivateKey\n\t\t\t}\n\n\t\t\t// check curve type matches private key curve type\n\t\t\tif curveBitSize != priv.Curve.Params().BitSize {\n\t\t\t\treturn nil, ErrInvalidPrivateKeySize\n\t\t\t}\n\t\t}\n\n\t\t// check public key\n\t\tif pubRaw, ok = store.PublicKey(); ok {\n\t\t\tif pub, ok = pubRaw.(*ecdsa.PublicKey); !ok {\n\t\t\t\treturn nil, ErrInvalidPublicKey\n\t\t\t}\n\t\t}\n\n\t\t// check that either a private or public key has been provided\n\t\tif priv == nil && pub == nil {\n\t\t\treturn nil, ErrMissingPrivateOrPublicKey\n\t\t}\n\n\t\treturn &EccSigner{\n\t\t\talg:    alg,\n\t\t\tcurve:  curve,\n\t\t\thash:   hash,\n\t\t\tpriv:   priv,\n\t\t\tpub:    pub,\n\t\t\tkeyLen: keyLen,\n\t\t}, nil\n\t}\n}", "reference": "// NewEllipticSigner creates an Elliptic Curve Signer for the specified curve.", "generated": "// Create new EccSigner instance for given algorithm and curve.\n//\n// This method returns signers which can be used to create signatures using\n// Elliptical Curve Digital Signature Algorithm (ECDSA). The signature is signed\n// by providing one of the keys from the stored secret set - if no secrets have"}
{"id": 5907, "code": "func FromFile(path string, opts ...Option) (*GServiceAccount, error) {\n\tbuf, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn FromJSON(buf, opts...)\n}", "reference": "// FromFile loads Google service account credentials from a reader.", "generated": "// Load from file path.\n//\n// This loads the service account data directly from the given file,\n// which is expected to be in JSON format (e.g., generated by gcloud). The options can also specify additional parameters for parsing."}
{"id": 5932, "code": "func PostEZCountTime(statName, ezkey string, count int, timestamp int64) error {\n\treturn DefaultReporter.PostEZCountTime(statName, ezkey, count, timestamp)\n}", "reference": "// Using the EZ API, posts a count to a stat at a specific time using DefaultReporter.", "generated": "// Post EZ Count Time - post time to statsd for each event\n//\n// This is used by default in all reports but can be overridden if needed.\n //\n// Note: this method will always return true regardless of whether it was successful or not,\n// because we don't care about errors here. We just want"}
{"id": 5952, "code": "func (s Scan) AddHosts(hosts ...string) Scan {\n\ts.configHosts = append(s.configHosts, hosts...)\n\treturn s\n}", "reference": "// AddHosts adds a list of hosts to the list of hosts to be scanned", "generated": "// Adds host names to scan list.\n//\n// Returns this scanner for method chaining."}
{"id": 5955, "code": "func (s Scan) SetPorts(ports ...uint16) Scan {\n\ts.configPorts = ports\n\treturn s\n}", "reference": "// SetPorts sets the ports that wil be used", "generated": "// Sets Ports to scan for connections from clients.\n//\n// This method sets all fields in its receiver by default so that no additional\n// arguments need be passed when calling this method. Use this method sparingly,\n// since it modifies the structure directly. If you want more control over which\n// field(s) get"}
{"id": 5964, "code": "func (otp HOTP) Counter() uint64 {\n\tcounter := binary.BigEndian.Uint64(otp.counter[:])\n\treturn counter\n}", "reference": "// Counter returns the HOTP's 8-byte counter as an unsigned 64-bit\n// integer.", "generated": "// Returns current hotp code value for this token.\n//\n// This method is intended to be used in situations where it's necessary to know\n// exactly how many times the key has been generated or when generating new keys,\n// but there isn't enough space left over from previous generation operations to store that information directly into"}
{"id": 5967, "code": "func (otp *HOTP) URL(label string) string {\n\tsecret := base32.StdEncoding.EncodeToString(otp.Key)\n\tu := url.URL{}\n\tv := url.Values{}\n\tu.Scheme = \"otpauth\"\n\tu.Host = \"hotp\"\n\tu.Path = label\n\tv.Add(\"secret\", secret)\n\tv.Add(\"counter\", fmt.Sprintf(\"%d\", otp.Counter()))\n\tu.RawQuery = v.Encode()\n\treturn u.String()\n}", "reference": "// URL returns a suitable URL, such as for the Google Authenticator\n// app. The label is used by these apps to identify the service to\n// which this OTP belongs. The digits value is ignored by the Google\n// authenticator app, and is therefore elided in the resulting URL.", "generated": "// Generate HOTP authentication URLs for various labels.\n//\n// This method returns hotp auth urls in standard format that can be used to authenticate using any client supporting OTPAuth protocol. The counter is incremented each time this method is called so it's possible to use same key multiple times without collision."}
{"id": 5975, "code": "func Marshal(otp *HOTP) ([]byte, error) {\n\tvar asnHOTP struct {\n\t\tKey     []byte\n\t\tCounter *big.Int\n\t\tDigits  int\n\t}\n\tasnHOTP.Key = otp.Key[:]\n\tasnHOTP.Counter = new(big.Int).SetUint64(otp.Counter())\n\tasnHOTP.Digits = otp.Digits\n\treturn asn1.Marshal(asnHOTP)\n}", "reference": "// Marshal serialises an HOTP key value as a DER-encoded byte slice.", "generated": "// Marshal converts HOTP to ASN.1 format.\n//\n// Note: This is only used for encoding purposes in this package,\n// so it's safe to use any value that can be encoded into bytes.\n //\n// The counter should always start from zero when using Hotp. If you want\n// to generate hot"}
{"id": 5981, "code": "func (pool *ReaderPool) Get(r io.Reader) (reader io.Reader, release func()) {\n\t// don't export a ThrottlerReader to prevent users changing the rate\n\t// and expecting their change to be respected, since we might modify\n\t// the rate under their feet\n\n\t// make the initial rate be 0, the actual rate is\n\t// set in the call to `setSharedRates`.\n\trd := ThrottledReader(r, 0, pool.maxBurst)\n\n\tpool.mu.Lock()\n\tpool.givenOut[rd] = struct{}{}\n\tpool.setSharedRates()\n\tpool.mu.Unlock()\n\n\treturn rd, func() {\n\t\tpool.mu.Lock()\n\t\tdelete(pool.givenOut, rd)\n\t\tpool.setSharedRates()\n\t\tpool.mu.Unlock()\n\t}\n}", "reference": "// Get a throttled reader that wraps r.", "generated": "//\n// Returns a reader that will throttle its output based on shared rates.\n //\n// The caller must ensure they do not hold onto this return value for more than\n// maxWait seconds or else it may block indefinitely if there's no available\n// readers at the current time. This can happen when all possible threads have"}
{"id": 6002, "code": "func JsonFile(path string) (Typed, error) {\n\tdata, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn Json(data)\n}", "reference": "// Create a Typed helper from the JSON within a file", "generated": "// Load JSON from file path.\n//\n// Returns Typed if successful or nil otherwise. Error is returned in case of failure,\n// but it's always non-nil for errors that occur while reading the file."}
{"id": 6018, "code": "func (t Typed) TimeMust(key string) time.Time {\n\ttt, exists := t.TimeIf(key)\n\tif exists == false {\n\t\tpanic(\"expected time.Time value for \" + key)\n\t}\n\treturn tt\n}", "reference": "// Returns a time.Time or panics", "generated": "// TimeMust returns the typed field if it is present in the map,\n// otherwise panic's with message indicating that expected type was missing.\n//\n// This method can be used to ensure that all fields have been set before using them."}
{"id": 6025, "code": "func (t Typed) BoolsOr(key string, d []bool) []bool {\n\tn, ok := t.BoolsIf(key)\n\tif ok {\n\t\treturn n\n\t}\n\treturn d\n}", "reference": "// Returns an slice of boolean, or the specified slice", "generated": "// Booleans or returns all values if key is present in typed map,\n// otherwise it will return given array."}
{"id": 6037, "code": "func NewWorker(logger log.Logger, db *reform.DB, ethBack eth.Backend,\n\tgasConc *GasConf, pscAddr common.Address, payAddr string,\n\tpwdGetter data.PWDGetter, countryConf *country.Config,\n\tdecryptKeyFunc data.ToPrivateKeyFunc, eptConf *ept.Config,\n\ttorHostname string, somcClientBuilder somc.ClientBuilderInterface) (*Worker, error) {\n\n\tl := logger.Add(\"type\", \"proc/worker.Worker\")\n\n\tabi, err := abi.JSON(\n\t\tstrings.NewReader(contract.PrivatixServiceContractABI))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\teptService, err := ept.New(db, logger, payAddr, eptConf.Timeout)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &Worker{\n\t\tabi:               abi,\n\t\tlogger:            l,\n\t\tdb:                db,\n\t\tdecryptKeyFunc:    decryptKeyFunc,\n\t\tgasConf:           gasConc,\n\t\tept:               eptService,\n\t\tethBack:           ethBack,\n\t\tpscAddr:           pscAddr,\n\t\tpwdGetter:         pwdGetter,\n\t\tcountryConfig:     countryConf,\n\t\ttorHostName:       data.FromBytes([]byte(torHostname)),\n\t\tsomcClientBuilder: somcClientBuilder,\n\t}, nil\n}", "reference": "// NewWorker returns new instance of worker.", "generated": "// Create new worker instance for private key service contract.\n//\n// Args:\n//   - logger: logging context to use in this process.\n//   - database connection used by all services.\n//   - backend interface that provides access to Ethereum network.\n//   - configuration object containing parameters related to transaction fees.\n//"}
{"id": 6089, "code": "func AddWithDelay(q Queue, tx *reform.TX,\n\tjobType, relatedType, relatedID, creator string,\n\tdelay time.Duration) error {\n\treturn AddWithDataAndDelay(q, tx,\n\t\tjobType, relatedType, relatedID, creator, &struct{}{}, delay)\n}", "reference": "// AddWithDelay is convenience method to add a job with given data delay.", "generated": "// Adds job to queue after specified amount of delays.\n//\n// This is useful when we need some extra space in our database for\n// certain operations (like creating new nodes). We can add them now but wait until later before actually adding it into DB."}
{"id": 6115, "code": "func NewFileLogger(conf *FileConfig) (Logger, io.Closer, error) {\n\tnow := time.Now()\n\tif conf.UTC {\n\t\tnow = now.UTC()\n\t}\n\n\tfile, err := os.OpenFile(\n\t\ttimeutil.Strftime(&now, conf.Filename),\n\t\tos.O_APPEND|os.O_CREATE|os.O_WRONLY, conf.FileMode)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tlogger, err := NewWriterLogger(conf.WriterConfig, file)\n\tif err != nil {\n\t\tfile.Close()\n\t\treturn nil, nil, err\n\t}\n\n\treturn logger, file, nil\n}", "reference": "// NewFileLogger creates a new file logger.", "generated": "// Create new File Logger instance from config.\n//\n// If filename is empty or zero string then it will be generated based on current date in UTC format,\n// if timezone option is set to true otherwise local time zone would be used for generating filename.\n //\n// The log writer can also append logs instead of overwriting them"}
{"id": 6138, "code": "func (b *backendInstance) EthBalanceAt(ctx context.Context,\n\towner common.Address) (*big.Int, error) {\n\tctx2, cancel := b.addTimeout(ctx)\n\tdefer cancel()\n\n\treturn b.conn.ethClient().BalanceAt(ctx2, owner, nil)\n}", "reference": "// EthBalanceAt returns the wei balance of the given account.", "generated": "// EthBalanceAt returns balance for given address at current block number.\n//\n// This method is used to get balance in eth units from blockchain\n// client's perspective. It doesn't take into account any fees or gas costs that may be associated with transaction operations."}
{"id": 6147, "code": "func (w *Worker) keyFromChannelData(logger log.Logger,\n\tchannel string) (data.Base64String, error) {\n\tch, err := w.channel(logger, channel)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\toffering, err := w.offering(logger, ch.Offering)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tkey, err := data.ChannelKey(ch.Client, ch.Agent,\n\t\tch.Block, offering.Hash)\n\t// internal\n\tif err != nil {\n\t\tlogger.Add(\"channel\", ch, \"offering\", offering).Error(err.Error())\n\t\treturn \"\", ErrInternal\n\t}\n\treturn data.FromBytes(key), nil\n}", "reference": "// keyFromChannelData returns the unique channel identifier\n// used in a Privatix Service Contract.", "generated": "// keyFromChannelData returns the base64 encoded ChannelKey from the given\n// Offering object for the specified channel.\n//\n// If there is no Offer or if it's invalid then return empty Base64String\n// and non-nil Error respectively."}
{"id": 6157, "code": "func (w *Worker) AgentAfterOfferingDelete(job *data.Job) error {\n\tlogger := w.logger.Add(\n\t\t\"method\", \"AgentAfterOfferingDelete\", \"job\", job)\n\n\toffering, err := w.relatedOffering(\n\t\tlogger, job, data.JobAgentAfterOfferingDelete)\n\tif err != nil {\n\t\treturn err\n\t}\n\toffering.Status = data.OfferRemoved\n\n\tif err := w.saveRecord(logger, w.db.Querier, offering); err != nil {\n\t\treturn err\n\t}\n\n\tagent, err := w.account(logger, offering.Agent)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn w.addJob(logger, nil,\n\t\tdata.JobAccountUpdateBalances, data.JobAccount, agent.ID)\n}", "reference": "// AgentAfterOfferingDelete set offering status to `remove`", "generated": "// AgentAfterOfferingDelete is called after removing an offer from the database.\n//\n// This method updates account balances for all agents that were involved in this\n// transaction to reflect their new balance due to removal of the offer.  The result\n// will be updated if there was any change made by this call or"}
{"id": 6177, "code": "func (m *Monitor) VerifyChannelsForInactivity() error {\n\tquery := `\n              SELECT channels.id::text\n\t\tFROM channels\n                     LEFT JOIN sessions ses\n                     ON channels.id = ses.channel\n                     LEFT JOIN offerings offer\n                     ON channels.offering = offer.id\n                     INNER JOIN accounts acc\n                     ON channels.agent = acc.eth_addr\n               WHERE channels.service_status IN ('pending', 'active', 'suspended')\n                 AND channels.channel_status NOT IN ('pending')\n                 AND acc.in_use\n               GROUP BY channels.id, offer.max_inactive_time_sec\n              HAVING GREATEST(MAX(ses.last_usage_time), channels.service_changed_time) +\n\t      (offer.max_inactive_time_sec * INTERVAL '1 second') < now();`\n\n\treturn m.processEachChannel(query, m.terminateService)\n}", "reference": "// VerifyChannelsForInactivity scans all channels, that are not terminated,\n// and terminates those of them, who are staying inactive too long.", "generated": "//Verify Channels for inactivity checks if any channel has been inactive longer than its maximum allowed time.\n//\n//This is used to terminate services that have had no activity after their max_inactivity period,\n//and should be called periodically by Monitor's timer.  This method returns nil when there were\n//no active or"}
{"id": 6235, "code": "func New(db *reform.DB, logger log.Logger, payAddr string,\n\ttimeout uint) (*Service, error) {\n\treturn &Service{\n\t\tdb:      db,\n\t\tmsgChan: make(chan *req),\n\t\tpayAddr: payAddr,\n\t\ttimeout: time.Duration(timeout) * time.Millisecond,\n\t\tlogger:  logger.Add(\"type\", \"messages/ept.Service\"),\n\t}, nil\n}", "reference": "// New function for initialize the service for generating\n// the Endpoint Message.", "generated": "// Create new service instance.\n//\n// This method creates new Service object which is used to send messages from client side.\n //\n// Args:\n //\n // - db     database connection for storing message history records.\n // - logger logging context where logs will be written in this case it's ept Logger type.\n // - pay"}
{"id": 6244, "code": "func BytesToUint32(b []byte) (uint32, error) {\n\tif len(b) != 4 {\n\t\treturn 0, fmt.Errorf(\"wrong len\")\n\t}\n\treturn binary.BigEndian.Uint32(b), nil\n}", "reference": "// BytesToUint32 using big endian.", "generated": "// Convert bytes to uint32.\n//\n// If length is incorrect return err."}
{"id": 6251, "code": "func ChannelKey(client, agent HexString, block uint32,\n\tofferingHash HexString) ([]byte, error) {\n\tclientAddr, err := HexToAddress(client)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tagentAddr, err := HexToAddress(agent)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\thash, err := base64.URLEncoding.DecodeString(\n\t\tstrings.TrimSpace(string(offeringHash)))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tblockBytes := Uint32ToBytes(block)\n\n\treturn crypto.Keccak256(clientAddr.Bytes(),\n\t\tagentAddr.Bytes(), blockBytes[:],\n\t\tcommon.BytesToHash(hash).Bytes()), nil\n}", "reference": "// ChannelKey returns the unique channel identifier\n// used in a Privatix Service Contract.", "generated": "// ChannelKey returns key for given client address, offering hash and block number.\n//\n// This is used to encrypt data in channel messages that need encryption. The result can be decoded by unkeying using UnchannelKey."}
{"id": 6280, "code": "func PanicHunter() {\n\tif panicIgnore {\n\t\treturn\n\t}\n\n\tif err := recover(); err != nil {\n\t\tif enable && notifier != nil {\n\t\t\tnotifier.NotifySync(\n\t\t\t\terrors.New(err, 3), true,\n\t\t\t\tmetadata([]data.HexString{defaultAccEth}))\n\t\t}\n\t\tpanic(err)\n\t}\n}", "reference": "// PanicHunter catches panic, in case of an enabled reporter.", "generated": "// PanicHunter is used to catch panics in go code that should be reported.\n//\n// This will call notify if it's enabled and there is no ignore set for this error type."}
{"id": 6291, "code": "func (m *Marshaller) MarshalRaw(bs []byte) {\n\tif m.Error != nil {\n\t\treturn\n\t}\n\tif len(m.Data) < m.offset+len(bs) {\n\t\tm.Error = io.ErrShortBuffer\n\t\treturn\n\t}\n\n\tm.offset += copy(m.Data[m.offset:], bs)\n}", "reference": "// MarshalRaw copies the raw bytes to the buffer, without a size prefix or\n// padding. This is suitable for appending data already in XDR format from\n// another source.", "generated": "// Marshals raw data into buffer.\n//\n// If error is set then no further marshaling will be done for this call,\n// but it can still return after calling another marshal method that may reset\n// errors to zero or change them again if needed."}
{"id": 6293, "code": "func (m *Marshaller) MarshalBytes(bs []byte) {\n\tif m.Error != nil {\n\t\treturn\n\t}\n\tif len(m.Data) < m.offset+4+len(bs)+Padding(len(bs)) {\n\t\tm.Error = io.ErrShortBuffer\n\t\treturn\n\t}\n\n\tm.MarshalUint32(uint32(len(bs)))\n\tm.offset += copy(m.Data[m.offset:], bs)\n\tm.offset += copy(m.Data[m.offset:], padBytes[:Padding(len(bs))])\n}", "reference": "// MarshalString appends the bytes to the buffer, with a size prefix and\n// correct padding.", "generated": "// Marshals bytes to buffer using marshaled data format.\n//\n// If error is set then no further operations can be performed by this object,\n// it should never happen in normal usage but may occur if there's some internal\n// issue or bug that causes unexpected errors during serialization process."}
{"id": 6308, "code": "func Prefix(prefix string, p AssetPipeline) AssetPipeline {\n\tif prefix == \"\" {\n\t\treturn p\n\t}\n\n\treturn &prefixPipeline{\n\t\tprefix:        prefix,\n\t\tAssetPipeline: p,\n\t}\n}", "reference": "// Prefix returns an AssetPipeline that prefixes URLs with the\n// given string", "generated": "// Prefix returns a new pipeline that includes all assets from this one but prefixed by the given name.\n//\n// This is useful for creating pipelines where each asset has its own namespace or prefix. For example if we have two pipes named 'pipe1' and 'pipe2', then using Pipe('pipe1').Prefix('"}
{"id": 6327, "code": "func Map(ss []string, callback func(string) string) []string {\n\tnewStrings := make([]string, len(ss))\n\tfor i, s := range ss {\n\t\tnewStrings[i] = callback(s)\n\t}\n\n\treturn newStrings\n}", "reference": "// Map returns a slice containing all the elements of ss\n// after applying the callback function to each one", "generated": "// Maps each element in the input slice to its corresponding result from the output slice.\n//\n// This is similar to map but returns slices instead of values. The order of elements remains unchanged,\n// unless there's a collision (i.e., two different inputs have the same index). In that case, only one value will"}
{"id": 6383, "code": "func SelectMany(subject Enumerable, toMany Unfolder) Enumerable {\n\treturn selectManyer{\n\t\toriginal: subject,\n\t\ttoMany:   toMany,\n\t}\n}", "reference": "// SelectMany allows for unfolding of values.", "generated": "// SelectMany returns all elements from'subject' that match any element in\n//\n// 'toMany'.  The result is ordered by matching order.\n //\n// This method can be used for selecting many-to-many relationships between two tables.\n //\n// Example:\n//\n// var users = db.Table(\"users\")\n// var"}
{"id": 6400, "code": "func (stack *Stack) IsEmpty() bool {\n\tstack.key.RLock()\n\tdefer stack.key.RUnlock()\n\treturn stack.underlyer == nil || stack.underlyer.IsEmpty()\n}", "reference": "// IsEmpty tests the Stack to determine if it is populate or not.", "generated": "// Returns true if there is no element in this Stack.\n//\n// This method returns false when it's called while iterating over\n// elements using Iterate()."}
{"id": 6407, "code": "func (list *LinkedList) Enumerate(cancel <-chan struct{}) Enumerator {\n\tretval := make(chan interface{})\n\n\tgo func() {\n\t\tlist.key.RLock()\n\t\tdefer list.key.RUnlock()\n\t\tdefer close(retval)\n\n\t\tcurrent := list.first\n\t\tfor current != nil {\n\t\t\tselect {\n\t\t\tcase retval <- current.payload:\n\t\t\t\tbreak\n\t\t\tcase <-cancel:\n\t\t\t\treturn\n\t\t\t}\n\t\t\tcurrent = current.next\n\t\t}\n\t}()\n\n\treturn retval\n}", "reference": "// Enumerate creates a new instance of Enumerable which can be executed on.", "generated": "// Enumerate returns enumerator for all elements in this LinkedList.\n//\n// This method is non-blocking if cancel channel has been closed or cancelled,\n// otherwise it blocks until cancellation happens."}
{"id": 6415, "code": "func (list *LinkedList) Sort(comparator Comparator) error {\n\tlist.key.Lock()\n\tdefer list.key.Unlock()\n\tvar err error\n\tlist.first, err = mergeSort(list.first, comparator)\n\tif err != nil {\n\t\treturn err\n\t}\n\tlist.last = findLast(list.first)\n\treturn err\n}", "reference": "// Sort rearranges the positions of the entries in this list so that they are\n// ascending.", "generated": "// Sort sorts this linked list in ascending order using the given comparison.\n//\n// This method returns any errors that occur during sorting. If no errors occurred,\n// then it sets last to first so we can start iterating over all elements from here.\n //\n// Note: The sorted list is stored within the lock held by key"}
{"id": 6420, "code": "func merge(left, right *llNode, comparator Comparator) (first *llNode, err error) {\n\tcurLeft := left\n\tcurRight := right\n\n\tvar last *llNode\n\n\tappendResults := func(updated *llNode) {\n\t\tif last == nil {\n\t\t\tlast = updated\n\t\t} else {\n\t\t\tlast.next = updated\n\t\t\tlast = last.next\n\t\t}\n\t\tif first == nil {\n\t\t\tfirst = last\n\t\t}\n\t}\n\n\tfor curLeft != nil && curRight != nil {\n\t\tvar res int\n\t\tif res, err = comparator(curLeft.payload, curRight.payload); nil != err {\n\t\t\tbreak // Don't return, stitch the remaining elements back on.\n\t\t} else if res < 0 {\n\t\t\tappendResults(curLeft)\n\t\t\tcurLeft = curLeft.next\n\t\t} else {\n\t\t\tappendResults(curRight)\n\t\t\tcurRight = curRight.next\n\t\t}\n\t}\n\n\tif curLeft != nil {\n\t\tappendResults(curLeft)\n\t}\n\tif curRight != nil {\n\t\tappendResults(curRight)\n\t}\n\treturn\n}", "reference": "// merge takes two sorted lists and merges them into one sorted list.\n// Behavior is undefined when you pass a non-sorted list as `left` or `right`", "generated": "// Merge two sorted lists into one ordered list using O(n+m). The result is\n// always in ascending order according to the comparison provided by the\n//Comparator interface. If there's no common element between both input,\n//the returned node will be null. This method returns errors for any other\n//case that"}
{"id": 6439, "code": "func (l *List) Remove(pos uint) (interface{}, bool) {\n\tl.key.Lock()\n\tdefer l.key.Unlock()\n\n\tif pos > uint(len(l.underlyer)) {\n\t\treturn nil, false\n\t}\n\tretval := l.underlyer[pos]\n\tl.underlyer = append(l.underlyer[:pos], l.underlyer[pos+1:]...)\n\treturn retval, true\n}", "reference": "// Remove retreives a value from this List and shifts all other values.", "generated": "// Removes item from list at given position.\n//\n// Returns value removed or nil if there is no such element in list,\n// also returns whether removal was successful."}
{"id": 6484, "code": "func (h *Handler) Rule(r rule.Rule) *Handler {\n\tif r == nil {\n\t\t// if nothing passed then use the allow-everyting rule\n\t\tr = rule.Satisfied()\n\t}\n\th.rule = r\n\n\treturn h\n}", "reference": "// Rule sets the ruleset for this handler.\n//\n// returns itself.", "generated": "//\n// Set up rules for this handler to be used in route handlers.\n //\n// This is useful when building routes that need specific permissions or access control checks,\n //\n// e.g., \"route\": \"/api/v1/users\", \"rule\": [\"user:\", []string{\"read\"}]\n //\n// Note: If no"}
{"id": 6515, "code": "func (c Client) CreateUser(email string, password string) (*user, error) {\n\tparams := map[string]interface{}{\n\t\t\"user[email]\":    email,\n\t\t\"user[password]\": password,\n\t}\n\tholder := userHolder{}\n\tif err := c.Post(\"users\", params, &holder); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := checkApiErrors(holder.response, \"CreateUser\"); err != nil {\n\t\treturn nil, err\n\t}\n\treturn &holder.User, nil\n}", "reference": "// CreateUser creates a new user given an email and password", "generated": "// Create User creates new account for given credentials.\n//\n// Returns *nil if there was any errors during creation process or *\n// created user object otherwise."}
{"id": 6523, "code": "func (c Client) GetTransfers(page int) (*transfers, error) {\n\tparams := map[string]int{\n\t\t\"page\": page,\n\t}\n\tholder := transfersHolder{}\n\tif err := c.Get(\"transfers\", params, &holder); err != nil {\n\t\treturn nil, err\n\t}\n\ttransfers := transfers{\n\t\tpaginationStats: holder.paginationStats,\n\t}\n\t// Remove one layer of nesting\n\tfor _, t := range holder.Transfers {\n\t\ttransfers.Transfers = append(transfers.Transfers, t.Transfer)\n\t}\n\treturn &transfers, nil\n}", "reference": "// GetTransfers get transfers associated with an account", "generated": "//\n// Returns list of all transactions in database.\n //\n// Page is used to get more than 1000 results at once. The first result will be returned when using this method for the second time or later. If there's no next page available then it returns nil."}
{"id": 6531, "code": "func (d *SerialDispatcher) DispatchOptional(cmd interface{}) (err error) {\n\td.mutex.RLock()\n\tdefer d.mutex.RUnlock()\n\n\terr = d.Dispatch(cmd)\n\tswitch err.(type) {\n\tcase *NoHandlerFoundError:\n\t\treturn nil\n\tdefault:\n\t\treturn err\n\t}\n}", "reference": "// DispatchOptional implements `Dispatcher.DispatchOptional`", "generated": "// DispatchOptional is similar to dispatch but returns if no handler was found for cmd.\n//\n// This can be used when we don't care about errors that aren't handled by our handlers,\n// such as No Handler Found Error or Invalid Command Errors."}
{"id": 6532, "code": "func NewParallelDispatcher(handlers []Handler) Dispatcher {\n\treturn &ParallelDispatcher{\n\t\thandlers: handlers,\n\t\tmutex:    sync.RWMutex{},\n\t}\n}", "reference": "// NewParallelDispatcher creates a new PrallelDispatcher with the given handlers", "generated": "// Create new parallel dispatcher.\n//\n// This is used to create dispatchers that can handle multiple requests in\n// parallel for each handler. The mutex ensures safe access from concurrent\n// threads."}
{"id": 6537, "code": "func (l *listener) Accept() (transport.Conn, error) {\n\tif c, ok := <-l.incoming; ok {\n\t\treturn c.conn, c.err\n\t}\n\treturn nil, fmt.Errorf(\"listener is closed\")\n}", "reference": "// Accept waits for and returns the next connection to the listener.", "generated": "// Accept returns connection from listener's queue or return nil if it has been closed.\n//\n// This method should be called only once per lifetime of listener instance,\n// otherwise this will lead to panic when trying to accept another connection after first one was accepted."}
{"id": 6557, "code": "func NewCommand(name string, args ...string) *Command {\n\treturn &Command{\n\t\tname: name,\n\t\targs: args,\n\t}\n}", "reference": "// NewCommand creates a new Livestatus command instance.", "generated": "// Create new command instance.\n//\n// Args must be non-empty strings or nils for empty commands\n// if there is no argument to pass in this case use default value \"command\"\n// which will return error when trying to execute it without any arguments."}
{"id": 6564, "code": "func (r Record) GetSlice(column string) ([]interface{}, error) {\n\tv, err := r.getKey(reflect.Slice, column)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trv := reflect.ValueOf(v)\n\tn := rv.Len()\n\tout := make([]interface{}, n)\n\n\tfor i := 0; i < n; i++ {\n\t\tout[i] = rv.Index(i).Interface()\n\t}\n\n\treturn out, nil\n}", "reference": "// GetSlice returns a slice of interface value for a specific column.", "generated": "// Get Slice returns all values in slice for given key.\n//\n// If value is empty or null it will return nil. Error if there's no such field,\n// otherwise errors returned by getKey method."}
{"id": 6588, "code": "func RemoveSvcAcknowledgement(\n\thost_name string,\n\tservice_description string,\n) *livestatus.Command {\n\treturn livestatus.NewCommand(\n\t\t\"REMOVE_SVC_ACKNOWLEDGEMENT\",\n\t\tstringifyArg(\"host_name\", \"string\", host_name),\n\t\tstringifyArg(\"service_description\", \"string\", service_description),\n\t)\n}", "reference": "// RemoveSvcAcknowledgement creates a new \"REMOVE_SVC_ACKNOWLEDGEMENT\" Nagios command.\n//\n// This removes the problem acknowledgement for a particular service.\n//\n// Once the acknowledgement has been removed, notifications can once again be sent out for the given service.", "generated": "// REMOVE_SVC_ACKNOWLEDGEMENT removes all acknowledgement for\n// given service from server.\n//\n// Args: host_name - name or IP address of machine to remove\n//        service_description - short description of service that should be removed"}
{"id": 6615, "code": "func NewCmdWithRunner(cmdName string, runner func()) (*CmdWithRunner, error) {\n\tif cmdName == \"\" {\n\t\treturn nil, errors.New(\"cmdName cannot be blank\")\n\t}\n\n\tfor _, r := range cmdName {\n\t\tif unicode.IsSpace(r) {\n\t\t\treturn nil, errors.Errorf(\"cmdName cannot contain whitespace: %q\", cmdName)\n\t\t}\n\t}\n\n\treturn &CmdWithRunner{\n\t\tcmdName: cmdName,\n\t\trunner:  runner,\n\t}, nil\n}", "reference": "// NewCmdWithRunner creates a new CmdWithRunner for the provided name and runner. Returns an error if the provided name\n// is not a legal command name.", "generated": "// Create new CmdWithRunner from given command name.\n//\n// This method checks if provided command is valid (contains only letters or digits). If it's invalid then returns error message indicating that."}
{"id": 6617, "code": "func importBreakPaths(file *ast.File) []string {\n\tvar output []string\n\n\tfor _, decl := range file.Decls {\n\t\tif gen, ok := decl.(*ast.GenDecl); ok && gen.Tok == token.IMPORT {\n\t\t\tfor srcIndex, currSpec := range gen.Specs {\n\t\t\t\tif srcIndex > 0 {\n\t\t\t\t\t// if there was a previous element, check if the group has changed\n\t\t\t\t\tcurrGroup := importGroup(importPath(currSpec))\n\t\t\t\t\tprevGroup := importGroup(importPath(gen.Specs[srcIndex-1]))\n\t\t\t\t\tif currGroup != prevGroup {\n\t\t\t\t\t\t// if group has changed, add path to the output\n\t\t\t\t\t\toutput = append(output, importPath(gen.Specs[srcIndex]))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// assume that only one import token block exists\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn output\n}", "reference": "// importBreakPaths returns a slice that contains the import paths before which a line breaks should be inserted.", "generated": "// Import paths from all imports in this package.\n//\n// This is used for generating documentation files which need to include\n// every imported module's name. The result will be empty if no imports exist,\n// or if they have been removed by removing them manually using go mod tidy."}
{"id": 6619, "code": "func SupplierWithPrependedArgs(s CmderSupplier, argsFunc func(cmd Cmd) []string) CmderSupplier {\n\treturn func(cmd Cmd) (Cmder, error) {\n\t\tr, err := s(cmd)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn CmderWithPrependedArgs(r, argsFunc(cmd)...), nil\n\t}\n}", "reference": "// SupplierWithPrependedArgs returns a new Supplier that invokes the provided supplier and returns the result of calling\n// RunnerWithPrependedArgs on the returned runner with the result of applying the provided \"argsFunc\" function to the\n// provided command.", "generated": "// SupplyerWithPreparedArguments returns a supplier that prepends its arguments to each command.\n//\n// ArgsFunction is called for every cmd in order to get additional commands which will be added before any other argument."}
{"id": 6633, "code": "func (t *Timer) ServeHTTP(w http.ResponseWriter, req *http.Request) {\n\n\treq.ParseForm()\n\tsortBy := req.Form.Get(\"sort\")\n\n\tstats := &Stats{}\n\tstats.SortBy = strings.ToLower(sortBy)\n\tstats.Generated = time.Now()\n\tstats.UpTime = fmt.Sprintf(\"%s\", stats.Generated.Sub(t.Since))\n\t// Read access OK for map?\n\tstats.Result = make([]*Stat, 0, len(t.routes))\n\tfor k, v := range t.routes {\n\t\tstat := &Stat{}\n\t\tstat.Route = k\n\t\tstat.Count = v.Count\n\t\tstat.Tot = v.Tot\n\t\tstat.Avg = time.Duration(int64(v.Tot) / v.Count)\n\t\tstat.AvgAfter = time.Duration(int64(v.AfterTot) / v.Count)\n\t\tstat.AvgBefore = time.Duration(int64(v.BeforeTot) / v.Count)\n\t\tstat.Max = v.Max\n\t\tstat.Min = v.Min\n\t\tstats.Result = append(stats.Result, stat)\n\t}\n\tsort.Sort(sort.Reverse(stats))\n\tjsonData, _ := json.Marshal(stats)\n\tw.Write(jsonData)\n}", "reference": "// For serving statistics", "generated": "//\n// Handle HTTP requests to return statistics about all routes.\n //\n// This is used by tools like go-tester which need this information in order\n// to generate reports that can be compared across different runs. The data returned\n// will include total counts, average times taken per route, max/min values,\n// etc"}
{"id": 6638, "code": "func RectFromSphere(c Vec3, r float32) Rectangle {\n\treturn RectWHD(c[0]-r, c[1]-r, c[2]-r, 2*r, 2*r, 2*r)\n}", "reference": "// RectFromSphere returns the minimum rectangle that contains the circle of\n// center c and radius r.", "generated": "// Convert from sphere to rectangle.\n//\n// The center is at (c), radius = r\n //\n // Returns a new rectangle that represents this region in world space,\n // centered around the origin. This will be used for collision detection etc.\n //\n // Note: if there's no overlap between two spheres then they don"}
{"id": 6640, "code": "func (r Rectangle) Size() Vec3 {\n\treturn Vec3{\n\t\tr.Max[0] - r.Min[0],\n\t\tr.Max[1] - r.Min[1],\n\t\tr.Max[2] - r.Min[2],\n\t}\n}", "reference": "// Size returns r's width, height and depth.", "generated": "// Returns size vector for rectangle.\n//\n// This is equivalent to calling VectorSub(r.max,r.min)."}
{"id": 6645, "code": "func (r Rectangle) In(s Rectangle) bool {\n\tif r.Empty() {\n\t\treturn true\n\t}\n\t// Note that r.Max is an exclusive bound for r, so that r.In(s)\n\t// does not require that r.Max.In(s).\n\treturn s.Min[0] <= r.Min[0] && r.Max[0] <= s.Max[0] &&\n\t\ts.Min[1] <= r.Min[1] && r.Max[1] <= s.Max[1]\n}", "reference": "// In reports whether Rectangle r is contained in s.", "generated": "//\n// Returns whether this rectangle contains another.\n //\n // This method returns false if either rectangle has zero area or one side\n // length equals to 0. The rectangles must be non-empty in order to make sense,\n // otherwise they can't contain each other. If both sides have equal lengths then\n // it's"}
{"id": 6647, "code": "func ApproxEpsilon(x, y float64, eps float64) bool {\n\treturn math.Abs(x-y) < eps*(1.0+math.Max(math.Abs(x), math.Abs(y)))\n}", "reference": "// ApproxEpsilon returns true if x ~= y, using provided epsilon value.", "generated": "// Returns true if x is close to y within epsilon.\n//\n// This method uses the definition from\n// http://en.wikipedia.org/wiki/Epsilon_delta_definition_of_limit#Epsilon-%C3%B2delta definition,\n// which states that for any positive real number \\epsilon > 0, we say that x"}
{"id": 6650, "code": "func (v Vec3) Copy(dst Vec3) {\n\tdst[0] = v[0]\n\tdst[1] = v[1]\n\tdst[2] = v[2]\n}", "reference": "// Vec3 methods\n// Copy copies the 3 vector components into dst.", "generated": "// Copies vector from source to destination\n//\n// This is used for copying vectors in memory or when creating new values.\n// It's faster than calling Set() because it doesn't check if dst has been set before,\n// but be aware that this can lead to bugs if called after setting dst first."}
{"id": 6703, "code": "func (c *Client) LoadBalancer(identifier string) (*LoadBalancer, error) {\n\tlb := new(LoadBalancer)\n\t_, err := c.MakeApiRequest(\"GET\", \"/1.0/load_balancers/\"+identifier, nil, lb)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn lb, err\n}", "reference": "// LoadBalancer retrieves a detailed view of one load balancer", "generated": "// Loads load balancer by identifier from API server.\n//\n// Returns nil if there is no such load balancer in the system or if it's already loaded into client cache,\n// otherwise returns the load balancer object which can be used to interact with this load balancer."}
{"id": 6730, "code": "func FromURL(src *url.URL, w io.Writer, options Options) error {\n\thttpClient := getHTTPClient(options)\n\tvar (\n\t\terr  error\n\t\tresp *http.Response\n\t)\n\tdownloader := func() error {\n\t\tresp, err = httpClient.Get(src.String())\n\t\tif err != nil {\n\t\t\treturn &retriableError{errors.Wrap(err, \"Temporary download error\")}\n\t\t}\n\t\tif resp.StatusCode != http.StatusOK {\n\t\t\tdefer func() { _ = resp.Body.Close() }() // #nosec\n\t\t\treturn errors.Errorf(\"received invalid status code: %d (expected %d)\", resp.StatusCode, http.StatusOK)\n\t\t}\n\t\treturn nil\n\t}\n\tretries := options.Retries\n\tif retries == 0 {\n\t\tretries = 5\n\t}\n\tif err = retryAfter(retries, downloader, options.RetryInterval); err != nil {\n\t\treturn errors.Wrap(err, \"download failed\")\n\t}\n\tdefer func() { _ = resp.Body.Close() }() // #nosec\n\n\tvar (\n\t\tvalidator checksumValidator\n\n\t\treader io.Reader = resp.Body\n\t)\n\n\tif options.ProgressBars != nil && resp.ContentLength > 0 {\n\t\tbar := newProgressBar(resp.ContentLength, options.ProgressBars.MaxWidth, options.ProgressBars.Writer)\n\t\tbar.Start()\n\t\treader = bar.NewProxyReader(reader)\n\t\tdefer func() {\n\t\t\t<-time.After(bar.RefreshRate)\n\t\t\tfmt.Println()\n\t\t}()\n\t}\n\n\tvalidator, reader, err = createValidatorReader(reader, options.ChecksumHash, httpClient, options.Checksum, path.Base(src.Path))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, err = io.Copy(w, reader); err != nil {\n\t\treturn errors.Wrap(err, \"failed to copy contents\")\n\t}\n\n\tif !validator.validate() {\n\t\treturn errors.New(\"checksum validation failed\")\n\t}\n\n\treturn nil\n}", "reference": "// FromURL downloads the specified `src` URL to `w` writer using\n// the specified `Options`.", "generated": "// FromURL downloads content from URL using HTTP client provided in option.\n//\n// If there is any issue during downloading it will be retried according to options.Retries,\n// if no value specified then default number of attempts for this operation is set to 3 times.\n //\n// The downloaded data can also contain check sum"}
{"id": 6733, "code": "func RandomSecret(length int, rnd *rand.Rand) string {\n\tif 0 <= length {\n\t\tlength = 10\n\t}\n\tsecret := make([]byte, length)\n\tfor i, _ := range secret {\n\t\tsecret[i] = byte(rnd.Int31() % 256)\n\t}\n\treturn base32.StdEncoding.EncodeToString(secret)\n}", "reference": "// Generate a Random secret encoded as a b32 string\n// If the length is <= 0, a default length of 10 bytes will\n// be used, which will generate a secret of length 16.", "generated": "// Generate random secrets for use in encryption or other security contexts.\n//\n// The generated strings will be at least 8 characters long (base64 encoded). If no randomness is available,\n// it returns \"random\" instead. Length can also specify minimum size if less than that value is desired."}
{"id": 6758, "code": "func (a *AddrBook) RemoveAddress(addr *NetAddress) {\n\ta.mtx.Lock()\n\tdefer a.mtx.Unlock()\n\tka := a.addrLookup[addr.String()]\n\tif ka == nil {\n\t\treturn\n\t}\n\tlog.Info(\"Remove address from book\", \"addr\", addr)\n\ta.removeFromAllBuckets(ka)\n}", "reference": "// RemoveAddress removes the address from the book.", "generated": "// Removes all addresses that match this one from any bucket in the AddrBook.\n//\n// This is used to remove old or invalid addresses when they're no longer needed,\n// but we don't want them removed until after our current buckets have been cleaned up."}
{"id": 6767, "code": "func (na *NetAddress) Dial() (net.Conn, error) {\n\tconn, err := net.Dial(\"tcp\", na.String())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn conn, nil\n}", "reference": "// Dial calls net.Dial on the address.", "generated": "// Dial returns a connection to this address using TCP.\n//\n// This method is intended for use by network code that needs direct access to\n// the underlying socket.  It should be used sparingly in favor of higher level\n// networking functions like Connect or ResolveAndConnect which provide more control\n// over how connections"}
{"id": 6778, "code": "func LogOnPanic(id int64, err interface{}, stacktrace []string, _ *http.Request) {\n\tlogMutex.Lock()\n\tdefer logMutex.Unlock()\n\n\tlog.Printf(\"panic=%016x message=%v\\n\", id, err)\n\tfor _, line := range stacktrace {\n\t\tlog.Printf(\"panic=%016x %s\", id, line)\n\t}\n}", "reference": "// LogOnPanic logs the given panic and its stacktrace, prefixing each line with\n// the panic ID.", "generated": "// Logs panic information to stdout.\n//\n// This is used by go's runtime when it panics in order to print out\n// more detailed error messages for debugging purposes.  It should be called from within\n// any code that may potentially cause a panic (i.e., all code)."}
{"id": 6791, "code": "func (hub *hub) getChannel(name string) *channel {\n\thub.Lock()\n\tdefer hub.Unlock()\n\tcn, ok := hub.channels[name]\n\tif ok {\n\t\treturn cn\n\t}\n\tcn = makeChannel(hub, name)\n\thub.channels[name] = cn\n\tgo cn.start()\n\treturn cn\n}", "reference": "// GetChannel gets or creates new pubsub channel.", "generated": "// Get channel by its name.\n//\n// Returns nil if there is no such channel in this hub or it's already started,\n// otherwise returns new instance for given channel which will be automatically\n// added to hubs channels map after start method call."}
{"id": 6814, "code": "func (c *Client) Push(value interface{}, params map[string]string) (*Client, error) {\n\tbody, err := json.Marshal(value)\n\tif err != nil {\n\t\tlog.Printf(\"%v\\n\", err)\n\t\treturn nil, err\n\t}\n\n\tres, err := c.api.Call(\"POST\", c.Url, c.Auth, body, params)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar r map[string]string\n\n\terr = json.Unmarshal(res, &r)\n\tif err != nil {\n\t\tlog.Printf(\"%v\\n\", err)\n\t\treturn nil, err\n\t}\n\n\tret := &Client{\n\t\tapi:   c.api,\n\t\tAuth:  c.Auth,\n\t\tUrl:   c.Url + \"/\" + r[\"name\"],\n\t\tvalue: value}\n\n\treturn ret, nil\n}", "reference": "// Push creates a new value under the current root url.\n// A populated pointer with that value is also returned.", "generated": "//Push sends data to server for storage.\n//\n//This method is used when storing values in memory or database. The result will be returned by this client if it's stored successfully. If there was any errors during sending then the return value would contain that information."}
{"id": 6821, "code": "func (t *trace) Finish() {\n\tif t.err {\n\t\tincrError(t)\n\t}\n\tincr(t)\n\tduration(t)\n\tif t.err {\n\t\tincrError(t)\n\t}\n\tt.trace.Finish()\n}", "reference": "// Finish declares that this trace is complete.\n// The trace should not be used after calling this method.", "generated": "// Finish marks this trace for completion. If there is still error,\n// it will be incremented again after finish.\n//\n// This should only be called once per thread to avoid double-counting\n// errors in case multiple threads call Finish at different times."}
{"id": 6843, "code": "func (c *Client) PushLinkToChannel(tag, title, u, body string) error {\n\tdata := Link{\n\t\tTag:   tag,\n\t\tType:  \"link\",\n\t\tTitle: title,\n\t\tURL:   u,\n\t\tBody:  body,\n\t}\n\treturn c.Push(\"/pushes\", data)\n}", "reference": "// PushLinkToChannel pushes a link with a title and url to a specific PushBullet device.", "generated": "// Push link to channel\n//\n// Args:\n// - Tag    : Channel name or ID.\n// - Title  : Title for push message.\n// - URL    : URL of content being pushed.\n// - Body   : Message text that will be displayed in chat window when user clicks this push.\n //\n// Returns"}
{"id": 6852, "code": "func (c *cachedLoader) MustGetString(key string) string {\n\tb, err := c.Get(key)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"Could not fetch config (%s) %v\", key, err))\n\t}\n\n\tvar s string\n\terr = json.Unmarshal(b, &s)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"Could not unmarshal config (%s) %v\", key, err))\n\t}\n\n\treturn s\n}", "reference": "// MustGetString fetches the config and parses it into a string.  Panics on failure.", "generated": "// Must GetString returns the value for this configuration option or panics if it cannot be read from storage.\n//\n// This method is used when we need to know that something exists in our cache,\n// but don't care about its contents - just return immediately.  It's faster than Get because\n// there's no"}
{"id": 6870, "code": "func (e *execStreamerBuilder) Exe(exe string) ExecStreamerBuilder {\n\te.d.Exe = exe\n\treturn e\n}", "reference": "//Exe sets the Exe", "generated": "// Set the executable to use for execution. This is used when executing commands from this builder.\n//\n// If set then all command executions will be executed using this executable instead of the default shell."}
{"id": 6884, "code": "func (w *Window) setCell(x, y int, c Cell) {\n\tc.dirty = true\n\tpos := x + (y * w.x)\n\tif pos < len(w.backingStore) {\n\t\tw.backingStore[pos] = c\n\t}\n}", "reference": "// setCell sets the content of the window cell at the x and y coordinate.\n// setCell shall be called from queue context.", "generated": "// Set cell at position in window's backing store.  This is used internally by\n// Window to update its internal state when it changes size or moves.\n//\n// Note: this method should be called from within the main thread only; if\n// done outside that context, there may be unexpected side effects due to"}
{"id": 6896, "code": "func Deinit() {\n\twait := make(chan interface{})\n\tQueue(func() {\n\t\ttermbox.Close()\n\t\tfocus = nil\n\t\tprevFocus = nil\n\t\twindows = make(map[int]*Window) // toss all windows\n\n\t\trawMtx.Lock()\n\t\ttermRaw = false\n\t\trawMtx.Unlock()\n\n\t\twait <- true\n\t})\n\t<-wait\n}", "reference": "// Deinit switches the terminal back to cooked mode and it terminates managed\n// window mode.  Init must be called again if a switch is required again.\n// Deinit shall be called on application exit; failing to do so may leave the\n// terminal corrupted.  If that does happen typing \"reset\" on the shell usually\n// fixes this problem.", "generated": "// Deinit closes termbox's raw mode if it was open when this is called.\n//\n// This should be used to clean up after using termbox in a go program that exits,\n// or for any other reason where we want to close our terminal before exiting."}
{"id": 6933, "code": "func (d *Derive) Update(v float64) {\n\tp := atomic.SwapUint64(&d.value, math.Float64bits(v))\n\td.rate.Update(v - math.Float64frombits(p))\n}", "reference": "// Update update rate value based on the stored previous value.", "generated": "// Updates d value to v.\n//\n// This is used for updating derived values that have been updated\n// by another process or thread.  The update operation will be done atomically,\n// so it's safe from concurrent access issues if multiple threads call this method at once."}
{"id": 6934, "code": "func (r *Reservoir) Snapshot() Distribution {\n\th := newHistogram(defaultHistogramSize)\n\tr.m.Lock()\n\th = r.hist.Copy(h)\n\tr.m.Unlock()\n\treturn h\n}", "reference": "// Snapshot returns a Distribution", "generated": "//Snapshot returns a copy of this reservoir's histogram at its current state.\n//\n//Note: This method is intended to be used for testing purposes only,\n//as it creates a deep copy of the internal histogram data structure."}
{"id": 6957, "code": "func (s *Set) RemoveAll(values ...interface{}) {\n\ts.Lock()\n\tdefer s.Unlock()\n\tfor _, value := range values {\n\t\tdelete(s.m, value)\n\t}\n}", "reference": "// RemoveAll removes all values from the set if they exist in the set.", "generated": "// Removes all specified keys from set.\n//\n// This method removes key-value pairs where both the key and the value\n// match any of the provided arguments. The argument can be either string or interface{} type,\n// but it must have equal comparison to another instance for this operation to succeed.\n //\n// Note: Set"}
{"id": 6980, "code": "func (s *Server) SendRequest(connID string, method string, params interface{}, resHandler func(ctx *ResCtx) error) (reqID string, err error) {\n\tif !s.running.Load().(bool) {\n\t\treturn \"\", errors.New(\"use of closed server\")\n\t}\n\n\tif conn, ok := s.conns.GetOk(connID); ok {\n\t\treqID, err = conn.(*Conn).SendRequest(method, params, resHandler)\n\t\t// todo: only log in debug mode?\n\t\tlog.Printf(\"server: send-request: connID: %v, reqID: %v, method: %v, params: %#v, err (if any): %v\", connID, reqID, method, params, err)\n\t\treturn\n\t}\n\n\treturn \"\", fmt.Errorf(\"connection with requested ID: %v does not exist\", connID)\n}", "reference": "// SendRequest sends a JSON-RPC request through the connection denoted by the connection ID with an auto generated request ID.\n// resHandler is called when a response is returned.", "generated": "//\n// Sends request to specified connection.\n //\n // Returns id of sent request or nil if it was failed due to lack of available connections. If there is no available connections,\n // returns non-zero value for last argument which indicates that this call has been successful but result will be ignored because all other\n // requests have already"}
{"id": 6996, "code": "func (r *Router) Request(route string, handler func(ctx *neptulon.ReqCtx) error) {\n\tr.routes[route] = handler\n}", "reference": "// Request adds a new request route registry.", "generated": "// Register route for request handling.\n//\n// This method registers new routes to be handled by this router instance,\n// which will then handle requests that match these routes when they arrive at it."}
{"id": 7042, "code": "func (c *Conn) setConn(ws *websocket.Conn) error {\n\tc.ws.Store(ws)\n\tc.connected.Store(true)\n\tif err := ws.SetDeadline(time.Now().Add(c.deadline)); err != nil {\n\t\treturn fmt.Errorf(\"conn: error while setting websocket connection deadline: %v\", err)\n\t}\n\treturn nil\n}", "reference": "// Reuse an established websocket.Conn.", "generated": "// Set conn sets up the WebSocket connection to be stored in c's store.\n//\n// This is called when we connect to a server for the first time,\n// or if our current connection has timed out.  It returns any errors that occur during this process."}
{"id": 7046, "code": "func (r *MockReadWriteCloser) Read(p []byte) (n int, err error) {\n\n\tif err = r.ReadErr; err == nil {\n\t\tr.BytesRead = p\n\t\tn = len(p)\n\t}\n\treturn\n}", "reference": "//Read - satisfies reader interface", "generated": "// MockedReader reads from mock reader.\n//\n// This method is used to simulate reading operation for testing purposes only,\n// it should be called before calling Write or Close methods in order to ensure that\n// read operations will return correct results. If this method has been already\n// called then any call to Write or close"}
{"id": 7078, "code": "func (m *MACMaskArg) MarshalBinary() ([]byte, error) {\n\t// Must indicate correct number of directives\n\tif int(m.DirCount) != len(m.Directives) {\n\t\treturn nil, ErrorBadArgumentParameter\n\t}\n\n\t// Allocate byte slice for argument and all directives\n\tb := make([]byte, macMaskArgLen+(directiveLen*m.DirCount))\n\n\t// 1 byte reserved\n\n\tb[1] = uint8(m.Command)\n\tb[2] = uint8(m.Error)\n\tb[3] = m.DirCount\n\n\t// Marshal each directive into binary and copy into byte slice\n\t// after argument\n\tn := 4\n\tfor _, d := range m.Directives {\n\t\tdb, err := d.MarshalBinary()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tcopy(b[n:n+directiveLen], db)\n\t\tn += directiveLen\n\t}\n\n\treturn b, nil\n}", "reference": "// MarshalBinary allocates a byte slice containing the data from a MACMaskArg.\n//\n// If m.DirCount does not indicate the actual length of m.Directives, or\n// a Directive is malformed, ErrorBadArgumentParameter is returned.", "generated": "//\n// Marshals MAC mask arguments to bytes.\n //\n// This method must be called before sending the command over network or file system,\n// otherwise it will result in incorrect data being sent. The returned value is used by\n// unmarshaling code when receiving the message from network or file system. If there's any"}
{"id": 7086, "code": "func (s *CORSHandler) CreatePreflight(routes Routes) Routes {\n\tlist := make(Routes, 0, len(routes))\n\thList := make(map[string]*CORSPreflight, len(routes))\n\tfor _, v := range routes {\n\t\tpreflight, ok := hList[v.Path]\n\t\tif !ok {\n\t\t\tpreflight = &CORSPreflight{\n\t\t\t\t*s,\n\t\t\t\tmake([]string, 0, 1),\n\t\t\t\tv.MustAuth,\n\t\t\t}\n\t\t\thList[v.Path] = preflight\n\t\t}\n\n\t\tpreflight.Methods = append(preflight.Methods, v.Method)\n\t\tif v.MustAuth {\n\t\t\tpreflight.UseCredentials = true\n\t\t}\n\t}\n\n\tfor k, v := range hList {\n\t\tlist = append(list, Route{\n\t\t\tName:       \"\",\n\t\t\tMethod:     DEFAULT_CORS_PREFLIGHT_METHOD,\n\t\t\tPath:       k,\n\t\t\tMustAuth:   v.UseCredentials,\n\t\t\tActionFunc: v.ServeHTTP,\n\t\t})\n\t}\n\treturn list\n}", "reference": "// CreatePreflight creates HTTP routes that handles pre-flight requests.", "generated": "// Create Preflights for CORS handler to use in route table.\n//\n// This method creates prefights that will be used by CORS middleware when it is called from behind proxy servers or other proxies which do not support CORS headers being sent directly to clients. The default methods supported should include OPTIONS if possible since this allows browsers to"}
{"id": 7097, "code": "func (b *RefCountBox) Alloc() (DB, error) {\n\tb.Lock()\n\tdefer b.Unlock()\n\n\tif b.db.DB == nil {\n\t\tif b.DataPath == nil {\n\t\t\treturn DB{}, errorsp.WithStacks(ErrBoxDataPathNotSpecified)\n\t\t}\n\t\tvar db DB\n\t\tvar err error\n\t\tif b.OpenFunc == nil {\n\t\t\tdb, err = Open(b.DataPath(), 0644, nil)\n\t\t} else {\n\t\t\tdb, err = b.OpenFunc(b.DataPath())\n\t\t}\n\t\tif err != nil {\n\t\t\treturn DB{}, errorsp.WithStacks(err)\n\t\t}\n\t\tb.db, b.count = db, 0\n\t}\n\tb.count++\n\treturn b.db, nil\n}", "reference": "// Alloc opens a DB if not openned yet. It adds a reference if already openned.", "generated": "// Allocate a new database instance from this refcount box.\n//\n// This is used to create a new database when it doesn't exist yet,\n// or if there's no existing database in use at all. The returned\n// Database object will be closed automatically by RefCountBox once its reference count reaches zero again."}
{"id": 7105, "code": "func ToSSN(theString, delimiter string) (string, error) {\n\tf := New(theString)\n\tf.removeNonDigits()\n\n\tif f.length != 9 {\n\t\treturn \"\", errors.New(\"string needs to be 9 digits for Social Security Numbers\")\n\t}\n\n\tvar buffer bytes.Buffer\n\tcount := 0\n\n\tfor _, i := range f.theString {\n\t\tcount++\n\n\t\tbuffer.WriteString(string(i))\n\n\t\tif count == 3 || count == 5 {\n\t\t\tbuffer.WriteString(delimiter)\n\t\t}\n\t}\n\treturn buffer.String(), nil\n}", "reference": "// ToSSN will format the provided string as a SSN.", "generated": "// Convert social security number from format \"XXX-XX-XXXX\" or just XXXX into SSN.\n//\n// The result is always in the form XX-XXXX where X's represent numbers,\n// but leading zeros will be removed if present. If there isn't enough\n// characters then it returns an empty string"}
{"id": 7113, "code": "func (c *Config) OptionMap(section string) map[string]string {\n\toptions := make(map[string]string)\n\tfor _, sect := range c.sections {\n\t\tif sect.name == section {\n\t\t\tfor _, opt := range sect.options {\n\t\t\t\toptions[opt.name] = opt.value\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t}\n\treturn options\n}", "reference": "// OptionMap returns the map option => value for a given section.", "generated": "// OptionMap returns all option values for given config section name.\n//\n// If no matching configuration sections is found then it will return empty map."}
{"id": 7121, "code": "func Convert(val interface{}, targetType reflect.Type) reflect.Value {\n\tvalue := reflect.ValueOf(val)\n\tif !value.IsValid() {\n\t\treturn reflect.Zero(targetType)\n\t}\n\n\tvalType := value.Type()\n\tif valType.ConvertibleTo(targetType) {\n\t\treturn value.Convert(targetType)\n\t}\n\n\t//fmt.Printf(\"Value type is %v, emptyInterfaceType is %v, equals %v\\n\", valType, emptyInterfaceType, valType == emptyInterfaceType)\n\tinterfaceVal := value.Interface()\n\n\tswitch realVal := interfaceVal.(type) {\n\tcase float64:\n\t\treturn reflect.ValueOf(realVal).Convert(targetType)\n\tcase []interface{}:\n\t\t// val is of type []interface{}, try to convert to typ\n\t\tsliceSize := len(realVal)\n\t\ttargetSlice := reflect.MakeSlice(targetType, 0, sliceSize)\n\t\telemType := targetType.Elem()\n\t\tfor i := 0; i < sliceSize; i++ {\n\t\t\ttargetSlice = reflect.Append(targetSlice, Convert(value.Index(i), elemType))\n\t\t}\n\t\treturn targetSlice\n\t}\n\n\tpanic(fmt.Errorf(\"convert from type %v to %v failed: %v\", valType, targetType, value))\n}", "reference": "// try to convert value to target type, panic if fail", "generated": "//\n// Converts a given value into another reflection Value.\n //\n // This method will return zero if it can't find any conversion for the values' types,\n // or panic otherwise (since we're using this in our tests).\n //\n // Note that when converting between two interfaces, only equal methods should be used.\n //\n //"}
{"id": 7123, "code": "func Filter(l LogBackend, r Ruler) LogBackend {\n\treturn &filter{\n\t\tLogBackend: l,\n\t\tr:          r,\n\t}\n}", "reference": "// Filter creates a new filter with rules r for l backend.", "generated": "// Filter returns a new log backend that filters logs based on rules.\n//\n// This is useful for testing or logging to different levels than\n// the default level set in the logger configuration file.  The rule\n// filter will only pass through messages where all conditions match true.\n //\n// Note: this method creates a"}
{"id": 7139, "code": "func (cn *ContentNegotiator) getEncoder(req *http.Request) Encoder {\n\tvar result = cn.DefaultEncoder\n\taccept := req.Header.Get(\"Accept\")\n\n\tfor k, v := range cn.encoderMap {\n\t\tif strings.Contains(accept, k) {\n\t\t\tresult = v\n\t\t\tbreak\n\t\t}\n\t}\n\treturn result\n}", "reference": "// getEncoder parses the Accept header an returns the appropriate encoder to use", "generated": "// Get encoder for given request based on Accept header.\n//\n// If no specific content type is specified in Accept,\n// default encoding will be used if available. Otherwise,\n// it returns nil to indicate that there's no suitable encoders."}
{"id": 7148, "code": "func DefaultServiceConfig() ServiceConfig {\n\treturn ServiceConfig{\n\t\t// Dependencies.\n\t\tBackoffFactory: func() Backoff {\n\t\t\treturn &backoff.StopBackOff{}\n\t\t},\n\t\tRandFactory: rand.Int,\n\n\t\t// Settings.\n\t\tRandReader: rand.Reader,\n\t\tTimeout:    1 * time.Second,\n\t}\n}", "reference": "// DefaultServiceConfig provides a default configuration to create a new random\n// service by best effort.", "generated": "//\n// Returns default service config for testing purposes\n//"}
{"id": 7222, "code": "func (logger *Logger) Log(level Level, a ...interface{}) {\n\tlogger.log(level, \"\", a...)\n}", "reference": "// Log logs provided message.", "generated": "// Logs messages to logger's output stream.\n//\n// This method is used for logging level 0-4. For levels above\n// this, use log() or logf()."}
{"id": 7234, "code": "func (e *Entry) getChildEntry(pat string) *Entry {\n\tfor _, entry := range e.entries {\n\t\tif pat == entry.Pattern() {\n\t\t\treturn entry\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// getChildEntry returns a child Entry that matches the given pattern string.", "generated": "//getChildEntry returns child entries matching given path pattern.\n//\n//If no match is found then return nil. If multiple matches exist,\n//return first one encountered in order to avoid infinite loop if there's circular dependency between them."}
{"id": 7263, "code": "func routeSplitFunc(data []byte, atEOF bool) (int, []byte, error) {\n\tif atEOF || data == nil {\n\t\treturn 0, nil, io.EOF\n\t}\n\n\tr, _ := utf8.DecodeRune(data)\n\n\t// matcher\n\tif r == '<' {\n\t\ti := bytes.IndexRune(data, '>')\n\t\tif i == -1 {\n\t\t\treturn 0, nil, NoClosingBracket\n\t\t}\n\t\treturn (i + 1), data[:(i + 1)], nil\n\t}\n\n\t// one char\n\tif len(data) == 1 {\n\t\treturn 1, data, nil\n\t}\n\n\t// should ignore first '/'\n\tslashIndex := bytes.IndexRune(data[1:], '/')\n\tif slashIndex != -1 {\n\t\tslashIndex++\n\t}\n\n\tmatchIndex := bytes.IndexRune(data, '<')\n\n\t// remaining string would be a static entry\n\tif slashIndex == -1 && matchIndex == -1 {\n\t\treturn len(data), data, nil\n\t}\n\n\t// split by '<'\n\t// return data before '<'\n\tif matchIndex != -1 && (slashIndex == -1 || slashIndex > matchIndex) {\n\t\treturn matchIndex, data[:matchIndex], nil\n\t}\n\n\t// split by '/'\n\t// return data before '/' including '/'\n\treturn slashIndex + 1, data[:(slashIndex + 1)], nil\n}", "reference": "// routeSplitFunc is the SplitFunc to scan url pattern.", "generated": "//\n// Split input into routes.\n //\n// This is used to parse the URL path in order to find out which route it matches.\n //\n// The result will contain two parts: the part that was matched against this rule,\n// and any additional text after the matching character ('<'). If there's no more\n//"}
{"id": 7282, "code": "func (s *Image) Run(cfg *RunConfig) (*Container, error) {\n\targs := make([]string, 0, len(cfg.Options)+len(cfg.Args)+1)\n\targs = append(args, cfg.Options...)\n\targs = append(args, s.name)\n\targs = append(args, cfg.Args...)\n\n\tout, err := s.docker.Run(\"run\", args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcontainer := &Container{\n\t\tdocker: s.docker,\n\t\tid:     strings.TrimSpace(out),\n\t}\n\tif container.id == \"\" {\n\t\treturn nil, UnexpectedOutputError(\n\t\t\t\"Unexpected empty output when running docker container\")\n\t}\n\n\treturn container, nil\n}", "reference": "// Run creates a new Docker container as defined by current image and container\n// template.\n//\n// Returns ExternalCmdError or UnexpectedOutputError on error.", "generated": "// Runs the image in Docker using the provided config options.\n//\n// Args:\n//   - cfg: The configuration to use for this run operation.\n//\n// Returns:\n//   - A Container object representing the new instance or nil if there was an error."}
{"id": 7285, "code": "func (s NetworkSettings) PortAt(index int) (string, *HostPublish) {\n\tcounter := 0\n\tfor k, v := range s.Ports {\n\t\tif counter != index {\n\t\t\tcounter++\n\t\t\tcontinue\n\t\t}\n\n\t\treturn k, v\n\t}\n\n\treturn \"\", nil\n}", "reference": "// PortAt returns expose and publish port information at especified index.", "generated": "// PortAt returns port at specified position in list.\n//\n// If there is no such element then it will return empty string for key,\n// and nil value if this field exists but has zero length."}
{"id": 7297, "code": "func (tx Tx) ForEachGob(folders [][]byte, f func(Bucket, bytesp.Slice, interface{}) error) error {\n\treturn tx.ForEach(folders, func(b Bucket, k, bs bytesp.Slice) error {\n\t\tvar v interface{}\n\t\tif err := gob.NewDecoder(&bs).Decode(&v); err != nil {\n\t\t\treturn errorsp.WithStacksAndMessage(err, \"decoding %d bytes value for key %q failed\", len(bs), string(k))\n\t\t}\n\t\treturn errorsp.WithStacks(f(b, k, v))\n\t})\n}", "reference": "// ForEach iterates over all key values of a folder, decode non-nil values using gob.", "generated": "// Each calls f once per bucket entry in each folder.\n//\n// If there is no match then it returns true to continue searching\n// otherwise false which stops further searches.  The default action when\n// this happens will be to return errors from all non-matching entries,\n// but if we pass a custom handler"}
{"id": 7310, "code": "func (handler *WriteHandler) Handle(record *Record) error {\n\t_, err := handler.Writer.Write([]byte(handler.Formatter.Format(record) + \"\\n\"))\n\treturn err\n}", "reference": "// Handle writes all provided log records to writer provided during creation.", "generated": "// Write handles writing to file or stream based on config options.\n//\n// If writer is nil then it will be set by default to stdout if output type is text,\n// otherwise it'll throw panic for non-text types."}
