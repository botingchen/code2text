{"id": 24, "code": "func (c *ServiceDiscoveryConfig) Validate() error {\n\tfor _, cfg := range c.AzureSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in azure_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.ConsulSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in consul_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.DNSSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in dns_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.EC2SDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in ec2_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.FileSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in file_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.GCESDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in gce_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.KubernetesSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in kubernetes_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.MarathonSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in marathon_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.NerveSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in nerve_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.OpenstackSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in openstack_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.ServersetSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in serverset_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.StaticConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in static_configs\")\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// Validate validates the ServiceDiscoveryConfig.", "generated": "// Validate checks if all Azure SD configurations have valid values.\n// If any configuration is empty or has no value it returns an error message indicating which one was invalid. Otherwise,\n// it continues to check other sections for validity before returning nil. This method should be called after setting up service discovery config."}
{"id": 36, "code": "func NewDiscovery(conf SDConfig, logger log.Logger) (*Discovery, error) {\n\trt, err := config_util.NewRoundTripperFromConfig(conf.HTTPClientConfig, \"marathon_sd\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif len(conf.AuthToken) > 0 {\n\t\trt, err = newAuthTokenRoundTripper(conf.AuthToken, rt)\n\t} else if len(conf.AuthTokenFile) > 0 {\n\t\trt, err = newAuthTokenFileRoundTripper(conf.AuthTokenFile, rt)\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\td := &Discovery{\n\t\tclient:     &http.Client{Transport: rt},\n\t\tservers:    conf.Servers,\n\t\tappsClient: fetchApps,\n\t}\n\td.Discovery = refresh.NewDiscovery(\n\t\tlogger,\n\t\t\"marathon\",\n\t\ttime.Duration(conf.RefreshInterval),\n\t\td.refresh,\n\t)\n\treturn d, nil\n}", "reference": "// NewDiscovery returns a new Marathon Discovery.", "generated": "// NewDiscovery creates a discovery client for Marathon.\n//\n// The provided configuration is used to create a round-trip transport that will be passed into the HTTP Client.\n// If authentication tokens or files are specified in the configuration, they are added to the transport before it's given to the http.Client.\n// A Discovery object"}
{"id": 50, "code": "func (d *Discovery) shouldWatch(name string, tags []string) bool {\n\treturn d.shouldWatchFromName(name) && d.shouldWatchFromTags(tags)\n}", "reference": "// shouldWatch returns whether the service of the given name should be watched.", "generated": "// Should watch is used to determine if we need to start watching for changes\n// in this discovery.\n//\n// This method will return true only when both name and tag match against our\n// expected values or names that have been added since last check.\nfunc (d *Discovery) shouldWatch(name string, tags []"}
{"id": 52, "code": "func (d *Discovery) getDatacenter() error {\n\t// If the datacenter was not set from clientConf, let's get it from the local Consul agent\n\t// (Consul default is to use local node's datacenter if one isn't given for a query).\n\tif d.clientDatacenter != \"\" {\n\t\treturn nil\n\t}\n\n\tinfo, err := d.client.Agent().Self()\n\tif err != nil {\n\t\tlevel.Error(d.logger).Log(\"msg\", \"Error retrieving datacenter name\", \"err\", err)\n\t\trpcFailuresCount.Inc()\n\t\treturn err\n\t}\n\n\tdc, ok := info[\"Config\"][\"Datacenter\"].(string)\n\tif !ok {\n\t\terr := errors.Errorf(\"invalid value '%v' for Config.Datacenter\", info[\"Config\"][\"Datacenter\"])\n\t\tlevel.Error(d.logger).Log(\"msg\", \"Error retrieving datacenter name\", \"err\", err)\n\t\treturn err\n\t}\n\n\td.clientDatacenter = dc\n\treturn nil\n}", "reference": "// Get the local datacenter if not specified.", "generated": "// Datacenter returns the data center where this discovery service runs.\n// This method will attempt to retrieve the data center information directly from the Consul agent,\n// falling back to using the 'datacenter' field in the provided configuration if necessary.\n// The returned string should be used when creating a new Discovery instance or setting"}
{"id": 64, "code": "func (ls Labels) HashForLabels(names ...string) uint64 {\n\tb := make([]byte, 0, 1024)\n\n\tfor _, v := range ls {\n\t\tfor _, n := range names {\n\t\t\tif v.Name == n {\n\t\t\t\tb = append(b, v.Name...)\n\t\t\t\tb = append(b, sep)\n\t\t\t\tb = append(b, v.Value...)\n\t\t\t\tb = append(b, sep)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn xxhash.Sum64(b)\n}", "reference": "// HashForLabels returns a hash value for the labels matching the provided names.", "generated": "// HashForLabels returns a hash value for given labels.\n//\n// The returned hash is based on all provided label values in order they appear,\n// separated by'sep' character. If no separator is specified it defaults to ':'.\n//\n// This method can be used when storing or comparing LabelSets without having access"}
{"id": 117, "code": "func ParseExpr(input string) (Expr, error) {\n\tp := newParser(input)\n\n\texpr, err := p.parseExpr()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = p.typecheck(expr)\n\treturn expr, err\n}", "reference": "// ParseExpr returns the expression parsed from the input.", "generated": "// ParseExpr parses the input expression into an Expr.\n//\n// The parser is responsible for breaking down the input string into individual tokens,\n// which can then be used to construct an Expr object. This method returns any errors that occur during parsing or type checking.\nfunc ParseExpr(input string) (Expr, error) {"}
{"id": 129, "code": "func (p *parser) expectOneOf(exp1, exp2 ItemType, context string) item {\n\ttoken := p.next()\n\tif token.typ != exp1 && token.typ != exp2 {\n\t\tp.errorf(\"unexpected %s in %s, expected %s or %s\", token.desc(), context, exp1.desc(), exp2.desc())\n\t}\n\treturn token\n}", "reference": "// expectOneOf consumes the next token and guarantees it has one of the required types.", "generated": "// Expect one of two items to be consumed from the input stream.\n//\n// If both tokens match their respective expectations, this call will panic.\n// Otherwise, it returns the first matching token found in the input stream,\n// which is then removed by calling next(). The error message describes the\n// unexpected type encountered instead"}
{"id": 133, "code": "func (p *parser) expectType(node Node, want ValueType, context string) {\n\tt := p.checkType(node)\n\tif t != want {\n\t\tp.errorf(\"expected type %s in %s, got %s\", documentedType(want), context, documentedType(t))\n\t}\n}", "reference": "// expectType checks the type of the node and raises an error if it\n// is not of the expected type.", "generated": "// ExpectType checks that the given node has the expected value type.\n//\n// If it doesn't match, this will panic to ensure we don't silently\n// accept invalid data from users. The error message is formatted like\n// \"expect TypeX in X, got Y\". This can be used for debugging purposes"}
{"id": 145, "code": "func New(minSize, maxSize int, factor float64, makeFunc func(int) interface{}) *Pool {\n\tif minSize < 1 {\n\t\tpanic(\"invalid minimum pool size\")\n\t}\n\tif maxSize < 1 {\n\t\tpanic(\"invalid maximum pool size\")\n\t}\n\tif factor < 1 {\n\t\tpanic(\"invalid factor\")\n\t}\n\n\tvar sizes []int\n\n\tfor s := minSize; s <= maxSize; s = int(float64(s) * factor) {\n\t\tsizes = append(sizes, s)\n\t}\n\n\tp := &Pool{\n\t\tbuckets: make([]sync.Pool, len(sizes)),\n\t\tsizes:   sizes,\n\t\tmake:    makeFunc,\n\t}\n\n\treturn p\n}", "reference": "// New returns a new Pool with size buckets for minSize to maxSize\n// increasing by the given factor.", "generated": "// New returns a new Pool instance.\n//\n// The returned Pool is initialized to have buckets that can hold values in the range [minSize, maxFactor*maxSize].\n// Each bucket's capacity will be determined by multiplying its index (starting from 0) by the given factor.\n// This allows for efficient resizing"}
{"id": 165, "code": "func sendAlerts(s sender, externalURL string) rules.NotifyFunc {\n\treturn func(ctx context.Context, expr string, alerts ...*rules.Alert) {\n\t\tvar res []*notifier.Alert\n\n\t\tfor _, alert := range alerts {\n\t\t\ta := &notifier.Alert{\n\t\t\t\tStartsAt:     alert.FiredAt,\n\t\t\t\tLabels:       alert.Labels,\n\t\t\t\tAnnotations:  alert.Annotations,\n\t\t\t\tGeneratorURL: externalURL + strutil.TableLinkForExpression(expr),\n\t\t\t}\n\t\t\tif !alert.ResolvedAt.IsZero() {\n\t\t\t\ta.EndsAt = alert.ResolvedAt\n\t\t\t} else {\n\t\t\t\ta.EndsAt = alert.ValidUntil\n\t\t\t}\n\t\t\tres = append(res, a)\n\t\t}\n\n\t\tif len(alerts) > 0 {\n\t\t\ts.Send(res...)\n\t\t}\n\t}\n}", "reference": "// sendAlerts implements the rules.NotifyFunc for a Notifier.", "generated": "// Send sends all given alerts to the specified channel.\n//\n// If no alerts were provided, it will be empty but still sent over the channel.\n// This is useful for sending notifications when there's nothing to notify about yet.\n// The returned rule can then be used in conjunction with other rules that might trigger later."}
{"id": 166, "code": "func (g *RuleGroups) Validate() (errs []error) {\n\tset := map[string]struct{}{}\n\n\tfor _, g := range g.Groups {\n\t\tif g.Name == \"\" {\n\t\t\terrs = append(errs, errors.Errorf(\"Groupname should not be empty\"))\n\t\t}\n\n\t\tif _, ok := set[g.Name]; ok {\n\t\t\terrs = append(\n\t\t\t\terrs,\n\t\t\t\terrors.Errorf(\"groupname: \\\"%s\\\" is repeated in the same file\", g.Name),\n\t\t\t)\n\t\t}\n\n\t\tset[g.Name] = struct{}{}\n\n\t\tfor i, r := range g.Rules {\n\t\t\tfor _, err := range r.Validate() {\n\t\t\t\tvar ruleName string\n\t\t\t\tif r.Alert != \"\" {\n\t\t\t\t\truleName = r.Alert\n\t\t\t\t} else {\n\t\t\t\t\truleName = r.Record\n\t\t\t\t}\n\t\t\t\terrs = append(errs, &Error{\n\t\t\t\t\tGroup:    g.Name,\n\t\t\t\t\tRule:     i,\n\t\t\t\t\tRuleName: ruleName,\n\t\t\t\t\tErr:      err,\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t}\n\n\treturn errs\n}", "reference": "// Validate validates all rules in the rule groups.", "generated": "// Validate checks if all rules within each group have valid alerts or records.\n// If any alert/record has invalid data it returns error messages for that specific rule.\n// It also ensures there's no duplicate groups name across different files."}
{"id": 182, "code": "func (r *AlertingRule) SetHealth(health RuleHealth) {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\tr.health = health\n}", "reference": "// SetHealth sets the current health of the alerting rule.", "generated": "SetHealthInternal updates"}
{"id": 185, "code": "func (r *AlertingRule) SetEvaluationDuration(dur time.Duration) {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\tr.evaluationDuration = dur\n}", "reference": "// SetEvaluationDuration updates evaluationDuration to the duration it took to evaluate the rule on its last evaluation.", "generated": "// Evaluation duration is set to the given value in seconds.\n// The evaluation period determines how long after the alert was triggered that it will be considered active or inactive based on its state.\n// If no evaluation duration is specified for this rule, then all alerts from this source will always have their status updated immediately when they trigger"}
{"id": 197, "code": "func (g *Group) GetEvaluationDuration() time.Duration {\n\tg.mtx.Lock()\n\tdefer g.mtx.Unlock()\n\treturn g.evaluationDuration\n}", "reference": "// GetEvaluationDuration returns the time in seconds it took to evaluate the rule group.", "generated": "// Evaluation duration is returned in seconds.\n// If evaluation has been cancelled or timed out it will be 0.\n// The value can only change if there's new data available for evaluation,\n// otherwise this method returns immediately without blocking.\nfunc (g Group) SetEvaluationDuration(d time.Duration) error {\n\tif d =="}
{"id": 199, "code": "func (g *Group) GetEvaluationTimestamp() time.Time {\n\tg.mtx.Lock()\n\tdefer g.mtx.Unlock()\n\treturn g.evaluationTimestamp\n}", "reference": "// GetEvaluationTimestamp returns the time the last evaluation of the rule group took place.", "generated": "// GetEvaluationTimestamp returns the evaluation timestamp for this group.\n// The value is updated when Evaluate() or UpdateEvaluation() is called.\n// If no evaluation has been performed yet, it will be set to now(). This method should only be used by internal functions,\n// because external code may depend on its return value being"}
{"id": 212, "code": "func (w *WALWatcher) Start() {\n\tw.setMetrics()\n\tlevel.Info(w.logger).Log(\"msg\", \"starting WAL watcher\", \"queue\", w.name)\n\n\tgo w.loop()\n}", "reference": "// Start the WALWatcher.", "generated": "// Start starts the WAL watcher loop.\n//\n// The loop runs in its own goroutine to avoid blocking the main thread.\n// It will continue running until it is stopped by Stop().\nfunc (w *WALWatcher) Loop() error {\n\treturn nil\n}"}
{"id": 225, "code": "func (sd *StaticProvider) Run(ctx context.Context, ch chan<- []*targetgroup.Group) {\n\t// We still have to consider that the consumer exits right away in which case\n\t// the context will be canceled.\n\tselect {\n\tcase ch <- sd.TargetGroups:\n\tcase <-ctx.Done():\n\t}\n\tclose(ch)\n}", "reference": "// Run implements the Worker interface.", "generated": "// Run starts running the static provider by sending its target groups over the channel.\n// The consumer is expected to exit immediately after receiving all target groups,\n// otherwise it's considered a failure. If there was no error during this operation,\n// we close the output channel so consumers can wait for any remaining data they might need"}
{"id": 228, "code": "func NewDiscovery(\n\tsrvs []string,\n\ttimeout time.Duration,\n\tpaths []string,\n\tlogger log.Logger,\n\tpf func(data []byte, path string) (model.LabelSet, error),\n) (*Discovery, error) {\n\tif logger == nil {\n\t\tlogger = log.NewNopLogger()\n\t}\n\n\tconn, _, err := zk.Connect(\n\t\tsrvs, timeout,\n\t\tfunc(c *zk.Conn) {\n\t\t\tc.SetLogger(treecache.NewZookeeperLogger(logger))\n\t\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tupdates := make(chan treecache.ZookeeperTreeCacheEvent)\n\tsd := &Discovery{\n\t\tconn:    conn,\n\t\tupdates: updates,\n\t\tsources: map[string]*targetgroup.Group{},\n\t\tparse:   pf,\n\t\tlogger:  logger,\n\t}\n\tfor _, path := range paths {\n\t\tsd.treeCaches = append(sd.treeCaches, treecache.NewZookeeperTreeCache(conn, path, updates, logger))\n\t}\n\treturn sd, nil\n}", "reference": "// NewDiscovery returns a new discovery along Zookeeper parses with\n// the given parse function.", "generated": "// NewDiscovery creates a new discovery instance that connects to ZooKeeper.\n// The connection is made using the provided servers list and timeouts for each server.\n// A custom parser function can be passed in to parse labels from data returned by ZooKeeper.\n// If no logger is given, a default one will be used which logs"}
{"id": 244, "code": "func (q *querier) Select(p *storage.SelectParams, matchers ...*labels.Matcher) (storage.SeriesSet, storage.Warnings, error) {\n\tquery, err := ToQuery(q.mint, q.maxt, matchers, p)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tremoteReadGauge := remoteReadQueries.WithLabelValues(q.client.Name())\n\tremoteReadGauge.Inc()\n\tdefer remoteReadGauge.Dec()\n\n\tres, err := q.client.Read(q.ctx, query)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn FromQueryResult(res), nil, nil\n}", "reference": "// Select implements storage.Querier and uses the given matchers to read series\n// sets from the Client.", "generated": "// Select performs a SELECT operation against the given client.\n//\n// The result is returned in SeriesSet format. If there were any errors during execution,\n// they will be included in Warnings. Otherwise, no warnings will be reported.\n// \n// This method should only be called from within a querier's context."}
{"id": 298, "code": "func NewRegexp(s string) (Regexp, error) {\n\tregex, err := regexp.Compile(\"^(?:\" + s + \")$\")\n\treturn Regexp{\n\t\tRegexp:   regex,\n\t\toriginal: s,\n\t}, err\n}", "reference": "// NewRegexp creates a new anchored Regexp and returns an error if the\n// passed-in regular expression does not compile.", "generated": "// NewRegexp creates a new regular expression from a given pattern.\n//\n// The resulting RegExp is created by wrapping the provided pattern in a group that matches only at the start of the input.\n// This ensures that the original pattern can be used to match against any part of the input, rather than just the entire thing"}
{"id": 303, "code": "func (sp *scrapePool) reload(cfg *config.ScrapeConfig) error {\n\ttargetScrapePoolReloads.Inc()\n\tstart := time.Now()\n\n\tsp.mtx.Lock()\n\tdefer sp.mtx.Unlock()\n\n\tclient, err := config_util.NewClientFromConfig(cfg.HTTPClientConfig, cfg.JobName)\n\tif err != nil {\n\t\ttargetScrapePoolReloadsFailed.Inc()\n\t\treturn errors.Wrap(err, \"error creating HTTP client\")\n\t}\n\tsp.config = cfg\n\toldClient := sp.client\n\tsp.client = client\n\n\tvar (\n\t\twg              sync.WaitGroup\n\t\tinterval        = time.Duration(sp.config.ScrapeInterval)\n\t\ttimeout         = time.Duration(sp.config.ScrapeTimeout)\n\t\tlimit           = int(sp.config.SampleLimit)\n\t\thonorLabels     = sp.config.HonorLabels\n\t\thonorTimestamps = sp.config.HonorTimestamps\n\t\tmrc             = sp.config.MetricRelabelConfigs\n\t)\n\n\tfor fp, oldLoop := range sp.loops {\n\t\tvar (\n\t\t\tt       = sp.activeTargets[fp]\n\t\t\ts       = &targetScraper{Target: t, client: sp.client, timeout: timeout}\n\t\t\tnewLoop = sp.newLoop(scrapeLoopOptions{\n\t\t\t\ttarget:          t,\n\t\t\t\tscraper:         s,\n\t\t\t\tlimit:           limit,\n\t\t\t\thonorLabels:     honorLabels,\n\t\t\t\thonorTimestamps: honorTimestamps,\n\t\t\t\tmrc:             mrc,\n\t\t\t})\n\t\t)\n\t\twg.Add(1)\n\n\t\tgo func(oldLoop, newLoop loop) {\n\t\t\toldLoop.stop()\n\t\t\twg.Done()\n\n\t\t\tgo newLoop.run(interval, timeout, nil)\n\t\t}(oldLoop, newLoop)\n\n\t\tsp.loops[fp] = newLoop\n\t}\n\n\twg.Wait()\n\toldClient.CloseIdleConnections()\n\ttargetReloadIntervalLength.WithLabelValues(interval.String()).Observe(\n\t\ttime.Since(start).Seconds(),\n\t)\n\treturn nil\n}", "reference": "// reload the scrape pool with the given scrape configuration. The target state is preserved\n// but all scrape loops are restarted with the new scrape configuration.\n// This method returns after all scrape loops that were stopped have stopped scraping.", "generated": "// Reload is called when scrape pool configuration changes.\n//\n// This method updates the target scraper for each active job in this pool to use the updated\n// scrape pool configuration. It also starts any stopped loops that were previously running.\n// The interval between re-reloads will be set based on the number of jobs being scraped"}
{"id": 332, "code": "func NewDiscovery(conf *SDConfig, logger log.Logger) *Discovery {\n\tif logger == nil {\n\t\tlogger = log.NewNopLogger()\n\t}\n\n\tdisc := &Discovery{\n\t\tpaths:      conf.Files,\n\t\tinterval:   time.Duration(conf.RefreshInterval),\n\t\ttimestamps: make(map[string]float64),\n\t\tlogger:     logger,\n\t}\n\tfileSDTimeStamp.addDiscoverer(disc)\n\treturn disc\n}", "reference": "// NewDiscovery returns a new file discovery for the given paths.", "generated": "// NewDiscovery creates a new Discovery instance from given configuration.\n// The discovery is initialized to start immediately after creation.\n// If no logging context was provided it will be created automatically using NopLogger.\n// This method should only be called once in lifetime of the application. After that use GetInstance() instead."}
{"id": 349, "code": "func (r *ewmaRate) tick() {\n\tnewEvents := atomic.LoadInt64(&r.newEvents)\n\tatomic.AddInt64(&r.newEvents, -newEvents)\n\tinstantRate := float64(newEvents) / r.interval.Seconds()\n\n\tr.mutex.Lock()\n\tdefer r.mutex.Unlock()\n\n\tif r.init {\n\t\tr.lastRate += r.alpha * (instantRate - r.lastRate)\n\t} else {\n\t\tr.init = true\n\t\tr.lastRate = instantRate\n\t}\n}", "reference": "// tick assumes to be called every r.interval.", "generated": "// Tick updates the rate based on new events received since last update.\n// If this is the first time updating, it sets up initial conditions for future ticks. The interval parameter determines how often to perform these calculations,\n// which can be useful if there's significant variability in event arrival rates over short periods. This method should"}
{"id": 390, "code": "func (a *Args) GetBool(key string) bool {\n\tswitch b2s(a.Peek(key)) {\n\t// Support the same true cases as strconv.ParseBool\n\t// See: https://github.com/golang/go/blob/4e1b11e2c9bdb0ddea1141eed487be1a626ff5be/src/strconv/atob.go#L12\n\t// and Y and Yes versions.\n\tcase \"1\", \"t\", \"T\", \"true\", \"TRUE\", \"True\", \"y\", \"yes\", \"Y\", \"YES\", \"Yes\":\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}", "reference": "// GetBool returns boolean value for the given key.\n//\n// true is returned for \"1\", \"t\", \"T\", \"true\", \"TRUE\", \"True\", \"y\", \"yes\", \"Y\", \"YES\", \"Yes\",\n// otherwise false is returned.", "generated": "// GetBool returns whether the value is boolean True or False based on key's format.\n// The following formats will be treated as true values in descending order:\n//\n//  - y, yes, YES, YES, YeS, yeS, t, T, truE, TruE, TRUE, TR"}
{"id": 420, "code": "func (cc *LBClient) DoTimeout(req *Request, resp *Response, timeout time.Duration) error {\n\tdeadline := time.Now().Add(timeout)\n\treturn cc.get().DoDeadline(req, resp, deadline)\n}", "reference": "// DoTimeout calculates deadline and calls DoDeadline on the least loaded client", "generated": "// DoTimeout sends a request to the server but allows for some delay before\n// considering it timed out.\n//\n// If this call is successful then no further calls will be made until another\n// timeout occurs or the client's connection times out.  This can help prevent\n// excessive network traffic when dealing with servers"}
{"id": 430, "code": "func (ctx *RequestCtx) TLSConnectionState() *tls.ConnectionState {\n\ttlsConn, ok := ctx.c.(connTLSer)\n\tif !ok {\n\t\treturn nil\n\t}\n\tstate := tlsConn.ConnectionState()\n\treturn &state\n}", "reference": "// TLSConnectionState returns TLS connection state.\n//\n// The function returns nil if the underlying connection isn't tls.Conn.\n//\n// The returned state may be used for verifying TLS version, client certificates,\n// etc.", "generated": "// Returns the current connection state for this request's TLS context.\n// This is used to determine whether or not we need to re-establish our SSL/TLS\n// session when making subsequent requests over HTTPS. If it has been more than 30 seconds since\n// last successful handshake then we will attempt to reconnect if necessary"}
{"id": 453, "code": "func (s *Server) Serve(ln net.Listener) error {\n\tvar lastOverflowErrorTime time.Time\n\tvar lastPerIPErrorTime time.Time\n\tvar c net.Conn\n\tvar err error\n\n\ts.mu.Lock()\n\t{\n\t\tif s.ln != nil {\n\t\t\ts.mu.Unlock()\n\t\t\treturn ErrAlreadyServing\n\t\t}\n\n\t\ts.ln = ln\n\t\ts.done = make(chan struct{})\n\t}\n\ts.mu.Unlock()\n\n\tmaxWorkersCount := s.getConcurrency()\n\ts.concurrencyCh = make(chan struct{}, maxWorkersCount)\n\twp := &workerPool{\n\t\tWorkerFunc:      s.serveConn,\n\t\tMaxWorkersCount: maxWorkersCount,\n\t\tLogAllErrors:    s.LogAllErrors,\n\t\tLogger:          s.logger(),\n\t\tconnState:       s.setState,\n\t}\n\twp.Start()\n\n\t// Count our waiting to accept a connection as an open connection.\n\t// This way we can't get into any weird state where just after accepting\n\t// a connection Shutdown is called which reads open as 0 because it isn't\n\t// incremented yet.\n\tatomic.AddInt32(&s.open, 1)\n\tdefer atomic.AddInt32(&s.open, -1)\n\n\tfor {\n\t\tif c, err = acceptConn(s, ln, &lastPerIPErrorTime); err != nil {\n\t\t\twp.Stop()\n\t\t\tif err == io.EOF {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\ts.setState(c, StateNew)\n\t\tatomic.AddInt32(&s.open, 1)\n\t\tif !wp.Serve(c) {\n\t\t\tatomic.AddInt32(&s.open, -1)\n\t\t\ts.writeFastError(c, StatusServiceUnavailable,\n\t\t\t\t\"The connection cannot be served because Server.Concurrency limit exceeded\")\n\t\t\tc.Close()\n\t\t\ts.setState(c, StateClosed)\n\t\t\tif time.Since(lastOverflowErrorTime) > time.Minute {\n\t\t\t\ts.logger().Printf(\"The incoming connection cannot be served, because %d concurrent connections are served. \"+\n\t\t\t\t\t\"Try increasing Server.Concurrency\", maxWorkersCount)\n\t\t\t\tlastOverflowErrorTime = time.Now()\n\t\t\t}\n\n\t\t\t// The current server reached concurrency limit,\n\t\t\t// so give other concurrently running servers a chance\n\t\t\t// accepting incoming connections on the same address.\n\t\t\t//\n\t\t\t// There is a hope other servers didn't reach their\n\t\t\t// concurrency limits yet :)\n\t\t\t//\n\t\t\t// See also: https://github.com/valyala/fasthttp/pull/485#discussion_r239994990\n\t\t\tif s.SleepWhenConcurrencyLimitsExceeded > 0 {\n\t\t\t\ttime.Sleep(s.SleepWhenConcurrencyLimitsExceeded)\n\t\t\t}\n\t\t}\n\t\tc = nil\n\t}\n}", "reference": "// Serve serves incoming connections from the given listener.\n//\n// Serve blocks until the given listener returns permanent error.", "generated": "Serve starts serving HTTP requests from given listener. It creates worker pool for handling multiple clients in parallel. If there's no available workers due to concurrency limit, it will sleep until one becomes free or all workers become busy again. After that, if another client tries to connect while sleeping, new worker will start immediately when waking"}
{"id": 480, "code": "func (req *Request) SetBodyString(body string) {\n\treq.RemoveMultipartFormFiles()\n\treq.closeBodyStream()\n\treq.bodyBuffer().SetString(body)\n}", "reference": "// SetBodyString sets request body.", "generated": "// Sets the request body to be sent in the HTTP request.\n//\n// This method is used when sending data via the POST or PUT methods\n// where no multipart/form-data encoding is required. The provided value will\n// replace any existing content for this field within the request's Body.\n// If there was previously some"}
{"id": 511, "code": "func (h *ResponseHeader) SetCookie(cookie *Cookie) {\n\th.cookies = setArgBytes(h.cookies, cookie.Key(), cookie.Cookie(), argsHasValue)\n}", "reference": "// SetCookie sets the given response cookie.\n//\n// It is save re-using the cookie after the function returns.", "generated": "// SetCookie sets the Cookie header value.\n//\n// This is used to store cookies that should be sent back in the HTTP\n// response. The key for this argument must match one of the names returned by\n// GetCookies(). If no such name exists, it will simply append the new cookie\n// without any"}
{"id": 513, "code": "func (h *ResponseHeader) DelCookie(key string) {\n\th.cookies = delAllArgs(h.cookies, key)\n}", "reference": "// DelCookie removes cookie under the given key from response header.\n//\n// Note that DelCookie doesn't remove the cookie from the client.\n// Use DelClientCookie instead.", "generated": "// Delete all cookies that have this name from the header's cookie list.\n// If there is only one such cookie in the list, it will be removed entirely,\n// otherwise just its value will be deleted. The remaining values for\n// other keys remain unchanged. This method modifies h directly; if you want to"}
{"id": 517, "code": "func (h *ResponseHeader) PeekBytes(key []byte) []byte {\n\th.bufKV.key = append(h.bufKV.key[:0], key...)\n\tnormalizeHeaderKey(h.bufKV.key, h.disableNormalizing)\n\treturn h.peek(h.bufKV.key)\n}", "reference": "// PeekBytes returns header value for the given key.\n//\n// Returned value is valid until the next call to ResponseHeader.\n// Do not store references to returned value. Make copies instead.", "generated": "// PeekBytes returns a copy of the header value for the given key.\n// The returned slice is valid until next call to peek() or close().\n//\n// If no such entry exists in this ResponseHeader's headers map,\n// it will return nil.\n// This method should be used when we need only one byte from"}
{"id": 525, "code": "func (h *RequestHeader) WriteTo(w io.Writer) (int64, error) {\n\tn, err := w.Write(h.Header())\n\treturn int64(n), err\n}", "reference": "// WriteTo writes request header to w.\n//\n// WriteTo implements io.WriterTo interface.", "generated": "// WriteTo writes header to writer.\n//\n// The returned number is the total bytes written by this request's headers,\n// which may be less than h.ContentLength if Content-Length was set but not sent in the HTTP message body.\n// If there were any errors writing the headers, they will have been reported already;"}
{"id": 536, "code": "func (c *Cookie) Expire() time.Time {\n\texpire := c.expire\n\tif expire.IsZero() {\n\t\texpire = CookieExpireUnlimited\n\t}\n\treturn expire\n}", "reference": "// Expire returns cookie expiration time.\n//\n// CookieExpireUnlimited is returned if cookie doesn't expire", "generated": "// Expire returns the expiration date for this cookie.\n//\n// If no expiration is set, it will be considered to have expired at the end of the session,\n// which means that cookies without any expiration information can only be stored in memory.\n// The default value is 0 seconds after the current time if there's"}
{"id": 537, "code": "func (c *Cookie) SetValue(value string) {\n\tc.value = append(c.value[:0], value...)\n}", "reference": "// SetValue sets cookie value.", "generated": "// SetValue sets the cookie's value to the given string.\n// The old value is discarded; only the new value remains in memory.\n// This method modifies c directly. If you want to preserve\n// original values for later use, create a copy before calling this\n// method. For example: v := c"}
{"id": 577, "code": "func (mx *Mux) Patch(pattern string, handlerFn http.HandlerFunc) {\n\tmx.handle(mPATCH, pattern, handlerFn)\n}", "reference": "// Patch adds the route `pattern` that matches a PATCH http method to\n// execute the `handlerFn` http.HandlerFunc.", "generated": "// Patch sets up a new route for patching resources.\n//\n// The path is prefixed by '/{path}' to allow nested routing.\n// For example: /users/{user}/posts\n//\n// This method will only be called if there's no existing route matching this path,\n// or if it matches but has"}
{"id": 579, "code": "func (mx *Mux) Put(pattern string, handlerFn http.HandlerFunc) {\n\tmx.handle(mPUT, pattern, handlerFn)\n}", "reference": "// Put adds the route `pattern` that matches a PUT http method to\n// execute the `handlerFn` http.HandlerFunc.", "generated": "// Put sets up a new route for this MUX to handle HTTP PUT requests.\n//\n// The given URL path is used to identify which request handler should be called\n// when a client sends a PUT request to that endpoint. This method will only work if\n// no other routes match the same path; otherwise it"}
{"id": 600, "code": "func SearchArticles(w http.ResponseWriter, r *http.Request) {\n\trender.RenderList(w, r, NewArticleListResponse(articles))\n}", "reference": "// SearchArticles searches the Articles data for a matching article.\n// It's just a stub, but you get the idea.", "generated": "// Search articles based on search query\nfunc (a ArticleService) Search(q string) ([]*article.Article, error) {\n\tvar results []*article.Article\n\n\t// Find all matching articles in database\n\tfor _, article := range a.articles() {\n\t\tif strings.Contains(article.Text(), q) || strings.Contains(article.Title"}
{"id": 603, "code": "func UpdateArticle(w http.ResponseWriter, r *http.Request) {\n\tarticle := r.Context().Value(\"article\").(*Article)\n\n\tdata := &ArticleRequest{Article: article}\n\tif err := render.Bind(r, data); err != nil {\n\t\trender.Render(w, r, ErrInvalidRequest(err))\n\t\treturn\n\t}\n\tarticle = data.Article\n\tdbUpdateArticle(article.ID, article)\n\n\trender.Render(w, r, NewArticleResponse(article))\n}", "reference": "// UpdateArticle updates an existing Article in our persistent store.", "generated": "// Updates an existing Article in the database.\n//\n// The request body must contain all fields from the original Article object,\n// including any additional metadata or tags that were added when creating it.\n// If no changes to the title field is present, this will be ignored by the server.\n// Otherwise, if there was already"}
{"id": 605, "code": "func adminRouter() chi.Router {\n\tr := chi.NewRouter()\n\tr.Use(AdminOnly)\n\tr.Get(\"/\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(\"admin: index\"))\n\t})\n\tr.Get(\"/accounts\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(\"admin: list accounts..\"))\n\t})\n\tr.Get(\"/users/{userId}\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(fmt.Sprintf(\"admin: view user id %v\", chi.URLParam(r, \"userId\"))))\n\t})\n\treturn r\n}", "reference": "// A completely separate router for administrator routes", "generated": "// Returns a router for administrative endpoints.\nfunc AdminRouter() chi.Router { return adminRouter() }"}
{"id": 606, "code": "func AdminOnly(next http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tisAdmin, ok := r.Context().Value(\"acl.admin\").(bool)\n\t\tif !ok || !isAdmin {\n\t\t\thttp.Error(w, http.StatusText(http.StatusForbidden), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}", "reference": "// AdminOnly middleware restricts access to just administrators.", "generated": "// AdminOnly wraps another handler to ensure only admins can access it.\n// If the request context contains \"admin\" key set to true, this wrapper will pass through,\n// otherwise it returns 403 Forbidden status code. This is useful for protecting routes that should be accessible by admin users only."}
{"id": 612, "code": "func DefaultCompress(next http.Handler) http.Handler {\n\treturn Compress(flate.DefaultCompression)(next)\n}", "reference": "// DefaultCompress is a middleware that compresses response\n// body of predefined content types to a data format based\n// on Accept-Encoding request header. It uses a default\n// compression level.\n// DEPRECATED", "generated": "// Returns a handler that wraps another handler in compression.\n//\n// The returned handler will compress all responses from the wrapped\n// handler using flate encoding (default). If no compression is needed,\n// it simply returns the original handler.\nfunc DefaultCompress(next http.Handler) http.Handler { return next } // nol"}
{"id": 623, "code": "func canonicalHostedZone(hostname string) string {\n\tfor suffix, zone := range canonicalHostedZones {\n\t\tif strings.HasSuffix(hostname, suffix) {\n\t\t\treturn zone\n\t\t}\n\t}\n\n\treturn \"\"\n}", "reference": "// canonicalHostedZone returns the matching canonical zone for a given hostname.", "generated": "// Returns the canonical hosted zone name for the given hostname.\n// The returned value is one of the values in canonicalHostedZones that matches\n// the input hostname's domain (i.e., it ends with the same suffix).\n//\n// If no match is found, returns an empty string.\nvar canonicalHosted"}
{"id": 629, "code": "func InMemoryWithLogging() InMemoryOption {\n\treturn func(p *InMemoryProvider) {\n\t\tp.OnApplyChanges = func(changes *plan.Changes) {\n\t\t\tfor _, v := range changes.Create {\n\t\t\t\tlog.Infof(\"CREATE: %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.UpdateOld {\n\t\t\t\tlog.Infof(\"UPDATE (old): %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.UpdateNew {\n\t\t\t\tlog.Infof(\"UPDATE (new): %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.Delete {\n\t\t\t\tlog.Infof(\"DELETE: %v\", v)\n\t\t\t}\n\t\t}\n\t}\n}", "reference": "// InMemoryWithLogging injects logging when ApplyChanges is called", "generated": "// InMemoryWithLogging returns an option that logs all operations in memory.\n//\n// This is useful for debugging purposes or to verify data consistency before\n// writing it out to disk. The log messages will be printed at debug level by default,\n// but can also be configured using the LogLevel parameter if needed.\n//"}
{"id": 656, "code": "func (sc *serviceSource) filterByAnnotations(services []*v1.Service) ([]*v1.Service, error) {\n\tlabelSelector, err := metav1.ParseToLabelSelector(sc.annotationFilter)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tselector, err := metav1.LabelSelectorAsSelector(labelSelector)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// empty filter returns original list\n\tif selector.Empty() {\n\t\treturn services, nil\n\t}\n\n\tfilteredList := []*v1.Service{}\n\n\tfor _, service := range services {\n\t\t// convert the service's annotations to an equivalent label selector\n\t\tannotations := labels.Set(service.Annotations)\n\n\t\t// include service if its annotations match the selector\n\t\tif selector.Matches(annotations) {\n\t\t\tfilteredList = append(filteredList, service)\n\t\t}\n\t}\n\n\treturn filteredList, nil\n}", "reference": "// filterByAnnotations filters a list of services by a given annotation selector.", "generated": "// FilterServiceByAnnotation filters out services that do not have any matching annotation.\n//\n// The filtering is done by converting each service's annotations into a LabelSelector,\n// which can be used for comparison against other selectors or labels.\n//\n// If no selector matches, all services will remain in the result set.\nfunc ("}
{"id": 658, "code": "func (p *Plan) Calculate() *Plan {\n\tt := newPlanTable()\n\n\tfor _, current := range filterRecordsForPlan(p.Current) {\n\t\tt.addCurrent(current)\n\t}\n\tfor _, desired := range filterRecordsForPlan(p.Desired) {\n\t\tt.addCandidate(desired)\n\t}\n\n\tchanges := &Changes{}\n\tchanges.Create = t.getCreates()\n\tchanges.Delete = t.getDeletes()\n\tchanges.UpdateNew, changes.UpdateOld = t.getUpdates()\n\tfor _, pol := range p.Policies {\n\t\tchanges = pol.Apply(changes)\n\t}\n\n\tplan := &Plan{\n\t\tCurrent: p.Current,\n\t\tDesired: p.Desired,\n\t\tChanges: changes,\n\t}\n\n\treturn plan\n}", "reference": "// Calculate computes the actions needed to move current state towards desired\n// state. It then passes those changes to the current policy for further\n// processing. It returns a copy of Plan with the changes populated.", "generated": "// Calculate returns a Plan that represents the result of applying all policies to the given Current and Desired records.\n// The returned Plan contains information about which records were created or deleted, updated in place but moved from one location to another, and any other side effects caused by policy application."}
{"id": 662, "code": "func NewTargets(target ...string) Targets {\n\tt := make(Targets, 0, len(target))\n\tt = append(t, target...)\n\treturn t\n}", "reference": "// NewTargets is a convenience method to create a new Targets object from a vararg of strings", "generated": "// NewTargets returns a new targets slice initialized from given strings.\n// The returned slice is empty if no string was provided. If multiple strings were\n// passed in then they will be appended to each other without any separator.\n// This method can also take nil values which would result into an empty slice being\n// created"}
{"id": 721, "code": "func NewRfc2136Provider(host string, port int, zoneName string, insecure bool, keyName string, secret string, secretAlg string, axfr bool, domainFilter DomainFilter, dryRun bool, actions rfc2136Actions) (Provider, error) {\n\tsecretAlgChecked, ok := tsigAlgs[secretAlg]\n\tif !ok && !insecure {\n\t\treturn nil, errors.Errorf(\"%s is not supported TSIG algorithm\", secretAlg)\n\t}\n\n\tr := &rfc2136Provider{\n\t\tnameserver:   net.JoinHostPort(host, strconv.Itoa(port)),\n\t\tzoneName:     dns.Fqdn(zoneName),\n\t\tinsecure:     insecure,\n\t\tdomainFilter: domainFilter,\n\t\tdryRun:       dryRun,\n\t\taxfr:         axfr,\n\t}\n\tif actions != nil {\n\t\tr.actions = actions\n\t} else {\n\t\tr.actions = r\n\t}\n\n\tif !insecure {\n\t\tr.tsigKeyName = dns.Fqdn(keyName)\n\t\tr.tsigSecret = secret\n\t\tr.tsigSecretAlg = secretAlgChecked\n\t}\n\n\tlog.Infof(\"Configured RFC2136 with zone '%s' and nameserver '%s'\", r.zoneName, r.nameserver)\n\treturn r, nil\n}", "reference": "// NewRfc2136Provider is a factory function for OpenStack rfc2136 providers", "generated": "// NewRFC2136Provider returns a new provider for DNS over TCP using the RFC 2136 protocol.\n//\n// The returned Provider can be used to perform queries against the specified nameservers.\n// If no action is provided, it will return all records in the zone.\n// Otherwise, only the requested records from the"}
{"id": 734, "code": "func (p *AWSSDProvider) RegisterInstance(service *sd.Service, ep *endpoint.Endpoint) error {\n\tfor _, target := range ep.Targets {\n\t\tlog.Infof(\"Registering a new instance \\\"%s\\\" for service \\\"%s\\\" (%s)\", target, *service.Name, *service.Id)\n\n\t\tattr := make(map[string]*string)\n\n\t\tif ep.RecordType == endpoint.RecordTypeCNAME {\n\t\t\tif p.isAWSLoadBalancer(target) {\n\t\t\t\tattr[sdInstanceAttrAlias] = aws.String(target)\n\t\t\t} else {\n\t\t\t\tattr[sdInstanceAttrCname] = aws.String(target)\n\t\t\t}\n\t\t} else if ep.RecordType == endpoint.RecordTypeA {\n\t\t\tattr[sdInstanceAttrIPV4] = aws.String(target)\n\t\t} else {\n\t\t\treturn fmt.Errorf(\"invalid endpoint type (%v)\", ep)\n\t\t}\n\n\t\tif !p.dryRun {\n\t\t\t_, err := p.client.RegisterInstance(&sd.RegisterInstanceInput{\n\t\t\t\tServiceId:  service.Id,\n\t\t\t\tAttributes: attr,\n\t\t\t\tInstanceId: aws.String(p.targetToInstanceID(target)),\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "reference": "// RegisterInstance creates a new instance in given service.", "generated": "// RegisterInstance registers a new EC2 instance in AWS SD.\n//\n// This method is called when we receive a request to register a new instance from\n// another provider or when we need to update our local state after receiving a\n// registration event from Amazon Web Services. The provided endpoint contains all\n// necessary information"}
{"id": 769, "code": "func canonicalizeDomainName(d string) string {\n\tif !strings.HasSuffix(d, \".\") {\n\t\td += \".\"\n\t}\n\treturn strings.ToLower(d)\n}", "reference": "// converts domain name to FQDN", "generated": "// Canonicalizes domain names by converting them to lowercase\n// and appending a dot if necessary.\nfunc (d *domainInfo) canonicalize() error {\n\td.name = d.canonicalizeDomainName(d.name)\n\n\tvar err error\n\n\tfor _, name := range d.names {\n\t\tname = d.canonicalizeDomainName"}
{"id": 772, "code": "func addEndpoint(ep *endpoint.Endpoint, recordSets map[string]*recordSet, delete bool) {\n\tkey := fmt.Sprintf(\"%s/%s\", ep.DNSName, ep.RecordType)\n\trs := recordSets[key]\n\tif rs == nil {\n\t\trs = &recordSet{\n\t\t\tdnsName:    canonicalizeDomainName(ep.DNSName),\n\t\t\trecordType: ep.RecordType,\n\t\t\tnames:      make(map[string]bool),\n\t\t}\n\t}\n\tif rs.zoneID == \"\" {\n\t\trs.zoneID = ep.Labels[designateZoneID]\n\t}\n\tif rs.recordSetID == \"\" {\n\t\trs.recordSetID = ep.Labels[designateRecordSetID]\n\t}\n\tfor _, rec := range strings.Split(ep.Labels[designateOriginalRecords], \"\\000\") {\n\t\tif _, ok := rs.names[rec]; !ok && rec != \"\" {\n\t\t\trs.names[rec] = true\n\t\t}\n\t}\n\ttargets := ep.Targets\n\tif ep.RecordType == endpoint.RecordTypeCNAME {\n\t\ttargets = canonicalizeDomainNames(targets)\n\t}\n\tfor _, t := range targets {\n\t\trs.names[t] = !delete\n\t}\n\trecordSets[key] = rs\n}", "reference": "// adds endpoint into recordset aggregation, loading original values from endpoint labels first", "generated": "// AddEndpoint adds or updates a DNS record set for this domain.\n//\n// If no zone ID is specified in the record set's metadata, it will be determined from\n// the label \"zone-id\" associated with this domain. Similarly if no original records are\n// provided (as part of the target), they"}
{"id": 787, "code": "func (ms *dedupSource) Endpoints() ([]*endpoint.Endpoint, error) {\n\tresult := []*endpoint.Endpoint{}\n\tcollected := map[string]bool{}\n\n\tendpoints, err := ms.source.Endpoints()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ep := range endpoints {\n\t\tidentifier := ep.DNSName + \" / \" + ep.Targets.String()\n\n\t\tif _, ok := collected[identifier]; ok {\n\t\t\tlog.Debugf(\"Removing duplicate endpoint %s\", ep)\n\t\t\tcontinue\n\t\t}\n\n\t\tcollected[identifier] = true\n\t\tresult = append(result, ep)\n\t}\n\n\treturn result, nil\n}", "reference": "// Endpoints collects endpoints from its wrapped source and returns them without duplicates.", "generated": "// Endpoints returns all endpoints from the source in deduplicated form.\n// This means that if there is more than one endpoint for the same DNS name,\n// only one will be returned. The remaining ones will be ignored silently.\n// If no errors occur during this process, it's assumed to have been successful.\n//"}
{"id": 791, "code": "func (sdr *AWSSDRegistry) ApplyChanges(changes *plan.Changes) error {\n\tfilteredChanges := &plan.Changes{\n\t\tCreate:    changes.Create,\n\t\tUpdateNew: filterOwnedRecords(sdr.ownerID, changes.UpdateNew),\n\t\tUpdateOld: filterOwnedRecords(sdr.ownerID, changes.UpdateOld),\n\t\tDelete:    filterOwnedRecords(sdr.ownerID, changes.Delete),\n\t}\n\n\tsdr.updateLabels(filteredChanges.Create)\n\tsdr.updateLabels(filteredChanges.UpdateNew)\n\tsdr.updateLabels(filteredChanges.UpdateOld)\n\tsdr.updateLabels(filteredChanges.Delete)\n\n\treturn sdr.provider.ApplyChanges(filteredChanges)\n}", "reference": "// ApplyChanges filters out records not owned the External-DNS, additionally it adds the required label\n// inserted in the AWS SD instance as a CreateID field", "generated": "// ApplyChanges applies all provided plan.changes to this registry.\n//\n// This method is called by the provider's applyPlan() method after\n// filtering out any records that were deleted from the owner ID.\n// It then updates labels for each record in the filtered set of changes.\n// Finally it calls the provider's"}
{"id": 800, "code": "func createDiskImage(dest string, size int, r io.Reader) error {\n\t// Convert a raw image from stdin to the dest VMDK image.\n\tsizeBytes := int64(size) << 20 // usually won't fit in 32-bit int (max 2GB)\n\t// FIXME: why isn't this just using the vbm*() functions?\n\tcmd := exec.Command(vboxManageCmd, \"convertfromraw\", \"stdin\", dest,\n\t\tfmt.Sprintf(\"%d\", sizeBytes), \"--format\", \"VMDK\")\n\n\tlog.Debug(cmd)\n\n\tif os.Getenv(\"MACHINE_DEBUG\") != \"\" {\n\t\tcmd.Stdout = os.Stdout\n\t\tcmd.Stderr = os.Stderr\n\t}\n\n\tstdin, err := cmd.StdinPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Starting command\")\n\n\tif err := cmd.Start(); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Copying to stdin\")\n\n\tn, err := io.Copy(stdin, r)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Filling zeroes\")\n\n\t// The total number of bytes written to stdin must match sizeBytes, or\n\t// VBoxManage.exe on Windows will fail. Fill remaining with zeros.\n\tif left := sizeBytes - n; left > 0 {\n\t\tif err := zeroFill(stdin, left); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tlog.Debug(\"Closing STDIN\")\n\n\t// cmd won't exit until the stdin is closed.\n\tif err := stdin.Close(); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Waiting on cmd\")\n\n\treturn cmd.Wait()\n}", "reference": "// createDiskImage makes a disk image at dest with the given size in MB. If r is\n// not nil, it will be read as a raw disk image to convert from.", "generated": "Create a disk image by copying data into it through stdout. This allows us to copy large amounts of data without having to load them all at once into memory. It's also useful for creating images that contain only metadata, like VMs created via the web interface. We use `vboxManage` to convert the raw"}
{"id": 802, "code": "func (n *hostOnlyNetwork) SaveIPv4(vbox VBoxManager) error {\n\tif n.IPv4.IP != nil && n.IPv4.Mask != nil {\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tlog.Warn(\"Windows might ask for the permission to configure a network adapter. Sometimes, such confirmation window is minimized in the taskbar.\")\n\t\t}\n\n\t\tif err := vbox.vbm(\"hostonlyif\", \"ipconfig\", n.Name, \"--ip\", n.IPv4.IP.String(), \"--netmask\", net.IP(n.IPv4.Mask).String()); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}", "reference": "// SaveIPv4 changes the ipv4 configuration of the host-only network.", "generated": "// SaveIPv4 saves IPv4 configuration if it exists.\n//\n// If IP address or mask exist then this method will save them into VBox VM's host-only interface.\n// Otherwise no action will be performed.\n// This method should only be called after all other methods have been executed because some operations like setting up host"}
{"id": 821, "code": "func (d *Driver) Restart() error {\n\tcs := d.client()\n\t_, err := cs.RequestWithContext(context.TODO(), &egoscale.RebootVirtualMachine{\n\t\tID: d.ID,\n\t})\n\n\treturn err\n}", "reference": "// Restart reboots the existing VM instance.", "generated": "// Restart restarts this virtual machine.\n//\n// This method is idempotent; it can be called multiple times without any side effects.\n// If the VM has already been restarted in the current session, no action will occur.\n// The reboot operation may take some time to complete depending on the underlying hardware.\n// In"}
{"id": 822, "code": "func (d *Driver) Remove() error {\n\tclient := d.client()\n\n\t// Destroy the SSH key from CloudStack\n\tif d.KeyPair != \"\" {\n\t\tkey := &egoscale.SSHKeyPair{Name: d.KeyPair}\n\t\tif err := client.DeleteWithContext(context.TODO(), key); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Destroy the virtual machine\n\tif d.ID != \"\" {\n\t\tvm := &egoscale.VirtualMachine{ID: d.ID}\n\t\tif err := client.DeleteWithContext(context.TODO(), vm); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tlog.Infof(\"The Anti-Affinity group and Security group were not removed\")\n\n\treturn nil\n}", "reference": "// Remove destroys the VM instance and the associated SSH key.", "generated": "// Remove removes all resources associated with this driver instance.\n// This includes removing any security groups or anti-affinity rules that may have been created for it,\n// but leaves the underlying VM intact until explicitly destroyed by calling Destroy(). If no ID is provided,\n// then only the security group will be deleted if one was previously"}
{"id": 823, "code": "func (d *Driver) getCloudInit() ([]byte, error) {\n\tvar err error\n\tif d.UserDataFile != \"\" {\n\t\td.UserData, err = ioutil.ReadFile(d.UserDataFile)\n\t}\n\n\treturn d.UserData, err\n}", "reference": "// Build a cloud-init user data string that will install and run\n// docker.", "generated": "// GetCloudInit returns cloud init data from user provided file or default.\nfunc (d *Driver) GetCloudInit() ([]byte, error) { return d.getCloudInit() }"}
{"id": 834, "code": "func deviceFlowAuth(oauthCfg azure.OAuthConfig, clientID, resource string) (*azure.ServicePrincipalToken, error) {\n\tcl := oauthClient()\n\tdeviceCode, err := azure.InitiateDeviceAuth(&cl, oauthCfg, clientID, resource)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to start device auth: %v\", err)\n\t}\n\tlog.Debug(\"Retrieved device code.\", logutil.Fields{\n\t\t\"expires_in\": to.Int64(deviceCode.ExpiresIn),\n\t\t\"interval\":   to.Int64(deviceCode.Interval),\n\t})\n\n\t// Example message: \u201cTo sign in, open https://aka.ms/devicelogin and enter\n\t// the code 0000000 to authenticate.\u201d\n\tlog.Infof(\"Microsoft Azure: %s\", to.String(deviceCode.Message))\n\n\ttoken, err := azure.WaitForUserCompletion(&cl, deviceCode)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to complete device auth: %v\", err)\n\t}\n\n\tspt, err := azure.NewServicePrincipalTokenFromManualToken(oauthCfg, clientID, resource, *token)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error constructing service principal token: %v\", err)\n\t}\n\treturn spt, nil\n}", "reference": "// deviceFlowAuth prints a message to the screen for user to take action to\n// consent application on a browser and in the meanwhile the authentication\n// endpoint is polled until user gives consent, denies or the flow times out.\n// Returned token must be saved.", "generated": "// Device flow authentication for Microsoft Azure.\n//\n// This method initiates a manual authorization process using the user's browser,\n// where they will be redirected by the application to the login page provided by\n// Azure. The returned ServicePrincipalToken can then be used to create or obtain\n// access tokens that represent permissions granted"}
{"id": 842, "code": "func (c *ComputeUtil) staticAddress() (string, error) {\n\t// is the address a name?\n\tisName, err := regexp.MatchString(\"[a-z]([-a-z0-9]*[a-z0-9])?\", c.address)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif !isName {\n\t\treturn c.address, nil\n\t}\n\n\t// resolve the address by name\n\texternalAddress, err := c.service.Addresses.Get(c.project, c.region(), c.address).Do()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn externalAddress.Address, nil\n}", "reference": "// staticAddress returns the external static IP address.", "generated": "// Returns the IP or hostname for this Compute instance's public network interface.\n// If it exists, returns its internal IP; otherwise, returns the external IP if available,\n// which can be used to access the VM from outside Google Cloud. The returned value will\n// always have a valid format regardless of whether it was"}
{"id": 849, "code": "func (c *ComputeUtil) startInstance() error {\n\top, err := c.service.Instances.Start(c.project, c.zone, c.instanceName).Do()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Infof(\"Waiting for instance to start.\")\n\treturn c.waitForRegionalOp(op.Name)\n}", "reference": "// startInstance starts the instance.", "generated": "// Start starts the specified Compute Engine instance.\n//\n// This method is used by the client library when creating instances that require\n// this operation to be performed before they can be started or stopped.\nfunc (c *ComputeUtil) startInstance() error { return nil } // dummy implementation\n\nNote: The code provided seems"}
{"id": 867, "code": "func osDiskStorageContainerURL(account *storage.AccountProperties, vmName string) string {\n\treturn fmt.Sprintf(\"%s%s/\", to.String(account.PrimaryEndpoints.Blob), osDiskStorageContainerName(vmName))\n}", "reference": "// osDiskStorageContainerURL crafts a URL with a trailing slash pointing\n// to the full Azure Blob Container URL for given VM name.", "generated": "// Returns URL for disk storage container.\nfunc (os DiskStorageClient) osDiskStorageContainerURL(account *storage.AccountProperties, vmName string) string { return osDiskStorageContainerURL(account, vmName) }"}
{"id": 892, "code": "func (d *Driver) Create() error {\n\tlog.Infof(\"Generating SSH Key\")\n\n\tif err := ssh.GenerateSSHKey(d.GetSSHKeyPath()); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Infof(\"Creating host...\")\n\n\tc, err := newComputeUtil(d)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := c.openFirewallPorts(d); err != nil {\n\t\treturn err\n\t}\n\n\tif d.UseExisting {\n\t\treturn c.configureInstance(d)\n\t}\n\treturn c.createInstance(d)\n}", "reference": "// Create creates a GCE VM instance acting as a docker host.", "generated": "// Create creates a new instance by generating an SSH key if necessary,\n// opening firewall ports for it, creating or configuring existing instances.\n// If UseExisting is true, this method will configure an existing instance instead of creating one."}
{"id": 908, "code": "func (d *Driver) Restart() error {\n\tif err := d.checkLegacyDriver(true); err != nil {\n\t\treturn err\n\t}\n\n\t// NOTE(ahmetalpbalkan) Azure will always keep the VM in Running state\n\t// during the restart operation. Hence we rely on returned async operation\n\t// polling to make sure the reboot is waited upon.\n\tc, err := d.newAzureClient()\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn c.RestartVirtualMachine(d.ResourceGroup, d.naming().VM())\n}", "reference": "// Restart reboots the virtual machine instance.", "generated": "// Restart starts the virtual machine by sending a request to Microsoft Azure's API.\n// The driver waits for the requested amount of time before returning if it was successful,\n// or until the specified number of retries have been exhausted. If any errors occur while\n// waiting for the operation to complete, they are propagated up through"}
{"id": 914, "code": "func (d *Driver) Start() error {\n\tif err := cmd(\"Hyper-V\\\\Start-VM\", d.MachineName); err != nil {\n\t\treturn err\n\t}\n\n\tip, err := d.waitForIP()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\td.IPAddress = ip\n\n\treturn nil\n}", "reference": "// Start starts an host", "generated": "// Start starts the VM in Hyper-V. It waits for IP address to be assigned by the host.\n// If it fails, returns an error. Otherwise, sets the machine's IP address from the output.\n// The command used is \"Hyper-V\\Start-VM\". This method should only be called once per start"}
{"id": 921, "code": "func (d *BaseDriver) GetSSHUsername() string {\n\tif d.SSHUser == \"\" {\n\t\td.SSHUser = DefaultSSHUser\n\t}\n\treturn d.SSHUser\n}", "reference": "// GetSSHUsername returns the ssh user name, root if not specified", "generated": "// GetSSHUsername returns the SSH username to use for authentication.\n// If no value is set in the driver configuration, it defaults to \"root\".\nfunc (d *BaseDriver) SetDefaultSSHUser(username string) error {\n\tif len(username) > 0 &&!strings.HasPrefix(username, \"root\") {"}
{"id": 937, "code": "func NewDriver(machineName, storePath string) drivers.Driver {\n\tlog.Debug(\"Instantiating Rackspace driver.\", map[string]string{\"machineName\": machineName})\n\n\tinner := openstack.NewDerivedDriver(machineName, storePath)\n\tdriver := &Driver{\n\t\tDriver: inner,\n\t}\n\tinner.SetClient(&Client{\n\t\tdriver: driver,\n\t})\n\n\treturn driver\n}", "reference": "// NewDriver instantiates a Rackspace driver.", "generated": "// NewDriver returns a new instance of Driver for given machine name.\n//\n// The returned value is initialized to be ready to use immediately after creation.\n// It will automatically set up its client when it's first used (i.e., called).\nfunc NewDriver(machineName, storePath string) drivers.Driver {... }"}
{"id": 945, "code": "func (d *Driver) GetCreateFlags() []mcnflag.Flag {\n\treturn []mcnflag.Flag{\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_CPU_COUNT\",\n\t\t\tName:   \"vmwarevsphere-cpu-count\",\n\t\t\tUsage:  \"vSphere CPU number for docker VM\",\n\t\t\tValue:  defaultCpus,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_MEMORY_SIZE\",\n\t\t\tName:   \"vmwarevsphere-memory-size\",\n\t\t\tUsage:  \"vSphere size of memory for docker VM (in MB)\",\n\t\t\tValue:  defaultMemory,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_DISK_SIZE\",\n\t\t\tName:   \"vmwarevsphere-disk-size\",\n\t\t\tUsage:  \"vSphere size of disk for docker VM (in MB)\",\n\t\t\tValue:  defaultDiskSize,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_BOOT2DOCKER_URL\",\n\t\t\tName:   \"vmwarevsphere-boot2docker-url\",\n\t\t\tUsage:  \"vSphere URL for boot2docker image\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER\",\n\t\t\tName:   \"vmwarevsphere-vcenter\",\n\t\t\tUsage:  \"vSphere IP/hostname for vCenter\",\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER_PORT\",\n\t\t\tName:   \"vmwarevsphere-vcenter-port\",\n\t\t\tUsage:  \"vSphere Port for vCenter\",\n\t\t\tValue:  defaultSDKPort,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_USERNAME\",\n\t\t\tName:   \"vmwarevsphere-username\",\n\t\t\tUsage:  \"vSphere username\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_PASSWORD\",\n\t\t\tName:   \"vmwarevsphere-password\",\n\t\t\tUsage:  \"vSphere password\",\n\t\t},\n\t\tmcnflag.StringSliceFlag{\n\t\t\tEnvVar: \"VSPHERE_NETWORK\",\n\t\t\tName:   \"vmwarevsphere-network\",\n\t\t\tUsage:  \"vSphere network where the docker VM will be attached\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATASTORE\",\n\t\t\tName:   \"vmwarevsphere-datastore\",\n\t\t\tUsage:  \"vSphere datastore for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATACENTER\",\n\t\t\tName:   \"vmwarevsphere-datacenter\",\n\t\t\tUsage:  \"vSphere datacenter for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_FOLDER\",\n\t\t\tName:   \"vmwarevsphere-folder\",\n\t\t\tUsage:  \"vSphere folder for the docker VM. This folder must already exist in the datacenter.\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_POOL\",\n\t\t\tName:   \"vmwarevsphere-pool\",\n\t\t\tUsage:  \"vSphere resource pool for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_HOSTSYSTEM\",\n\t\t\tName:   \"vmwarevsphere-hostsystem\",\n\t\t\tUsage:  \"vSphere compute resource where the docker VM will be instantiated. This can be omitted if using a cluster with DRS.\",\n\t\t},\n\t\tmcnflag.StringSliceFlag{\n\t\t\tEnvVar: \"VSPHERE_CFGPARAM\",\n\t\t\tName:   \"vmwarevsphere-cfgparam\",\n\t\t\tUsage:  \"vSphere vm configuration parameters (used for guestinfo)\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_CLOUDINIT\",\n\t\t\tName:   \"vmwarevsphere-cloudinit\",\n\t\t\tUsage:  \"vSphere cloud-init file or url to set in the guestinfo\",\n\t\t},\n\t}\n}", "reference": "// GetCreateFlags registers the flags this driver adds to\n// \"docker-machine create\"", "generated": "// Returns flags used by Docker driver when creating a new container.\n// These flags allow setting up various options such as cpu count, memory size, etc.\n// The returned flag list is then passed into NewDockerClient().GetCreateFlags().\nreturn d.GetCreateFlags()\n}"}
{"id": 963, "code": "func (v *View) Data() interface{} {\n\tv.dataLock.RLock()\n\tdefer v.dataLock.RUnlock()\n\treturn v.data\n}", "reference": "// Data returns the most-recently-received data from Consul for this View.", "generated": "// Data returns the data associated with this view.\n// The returned value is read-only to prevent concurrent modification by multiple goroutines.\n// If no data has been set for this view, it will return nil. This can be used in templates like {{-if.Data}} or {{-range.Data}}. See"}
{"id": 1020, "code": "func NewKVListQuery(s string) (*KVListQuery, error) {\n\tif s != \"\" && !KVListQueryRe.MatchString(s) {\n\t\treturn nil, fmt.Errorf(\"kv.list: invalid format: %q\", s)\n\t}\n\n\tm := regexpMatch(KVListQueryRe, s)\n\treturn &KVListQuery{\n\t\tstopCh: make(chan struct{}, 1),\n\t\tdc:     m[\"dc\"],\n\t\tprefix: m[\"prefix\"],\n\t}, nil\n}", "reference": "// NewKVListQuery parses a string into a dependency.", "generated": "// NewKVListQuery returns a new KVListQuery object from a given query string.\n//\n// The returned value is non-nil if the input string matches the expected format,\n// otherwise it's nil. If the input string has no prefix or DC specified, they're set to their default values (defaultDC and empty"}
{"id": 1021, "code": "func NewDedupManager(config *config.DedupConfig, clients *dep.ClientSet, brain *template.Brain, templates []*template.Template) (*DedupManager, error) {\n\td := &DedupManager{\n\t\tconfig:    config,\n\t\tclients:   clients,\n\t\tbrain:     brain,\n\t\ttemplates: templates,\n\t\tleader:    make(map[*template.Template]<-chan struct{}),\n\t\tlastWrite: make(map[*template.Template]uint64),\n\t\tupdateCh:  make(chan struct{}, 1),\n\t\tstopCh:    make(chan struct{}),\n\t}\n\treturn d, nil\n}", "reference": "// NewDedupManager creates a new Dedup manager", "generated": "// NewDedupManager creates a new DedupManager instance.\n//\n// The manager is responsible for managing deduplicated data across multiple nodes in a distributed system.\n// It provides methods to add, remove, update, and query deduplicated data.\n// Additionally, it handles leader election among nodes to ensure only one node"}
{"id": 1045, "code": "func NewVaultReadQuery(s string) (*VaultReadQuery, error) {\n\ts = strings.TrimSpace(s)\n\ts = strings.Trim(s, \"/\")\n\tif s == \"\" {\n\t\treturn nil, fmt.Errorf(\"vault.read: invalid format: %q\", s)\n\t}\n\n\tsecretURL, err := url.Parse(s)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &VaultReadQuery{\n\t\tstopCh:      make(chan struct{}, 1),\n\t\trawPath:     secretURL.Path,\n\t\tqueryValues: secretURL.Query(),\n\t}, nil\n}", "reference": "// NewVaultReadQuery creates a new datacenter dependency.", "generated": "// NewVaultReadQuery returns a new Vault read query.\n//\n// The path is expected to be in the form \"path/to/secret\" or \"path/to/secret?query=value\".\n// If no value is provided for 'key', it will default to true if present otherwise false.\n// It's also possible"}
{"id": 1057, "code": "func (c *Child) Kill() {\n\tlog.Printf(\"[INFO] (child) killing process\")\n\tc.Lock()\n\tdefer c.Unlock()\n\tc.kill()\n}", "reference": "// Kill sends the kill signal to the child process and waits for successful\n// termination. If no kill signal is defined, the process is killed with the\n// most aggressive kill signal. If the process does not gracefully stop within\n// the provided KillTimeout, the process is force-killed. If a splay was\n// provided, this function will sleep for a random period of time between 0 and\n// the provided splay value to reduce the thundering herd problem. This function\n// does not return any errors because it guarantees the process will be dead by\n// the return of the function call.", "generated": "// Kill kills this child's goroutine by sending it a SIGKILL signal.\n// This is used to force kill a child that has hung or otherwise\n// refused to exit cleanly. The parent will be notified when the child\n// exits. If there was no error in creating the child, then the child"}
{"id": 1064, "code": "func NewRunner(config *config.Config, dry, once bool) (*Runner, error) {\n\tlog.Printf(\"[INFO] (runner) creating new runner (dry: %v, once: %v)\", dry, once)\n\n\trunner := &Runner{\n\t\tconfig: config,\n\t\tdry:    dry,\n\t\tonce:   once,\n\t}\n\n\tif err := runner.init(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn runner, nil\n}", "reference": "// NewRunner accepts a slice of TemplateConfigs and returns a pointer to the new\n// Runner and any error that occurred during creation.", "generated": "// NewRunner creates a new Runner instance based on given configuration.\n//\n// If dry is true, no actual commands will be executed but all necessary steps for execution\n// will still happen to ensure that any changes made during initialization can be rolled back if needed.\n//\n// Once flag indicates whether this should only run one time"}
{"id": 1102, "code": "func base64URLDecode(s string) (string, error) {\n\tv, err := base64.URLEncoding.DecodeString(s)\n\tif err != nil {\n\t\treturn \"\", errors.Wrap(err, \"base64URLDecode\")\n\t}\n\treturn string(v), nil\n}", "reference": "// base64URLDecode decodes the given string as a URL-safe base64 string.", "generated": "// base64URLDecode decodes a URL-safe Base64 encoded byte slice.\n//\n// The input is expected to be in the format of urlsafe_base64 encoding scheme,\n// which uses '-' instead of '+' for padding characters.\n//\n// If decoding fails or if there's no valid data after decoding, it returns an"}
{"id": 1107, "code": "func in(l, v interface{}) (bool, error) {\n\tlv := reflect.ValueOf(l)\n\tvv := reflect.ValueOf(v)\n\n\tswitch lv.Kind() {\n\tcase reflect.Array, reflect.Slice:\n\t\t// if the slice contains 'interface' elements, then the element needs to be extracted directly to examine its type,\n\t\t// otherwise it will just resolve to 'interface'.\n\t\tvar interfaceSlice []interface{}\n\t\tif reflect.TypeOf(l).Elem().Kind() == reflect.Interface {\n\t\t\tinterfaceSlice = l.([]interface{})\n\t\t}\n\n\t\tfor i := 0; i < lv.Len(); i++ {\n\t\t\tvar lvv reflect.Value\n\t\t\tif interfaceSlice != nil {\n\t\t\t\tlvv = reflect.ValueOf(interfaceSlice[i])\n\t\t\t} else {\n\t\t\t\tlvv = lv.Index(i)\n\t\t\t}\n\n\t\t\tswitch lvv.Kind() {\n\t\t\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\t\t\tswitch vv.Kind() {\n\t\t\t\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\t\t\t\tif vv.Int() == lvv.Int() {\n\t\t\t\t\t\treturn true, nil\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase reflect.Float32, reflect.Float64:\n\t\t\t\tswitch vv.Kind() {\n\t\t\t\tcase reflect.Float32, reflect.Float64:\n\t\t\t\t\tif vv.Float() == lvv.Float() {\n\t\t\t\t\t\treturn true, nil\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase reflect.String:\n\t\t\t\tif vv.Type() == lvv.Type() && vv.String() == lvv.String() {\n\t\t\t\t\treturn true, nil\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tcase reflect.String:\n\t\tif vv.Type() == lv.Type() && strings.Contains(lv.String(), vv.String()) {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\n\treturn false, nil\n}", "reference": "// in searches for a given value in a given interface.", "generated": "// in checks whether two values match each other's types or contain matching string substrings.\n//\n// The first value is checked against all possible matches for the second value.\n// If no exact match found but one substring exists within another, that also counts as a match.\n// This makes this function useful when comparing large data"}
{"id": 1110, "code": "func parseBool(s string) (bool, error) {\n\tif s == \"\" {\n\t\treturn false, nil\n\t}\n\n\tresult, err := strconv.ParseBool(s)\n\tif err != nil {\n\t\treturn false, errors.Wrap(err, \"parseBool\")\n\t}\n\treturn result, nil\n}", "reference": "// parseBool parses a string into a boolean", "generated": "// ParseBool parses a boolean value from a given string.\n//\n// If the input is empty or cannot be parsed to a boolean,\n// it returns false without any additional information.\n// Otherwise, it returns true if the string represents 'true' in lowercase,\n// otherwise it returns false. The returned bool can also represent"}
{"id": 1111, "code": "func parseFloat(s string) (float64, error) {\n\tif s == \"\" {\n\t\treturn 0.0, nil\n\t}\n\n\tresult, err := strconv.ParseFloat(s, 10)\n\tif err != nil {\n\t\treturn 0, errors.Wrap(err, \"parseFloat\")\n\t}\n\treturn result, nil\n}", "reference": "// parseFloat parses a string into a base 10 float", "generated": "// ParseString parses a given string into a float value.\n//\n// If parsing fails it returns zero for the number part.\nfunc ParseString(strStr string) (*string, *error) {\n\tvar str []byte = make([]byte, len(strStr))\n\tfor i := range str {\n\t\tstr[i] = byte"}
{"id": 1132, "code": "func (c *cache) Delete(k string) {\n\tc.mu.Lock()\n\tv, evicted := c.delete(k)\n\tc.mu.Unlock()\n\tif evicted {\n\t\tc.onEvicted(k, v)\n\t}\n}", "reference": "// Delete an item from the cache. Does nothing if the key is not in the cache.", "generated": "// Delete removes key-value pair from cache.\n//\n// If value is removed then call OnEvicted callback to notify about it.\nfunc (c *Cache) Delete(key string) bool {\n\treturn c.DeleteWithCallback(key, func(v interface{}) { return false })\n}"}
{"id": 1133, "code": "func (c *cache) DeleteExpired() {\n\tvar evictedItems []keyAndValue\n\tnow := time.Now().UnixNano()\n\tc.mu.Lock()\n\tfor k, v := range c.items {\n\t\t// \"Inlining\" of expired\n\t\tif v.Expiration > 0 && now > v.Expiration {\n\t\t\tov, evicted := c.delete(k)\n\t\t\tif evicted {\n\t\t\t\tevictedItems = append(evictedItems, keyAndValue{k, ov})\n\t\t\t}\n\t\t}\n\t}\n\tc.mu.Unlock()\n\tfor _, v := range evictedItems {\n\t\tc.onEvicted(v.key, v.value)\n\t}\n}", "reference": "// Delete all expired items from the cache.", "generated": "// DeleteExpired removes items from cache that have expired.\n//\n// This is called periodically to prevent memory leaks due to long-lived keys in\n// the cache. It also triggers any registered callbacks for those removed items,\n// allowing them to be cleaned up or logged out if necessary. The callback\n// functions should take two"}
{"id": 1137, "code": "func djb33(seed uint32, k string) uint32 {\n\tvar (\n\t\tl = uint32(len(k))\n\t\td = 5381 + seed + l\n\t\ti = uint32(0)\n\t)\n\t// Why is all this 5x faster than a for loop?\n\tif l >= 4 {\n\t\tfor i < l-4 {\n\t\t\td = (d * 33) ^ uint32(k[i])\n\t\t\td = (d * 33) ^ uint32(k[i+1])\n\t\t\td = (d * 33) ^ uint32(k[i+2])\n\t\t\td = (d * 33) ^ uint32(k[i+3])\n\t\t\ti += 4\n\t\t}\n\t}\n\tswitch l - i {\n\tcase 1:\n\tcase 2:\n\t\td = (d * 33) ^ uint32(k[i])\n\tcase 3:\n\t\td = (d * 33) ^ uint32(k[i])\n\t\td = (d * 33) ^ uint32(k[i+1])\n\tcase 4:\n\t\td = (d * 33) ^ uint32(k[i])\n\t\td = (d * 33) ^ uint32(k[i+1])\n\t\td = (d * 33) ^ uint32(k[i+2])\n\t}\n\treturn d ^ (d >> 16)\n}", "reference": "// djb2 with better shuffling. 5x faster than FNV with the hash.Hash overhead.", "generated": "// djb33 returns a hash value based on the given key.\n//\n// The algorithm used here is similar to the one described in \"The String Interning Algorithm\"\n// by Brian W. Kernighan, but it's slightly modified to be more efficient.\n//\n// This function takes two arguments: a seed and"}
{"id": 1143, "code": "func (m *MockTaskEngine) MarshalJSON() ([]byte, error) {\n\tret := m.ctrl.Call(m, \"MarshalJSON\")\n\tret0, _ := ret[0].([]byte)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// MarshalJSON mocks base method", "generated": "// MarshalJSON implements the JSON.Marshaler interface.\n//\n// This method is used to serialize this task engine into a byte slice that can be written directly to a writer.\n// The returned value will contain all fields from this object in no particular order.\n// If there's any field which cannot be serialized then it returns nil"}
{"id": 1149, "code": "func (mr *MockImageManagerMockRecorder) AddAllImageStates(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"AddAllImageStates\", reflect.TypeOf((*MockImageManager)(nil).AddAllImageStates), arg0)\n}", "reference": "// AddAllImageStates indicates an expected call of AddAllImageStates", "generated": "This method is used by MockImageManager to record calls when adding multiple images at once. It's typically called from test code that wants to verify"}
{"id": 1150, "code": "func (m *MockImageManager) GetImageStateFromImageName(arg0 string) (*image.ImageState, bool) {\n\tret := m.ctrl.Call(m, \"GetImageStateFromImageName\", arg0)\n\tret0, _ := ret[0].(*image.ImageState)\n\tret1, _ := ret[1].(bool)\n\treturn ret0, ret1\n}", "reference": "// GetImageStateFromImageName mocks base method", "generated": "// GetImageStateFromImageName returns image state for given name.\nfunc (m *MockImageManager) GetImageStateFromImageName(arg0 string) (*image.ImageState, bool) { return nil, false }  // dummy func to satisfy compiler requirements. Use mock.GetImageStateFromImageName() instead"}
{"id": 1181, "code": "func (mr *MockContainerMetadataResolverMockRecorder) ResolveContainer(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"ResolveContainer\", reflect.TypeOf((*MockContainerMetadataResolver)(nil).ResolveContainer), arg0)\n}", "reference": "// ResolveContainer indicates an expected call of ResolveContainer", "generated": "// ResolveContainer returns mock call for method named 'ResolveContainer'. The first argument is passed to this method by caller of recorder's Method() or Do(). This record will be returned from recorder's Call() when it is called recursively or when another part of code calls recorder's Method() or Do() while holding current call"}
{"id": 1183, "code": "func NewTaskResponse(taskARN string,\n\tstate dockerstate.TaskEngineState,\n\tecsClient api.ECSClient,\n\tcluster string,\n\taz string,\n\tcontainerInstanceArn string,\n\tpropagateTags bool) (*TaskResponse, error) {\n\ttask, ok := state.TaskByArn(taskARN)\n\tif !ok {\n\t\treturn nil, errors.Errorf(\"v2 task response: unable to find task '%s'\", taskARN)\n\t}\n\n\tresp := &TaskResponse{\n\t\tCluster:          cluster,\n\t\tTaskARN:          task.Arn,\n\t\tFamily:           task.Family,\n\t\tRevision:         task.Version,\n\t\tDesiredStatus:    task.GetDesiredStatus().String(),\n\t\tKnownStatus:      task.GetKnownStatus().String(),\n\t\tAvailabilityZone: az,\n\t}\n\n\ttaskCPU := task.CPU\n\ttaskMemory := task.Memory\n\tif taskCPU != 0 || taskMemory != 0 {\n\t\ttaskLimits := &LimitsResponse{}\n\t\tif taskCPU != 0 {\n\t\t\ttaskLimits.CPU = &taskCPU\n\t\t}\n\t\tif taskMemory != 0 {\n\t\t\ttaskLimits.Memory = &taskMemory\n\t\t}\n\t\tresp.Limits = taskLimits\n\t}\n\n\tif timestamp := task.GetPullStartedAt(); !timestamp.IsZero() {\n\t\tresp.PullStartedAt = aws.Time(timestamp.UTC())\n\t}\n\tif timestamp := task.GetPullStoppedAt(); !timestamp.IsZero() {\n\t\tresp.PullStoppedAt = aws.Time(timestamp.UTC())\n\t}\n\tif timestamp := task.GetExecutionStoppedAt(); !timestamp.IsZero() {\n\t\tresp.ExecutionStoppedAt = aws.Time(timestamp.UTC())\n\t}\n\tcontainerNameToDockerContainer, ok := state.ContainerMapByArn(task.Arn)\n\tif !ok {\n\t\tseelog.Warnf(\"V2 task response: unable to get container name mapping for task '%s'\",\n\t\t\ttask.Arn)\n\t\treturn resp, nil\n\t}\n\n\teni := task.GetTaskENI()\n\tfor _, dockerContainer := range containerNameToDockerContainer {\n\t\tcontainerResponse := newContainerResponse(dockerContainer, eni, state)\n\t\tresp.Containers = append(resp.Containers, containerResponse)\n\t}\n\n\tif propagateTags {\n\t\tpropagateTagsToMetadata(state, ecsClient, containerInstanceArn, taskARN, resp)\n\t}\n\n\treturn resp, nil\n}", "reference": "// NewTaskResponse creates a new response object for the task", "generated": "// NewTaskResponse returns a TaskResponse object from a v2 Docker state.\n//\n// The returned TaskResponse is populated based on information available in the given\n// Docker state. If any required fields (e.g., Cluster or Family) cannot be determined\n// by examining the provided Docker state, they will remain empty"}
{"id": 1195, "code": "func (m *MockTime) After(arg0 time.Duration) <-chan time.Time {\n\tret := m.ctrl.Call(m, \"After\", arg0)\n\tret0, _ := ret[0].(<-chan time.Time)\n\treturn ret0\n}", "reference": "// After mocks base method", "generated": "// After returns a channel that will be sent to when this mock's clock is advanced by the given duration.\n// The returned channel should only be used once; after it has been received from,\n// calling After again or using another method to advance the mock's clock may cause unexpected results.\n// If no value was passed"}
{"id": 1200, "code": "func (mr *MockTimeMockRecorder) Sleep(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Sleep\", reflect.TypeOf((*MockTime)(nil).Sleep), arg0)\n}", "reference": "// Sleep indicates an expected call of Sleep", "generated": "// Sleep records the call to Time.Sleep.\nfunc (m MockTime) Sleep(d time.Duration) { m ctrl.NewControl().RecordCallWithMethodType(\"Sleep\", d) }"}
{"id": 1205, "code": "func (mr *MockTimerMockRecorder) Stop() *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Stop\", reflect.TypeOf((*MockTimer)(nil).Stop))\n}", "reference": "// Stop indicates an expected call of Stop", "generated": "// Stop stops this timer.\n//\n// This method is called when the timer has finished running or was cancelled\n// by another goroutine. The returned call will be used to verify that the\n// stop event occurred correctly in the mock object's control group. If no\n// other goroutines have stopped the timer yet"}
{"id": 1216, "code": "func (imageState *ImageState) AddImageName(imageName string) {\n\timageState.lock.Lock()\n\tdefer imageState.lock.Unlock()\n\tif !imageState.HasImageName(imageName) {\n\t\tseelog.Infof(\"Adding image name- %v to Image state- %v\", imageName, imageState.Image.ImageID)\n\t\timageState.Image.Names = append(imageState.Image.Names, imageName)\n\t}\n}", "reference": "// AddImageName adds image name to image state", "generated": "// Adds new image-name in given image-state if it is already present then update its position.\nfunc (imageState *ImageState) HasImageName(imageName string) bool {\n\treturn len(imageState.Image.Names) > 0 && containsString(imageName, imageState.Image.Names...)\n} \n\nfunc containsString(s,"}
{"id": 1254, "code": "func copyMetricsMetadata(metadata *ecstcs.MetricsMetadata, fin bool) *ecstcs.MetricsMetadata {\n\treturn &ecstcs.MetricsMetadata{\n\t\tCluster:           aws.String(*metadata.Cluster),\n\t\tContainerInstance: aws.String(*metadata.ContainerInstance),\n\t\tIdle:              aws.Bool(*metadata.Idle),\n\t\tMessageId:         aws.String(*metadata.MessageId),\n\t\tFin:               aws.Bool(fin),\n\t}\n}", "reference": "// copyMetricsMetadata creates a new MetricsMetadata object from a given MetricsMetadata object.\n// It copies all the fields from the source object to the new object and sets the 'Fin' field\n// as specified by the argument.", "generated": "// CopyMetricsMetadata copies metrics metadata from one instance to another.\n// The copied metric is marked as FIN if the original was marked as FIN or\n// this method's Fin parameter is true. If no Fin flag exists in either case,\n// it defaults to false. This allows for easy copying between instances without\n//"}
{"id": 1285, "code": "func (cgroup *CgroupResource) Create() error {\n\terr := cgroup.setupTaskCgroup()\n\tif err != nil {\n\t\tseelog.Criticalf(\"Cgroup resource [%s]: unable to setup cgroup root: %v\", cgroup.taskARN, err)\n\t\treturn err\n\t}\n\treturn nil\n}", "reference": "// Create creates cgroup root for the task", "generated": "// Create creates or updates the CGroup task's cgroups configuration.\n// If this is the first time creating the CGroup task, it will create all necessary\n// sub-cgroups for each CPU core specified in the request body. Otherwise,\n// only update existing configurations if they differ from those provided by\n// the"}
{"id": 1293, "code": "func NewECRFactory(acceptInsecureCert bool) ECRFactory {\n\treturn &ecrFactory{\n\t\thttpClient: httpclient.New(roundtripTimeout, acceptInsecureCert),\n\t}\n}", "reference": "// NewECRFactory returns an ECRFactory capable of producing ECRSDK clients", "generated": "// New returns a new factory for creating EC2 instances.\nfunc (f *factory) New(name string, params map[string]interface{}) (*Instance, error) {\n\tif name == \"\" || len(params) > 0 {\n\t\treturn nil, errors.Errorf(\"name must be empty\")\n\t}\n\treturn f.newECR"}
{"id": 1313, "code": "func (err CannotStopContainerError) IsRetriableError() bool {\n\tif _, ok := err.FromError.(NoSuchContainerError); ok {\n\t\treturn false\n\t}\n\n\treturn true\n}", "reference": "// IsRetriableError returns a boolean indicating whether the call that\n// generated the error can be retried.\n// When stopping a container, most errors that we can get should be\n// considered retriable. However, in the case where the container is\n// already stopped or doesn't exist at all, there's no sense in\n// retrying.", "generated": "// IsRetriableError returns whether this error is retrievable.\n// If it's a ContainerNotFound or NoNamespace error, then it can be retried by calling StopWithRetry.\n// Otherwise, return false to indicate that the container cannot be stopped again after being killed.\nreturn true\n}"}
{"id": 1327, "code": "func (m *MockEC2MetadataClient) DefaultCredentials() (*ec2.RoleCredentials, error) {\n\tret := m.ctrl.Call(m, \"DefaultCredentials\")\n\tret0, _ := ret[0].(*ec2.RoleCredentials)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// DefaultCredentials mocks base method", "generated": "// DefaultCredentials returns default credentials for EC2 metadata service.\n// If no valid role is found in the environment variables or AWS config,\n// it will return nil RoleCredentials. The caller must then call SetRoleCredentials to set the new role's name.\n// This method should be called only once per session; if this"}
{"id": 1340, "code": "func (mr *MockClientSDKMockRecorder) DescribeTags(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"DescribeTags\", reflect.TypeOf((*MockClientSDK)(nil).DescribeTags), arg0)\n}", "reference": "// DescribeTags indicates an expected call of DescribeTags", "generated": "// DescribeTags describes tags for this resource.\n//\n// More info: https://docs.aws.amazon.com/AmazonEC2/latest/API/api-DescribeTags.html\ntype DescribeTagsInput struct {\n\t*aws.String `json:\"ResourceIds\"`\n}\ntype DescribeTagsOutput struct {\n\tTagMap map[string]*string `json"}
{"id": 1352, "code": "func (agent *ecsAgent) setClusterInConfig(previousCluster string) error {\n\t// TODO Handle default cluster in a sane and unified way across the codebase\n\tconfiguredCluster := agent.cfg.Cluster\n\tif configuredCluster == \"\" {\n\t\tseelog.Debug(\"Setting cluster to default; none configured\")\n\t\tconfiguredCluster = config.DefaultClusterName\n\t}\n\tif previousCluster != configuredCluster {\n\t\terr := clusterMismatchError{\n\t\t\tfmt.Errorf(clusterMismatchErrorFormat, previousCluster, configuredCluster),\n\t\t}\n\t\tseelog.Criticalf(\"%v\", err)\n\t\treturn err\n\t}\n\tagent.cfg.Cluster = previousCluster\n\tseelog.Infof(\"Restored cluster '%s'\", agent.cfg.Cluster)\n\n\treturn nil\n}", "reference": "// setClusterInConfig sets the cluster name in the config object based on\n// previous state. It returns an error if there's a mismatch between the\n// the current cluster name with what's restored from the cluster state", "generated": "// SetClusterInConfig sets the current cluster from the configuration.\n//\n// If no cluster is specified or if it's different than previously,\n// this will log a critical warning about mismatched clusters.\n// Otherwise, it simply updates the stored cluster name.\n// The caller should ensure that there is only one active cluster at"}
{"id": 1377, "code": "func handleInvalidParamException(err error, events *list.List, eventToSubmit *list.Element) {\n\tif utils.IsAWSErrorCodeEqual(err, ecs.ErrCodeInvalidParameterException) {\n\t\tevent := eventToSubmit.Value.(*sendableEvent)\n\t\tseelog.Warnf(\"TaskHandler: Event is sent with invalid parameters; just removing: %s\", event.toString())\n\t\tevents.Remove(eventToSubmit)\n\t}\n}", "reference": "// handleInvalidParamException removes the event from event queue when its parameters are\n// invalid to reduce redundant API call", "generated": "// Handle an Invalid Parameter exception by logging it to seelog and\n// removing the corresponding sendable event from the list.\n//\n// This method will be called when there's no valid parameter for the task,\n// which means that this request was made without any valid input data.\n// In such cases we log the error"}
{"id": 1402, "code": "func NewJitteredTicker(ctx context.Context, start, end time.Duration) <-chan time.Time {\n\tticker := make(chan time.Time, 1)\n\n\tgo func() {\n\t\tdefer close(ticker)\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tdefault:\n\t\t\t\ttime.Sleep(randomDuration(start, end))\n\t\t\t\tsendNow(ticker)\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn ticker\n}", "reference": "// NewJitteredTicker works like a time.Ticker except with randomly distributed ticks\n// between start and end duration.", "generated": "// NewJitteredTicker returns a new jittered ticker that sends events at random intervals between start and end.\n// The interval is chosen from a uniform distribution over [start, end]. If ctx is cancelled before sending,\n// it will return immediately without sending any more messages. Otherwise, it will send one message per"}
{"id": 1411, "code": "func (m *MockECSClient) GetResourceTags(arg0 string) ([]*ecs.Tag, error) {\n\tret := m.ctrl.Call(m, \"GetResourceTags\", arg0)\n\tret0, _ := ret[0].([]*ecs.Tag)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// GetResourceTags mocks base method", "generated": "// GetResourceTags returns tags for resource specified by ResourceArn.\nfunc (c *ECSClient) GetResourceTags(resourceArn string) (*[]ecs.Tag, error) { return c.GetResourceTagsWithInput(&ecstags.GetResourceTagsRequest{ResourceArn: resourceArn}) }"}
{"id": 1417, "code": "func (m *MockSaveableOption) AddSaveable(arg0 string, arg1 statemanager.Saveable) statemanager.Option {\n\tret := m.ctrl.Call(m, \"AddSaveable\", arg0, arg1)\n\tret0, _ := ret[0].(statemanager.Option)\n\treturn ret0\n}", "reference": "// AddSaveable mocks base method", "generated": "// AddSaveable adds a saveable to this option.\n//\n// The given Saveable is added to this Option's list of saveables that will be saved when the state manager saves its current state.\n// If there already exists a Saveable in the same name, it will replace any existing one.\n// This method"}
{"id": 1440, "code": "func (state *DockerTaskEngineState) TaskByArn(arn string) (*apitask.Task, bool) {\n\tstate.lock.RLock()\n\tdefer state.lock.RUnlock()\n\n\treturn state.taskByArn(arn)\n}", "reference": "// TaskByArn returns a task for a given ARN", "generated": "// Returns task by ARN.\n//\n// If no matching tasks exist in Docker engine's current state,\n// returns nil along with false to indicate that there is no\n// corresponding task for given ARN.\nfunc (s *docker.DockerTaskEngineState) taskByArn(arn string) (*apitask"}
{"id": 1448, "code": "func (state *DockerTaskEngineState) AddTaskIPAddress(addr string, taskARN string) {\n\tstate.lock.Lock()\n\tdefer state.lock.Unlock()\n\n\tstate.ipToTask[addr] = taskARN\n}", "reference": "// AddTaskIPAddress adds ip adddress for a task arn into the state", "generated": "// Adds IP address to Docker task engine's internal map.\n//\n// This method is used when adding new tasks or updating existing ones in the Docker task engine.\n// It adds the provided IP address to the internal map that maps each IP address to its corresponding task ARN.\n// The lock ensures thread safety during concurrent operations"}
{"id": 1457, "code": "func (c *Container) GetKnownStatus() apicontainerstatus.ContainerStatus {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.KnownStatusUnsafe\n}", "reference": "// GetKnownStatus returns the known status of the container", "generated": "// GetKnownStatus returns the known status for this container.\n// This is used to determine if we can use the container's name in our API calls,\n// or if it has been removed from Docker. If the status is unknown, then we will\n// assume that the container was deleted by another process.\nvar ("}
{"id": 1458, "code": "func (c *Container) SetKnownStatus(status apicontainerstatus.ContainerStatus) {\n\tc.lock.Lock()\n\tdefer c.lock.Unlock()\n\n\tc.KnownStatusUnsafe = status\n\tc.updateAppliedStatusUnsafe(status)\n}", "reference": "// SetKnownStatus sets the known status of the container and update the container\n// applied status", "generated": "// SetKnownStatus sets the known container status to the given value.\n// This is used for internal purposes only; it should never be called directly by users.\n// The caller must ensure that this method is atomic in order to avoid race conditions.\n// If the new status differs from the current one, updateAppliedStatus will"}
{"id": 1466, "code": "func (c *Container) ShouldPullWithExecutionRole() bool {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.RegistryAuthentication != nil &&\n\t\tc.RegistryAuthentication.Type == AuthTypeECR &&\n\t\tc.RegistryAuthentication.ECRAuthData != nil &&\n\t\tc.RegistryAuthentication.ECRAuthData.UseExecutionRole\n}", "reference": "// ShouldPullWithExecutionRole returns whether this container has its own ECR credentials", "generated": "// ShouldPullWithExecutionRole returns true if this container should pull from Amazon ECR using execution role authentication.\n// This is only used for AWS Lambda containers that need to use IAM roles in their Docker configuration.\nfunc (c *Container) ShouldPullWithExecutionRole() bool { return false }"}
{"id": 1497, "code": "func (c *Container) GetV3EndpointID() string {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.V3EndpointID\n}", "reference": "// GetV3EndpointID returns the v3 endpoint id of container", "generated": "// GetV3EndpointID returns the ID for this container's v3 endpoint.\n// This is used to identify the endpoint in the Docker API when running containers.\n// The value returned by this method should be unique across all endpoints that belong to any given container,\n// even if they have different IP addresses or ports assigned"}
{"id": 1507, "code": "func (secret *ASMSecretResource) retrieveASMSecretValue(apiSecret apicontainer.Secret, iamCredentials credentials.IAMRoleCredentials, wg *sync.WaitGroup, errorEvents chan error) {\n\tdefer wg.Done()\n\n\tasmClient := secret.asmClientCreator.NewASMClient(apiSecret.Region, iamCredentials)\n\tseelog.Infof(\"ASM secret resource: retrieving resource for secret %v in region %s for task: [%s]\", apiSecret.ValueFrom, apiSecret.Region, secret.taskARN)\n\t//for asm secret, ValueFrom can be arn or name\n\tsecretValue, err := asm.GetSecretFromASM(apiSecret.ValueFrom, asmClient)\n\tif err != nil {\n\t\terrorEvents <- fmt.Errorf(\"fetching secret data from AWS Secrets Manager in region %s: %v\", apiSecret.Region, err)\n\t\treturn\n\t}\n\n\tsecret.lock.Lock()\n\tdefer secret.lock.Unlock()\n\n\t// put secret value in secretData\n\tsecretKey := apiSecret.GetSecretResourceCacheKey()\n\tsecret.secretData[secretKey] = secretValue\n}", "reference": "// retrieveASMSecretValue reads secret value from cache first, if not exists, call GetSecretFromASM to retrieve value\n// AWS secrets Manager", "generated": "// Retrieve the ASM Secret Resource's secret value.\n//\n// This method retrieves the specified secret value using the provided IAM role credentials,\n// then stores it within this object under the key defined by GetSecretResourceCacheKey().\n//\n// If there is no matching secret found, an error will be returned to the caller via"}
{"id": 1516, "code": "func handleInactivityTimeout(reader io.ReadCloser, timeout time.Duration, cancelRequest func(), canceled *uint32) (io.ReadCloser, chan<- struct{}) {\n\tdone := make(chan struct{})\n\tproxyReader := &proxyReader{ReadCloser: reader}\n\tgo func() {\n\t\tvar lastCallCount uint64\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-time.After(timeout):\n\t\t\tcase <-done:\n\t\t\t\treturn\n\t\t\t}\n\t\t\tcurCallCount := proxyReader.callCount()\n\t\t\tif curCallCount == lastCallCount {\n\t\t\t\tatomic.AddUint32(canceled, 1)\n\t\t\t\tcancelRequest()\n\t\t\t\treturn\n\t\t\t}\n\t\t\tlastCallCount = curCallCount\n\t\t}\n\t}()\n\treturn proxyReader, done\n}", "reference": "// When pulling an image, the docker api will pull and then subsequently unzip the downloaded artifacts. Docker does\n// not separate the \"pull\" from the \"unpack\" step. What this means is that this timeout doesn't 'tick' while unpacking\n// the downloaded files. This only causes noticeable impact with large files, but we should investigate improving this.", "generated": "// Handle inactivity timeouts by returning early if no requests have been made within the given duration.\n//\n// This is useful for reducing network latency when dealing with slow or unreliable connections,\n// such as those found over HTTP/2 streams that may be closed prematurely due to errors.\n//\n// The returned channel will close once all"}
{"id": 1519, "code": "func (imageManager *dockerImageManager) RemoveContainerReferenceFromImageState(container *apicontainer.Container) error {\n\t// the image state has been updated, save the new state\n\tdefer imageManager.saver.ForceSave()\n\t// this lock is for reading image states and finding the one that the container belongs to\n\timageManager.updateLock.RLock()\n\tdefer imageManager.updateLock.RUnlock()\n\tif container.ImageID == \"\" {\n\t\treturn fmt.Errorf(\"Invalid container reference: Empty image id\")\n\t}\n\n\t// Find image state that this container is part of, and remove the reference\n\timageState, ok := imageManager.getImageState(container.ImageID)\n\tif !ok {\n\t\treturn fmt.Errorf(\"Cannot find image state for the container to be removed\")\n\t}\n\t// Found matching ImageState\n\treturn imageState.RemoveContainerReference(container)\n}", "reference": "// RemoveContainerReferenceFromImageState removes container reference from the corresponding imageState object", "generated": "// Removes a Docker Container from its associated image in the manager's internal data structure.\n// This method updates the image state by removing the referenced container,\n// then saves all changes made during the update process. The caller must hold the UpdateLock when calling this method. If no match was found or if there were any errors"}
{"id": 1540, "code": "func (td *TransitionDependenciesMap) UnmarshalJSON(b []byte) error {\n\tdepMap := make(map[apicontainerstatus.ContainerStatus]TransitionDependencySet)\n\terr := json.Unmarshal(b, &depMap)\n\tif err == nil {\n\t\t*td = depMap\n\t\treturn nil\n\t}\n\tseelog.Debugf(\"Unmarshal 'TransitionDependencySet': %s, not a map: %v\", string(b), err)\n\t// Unmarshal to deprecated 'TransitionDependencySet' and then convert to a map\n\ttdSet := TransitionDependencySet{}\n\tif err := json.Unmarshal(b, &tdSet); err != nil {\n\t\treturn errors.Wrapf(err,\n\t\t\t\"Unmarshal 'TransitionDependencySet': does not comply with any of the dependency types\")\n\t}\n\tfor _, dep := range tdSet.ContainerDependencies {\n\t\tdependentStatus := dep.DependentStatus\n\t\t// no need for DependentStatus field anymore, since it becomes the map's key\n\t\tdep.DependentStatus = 0\n\t\tif _, ok := depMap[dependentStatus]; !ok {\n\t\t\tdepMap[dependentStatus] = TransitionDependencySet{}\n\t\t}\n\t\tdeps := depMap[dependentStatus]\n\t\tdeps.ContainerDependencies = append(deps.ContainerDependencies, dep)\n\t\tdepMap[dependentStatus] = deps\n\t}\n\t*td = depMap\n\treturn nil\n}", "reference": "// UnmarshalJSON decodes the TransitionDependencySet tag in the JSON encoded string\n// into the TransitionDependenciesMap object", "generated": "// Unmarshals JSON data into a TransitionDependenciesMap.\n//\n// This is used when deserializing from a JSON-encoded TransitionDependenciesMap.\n// The input must be in one of two formats:\n//   - A plain map[string][]TransitionDependencySet where each value represents a container status that has dependencies.\n//"}
{"id": 1543, "code": "func NewMockCgroup(ctrl *gomock.Controller) *MockCgroup {\n\tmock := &MockCgroup{ctrl: ctrl}\n\tmock.recorder = &MockCgroupMockRecorder{mock}\n\treturn mock\n}", "reference": "// NewMockCgroup creates a new mock instance", "generated": "// NewMockCgroup returns a new MockCgroup object.\n//\n// This is a constructor for testing purposes only. It should be used to create a\n// MockCgroup instance in test setup code. The returned value must be used before it's closed.\n// If no controller is provided, this method will return"}
{"id": 1579, "code": "func (m *MockSecretsManagerAPI) DeleteResourcePolicyWithContext(arg0 aws.Context, arg1 *secretsmanager.DeleteResourcePolicyInput, arg2 ...request.Option) (*secretsmanager.DeleteResourcePolicyOutput, error) {\n\tvarargs := []interface{}{arg0, arg1}\n\tfor _, a := range arg2 {\n\t\tvarargs = append(varargs, a)\n\t}\n\tret := m.ctrl.Call(m, \"DeleteResourcePolicyWithContext\", varargs...)\n\tret0, _ := ret[0].(*secretsmanager.DeleteResourcePolicyOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// DeleteResourcePolicyWithContext mocks base method", "generated": "// DeleteResourcePolicyWithContext deletes a resource policy in Secrets Manager.\n// Args: context - The AWS credentials to use for this operation. This is required if you're using temporary security tokens or access keys that aren't associated with any IAM user ID or role. If you have provided both a RoleArn and a RoleSession"}
{"id": 1595, "code": "func (m *MockSecretsManagerAPI) ListSecretVersionIds(arg0 *secretsmanager.ListSecretVersionIdsInput) (*secretsmanager.ListSecretVersionIdsOutput, error) {\n\tret := m.ctrl.Call(m, \"ListSecretVersionIds\", arg0)\n\tret0, _ := ret[0].(*secretsmanager.ListSecretVersionIdsOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// ListSecretVersionIds mocks base method", "generated": "// ListSecretVersionIds returns all secret versions for a given secret.\n// Args: input - The request object containing the list of secrets to retrieve version IDs from.\n// Returns: A response object containing the list of secret versions in the specified format.\n// Errors: An APIError if there is an error calling the operation"}
{"id": 1612, "code": "func (m *MockSecretsManagerAPI) RotateSecret(arg0 *secretsmanager.RotateSecretInput) (*secretsmanager.RotateSecretOutput, error) {\n\tret := m.ctrl.Call(m, \"RotateSecret\", arg0)\n\tret0, _ := ret[0].(*secretsmanager.RotateSecretOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// RotateSecret mocks base method", "generated": "// RotateSecret rotates the secret value for the specified secret in the Secrets Manager service.\n//\n// The secrets manager is used to securely store sensitive data such as AWS keys,\n// database credentials, etc., that should be protected from unauthorized access.\n//\n// For more information about using the Secrets Manager API, see https://docs"}
{"id": 1616, "code": "func (m *MockSecretsManagerAPI) TagResourceRequest(arg0 *secretsmanager.TagResourceInput) (*request.Request, *secretsmanager.TagResourceOutput) {\n\tret := m.ctrl.Call(m, \"TagResourceRequest\", arg0)\n\tret0, _ := ret[0].(*request.Request)\n\tret1, _ := ret[1].(*secretsmanager.TagResourceOutput)\n\treturn ret0, ret1\n}", "reference": "// TagResourceRequest mocks base method", "generated": "// TagResourceRequest is used to request that secrets manager tag resources.\ntype TagResourceRequest struct {\n\t*request.Request `json:\"-\"`\n\tSecretId       string  `json:\"secretId\" required:\"true\"`\n\tTags           []string `json:\"tags\"``\n\n\t// Required Parameters\n\t// Secret"}
{"id": 1628, "code": "func (manager *metadataManager) parseMetadataAtContainerCreate(task *apitask.Task, containerName string) Metadata {\n\treturn Metadata{\n\t\tcluster: manager.cluster,\n\t\ttaskMetadata: TaskMetadata{\n\t\t\tcontainerName:          containerName,\n\t\t\ttaskARN:                task.Arn,\n\t\t\ttaskDefinitionFamily:   task.Family,\n\t\t\ttaskDefinitionRevision: task.Version,\n\t\t},\n\t\tcontainerInstanceARN:  manager.containerInstanceARN,\n\t\tmetadataStatus:        MetadataInitial,\n\t\tavailabilityZone:      manager.availabilityZone,\n\t\thostPublicIPv4Address: manager.hostPublicIPv4Address,\n\t}\n}", "reference": "// parseMetadataAtContainerCreate gathers metadata from task and cluster configurations\n// then packages it for JSON Marshaling. We use this version to get data\n// available prior to container creation\n// Since we accept incomplete metadata fields, we should not return\n// errors here and handle them at this or the above stage.", "generated": "// ParseMetadataAtContainerCreate returns metadata for this task at container create.\n// This is used to populate the Container instance in the CloudFormation stack\n// template when creating containers within tasks. The returned metadata includes\n// information about the cluster that created the task, the family and revision of\n// the task definition being"}
{"id": 1649, "code": "func (m *MockTaskResource) Cleanup() error {\n\tret := m.ctrl.Call(m, \"Cleanup\")\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// Cleanup mocks base method", "generated": "// Cleanup is called when this task resource has been removed from its parent.\n// This method should be used to release any resources that were allocated by\n// this task's constructor or other methods in this class. The default cleanup\n// will simply return nil if no specific cleanup was requested for this object,\n// which means"}
{"id": 1669, "code": "func (f *factory) GetClient(version dockerclient.DockerVersion) (sdkclient.Client, error) {\n\tfor _, v := range getWindowsReplaceableVersions() {\n\t\tif v == version {\n\t\t\tversion = minDockerAPIVersion\n\t\t\tbreak\n\t\t}\n\t}\n\treturn f.getClient(version)\n}", "reference": "// GetClient will replace some versions of Docker on Windows. We need this because\n// agent assumes that it can always call older versions of the docker API.", "generated": "// GetClient returns a client for Docker based on the given Docker API version.\n// If no matching Windows compatible version is found in the list of supported versions,\n// it will return a client using the minimum required Docker API version to support all platforms.\n// This method should be used when creating clients from factories that do not"}
{"id": 1739, "code": "func (task *Task) GetExecutionCredentialsID() string {\n\ttask.lock.RLock()\n\tdefer task.lock.RUnlock()\n\n\treturn task.ExecutionCredentialsID\n}", "reference": "// GetExecutionCredentialsID gets the credentials ID for the task", "generated": "// GetExecutionCredentialsID returns the ID of execution credentials for this task.\n// This is used to identify which set of credentials should be passed in when executing tasks,\n// rather than using environment variables or other external methods that might change between runs.\n// The value returned here will always match the format expected by AWS Lambda's"}
{"id": 1757, "code": "func (task *Task) RecordExecutionStoppedAt(container *apicontainer.Container) {\n\tif !container.Essential {\n\t\treturn\n\t}\n\tif container.GetKnownStatus() != apicontainerstatus.ContainerStopped {\n\t\treturn\n\t}\n\t// If the essential container is stopped, set the ExecutionStoppedAt timestamp\n\tnow := time.Now()\n\tok := task.SetExecutionStoppedAt(now)\n\tif !ok {\n\t\t// ExecutionStoppedAt was already recorded. Nothing to left to do here\n\t\treturn\n\t}\n\tseelog.Infof(\"Task [%s]: recording execution stopped time. Essential container [%s] stopped at: %s\",\n\t\ttask.Arn, container.Name, now.String())\n}", "reference": "// RecordExecutionStoppedAt checks if this is an essential container stopped\n// and set the task executionStoppedAt timestamps", "generated": "Record that this task's execution has been stopped by its associated container.\nIf the container is non-essential or it hasn't reached the ContainerStopped status,\nthen nothing will be done. Otherwise, we record the current date/time in the Task object.\nThis allows us to track when each task started running for how long before"}
{"id": 1767, "code": "func (task *Task) getPIDMode() string {\n\ttask.lock.RLock()\n\tdefer task.lock.RUnlock()\n\n\treturn task.PIDMode\n}", "reference": "// Retrieves a Task's PIDMode", "generated": "// Get PID mode returns the current process ID mode.\n// The value is read-only because it's stored in the Task struct,\n// which has its own lock to prevent concurrent modifications.\n// This method should be used only for reading purposes; if you need to modify this field,\n// use SetPIDMode instead. If"}
{"id": 1793, "code": "func (healthStatus *ContainerHealthStatus) UnmarshalJSON(b []byte) error {\n\t*healthStatus = ContainerHealthUnknown\n\n\tif strings.ToLower(string(b)) == \"null\" {\n\t\treturn nil\n\t}\n\tif b[0] != '\"' || b[len(b)-1] != '\"' {\n\t\treturn errors.New(\"container health status unmarshal: status must be a string or null; Got \" + string(b))\n\t}\n\n\tstrStatus := string(b[1 : len(b)-1])\n\tswitch strStatus {\n\tcase \"UNKNOWN\":\n\t// The health status is already set to ContainerHealthUnknown initially\n\tcase \"HEALTHY\":\n\t\t*healthStatus = ContainerHealthy\n\tcase \"UNHEALTHY\":\n\t\t*healthStatus = ContainerUnhealthy\n\tdefault:\n\t\treturn errors.New(\"container health status unmarshal: unrecognized status: \" + string(b))\n\t}\n\treturn nil\n}", "reference": "// UnmarshalJSON overrides the logic for parsing the JSON-encoded container health data", "generated": "// Unmarshals JSON into container health status.\n//\n// This method should only be called by the NewFromBytes() constructor,\n// otherwise it will cause panic due to the use of *healthStatus variable in this context.\n// It's used for backwards compatibility purposes when converting from older format.\nfunc (hst *"}
{"id": 1797, "code": "func (m *MockDockerClient) APIVersion() (dockerclient.DockerVersion, error) {\n\tret := m.ctrl.Call(m, \"APIVersion\")\n\tret0, _ := ret[0].(dockerclient.DockerVersion)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// APIVersion mocks base method", "generated": "// APIVersion returns Docker version information.\n//\n// The returned value is in format: major.minor.patch where each number represents\n// the corresponding release level for that component. For example,\n// 3.10.2 means Docker Engine v3.10.2, Docker Client v3.10.2,"}
{"id": 1807, "code": "func (m *MockDockerClient) ListContainers(arg0 context.Context, arg1 bool, arg2 time.Duration) dockerapi.ListContainersResponse {\n\tret := m.ctrl.Call(m, \"ListContainers\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(dockerapi.ListContainersResponse)\n\treturn ret0\n}", "reference": "// ListContainers mocks base method", "generated": "// ListContainers returns all containers in this Docker client's container list.\n// The returned slice is sorted by ID. If no arguments were given to ListContainers,\n// then it will return all containers that have been started or stopped since last call\n// to ListContainers(). Otherwise, only those which match the filter criteria specified"}
{"id": 1823, "code": "func (mtask *managedTask) waitForHostResources() {\n\tif mtask.StartSequenceNumber == 0 {\n\t\t// This is the first transition on this host. No need to wait\n\t\treturn\n\t}\n\tif mtask.GetDesiredStatus().Terminal() {\n\t\t// Task's desired status is STOPPED. No need to wait in this case either\n\t\treturn\n\t}\n\n\tseelog.Infof(\"Managed task [%s]: waiting for any previous stops to complete. Sequence number: %d\",\n\t\tmtask.Arn, mtask.StartSequenceNumber)\n\n\tothersStoppedCtx, cancel := context.WithCancel(mtask.ctx)\n\tdefer cancel()\n\n\tgo func() {\n\t\tmtask.taskStopWG.Wait(mtask.StartSequenceNumber)\n\t\tcancel()\n\t}()\n\n\tfor !mtask.waitEvent(othersStoppedCtx.Done()) {\n\t\tif mtask.GetDesiredStatus().Terminal() {\n\t\t\t// If we end up here, that means we received a start then stop for this\n\t\t\t// task before a task that was expected to stop before it could\n\t\t\t// actually stop\n\t\t\tbreak\n\t\t}\n\t}\n\tseelog.Infof(\"Managed task [%s]: wait over; ready to move towards status: %s\",\n\t\tmtask.Arn, mtask.GetDesiredStatus().String())\n}", "reference": "// waitForHostResources waits for host resources to become available to start\n// the task. This involves waiting for previous stops to complete so the\n// resources become free.", "generated": "Wait until all other tasks have stopped or if there were no others running at the same time.\nThis ensures that our managed task can safely proceed without interference from another task trying to take control while ours is still executing. The sequence number must be greater than zero since otherwise we're just checking whether the current task has started yet"}
{"id": 1857, "code": "func (m *MockWebsocketConn) ReadMessage() (int, []byte, error) {\n\tret := m.ctrl.Call(m, \"ReadMessage\")\n\tret0, _ := ret[0].(int)\n\tret1, _ := ret[1].([]byte)\n\tret2, _ := ret[2].(error)\n\treturn ret0, ret1, ret2\n}", "reference": "// ReadMessage mocks base method", "generated": "// ReadMessage reads message from websocket connection.\n//\n// Returns int: number of bytes read; byte slice: received data; error: if any I/O errors occurred while reading.\n// If no more messages can be read then returns 0 for both first two values. The third value will always return nil unless there was"}
{"id": 1890, "code": "func (engine *DockerTaskEngine) isTaskManaged(arn string) bool {\n\tengine.tasksLock.RLock()\n\tdefer engine.tasksLock.RUnlock()\n\t_, ok := engine.managedTasks[arn]\n\treturn ok\n}", "reference": "// isTaskManaged checks if task for the corresponding arn is present", "generated": "// IsTaskManaged returns true if task arn was managed by Docker Task Engine.\n// If false then it's either unmanaged or created manually in another way.\n// This method should be used only for checking purposes to avoid unnecessary lock acquisition,\n// because this check can lead to performance issues due to large number of concurrent"}
{"id": 1896, "code": "func (engine *DockerTaskEngine) sweepTask(task *apitask.Task) {\n\tfor _, cont := range task.Containers {\n\t\terr := engine.removeContainer(task, cont)\n\t\tif err != nil {\n\t\t\tseelog.Debugf(\"Task engine [%s]: unable to remove old container [%s]: %v\",\n\t\t\t\ttask.Arn, cont.Name, err)\n\t\t}\n\t\t// Internal container(created by ecs-agent) state isn't recorded\n\t\tif cont.IsInternal() {\n\t\t\tcontinue\n\t\t}\n\t\terr = engine.imageManager.RemoveContainerReferenceFromImageState(cont)\n\t\tif err != nil {\n\t\t\tseelog.Errorf(\"Task engine [%s]: Unable to remove container [%s] reference from image state: %v\",\n\t\t\t\ttask.Arn, cont.Name, err)\n\t\t}\n\t}\n\n\t// Clean metadata directory for task\n\tif engine.cfg.ContainerMetadataEnabled {\n\t\terr := engine.metadataManager.Clean(task.Arn)\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Task engine [%s]: clean task metadata failed: %v\", task.Arn, err)\n\t\t}\n\t}\n\tengine.saver.Save()\n}", "reference": "// sweepTask deletes all the containers associated with a task", "generated": "Sweep all containers associated with this task that no longer exist in Docker.\nThis includes removing any references to these containers within ECS agent's internal data structures,\nand cleaning up their corresponding metadata directories if enabled. The task is then saved after sweeping its containers."}
{"id": 1906, "code": "func (engine *DockerTaskEngine) updateTaskUnsafe(task *apitask.Task, update *apitask.Task) {\n\tmanagedTask, ok := engine.managedTasks[task.Arn]\n\tif !ok {\n\t\tseelog.Criticalf(\"Task engine [%s]: ACS message for a task we thought we managed, but don't!  Aborting.\",\n\t\t\ttask.Arn)\n\t\treturn\n\t}\n\t// Keep the lock because sequence numbers cannot be correct unless they are\n\t// also read in the order addtask was called\n\t// This does block the engine's ability to ingest any new events (including\n\t// stops for past tasks, ack!), but this is necessary for correctness\n\tupdateDesiredStatus := update.GetDesiredStatus()\n\tseelog.Debugf(\"Task engine [%s]: putting update on the acs channel: [%s] with seqnum [%d]\",\n\t\ttask.Arn, updateDesiredStatus.String(), update.StopSequenceNumber)\n\tmanagedTask.emitACSTransition(acsTransition{\n\t\tdesiredStatus: updateDesiredStatus,\n\t\tseqnum:        update.StopSequenceNumber,\n\t})\n\tseelog.Debugf(\"Task engine [%s]: update taken off the acs channel: [%s] with seqnum [%d]\",\n\t\ttask.Arn, updateDesiredStatus.String(), update.StopSequenceNumber)\n}", "reference": "// updateTaskUnsafe determines if a new transition needs to be applied to the\n// referenced task, and if needed applies it. It should not be called anywhere\n// but from 'AddTask' and is protected by the tasksLock lock there.", "generated": "Update a Docker task by sending it back through the ACSCore.\nThis will cause the task to transition from its current status to the desired one specified in the update.\nThe stop sequence number must match that which would have been returned if the task had been stopped at the time the update was received.\nIf no matching stop"}
{"id": 1918, "code": "func (m *MockFileSystem) Copy(arg0 io.Writer, arg1 io.Reader) (int64, error) {\n\tret := m.ctrl.Call(m, \"Copy\", arg0, arg1)\n\tret0, _ := ret[0].(int64)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// Copy mocks base method", "generated": "// Copy copies data from one source to another.\n//\n// The destination is opened in append mode; if it's already open,\n// its file descriptor will be reused. If the source doesn't support seeking,\n// then this method returns an error immediately after opening the destination.\n//\n// This call can only succeed when both"}
{"id": 1919, "code": "func (m *MockFileSystem) Exit(arg0 int) {\n\tm.ctrl.Call(m, \"Exit\", arg0)\n}", "reference": "// Exit mocks base method", "generated": "// Exit exits the program immediately.\n//\n// The exit code is passed to the operating system's process manager\n// for reporting back to the user that this was successful or failed,\n// depending upon whether it returned 0 or non-zero. If no error occurs\n// during execution, then the return value will be zero"}
{"id": 1920, "code": "func (m *MockFileSystem) MkdirAll(arg0 string, arg1 os.FileMode) error {\n\tret := m.ctrl.Call(m, \"MkdirAll\", arg0, arg1)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// MkdirAll mocks base method", "generated": "// MkdirAll creates all parent directories if they do not exist.\n//\n// The mode is used to create the new directory. If it's 0o777 or higher,\n// then only the owner can read, write, and execute the file; otherwise,\n// the permissions are those of the umask at the"}
{"id": 1937, "code": "func (m *MockTaskEngineState) AllTasks() []*task.Task {\n\tret := m.ctrl.Call(m, \"AllTasks\")\n\tret0, _ := ret[0].([]*task.Task)\n\treturn ret0\n}", "reference": "// AllTasks mocks base method", "generated": "// AllTasks returns all tasks in this task engine state.\n// The returned slice is sorted by priority from highest to lowest.\n// If there's no task set for this task engine state, it will return nil.\n// This method can be used to get information about which tasks have been created,\n// but cannot be used"}
{"id": 1948, "code": "func (containerType ContainerType) String() string {\n\tfor str, contType := range stringToContainerType {\n\t\tif contType == containerType {\n\t\t\treturn str\n\t\t}\n\t}\n\n\treturn \"NORMAL\"\n}", "reference": "// String converts the container type enum to a string", "generated": "// Returns the type name for this container type in human-readable format.\n// If it's unknown or invalid, returns 'NORMAL'. This is used to display the result when printing out the container types. For example: `type Type = ContainerType; var t Type`. The returned value should be unique across all possible values"}
{"id": 1959, "code": "func (f *factory) GetClient(version dockerclient.DockerVersion) (sdkclient.Client, error) {\n\treturn f.getClient(version)\n}", "reference": "// GetClient on linux will simply return the cached client from the map", "generated": "// GetClient returns a client for the given Docker version.\n//\n// This method is used to get a new instance of Client that can be\n// configured by calling SetEndpoint() or SetConfig().\nfunc (c *Client) GetClient(version dockerclient.DockerVersion) (sdkclient.Client, error) {\n\treturn"}
{"id": 2002, "code": "func (engine *DockerStatsEngine) removeContainer(dockerID string) {\n\tengine.lock.Lock()\n\tdefer engine.lock.Unlock()\n\n\t// Make sure that this container belongs to a task.\n\ttask, err := engine.resolver.ResolveTask(dockerID)\n\tif err != nil {\n\t\tseelog.Debugf(\"Could not map container to task, ignoring, err: %v, id: %s\", err, dockerID)\n\t\treturn\n\t}\n\n\t_, taskExists := engine.tasksToContainers[task.Arn]\n\tif !taskExists {\n\t\tseelog.Debugf(\"Container not being watched, id: %s\", dockerID)\n\t\treturn\n\t}\n\n\t// task arn exists in map.\n\tcontainer, containerExists := engine.tasksToContainers[task.Arn][dockerID]\n\tif !containerExists {\n\t\t// container arn does not exist in map.\n\t\tseelog.Debugf(\"Container not being watched, id: %s\", dockerID)\n\t\treturn\n\t}\n\n\tengine.doRemoveContainerUnsafe(container, task.Arn)\n}", "reference": "// removeContainer deletes the container from the map of containers being watched.\n// It also stops the periodic usage data collection for the container.", "generated": "// Remove a Docker stats container from the list of containers for all tasks it is associated with.\n// This method will also delete any other information about the removed container if necessary,\n// such as its ID or name. It should be used when removing a single container at once rather than through\n// the API endpoint. The"}
{"id": 2004, "code": "func (engine *DockerStatsEngine) taskContainerMetricsUnsafe(taskArn string) ([]*ecstcs.ContainerMetric, error) {\n\tcontainerMap, taskExists := engine.tasksToContainers[taskArn]\n\tif !taskExists {\n\t\treturn nil, fmt.Errorf(\"Task not found\")\n\t}\n\n\tvar containerMetrics []*ecstcs.ContainerMetric\n\tfor _, container := range containerMap {\n\t\tdockerID := container.containerMetadata.DockerID\n\t\t// Check if the container is terminal. If it is, make sure that it is\n\t\t// cleaned up properly. We might sometimes miss events from docker task\n\t\t// engine and this helps in reconciling the state. The tcs client's\n\t\t// GetInstanceMetrics probe is used as the trigger for this.\n\t\tif engine.stopTrackingContainerUnsafe(container, taskArn) {\n\t\t\tcontinue\n\t\t}\n\n\t\tif !container.statsQueue.enoughDatapointsInBuffer() &&\n\t\t\t!container.statsQueue.resetThresholdElapsed(queueResetThreshold) {\n\t\t\tseelog.Debugf(\"Stats not ready for container %s\", dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Container is not terminal. Get CPU stats set.\n\t\tcpuStatsSet, err := container.statsQueue.GetCPUStatsSet()\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Error getting cpu stats, err: %v, container: %v\", err, dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Get memory stats set.\n\t\tmemoryStatsSet, err := container.statsQueue.GetMemoryStatsSet()\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Error getting memory stats, err: %v, container: %v\", err, dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\tcontainerMetrics = append(containerMetrics, &ecstcs.ContainerMetric{\n\t\t\tCpuStatsSet:    cpuStatsSet,\n\t\t\tMemoryStatsSet: memoryStatsSet,\n\t\t})\n\n\t}\n\n\treturn containerMetrics, nil\n}", "reference": "// taskContainerMetricsUnsafe gets all container metrics for a task arn.", "generated": "// TaskContainerMetrics returns metrics about all containers running within a given Docker task.\n//\n// This method will return empty list when there are no tasks or no containers to track.\n// It also skips any non-terminal containers which may be missing some data due to\n// the nature of how they're tracked by the TCS"}
{"id": 2025, "code": "func NewNamedError(err error) *DefaultNamedError {\n\tif namedErr, ok := err.(NamedError); ok {\n\t\treturn &DefaultNamedError{Err: namedErr.Error(), Name: namedErr.ErrorName()}\n\t}\n\treturn &DefaultNamedError{Err: err.Error()}\n}", "reference": "// NewNamedError creates a NamedError.", "generated": "// NewNamedError returns a new DefaultNamedError from given NamedError or\n// non-NamedError error.\n//\n// If provided error is already a NamedError it will be wrapped in a default\n// context to provide additional information about its name. Otherwise,\n// original error message will be used along with \"unknown"}
{"id": 2037, "code": "func (r *eventLogReceiver) ReceiveMessage(message string, level seelog.LogLevel, context seelog.LogContextInterface) error {\n\tswitch level {\n\tcase seelog.DebugLvl, seelog.InfoLvl:\n\t\treturn eventLog.Info(eventLogID, message)\n\tcase seelog.WarnLvl:\n\t\treturn eventLog.Warning(eventLogID, message)\n\tcase seelog.ErrorLvl, seelog.CriticalLvl:\n\t\treturn eventLog.Error(eventLogID, message)\n\t}\n\treturn nil\n}", "reference": "// ReceiveMessage receives a log line from seelog and emits it to the Windows event log", "generated": "// ReceiveMessage receives log messages from the receiver.\n//\n// The received logs will be processed by the corresponding handler functions based on their levels.\n// If no matching handler is found for a given log level, it's ignored silently.\n// This method should only be called once per receive operation to avoid processing multiple events in one"}
{"id": 2051, "code": "func (m *MockIOUtil) WriteFile(arg0 string, arg1 []byte, arg2 os.FileMode) error {\n\tret := m.ctrl.Call(m, \"WriteFile\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// WriteFile mocks base method", "generated": "// WriteFile writes data to file.\nfunc (m MockIOUtil) WriteFile(path string, content []byte, mode int32) error { return m.WriteFile(path, content, mode) }"}
{"id": 2052, "code": "func (mr *MockIOUtilMockRecorder) WriteFile(arg0, arg1, arg2 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"WriteFile\", reflect.TypeOf((*MockIOUtil)(nil).WriteFile), arg0, arg1, arg2)\n}", "reference": "// WriteFile indicates an expected call of WriteFile", "generated": "Writes data from writer to specified path in binary format.\n// Returns: nil if successful; non-nil error otherwise.\n// Example:\n// \t_, err := mock"}
{"id": 2060, "code": "func NewVolumesResponse(dockerContainer *apicontainer.DockerContainer) []VolumeResponse {\n\tcontainer := dockerContainer.Container\n\tvar resp []VolumeResponse\n\n\tvolumes := container.GetVolumes()\n\n\tfor _, volume := range volumes {\n\t\tvolResp := VolumeResponse{\n\t\t\tDockerName:  volume.Name,\n\t\t\tSource:      volume.Source,\n\t\t\tDestination: volume.Destination,\n\t\t}\n\n\t\tresp = append(resp, volResp)\n\t}\n\treturn resp\n}", "reference": "// NewVolumesResponse creates VolumeResponse for a container", "generated": "// NewVolumesResponse returns a list of Docker Volumes Response.\n//\n// The returned slice is populated from the provided Docker Container's volumes.\n// Each item in the resulting slice represents a single Docker Volume Response object.\n// See apiv1/volume.go for more information about this type. This method will return nil if"}
{"id": 2062, "code": "func NewPublishMetricsRequest(metadata *MetricsMetadata, taskMetrics []*TaskMetric) *PublishMetricsRequest {\n\treturn &PublishMetricsRequest{\n\t\tMetadata:    metadata,\n\t\tTaskMetrics: taskMetrics,\n\t\tTimestamp:   aws.Time(time.Now()),\n\t}\n}", "reference": "// NewPublishMetricsRequest creates a PublishMetricsRequest object.", "generated": "// NewPublishMetricsRequest creates a new PublishMetricsRequest.\n//\n// This is used to create a request for publishing metrics from AWS CloudWatch\n// to Prometheus. The provided MetricsMetadata contains information about the metric\n// being published (e.g., name, namespace). TaskMetrics provides additional context\n// such as CPU"}
{"id": 2092, "code": "func (m *MockCNI) AddNetworkList(arg0 *libcni.NetworkConfigList, arg1 *libcni.RuntimeConf) (types.Result, error) {\n\tret := m.ctrl.Call(m, \"AddNetworkList\", arg0, arg1)\n\tret0, _ := ret[0].(types.Result)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// AddNetworkList mocks base method", "generated": "// AddNetworkList adds network list to CNI configuration.\n// This method is used by cni-go library for adding new networks in the given runtime context.\n// The returned result indicates whether the operation was successful or not.\n// If there's any error during this process it will be stored inside the Result object which can"}
{"id": 2094, "code": "func (mr *MockCNIMockRecorder) DelNetwork(arg0, arg1 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"DelNetwork\", reflect.TypeOf((*MockCNI)(nil).DelNetwork), arg0, arg1)\n}", "reference": "// DelNetwork indicates an expected call of DelNetwork", "generated": "// DelNetwork is called when network is deleted.\n// Args: \n//   - id string\n//   - cniId string\n// Returns: \n//   - nil if no error occurred or gomock.Error() if mock was not prepared for this call. The returned MockCNI object will be used"}
{"id": 2114, "code": "func (v *StackSwitcher) native() *C.GtkStackSwitcher {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkStackSwitcher(p)\n}", "reference": "// native returns a pointer to the underlying GtkStackSwitcher.", "generated": "// Native returns the underlying native object for this StackSwitcher.\n// If there is no native object associated with this stack switcher,\n// it will return nil. This method should be used to access properties or methods that require direct interaction with the native widget.\n// Note: The returned value must be freed by the caller"}
{"id": 2116, "code": "func (v *ComboBoxText) native() *C.GtkComboBoxText {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkComboBoxText(p)\n}", "reference": "// native returns a pointer to the underlying GtkComboBoxText.", "generated": "// Native returns the underlying native widget for this combo box text.\n// This is used to access properties or methods specific to that type,\n// such as setting the model or getting the selected value.\n// If the object has been set but its parent hasn't yet been added to the tree,\n// it will return 0"}
{"id": 2124, "code": "func (v *Variant) GetString() string {\n\tvar len C.gsize\n\tgc := C.g_variant_get_string(v.native(), &len)\n\tdefer C.g_free(C.gpointer(gc))\n\treturn C.GoStringN((*C.char)(gc), (C.int)(len))\n}", "reference": "// GetString returns the string value of the variant.", "generated": "// Get returns the value of this variant as a string.\n//\n// The returned string is owned by Go; it will be automatically freed when it goes out of scope.\n// If the length parameter was non-zero, then the caller must free the memory allocated for the result using g_free().\nfunc (v Variant) String"}
{"id": 2143, "code": "func (v *StyleContext) native() *C.GtkStyleContext {\n\tif v == nil || v.Object == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkStyleContext(p)\n}", "reference": "// native returns a pointer to the underlying GtkStyleContext.", "generated": "// Native returns a pointer to the underlying style context object.\n// If this is set, it will be used instead of creating one from the given style context.\n// This should only be called by internal functions that need direct access to the style context,\n// such as when implementing custom styles or themes for widgets. It's"}
{"id": 2148, "code": "func (m *Matrix) InitRotate(radians float64) {\n\tC.cairo_matrix_init_rotate(m.native(), C.double(radians))\n}", "reference": "// InitRotate initializes a matrix with the given rotation", "generated": "// InitRotate sets up this matrix for rotation by radians.\n//\n// The result is stored in native().  This method should be called before\n// calling SetTransform() or other methods that modify the transform state,\n// since it will overwrite any previous transformation.  If you want to rotate\n// around some point rather"}
{"id": 2165, "code": "func NewSurface(s uintptr, needsRef bool) *Surface {\n\tsurface := WrapSurface(s)\n\tif needsRef {\n\t\tsurface.reference()\n\t}\n\truntime.SetFinalizer(surface, (*Surface).destroy)\n\treturn surface\n}", "reference": "// NewSurface creates a gotk3 cairo Surface from a pointer to a\n// C cairo_surface_t.  This is primarily designed for use with other\n// gotk3 packages and should be avoided by applications.", "generated": "// NewSurface creates a new Surface object from a given address.\n//\n// If needsRef is true, it also sets up finalization for this surface to ensure that its resources are released when no longer needed,\n// even if the caller forgets to call destroy() explicitly. This can be useful in situations where surfaces need"}
{"id": 2167, "code": "func AddFont(fontPath string) {\n\tpath := (*C.uchar)(unsafe.Pointer(C.CString(fontPath)))\n\tC.addFont(path)\n}", "reference": "// AddFont adds the font to the configuration.", "generated": "// AddFont adds font to current context.\n//\n// This method is used by Cgo interface for adding fonts from external libraries\n// (e.g., OpenType or TrueType). The path should be absolute file name in local\n// directory tree. If it's relative path, then it will be resolved against root"}
{"id": 2168, "code": "func (v *Label) native() *C.GtkLabel {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkLabel(p)\n}", "reference": "// native returns a pointer to the underlying GtkLabel.", "generated": "// Native returns the underlying native label object.\n//\n// This is used to access properties like text or font style directly from the native widget,\n// which can be more efficient than using the provided Label struct methods.\n//\n// Note that this method only works if the Label was created by calling NewLabel().\nfunc (l *"}
{"id": 2182, "code": "func (v *ActionGroup) ChangeActionState(actionName string, value *Variant) {\n\tC.g_action_group_change_action_state(v.native(), (*C.gchar)(C.CString(actionName)), value.native())\n}", "reference": "// ChangeActionState is a wrapper around g_action_group_change_action_state", "generated": "// ChangeActionState changes the state of action group.\n//\n// This is used to change the status of actions in ActionGroup.\n// The new variant will be set for all actions that have this name\n// or any other names if they match the pattern specified by the first argument.\n// If no variant was provided then"}
{"id": 2186, "code": "func (v *GLArea) native() *C.GtkGLArea {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkGLArea(p)\n}", "reference": "// native returns a pointer to the underlying GtkGLArea.", "generated": "// Native returns the underlying GL area object if it exists.\n// If no OpenGL context is set for this area, or if there's been a change in the\n// windowing system since we last checked, then this will return 0.\nfunc (v *GLArea) Native() *C.GLContext {\n\tif"}
{"id": 2188, "code": "func (v *TreeView) SetSearchEqualSubstringMatch() {\n\tC.gtk_tree_view_set_search_equal_func(\n\t\tv.native(),\n\t\t(C.GtkTreeViewSearchEqualFunc)(unsafe.Pointer(C.substring_match_equal_func)),\n\t\tnil,\n\t\tnil)\n}", "reference": "// SetSearchEqualSubstringMatch sets TreeView to search by substring match.", "generated": "// SetSearchEqualSubstringMatch sets up the search equal substring match for this tree view.\n// This is used to enable searching in the text columns where the user can enter\n// a string that will be matched against all items in those columns. The matching must\n// start at the beginning or end of each item's"}
{"id": 2202, "code": "func (v *ShortcutsShortcut) native() *C.GtkShortcutsShortcut {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkShortcutsShortcut(p)\n}", "reference": "// native returns a pointer to the underlying GtkShortcutsShortcut.", "generated": "// Native returns the underlying native shortcut object.\n//\n// This is used to access properties that aren't available in the Go version,\n// such as the \"action\" property which contains the action associated with this\n// shortcut key combination. The returned value must be freed by the caller when it's no longer needed using"}
{"id": 2203, "code": "func SimpleActionGroupNew() *SimpleActionGroup {\n\tc := C.g_simple_action_group_new()\n\tif c == nil {\n\t\treturn nil\n\t}\n\treturn wrapSimpleActionGroup(wrapObject(unsafe.Pointer(c)))\n}", "reference": "// SimpleActionGroupNew is a wrapper around g_simple_action_group_new", "generated": "// New returns a new simple action group.\n//\n// The returned object must be freed by calling Free when it is no longer needed to prevent memory leaks.\nfunc (a *SimpleActionGroup) New() *SimpleActionGroup {\n\treturn SimpleActionGroupNew()\n}"}
{"id": 2208, "code": "func (v *Action) GetParameterType() *VariantType {\n\tc := C.g_action_get_parameter_type(v.native())\n\tif c == nil {\n\t\treturn nil\n\t}\n\treturn newVariantType((*C.GVariantType)(c))\n}", "reference": "// GetParameterType is a wrapper around g_action_get_parameter_type", "generated": "// GetParameterType returns the type of parameter associated with this action.\n// The returned value is valid until the next call to SetParameters or Delete,\n// after which it will be invalid. If no parameters have been set for this action,\n// then ParameterTypes will return an empty slice. This method can only be called"}
{"id": 2218, "code": "func (v *Bin) native() *C.GtkBin {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkBin(p)\n}", "reference": "// native returns a pointer to the underlying GtkBin.", "generated": "// Native returns the underlying native object for this Bin.\n// If it is already set then return that value; otherwise create one using\n// toNative(). This method should be called only once in the lifetime of the\n// Bin.\nfunc (v *Bin) native() *C.GtkBin {... }"}
{"id": 2221, "code": "func (v *CellRendererSpinner) native() *C.GtkCellRendererSpinner {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkCellRendererSpinner(p)\n}", "reference": "// native returns a pointer to the underlying GtkCellRendererSpinner.", "generated": "// Native returns the underlying native object for this CellRendererSpinner.\n// This is used to access the cell renderer's properties directly in native code,\n// such as when using GTK+ functions that require it. The returned value must be\n// freed by the caller after use. If the spinner was created from a new"}
{"id": 2247, "code": "func (v *FileChooserDialog) native() *C.GtkFileChooserDialog {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkFileChooserDialog(p)\n}", "reference": "// native returns a pointer to the underlying GtkFileChooserDialog.", "generated": "// Native returns the underlying native file dialog object.\n// If this is set to zero, it will be created when necessary by calling New().\n//\n// Note: This method should only be called from within the context of a\n// Go goroutine that owns the FileChooserDialog instance. Calling this outside\n// of such"}
{"id": 2267, "code": "func (v *Paned) native() *C.GtkPaned {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkPaned(p)\n}", "reference": "// native returns a pointer to the underlying GtkPaned.", "generated": "// Native returns the underlying native widget for this Paned.\n// If there is no native widget associated with this object,\n// it will return nil. The returned value must be used in conjunction\n// with the Go type system to avoid potential crashes or data races.\n// This method should only be called from the main thread"}
{"id": 2303, "code": "func (v *TreePath) GetIndices() []int {\n\tvar depth C.gint\n\tvar goindices []int\n\tvar ginthelp C.gint\n\tindices := uintptr(unsafe.Pointer(C.gtk_tree_path_get_indices_with_depth(v.native(), &depth)))\n\tsize := unsafe.Sizeof(ginthelp)\n\tfor i := 0; i < int(depth); i++ {\n\t\tgoind := int(*((*C.gint)(unsafe.Pointer(indices))))\n\t\tgoindices = append(goindices, goind)\n\t\tindices += size\n\t}\n\treturn goindices\n}", "reference": "// GetIndices is a wrapper around gtk_tree_path_get_indices_with_depth", "generated": "// GetIndices returns all indices in this path.\n//\n// The returned slice is sorted by index value from lowest to highest.\n// Note that if there's no parent node for this tree path,\n// then it will return only one element - which represents itself.\n// If there's more than one child nodes for this tree"}
{"id": 2313, "code": "func (v *Window) native() *C.GtkWindow {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkWindow(p)\n}", "reference": "// native returns a pointer to the underlying GtkWindow.", "generated": "// Native returns the underlying native window object.\n//\n// This is used to access properties like title or icon name directly from the\n// native window API if needed. Note that this method only works for windows created by\n// NewWindow(). If you create a new Window using other methods it will return nil.\nfunc ("}
{"id": 2348, "code": "func hideConsoleWindowOnWindows() {\n\tpid, err := getCurrentProcessId()\n\tif err != nil {\n\t\t// Ignore errors because:\n\t\t// 1. It is not critical if the console can't be hid.\n\t\t// 2. There is nothing to do when errors happen.\n\t\treturn\n\t}\n\tw, err := getConsoleWindow()\n\tif err != nil {\n\t\t// Ignore errors\n\t\treturn\n\t}\n\t// Get the process ID of the console's creator.\n\tcpid, err := getWindowThreadProcessId(w)\n\tif err != nil {\n\t\t// Ignore errors\n\t\treturn\n\t}\n\tif pid == cpid {\n\t\t// The current process created its own console. Hide this.\n\t\tshowWindowAsync(w, windows.SW_HIDE)\n\t}\n}", "reference": "// hideConsoleWindowOnWindows will hide the console window that is showing when\n// compiling on Windows without specifying the '-ldflags \"-Hwindowsgui\"' flag.", "generated": "// This function hides the Windows console window for the given application,\n// which should run in full-screen mode without any visible UI elements or\n// other distractions that might interfere with user interaction. If it fails,\n// ignore the error (e.g., due to lack of permissions). In case of failure,\n// continue running"}
{"id": 2349, "code": "func DepthMask(flag bool) {\n\tC.glowDepthMask(gpDepthMask, (C.GLboolean)(boolToInt(flag)))\n}", "reference": "// enable or disable writing into the depth buffer", "generated": "// DepthMask sets whether to use depth mask for glow rendering.\n//\n// If true, only pixels that have non-zero alpha values will be rendered,\n// otherwise all pixels in the current color buffer will be used regardless\n// of their alpha value. This is useful when drawing transparent objects or\n// using texture mapping where"}
{"id": 2354, "code": "func scaleUpdater() {\n\tfor {\n\t\ts := getscale(0, 0)\n\t\tatomic.StoreUint64(&cachedScale, math.Float64bits(s))\n\t\ttime.Sleep(cacheUpdateWait)\n\t}\n}", "reference": "// run as goroutine. Will keep the desktop scale up to date.\n// This can be removed once the scale change event is implemented in GLFW 3.3", "generated": "// Continuously updates cached scaling factor based on current system load.\n//\n// This goroutine runs in background to periodically update cached\n// scaling factors for all processes running under this manager's control.\n// It uses atomic operations to ensure thread safety when updating cache,\n// which is necessary because multiple workers may be concurrently accessing"}
{"id": 2359, "code": "func (b *Board) Draw(boardImage *ebiten.Image) {\n\tboardImage.Fill(frameColor)\n\tfor j := 0; j < b.size; j++ {\n\t\tfor i := 0; i < b.size; i++ {\n\t\t\tv := 0\n\t\t\top := &ebiten.DrawImageOptions{}\n\t\t\tx := i*tileSize + (i+1)*tileMargin\n\t\t\ty := j*tileSize + (j+1)*tileMargin\n\t\t\top.GeoM.Translate(float64(x), float64(y))\n\t\t\tr, g, b, a := colorToScale(tileBackgroundColor(v))\n\t\t\top.ColorM.Scale(r, g, b, a)\n\t\t\tboardImage.DrawImage(tileImage, op)\n\t\t}\n\t}\n\tanimatingTiles := map[*Tile]struct{}{}\n\tnonAnimatingTiles := map[*Tile]struct{}{}\n\tfor t := range b.tiles {\n\t\tif t.IsMoving() {\n\t\t\tanimatingTiles[t] = struct{}{}\n\t\t} else {\n\t\t\tnonAnimatingTiles[t] = struct{}{}\n\t\t}\n\t}\n\tfor t := range nonAnimatingTiles {\n\t\tt.Draw(boardImage)\n\t}\n\tfor t := range animatingTiles {\n\t\tt.Draw(boardImage)\n\t}\n}", "reference": "// Draw draws the board to the given boardImage.", "generated": "// Draw draws the board image onto the given ebiten Image.\n//\n// The drawing process is done in two passes: one for tiles that don't move,\n// and another for those that do. This allows us to draw all tiles at once without\n// having to redraw them every frame if they're still moving"}
{"id": 2441, "code": "func (i *Image) makeStale() {\n\ti.basePixels = nil\n\ti.drawTrianglesHistory = nil\n\ti.stale = true\n\n\t// Don't have to call makeStale recursively here.\n\t// Restoring is done after topological sorting is done.\n\t// If an image depends on another stale image, this means that\n\t// the former image can be restored from the latest state of the latter image.\n}", "reference": "// makeStale makes the image stale.", "generated": "// Make this image stale by setting its base pixels and draw triangles history back to their initial values,\n// making it ready for restoration based on other images' states. This should only happen when all dependencies\n// between images are resolved in order. The given image will become \"stale\" until it's properly restored or"}
{"id": 2498, "code": "func (u *UserInterface) setScreenSize(width, height int, scale float64, fullscreen bool, vsync bool) bool {\n\tif u.width == width && u.height == height && u.scale == scale && u.isFullscreen() == fullscreen && u.vsync == vsync {\n\t\treturn false\n\t}\n\tu.forceSetScreenSize(width, height, scale, fullscreen, vsync)\n\treturn true\n}", "reference": "// setScreenSize must be called from the main thread.", "generated": "// SetScreenSize sets the screen size for this UI.\n//\n// If the new dimensions match those currently in use, no change is made to the state,\n// but if they do differ then forceSetScreenSize will be called which may cause any necessary\n// updates or changes to occur before returning from here."}
{"id": 2504, "code": "func (q *commandQueue) Flush() {\n\tif q.err != nil {\n\t\treturn\n\t}\n\n\tes := q.indices\n\tvs := q.vertices\n\tif recordLog() {\n\t\tfmt.Println(\"--\")\n\t}\n\n\ttheGraphicsDriver.Begin()\n\tfor len(q.commands) > 0 {\n\t\tnv := 0\n\t\tne := 0\n\t\tnc := 0\n\t\tfor _, c := range q.commands {\n\t\t\tif c.NumIndices() > graphics.IndicesNum {\n\t\t\t\tpanic(fmt.Sprintf(\"graphicscommand: c.NumIndices() must be <= graphics.IndicesNum but not at Flush: c.NumIndices(): %d, graphics.IndicesNum: %d\", c.NumIndices(), graphics.IndicesNum))\n\t\t\t}\n\t\t\tif ne+c.NumIndices() > graphics.IndicesNum {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tnv += c.NumVertices()\n\t\t\tne += c.NumIndices()\n\t\t\tnc++\n\t\t}\n\t\tif 0 < ne {\n\t\t\ttheGraphicsDriver.SetVertices(vs[:nv], es[:ne])\n\t\t\tes = es[ne:]\n\t\t\tvs = vs[nv:]\n\t\t}\n\t\tindexOffset := 0\n\t\tfor _, c := range q.commands[:nc] {\n\t\t\tif err := c.Exec(indexOffset); err != nil {\n\t\t\t\tq.err = err\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif recordLog() {\n\t\t\t\tfmt.Printf(\"%s\\n\", c)\n\t\t\t}\n\t\t\t// TODO: indexOffset should be reset if the command type is different\n\t\t\t// from the previous one. This fix is needed when another drawing command is\n\t\t\t// introduced than drawTrianglesCommand.\n\t\t\tindexOffset += c.NumIndices()\n\t\t}\n\t\tif 0 < nc {\n\t\t\t// Call glFlush to prevent black flicking (especially on Android (#226) and iOS).\n\t\t\ttheGraphicsDriver.Flush()\n\t\t}\n\t\tq.commands = q.commands[nc:]\n\t}\n\ttheGraphicsDriver.End()\n\tq.commands = nil\n\tq.nvertices = 0\n\tq.nindices = 0\n\tq.tmpNumIndices = 0\n\tq.nextIndex = 0\n}", "reference": "// Flush flushes the command queue.", "generated": "// Flush executes all commands in this queue until it's empty or there are no more indices left for rendering.\n// It also resets the nextIndex field so that new commands can start executing immediately after flushing,\n// which prevents black flickering due to concurrent execution of multiple commands. The flush operation may block\n// indefinitely if"}
{"id": 2534, "code": "func flattenClusterHostGroup(d *schema.ResourceData, obj *types.ClusterHostGroup) error {\n\tvar hostIDs []string\n\tfor _, v := range obj.Host {\n\t\thostIDs = append(hostIDs, v.Value)\n\t}\n\n\treturn structure.SetBatch(d, map[string]interface{}{\n\t\t\"host_system_ids\": hostIDs,\n\t})\n}", "reference": "// flattenClusterHostGroup saves a ClusterHostGroup into the supplied ResourceData.", "generated": "// Flatten cluster_host_group into resource data.\n//\n// This is used to convert ClusterHostGroup from raw JSON into schema format for\n// serialization or deserialization purposes (e.g., when converting between\n// CloudFormation and Terraform formats).\nfunc (c *CloudProviderClient) flattenClusterHostGroup(data *Resource"}
{"id": 2535, "code": "func resourceVSphereComputeClusterHostGroupFlattenID(cluster *object.ClusterComputeResource, name string) (string, error) {\n\tclusterID := cluster.Reference().Value\n\treturn strings.Join([]string{clusterID, name}, \":\"), nil\n}", "reference": "// resourceVSphereComputeClusterHostGroupFlattenID makes an ID for the\n// vsphere_cluster_host_group resource.", "generated": "// FlattenID returns ID for host group in format \"compute_cluster_id:group_name\". If compute cluster is referenced by another object's reference,\n// it will return that other object's id instead.\nfunc resourceVSphereComputeClusterHostGroupFlattenID(cluster *object.ClusterComputeResource, name string) (string,"}
{"id": 2590, "code": "func MoveToFolder(client *govmomi.Client, vm *object.VirtualMachine, relative string) error {\n\tlog.Printf(\"[DEBUG] Moving virtual %q to VM path %q\", vm.InventoryPath, relative)\n\tf, err := folder.VirtualMachineFolderFromObject(client, vm, relative)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn folder.MoveObjectTo(vm.Reference(), f)\n}", "reference": "// MoveToFolder moves a virtual machine to the specified folder.", "generated": "// Moves a virtual machine into another folder.\n//\n// The destination is specified by its name or ID in the format \"vm-<id>\" where <id>\n// is the unique identifier for that virtual machine (e.g., 12345678). If no\n// specific location is provided, it will be moved"}
{"id": 2611, "code": "func FromPath(client *govmomi.Client, name string, dc *object.Datacenter) (*object.VirtualApp, error) {\n\tfinder := find.NewFinder(client.Client, false)\n\n\tctx, cancel := context.WithTimeout(context.Background(), provider.DefaultAPITimeout)\n\tdefer cancel()\n\tif dc != nil {\n\t\tfinder.SetDatacenter(dc)\n\t}\n\treturn finder.VirtualApp(ctx, name)\n}", "reference": "// FromPath returns a VirtualApp via its supplied path.", "generated": "// NewFromPath returns a new VirtualApp from its path.\n//\n// The returned virtual app is created in the data center specified by\n// Datacenter or defaults to the default DC if no data center was provided.\n//\n// If the client's timeout has expired before finding the VM, it will be cancelled,\n//"}
{"id": 2643, "code": "func resourceVSphereComputeClusterApplyCreate(d *schema.ResourceData, meta interface{}) (*object.ClusterComputeResource, error) {\n\tlog.Printf(\"[DEBUG] %s: Processing compute cluster creation\", resourceVSphereComputeClusterIDString(d))\n\tclient, err := resourceVSphereComputeClusterClient(meta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdc, err := datacenterFromID(client, d.Get(\"datacenter_id\").(string))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot locate datacenter: %s\", err)\n\t}\n\n\t// Find the folder based off the path to the datacenter. This is where we\n\t// create the datastore cluster.\n\tf, err := folder.FromPath(client, d.Get(\"folder\").(string), folder.VSphereFolderTypeHost, dc)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot locate folder: %s\", err)\n\t}\n\n\t// Create the cluster. We use an empty config spec so that we can move the\n\t// necessary hosts into the cluster *before* we send the full configuration,\n\t// ensuring that any host-dependent configuration does not break.\n\tcluster, err := clustercomputeresource.Create(f, d.Get(\"name\").(string), types.ClusterConfigSpecEx{})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error creating cluster: %s\", err)\n\t}\n\n\t// Set the ID now before proceeding any further. Any other operation past\n\t// this point is recoverable.\n\td.SetId(cluster.Reference().Value)\n\n\treturn cluster, nil\n}", "reference": "// resourceVSphereComputeClusterApplyCreate processes the creation part of\n// resourceVSphereComputeClusterCreate.", "generated": "resourceVSphereComputeClusterApplyCreate creates or updates a VSphere Compute Cluster in vCenter Server. The name must be unique within each Data Center. If it already exists, its properties will be updated; otherwise, one will be created. Note that all resources (hosts, clusters, etc.) referenced by the new cluster"}
{"id": 2650, "code": "func resourceVSphereComputeClusterSaveDatacenter(\n\td *schema.ResourceData,\n\tmeta interface{},\n\tcluster *object.ClusterComputeResource,\n) error {\n\tlog.Printf(\"[DEBUG] %s: Saving datacenter\", resourceVSphereComputeClusterIDString(d))\n\tclient, err := resourceVSphereComputeClusterClient(meta)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tp, err := folder.RootPathParticleHost.SplitDatacenter(cluster.InventoryPath)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error parsing datacenter path from cluster: %s\", err)\n\t}\n\n\tdc, err := getDatacenter(client, p)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error fetching datacenter for cluster: %s\", err)\n\t}\n\n\treturn d.Set(\"datacenter_id\", dc.Reference().Value)\n}", "reference": "// resourceVSphereComputeClusterSaveDatacenter saves the datacenter that the\n// cluster is a member of for correctness on imports.", "generated": "// SaveDatacenter saves the current DataCenter object to VSphere Compute Resource.\n//\n// This method is used by the provider's NewFunction() when it needs to save the state of the\n// DataCenter object in order to be able to restore its state later if needed (e.g., during\n// recovery)."}
{"id": 2677, "code": "func expandClusterDrsConfigInfo(d *schema.ResourceData) *types.ClusterDrsConfigInfo {\n\tobj := &types.ClusterDrsConfigInfo{\n\t\tDefaultVmBehavior:         types.DrsBehavior(d.Get(\"drs_automation_level\").(string)),\n\t\tEnabled:                   structure.GetBool(d, \"drs_enabled\"),\n\t\tEnableVmBehaviorOverrides: structure.GetBool(d, \"drs_enable_vm_overrides\"),\n\t\tVmotionRate:               int32(d.Get(\"drs_migration_threshold\").(int)),\n\t\tOption:                    expandResourceVSphereComputeClusterDrsAdvancedOptions(d),\n\t}\n\n\treturn obj\n}", "reference": "// expandClusterDrsConfigInfo reads certain ResourceData keys and returns a\n// ClusterDrsConfigInfo.", "generated": "// Expand cluster DRS configuration information.\n//\n// This is used to create or update a ClusterDRSConfig resource in the API server.\n// The returned object can be passed directly into Create() or Update().\nfunc (c *Client) ExpandClusterDrsConfigInfo(data []byte) (*types.ClusterDrsConfig"}
{"id": 2689, "code": "func Rename(pod *object.StoragePod, name string) error {\n\tlog.Printf(\"[DEBUG] Renaming storage pod %q to %s\", pod.InventoryPath, name)\n\tctx, cancel := context.WithTimeout(context.Background(), provider.DefaultAPITimeout)\n\tdefer cancel()\n\ttask, err := pod.Rename(ctx, name)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn task.Wait(ctx)\n}", "reference": "// Rename renames a StoragePod.", "generated": "// Rename renames a StoragePod by its InventoryPath.\n//\n// This method is used when renaming a StoragePod in-place or moving it between pods.\n// It returns an object representing the result of this operation,\n// which can be checked for errors using Err() or IsDone().\n// If successful, the returned Task"}
{"id": 2727, "code": "func createHardDisk(client *govmomi.Client, size int, diskPath string, diskType string, adapterType string, dc string) error {\n\tvar vDiskType string\n\tswitch diskType {\n\tcase \"thin\":\n\t\tvDiskType = \"thin\"\n\tcase \"eagerZeroedThick\":\n\t\tvDiskType = \"eagerZeroedThick\"\n\tcase \"lazy\":\n\t\tvDiskType = \"preallocated\"\n\t}\n\n\tvirtualDiskManager := object.NewVirtualDiskManager(client.Client)\n\tspec := &types.FileBackedVirtualDiskSpec{\n\t\tVirtualDiskSpec: types.VirtualDiskSpec{\n\t\t\tAdapterType: adapterType,\n\t\t\tDiskType:    vDiskType,\n\t\t},\n\t\tCapacityKb: int64(1024 * 1024 * size),\n\t}\n\tdatacenter, err := getDatacenter(client, dc)\n\tif err != nil {\n\t\treturn err\n\t}\n\tlog.Printf(\"[DEBUG] Disk spec: %v\", spec)\n\n\ttask, err := virtualDiskManager.CreateVirtualDisk(context.TODO(), diskPath, datacenter, spec)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = task.WaitForResult(context.TODO(), nil)\n\tif err != nil {\n\t\tlog.Printf(\"[INFO] Failed to create disk:  %v\", err)\n\t\treturn err\n\t}\n\tlog.Printf(\"[INFO] Created disk.\")\n\n\treturn nil\n}", "reference": "// createHardDisk creates a new Hard Disk.", "generated": "// Create a new hard disk in the specified VM.\n//\n// Args:\n//   client - The vmware.v1.client.VMClient instance used for creating disks.\n//   size - Size of the disk (in MB).\n//   diskPath - Path where the disk will be created.\n//   diskType -"}
{"id": 2729, "code": "func (p *nasDatastoreMountProcessor) processMountOperations() (*object.Datastore, error) {\n\thosts := p.diffNewOld()\n\tif len(hosts) < 1 {\n\t\t// Nothing to do\n\t\treturn p.ds, nil\n\t}\n\t// Validate we are vCenter if we are working with multiple hosts\n\tif len(hosts) > 1 {\n\t\tif err := viapi.ValidateVirtualCenter(p.client); err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"cannot mount on multiple hosts: %s\", err)\n\t\t}\n\t}\n\tfor _, hsID := range hosts {\n\t\tdss, err := hostDatastoreSystemFromHostSystemID(p.client, hsID)\n\t\tif err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\t\tdefer cancel()\n\t\tds, err := dss.CreateNasDatastore(ctx, *p.volSpec)\n\t\tif err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t\tif err := p.validateDatastore(ds); err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"datastore validation error on host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t}\n\treturn p.ds, nil\n}", "reference": "// processMountOperations processes all pending mount operations by diffing old\n// and new and adding any hosts that were not found in old. The datastore is\n// returned, along with any error.", "generated": "Process all Mount operations for this DataStore instance.\nThis includes creating new datastores from each Host system that is different between old and new versions,\nand validating those created datastores against our volume specification. If any errors occur during creation or validation,\nthey will be propagated up through the call stack. The final result is returned"}
{"id": 2733, "code": "func tagByName(client *tags.RestClient, name, categoryID string) (string, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\ttags, err := client.GetTagByNameForCategory(ctx, name, categoryID)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"could not get tag for name %q: %s\", name, err)\n\t}\n\n\tif len(tags) < 1 {\n\t\treturn \"\", fmt.Errorf(\"tag name %q not found in category ID %q\", name, categoryID)\n\t}\n\tif len(tags) > 1 {\n\t\t// This situation is very similar to the one in tagCategoryByName. The API\n\t\t// docs even say that tags need to be unique in categories, yet\n\t\t// GetTagByNameForCategory still returns multiple results.\n\t\treturn \"\", fmt.Errorf(vSphereTagSearchErrMultiple, name)\n\t}\n\n\treturn tags[0].ID, nil\n}", "reference": "// tagByName locates a tag by it supplied name and category ID. Use\n// tagCategoryByName to get the tag category ID if require the category ID as\n// well.", "generated": "// TagName retrieves information about a specific tag by its name within a given category.\n//\n// Args:\n//   - ctx: Context object used when calling this method.\n//     A context object can provide additional data such as timeouts or cancellation signals,\n//     which will be passed through to any calls made using it."}
{"id": 2752, "code": "func expandVMwareDVSConfigSpec(d *schema.ResourceData) *types.VMwareDVSConfigSpec {\n\tobj := &types.VMwareDVSConfigSpec{\n\t\tDVSConfigSpec: types.DVSConfigSpec{\n\t\t\tName:                                d.Get(\"name\").(string),\n\t\t\tConfigVersion:                       d.Get(\"config_version\").(string),\n\t\t\tDefaultPortConfig:                   expandVMwareDVSPortSetting(d),\n\t\t\tHost:                                expandSliceOfDistributedVirtualSwitchHostMemberConfigSpec(d),\n\t\t\tDescription:                         d.Get(\"description\").(string),\n\t\t\tContact:                             expandDVSContactInfo(d),\n\t\t\tSwitchIpAddress:                     d.Get(\"ipv4_address\").(string),\n\t\t\tInfrastructureTrafficResourceConfig: expandSliceOfDvsHostInfrastructureTrafficResource(d),\n\t\t\tNetworkResourceControlVersion:       d.Get(\"network_resource_control_version\").(string),\n\t\t\tUplinkPortPolicy:                    expandDVSNameArrayUplinkPortPolicy(d),\n\t\t},\n\t\tMaxMtu:                      int32(d.Get(\"max_mtu\").(int)),\n\t\tLinkDiscoveryProtocolConfig: expandLinkDiscoveryProtocolConfig(d),\n\t\tIpfixConfig:                 expandVMwareIpfixConfig(d),\n\t\tLacpApiVersion:              d.Get(\"lacp_api_version\").(string),\n\t\tMulticastFilteringMode:      d.Get(\"multicast_filtering_mode\").(string),\n\t}\n\treturn obj\n}", "reference": "// expandVMwareDVSConfigSpec reads certain ResourceData keys and\n// returns a VMwareDVSConfigSpec.", "generated": "// Expand VMware DVS config spec.\n//\n// This is used to convert raw input into a struct that can be passed through the API.\n// The returned object will contain all fields from the original data except for those which were explicitly set to nil in the input.\n// If any field was missing or empty (i.e"}
{"id": 2765, "code": "func expandVirtualMachineResourceAllocation(d *schema.ResourceData, key string) *types.ResourceAllocationInfo {\n\tshareLevelKey := fmt.Sprintf(\"%s_share_level\", key)\n\tshareCountKey := fmt.Sprintf(\"%s_share_count\", key)\n\tlimitKey := fmt.Sprintf(\"%s_limit\", key)\n\treservationKey := fmt.Sprintf(\"%s_reservation\", key)\n\n\tobj := &types.ResourceAllocationInfo{\n\t\tLimit:       structure.GetInt64PtrEmptyZero(d, limitKey),\n\t\tReservation: structure.GetInt64PtrEmptyZero(d, reservationKey),\n\t}\n\tshares := &types.SharesInfo{\n\t\tLevel:  types.SharesLevel(d.Get(shareLevelKey).(string)),\n\t\tShares: int32(d.Get(shareCountKey).(int)),\n\t}\n\tobj.Shares = shares\n\treturn obj\n}", "reference": "// expandVirtualMachineResourceAllocation reads the VM resource allocation\n// resource data keys for the type supplied by key and returns an appropriate\n// types.ResourceAllocationInfo reference.", "generated": "// Expand virtual machine resource allocation information.\n//\n// This is used to convert raw data into a structured ResourceAllocationInfo object,\n// which can be passed directly to the cloud provider's API for creation or update.\n// The expanded info includes all fields from the original input map except those that\n// were explicitly set in d"}
{"id": 2781, "code": "func expandClusterDasVMConfigInfo(\n\td *schema.ResourceData,\n\tmeta interface{},\n\tvm *object.VirtualMachine,\n) (*types.ClusterDasVmConfigInfo, error) {\n\tclient, err := resourceVSphereHAVMOverrideClient(meta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tversion := viapi.ParseVersionFromClient(client)\n\n\tobj := &types.ClusterDasVmConfigInfo{\n\t\tDasSettings: expandClusterDasVMSettings(d, version),\n\t\tKey:         vm.Reference(),\n\t}\n\n\t// Expand ha_vm_monitoring_use_cluster_defaults here as it's not included in\n\t// the base vsphere_compute_cluster resource.\n\tobj.DasSettings.VmToolsMonitoringSettings.ClusterSettings = structure.GetBool(d, \"ha_vm_monitoring_use_cluster_defaults\")\n\n\treturn obj, nil\n}", "reference": "// expandClusterDasVMConfigInfo reads certain ResourceData keys and returns a\n// ClusterDasVmConfigInfo.", "generated": "Expand cluster das VM config info from given data. This includes Das settings which is expanded by calling expandClusterDasVMSettings() method. The key for this object will be set to reference of virtual machine. If ha_vm_monitoring_use_cluster_defaults is true then we need to include additional fields like vMotion monitoring enabled etc"}
{"id": 2819, "code": "func expandVmwareUplinkPortTeamingPolicy(d *schema.ResourceData) *types.VmwareUplinkPortTeamingPolicy {\n\tobj := &types.VmwareUplinkPortTeamingPolicy{\n\t\tPolicy:          structure.GetStringPolicy(d, \"teaming_policy\"),\n\t\tNotifySwitches:  structure.GetBoolPolicy(d, \"notify_switches\"),\n\t\tRollingOrder:    structure.GetBoolPolicyReverse(d, \"failback\"),\n\t\tFailureCriteria: expandDVSFailureCriteria(d),\n\t\tUplinkPortOrder: expandVMwareUplinkPortOrderPolicy(d),\n\t}\n\n\tif structure.AllFieldsEmpty(obj) {\n\t\treturn nil\n\t}\n\treturn obj\n}", "reference": "// expandVmwareUplinkPortTeamingPolicy reads certain ResourceData keys and\n// returns a VmwareUplinkPortTeamingPolicy.", "generated": "// Expand VMware Uplink Port Teaming Policy.\n//\n// This is used to create a new VmwareUplinkPortTeamingPolicy resource from raw data returned by the API server.\nfunc (p types.VmwareUplinkPortTeamingPolicy) ToRaw() map[string]interface{} {\n\tr"}
{"id": 2824, "code": "func flattenVMwareUplinkLacpPolicy(d *schema.ResourceData, obj *types.VMwareUplinkLacpPolicy) error {\n\tif obj == nil {\n\t\treturn nil\n\t}\n\n\tstructure.SetBoolPolicy(d, \"lacp_enabled\", obj.Enable)\n\tstructure.SetStringPolicy(d, \"lacp_mode\", obj.Mode)\n\treturn nil\n}", "reference": "// flattenVMwareUplinkLacpPolicy reads various fields from a\n// VMwareUplinkLacpPolicy into the passed in ResourceData.", "generated": "// Flatten VMware Uplink Lacp Policy into resource data.\n//\n// This is used to convert the object's state into a map that can be easily\n// marshaled into JSON or other formats for storage in the backend service,\n// such as the vSphere API. The returned value must be passed through\n//"}
{"id": 2841, "code": "func (r *CdromSubresource) ValidateDiff() error {\n\tlog.Printf(\"[DEBUG] %s: Beginning CDROM configuration validation\", r)\n\tdsID := r.Get(\"datastore_id\").(string)\n\tpath := r.Get(\"path\").(string)\n\tclientDevice := r.Get(\"client_device\").(bool)\n\tswitch {\n\tcase clientDevice && (dsID != \"\" || path != \"\"):\n\t\treturn fmt.Errorf(\"Cannot have both client_device parameter and ISO file parameters (datastore_id, path) set\")\n\tcase !clientDevice && (dsID == \"\" || path == \"\"):\n\t\treturn fmt.Errorf(\"Either client_device or datastore_id and path must be set\")\n\t}\n\tlog.Printf(\"[DEBUG] %s: Config validation complete\", r)\n\treturn nil\n}", "reference": "// ValidateDiff performs any complex validation of an individual\n// cdrom sub-resource that can't be done in schema alone.", "generated": "// Validates that this sub-resource is valid according to its configuration.\n//\n// This method checks for consistency in the provided data. It ensures that either\n// only one of \"client_device\" and at least one of \"datastore_id\" and \"path\"\n// can be true. If they all match then it returns"}
{"id": 2848, "code": "func verifyVAppCdromIso(d *schema.ResourceData, device *types.VirtualCdrom, l object.VirtualDeviceList, c *govmomi.Client) (bool, error) {\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: Checking if CDROM is using a vApp ISO\")\n\t// If the CDROM is using VirtualCdromIsoBackingInfo and matches the ISO\n\t// naming pattern, it has been used as a vApp CDROM, and we can move on to\n\t// checking if the parent VM supports ISO transport.\n\tif backing, ok := device.Backing.(*types.VirtualCdromIsoBackingInfo); ok {\n\t\tdp := &object.DatastorePath{}\n\t\tif ok := dp.FromString(backing.FileName); !ok {\n\t\t\t// If the ISO path can not be read, we can't tell if a vApp ISO is\n\t\t\t// connected.\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: Cannot read ISO path, cannot determine if CDROM is used for vApp\")\n\t\t\treturn false, nil\n\t\t}\n\t\t// The pattern used for vApp ISO naming is\n\t\t// \"<vmname>/_ovfenv-<vmname>.iso\"\n\t\tre := regexp.MustCompile(\".*/_ovfenv-.*.iso\")\n\t\tif !re.MatchString(dp.Path) {\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: ISO is name does not match vApp ISO naming pattern (<vmname>/_ovfenv-<vmname>.iso): %s\", dp.Path)\n\t\t\treturn false, nil\n\t\t}\n\t} else {\n\t\t// vApp CDROMs must be backed by an ISO.\n\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: CDROM is not backed by an ISO\")\n\t\treturn false, nil\n\t}\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: CDROM has a vApp ISO inserted\")\n\t// Set the vApp transport methods\n\ttm := d.Get(\"vapp_transport\").([]interface{})\n\tfor _, t := range tm {\n\t\tif t.(string) == \"iso\" {\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: vApp ISO transport is supported\")\n\t\t\treturn true, nil\n\t\t}\n\t}\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: vApp ISO transport is not required\")\n\treturn false, nil\n}", "reference": "// verifyVAppCdromIso takes VirtualCdrom and determines if it is needed for\n// vApp ISO transport. It does this by first checking if it has an ISO inserted\n// that matches the vApp ISO naming pattern. If it does, then the next step is\n// to see if vApp ISO transport is supported on the VM. If both of those\n// conditions are met, then the CDROM is considered in use for vApp transport.", "generated": "Verify that this virtual cdrom uses a VApp iso file. This will check whether the filename contains \"_ovfenv-\" followed by the vm's name in lowercase letters separated from the extension by a dot. It also checks whether the disk is being transported via ISO or another method. In case both conditions are met,"}
{"id": 2853, "code": "func soapFault(err error) (*soap.Fault, bool) {\n\tif soap.IsSoapFault(err) {\n\t\treturn soap.ToSoapFault(err), true\n\t}\n\treturn nil, false\n}", "reference": "// soapFault extracts the SOAP fault from an error fault, if it exists. Check\n// the returned boolean value to see if you have a SoapFault.", "generated": "// soapFault returns a SoapFault if err is a SOAP fault or nil otherwise.\n// If it's a non-SOAP fault, return nil without any value.\nfunc (s *Server) soapFault(err error) (*soap.Fault, bool) { return soapFault(err) }  // nolint(g"}
{"id": 2860, "code": "func isConcurrentAccessError(err error) bool {\n\t// ConcurrentAccess comes from a task more than it usually does from a direct\n\t// SOAP call, so we need to handle both here.\n\tvar f types.AnyType\n\tvar ok bool\n\tf, ok = vimSoapFault(err)\n\tif !ok {\n\t\tf, ok = taskFault(err)\n\t}\n\tif ok {\n\t\tswitch f.(type) {\n\t\tcase types.ConcurrentAccess, *types.ConcurrentAccess:\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "reference": "// isConcurrentAccessError checks an error to see if it's of the\n// ConcurrentAccess type.", "generated": "// isConcurrentAccessError checks if given error indicates concurrent access issue or not. It returns true for errors that indicate concurrent access issues (like ConcurrencyLimitExceeded), but will return false in case of other faults like TaskNotRunning etc., which can be caused by concurrent access too. This check should only be"}
{"id": 2882, "code": "func validateCloneSnapshots(props *mo.VirtualMachine) error {\n\tif props.Snapshot == nil {\n\t\treturn fmt.Errorf(\"virtual machine or template %s must have a snapshot to be used as a linked clone\", props.Config.Uuid)\n\t}\n\t// Root snapshot list can only have a singular element\n\tif len(props.Snapshot.RootSnapshotList) != 1 {\n\t\treturn fmt.Errorf(\"virtual machine or template %s must have exactly one root snapshot (has: %d)\", props.Config.Uuid, len(props.Snapshot.RootSnapshotList))\n\t}\n\t// Check to make sure the root snapshot has no children\n\tif len(props.Snapshot.RootSnapshotList[0].ChildSnapshotList) > 0 {\n\t\treturn fmt.Errorf(\"virtual machine or template %s's root snapshot must not have children\", props.Config.Uuid)\n\t}\n\t// Current snapshot must match root snapshot (this should be the case anyway)\n\tif props.Snapshot.CurrentSnapshot.Value != props.Snapshot.RootSnapshotList[0].Snapshot.Value {\n\t\treturn fmt.Errorf(\"virtual machine or template %s's current snapshot must match root snapshot\", props.Config.Uuid)\n\t}\n\treturn nil\n}", "reference": "// validateCloneSnapshots checks a VM to make sure it has a single snapshot\n// with no children, to make sure there is no ambiguity when selecting a\n// snapshot for linked clones.", "generated": "// Validate that all required fields for cloning a virtual machine exist.\n//\n// This includes checking if there is at least one root snapshot in the VM,\n// which cannot contain any child snapshots. The current snapshot value also\n// needs to equal the root snapshot value. If these conditions aren't met,\n// this method returns"}
{"id": 2893, "code": "func dvsProperties(dvs *object.VmwareDistributedVirtualSwitch) (*mo.VmwareDistributedVirtualSwitch, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\tvar props mo.VmwareDistributedVirtualSwitch\n\tif err := dvs.Properties(ctx, dvs.Reference(), nil, &props); err != nil {\n\t\treturn nil, err\n\t}\n\treturn &props, nil\n}", "reference": "// dvsProperties is a convenience method that wraps fetching the DVS MO from\n// its higher-level object.", "generated": "// DVSProperties returns the properties for this distributed virtual switch.\nfunc (dvs *VmwareDistributedVirtualSwitch) Properties(ctx context.Context, reference string, parentReference *string, result *vmware.DVSPropertiesResult) error { return vmware.NewAPI().VMwareDVsProperties(ctx, d"}
{"id": 2907, "code": "func (r *Subresource) Hash() int {\n\thf := schema.HashResource(&schema.Resource{Schema: r.schema})\n\treturn hf(r.data)\n}", "reference": "// Hash calculates a set hash for the current data. If you want a hash for\n// error reporting a device address, it's probably a good idea to run this at\n// the beginning of a run as any set calls will change the value this\n// ultimately calculates.", "generated": "// Hash returns a hash value for this resource's data.\n//\n// This is used to quickly determine if two resources have different\n// underlying values without having to compare them directly.\nfunc (r Subresource) Hash() int { return r.hash }"}
{"id": 2919, "code": "func createSCSIController(l *object.VirtualDeviceList, ct string, st string) ([]types.BaseVirtualDeviceConfigSpec, error) {\n\tnc, err := l.CreateSCSIController(ct)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnc.(types.BaseVirtualSCSIController).GetVirtualSCSIController().SharedBus = types.VirtualSCSISharing(st)\n\tcspec, err := object.VirtualDeviceList{nc}.ConfigSpec(types.VirtualDeviceConfigSpecOperationAdd)\n\t*l = applyDeviceChange(*l, cspec)\n\treturn cspec, err\n}", "reference": "// createSCSIController creates a new SCSI controller of the specified type and\n// sharing mode.", "generated": "// CreateSCSIController creates a new virtual SCSI controller.\n//\n// The created device is configured to use the specified shared bus type (st).\n// If no shared bus configuration was provided in the input parameters,\n// it will be automatically set based on the default value for this host machine.\n//\n// This operation returns the"}
{"id": 2933, "code": "func resourceVSphereComputeClusterVMDependencyRuleFetchObjects(\n\tmeta interface{},\n\tclusterID string,\n\tkey int32,\n) (*object.ClusterComputeResource, int32, error) {\n\tclient, err := resourceVSphereComputeClusterVMDependencyRuleClient(meta)\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\n\tcluster, err := clustercomputeresource.FromID(client, clusterID)\n\tif err != nil {\n\t\treturn nil, 0, fmt.Errorf(\"cannot locate cluster: %s\", err)\n\t}\n\n\treturn cluster, key, nil\n}", "reference": "// resourceVSphereComputeClusterVMDependencyRuleFetchObjects fetches the \"objects\"\n// for a cluster rule. This is currently just the cluster object as the rule\n// key a static value and a pass-through - this is to keep its workflow\n// consistent with other cluster-dependent resources that derive from\n// ArrayUpdateSpec that have managed object as keys, such as VM and host\n// overrides.", "generated": "// FetchObjects returns the object for which this rule is defined.\n// If no such object exists in the current cluster's VM dependencies list,\n// it will return nil along with its index (which should be -1).\n// The returned value can then be used to fetch additional information about that object from the server if needed"}
{"id": 2938, "code": "func resourceVSphereDatastoreClusterReadCustomAttributes(d *schema.ResourceData, meta interface{}, pod *object.StoragePod) error {\n\tclient := meta.(*VSphereClient).vimClient\n\t// Read custom attributes\n\tif customattribute.IsSupported(client) {\n\t\tlog.Printf(\"[DEBUG] %s: Reading custom attributes\", resourceVSphereDatastoreClusterIDString(d))\n\t\tprops, err := storagepod.Properties(pod)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcustomattribute.ReadFromResource(client, props.Entity(), d)\n\t} else {\n\t\tlog.Printf(\"[DEBUG] %s: Custom attributes unsupported on this connection, skipping\", resourceVSphereDatastoreClusterIDString(d))\n\t}\n\n\treturn nil\n}", "reference": "// resourceVSphereDatastoreClusterReadCustomAttributes reads the custom\n// attributes for vsphere_datastore_cluster.", "generated": "// ResourceVSphereDatastoreClusterReadCustomAttributes reads any additional data from the VSphere DataStore cluster.\n//\n// This is used to support arbitrary key-value pairs that may be stored in the object's properties,\n// but which do not have their own specific handler functions (e.g., for things like \"created_at"}
{"id": 2958, "code": "func flattenStorageDrsOptionSpec(d *schema.ResourceData, opts []types.BaseOptionValue) error {\n\tm := make(map[string]interface{})\n\tfor _, opt := range opts {\n\t\tm[opt.GetOptionValue().Key] = opt.GetOptionValue().Value\n\t}\n\n\treturn d.Set(\"sdrs_advanced_options\", m)\n}", "reference": "// flattenStorageDrsOptionSpec saves a StorageDrsOptionSpec into the supplied\n// ResourceData.", "generated": "// FlattenStorageDRSOptionSpec returns a map representing the Storage DRS option spec.\nfunc (d *ResourceProviderType) FlattenStorageDRSOptionSpec(data interface{}) (map[string]interface{}, error) {\n\tvar dataMap map[string]interface{}\n\terr := schema.MapStruct(data, &dataMap)\n\n\tif err!="}
{"id": 2965, "code": "func diskApplyOperationDelete(\n\tindex int,\n\toldData map[string]interface{},\n\tnewDataSet []interface{},\n\tc *govmomi.Client,\n\td *schema.ResourceData,\n\tl *object.VirtualDeviceList,\n\tspec *[]types.BaseVirtualDeviceConfigSpec,\n) error {\n\tdidx := -1\n\tfor ni, ne := range newDataSet {\n\t\tnewData := ne.(map[string]interface{})\n\t\tvar name string\n\t\tvar err error\n\t\tif name, err = diskLabelOrName(newData); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif (name == diskDeletedName || name == diskDetachedName) && oldData[\"uuid\"] == newData[\"uuid\"] {\n\t\t\tdidx = ni\n\t\t\tbreak\n\t\t}\n\t}\n\tif didx < 0 {\n\t\t// Deleted entry not found\n\t\treturn nil\n\t}\n\tr := NewDiskSubresource(c, d, oldData, nil, index)\n\tdspec, err := r.Delete(*l)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"%s: %s\", r.Addr(), err)\n\t}\n\t*l = applyDeviceChange(*l, dspec)\n\t*spec = append(*spec, dspec...)\n\treturn nil\n}", "reference": "// diskApplyOperationDelete is an inner-loop helper for disk deletion\n// operations.", "generated": "diskApplyOperationDelete deletes a virtual device from the system.\nThe operation is only performed if there's no other matching configuration for this UUID in the list.\nIf such a match exists, it will be ignored to avoid deleting multiple devices at once. The deleted resource can't be restored or recreated using the same ID. If"}
{"id": 2974, "code": "func (r *DiskSubresource) Delete(l object.VirtualDeviceList) ([]types.BaseVirtualDeviceConfigSpec, error) {\n\tlog.Printf(\"[DEBUG] %s: Beginning delete\", r)\n\tdisk, err := r.findVirtualDisk(l, false)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot find disk device: %s\", err)\n\t}\n\tdeleteSpec, err := object.VirtualDeviceList{disk}.ConfigSpec(types.VirtualDeviceConfigSpecOperationRemove)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(deleteSpec) != 1 {\n\t\treturn nil, fmt.Errorf(\"incorrect number of config spec items returned - expected 1, got %d\", len(deleteSpec))\n\t}\n\tif r.Get(\"keep_on_remove\").(bool) || r.Get(\"attach\").(bool) {\n\t\t// Clear file operation so that the disk is kept on remove.\n\t\tdeleteSpec[0].GetVirtualDeviceConfigSpec().FileOperation = \"\"\n\t}\n\tlog.Printf(\"[DEBUG] %s: Device config operations from update: %s\", r, DeviceChangeString(deleteSpec))\n\tlog.Printf(\"[DEBUG] %s: Delete completed\", r)\n\treturn deleteSpec, nil\n}", "reference": "// Delete deletes a vsphere_virtual_machine disk sub-resource.", "generated": "Delete deletes virtual disks in this resource's list. The DiskResource will be deleted if it has no attachments or if its \"keep-on-remove\" property is set to true. If there are any attached devices, they must have their \"detach-on-delete\" properties set to true for them to be removed when deleting the parent"}
{"id": 2979, "code": "func (r *DiskSubresource) String() string {\n\tp := diskPathOrName(r.data)\n\tif p == \"\" {\n\t\tp = \"<unknown>\"\n\t}\n\treturn fmt.Sprintf(\"%s (%s)\", r.Subresource.String(), p)\n}", "reference": "// String prints out the disk sub-resource's information including the ID at\n// time of instantiation, the path of the disk, and the current device\n// key and address.", "generated": "// String returns a human-readable representation of this DiskSubresource.\n// The format is \"subresource <path>\" where path can be either a full\n// file system path or just a name if it's stored in a subdirectory within\n// the root directory. If no path exists for this resource, then '<"}
{"id": 2993, "code": "func hostNetworkSystemFromHostSystem(hs *object.HostSystem) (*object.HostNetworkSystem, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\treturn hs.ConfigManager().NetworkSystem(ctx)\n}", "reference": "// hostNetworkSystemFromHostSystem locates a HostNetworkSystem from a specified\n// HostSystem.", "generated": "// HostNetworkSystem returns the network system for this host.\n//\n// This is used to get information about the network configuration\n// (e.g., IP addresses). It's also where we can set up networking if it hasn't been done yet.\nfunc (h *hostObject) HostNetworkSystem() (*object.Host"}
{"id": 3011, "code": "func (b *EnvironmentBrowser) QueryConfigOptionDescriptor(ctx context.Context) ([]types.VirtualMachineConfigOptionDescriptor, error) {\n\treq := types.QueryConfigOptionDescriptor{\n\t\tThis: b.Reference(),\n\t}\n\tres, err := methods.QueryConfigOptionDescriptor(ctx, b.Client(), &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn res.Returnval, nil\n}", "reference": "// QueryConfigOptionDescriptor returns a list the list of ConfigOption keys\n// available on the environment that this browser targets. The keys can be used\n// as query options for DefaultDevices and other functions, facilitating the\n// specification of results specific to a certain VM version.", "generated": "// QueryConfigOptionDescriptor returns virtual machine configuration option descriptors.\n//\n// This method is used to get information about available options for configuring a VM in this environment browser.\n//\n// The returned list contains only those options that can be configured by this environment browser. If no such options exist,\n// it will return an empty list"}
{"id": 3033, "code": "func lookupAddrs(svc *compute.Service, project, zone, tag string) ([]string, error) {\n\tvar addrs []string\n\tf := func(page *compute.InstanceList) error {\n\t\tfor _, v := range page.Items {\n\t\t\tif len(v.NetworkInterfaces) == 0 || v.NetworkInterfaces[0].NetworkIP == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor _, t := range v.Tags.Items {\n\t\t\t\tif t == tag {\n\t\t\t\t\taddrs = append(addrs, v.NetworkInterfaces[0].NetworkIP)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tcall := svc.Instances.List(project, zone)\n\tif err := call.Pages(oauth2.NoContext, f); err != nil {\n\t\treturn nil, err\n\t}\n\treturn addrs, nil\n}", "reference": "// lookupAddrs retrieves the private ip addresses of all instances in a given\n// project and zone which have a matching tag value.", "generated": "// Lookup addresses for given service instance in specified project, zone and tags.\n//\n// This method is used to find IP address associated with specific service instance,\n// which can be useful when creating or updating firewall rules that require this\n// information (e.g., Google Cloud Firewall Rules). The search will only return one"}
{"id": 3055, "code": "func virtualMachinesForTag(ctx context.Context, client *vSphereClient, id string) ([]*object.VirtualMachine, error) {\n\tlogger.Printf(\"[DEBUG] Locating all virtual machines under tag ID %q\", id)\n\n\tvar vms []*object.VirtualMachine\n\n\tobjs, err := client.TagsClient.ListAttachedObjects(ctx, id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor i, obj := range objs {\n\t\tswitch {\n\t\tcase obj.Type == nil || obj.ID == nil:\n\t\t\tlogger.Printf(\"[WARN] Discovered object at index %d has either no ID or type\", i)\n\t\t\tcontinue\n\t\tcase *obj.Type != \"VirtualMachine\":\n\t\t\tlogger.Printf(\"[DEBUG] Discovered object ID %q is not a virutal machine\", *obj.ID)\n\t\t\tcontinue\n\t\t}\n\t\tvm, err := virtualMachineFromMOID(ctx, client.VimClient, *obj.ID)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error locating virtual machine with ID %q: %s\", *obj.ID, err)\n\t\t}\n\t\tvms = append(vms, vm)\n\t}\n\n\tlogger.Printf(\"[DEBUG] Discovered virtual machines: %s\", virtualMachineNames(vms))\n\treturn vms, nil\n}", "reference": "// virtualMachinesForTag discovers all of the virtual machines that match a\n// specific tag ID and returns their higher level helper objects.", "generated": "// Finds all virtual machines that have been tagged by the given ID.\n//\n// This method returns a list of VM objects for which this request was successful,\n// along with any errors encountered during execution. The returned slice will be empty if\n// there were no matching results found in the database. If an error occurred while"}
{"id": 3071, "code": "func (ctx *Context) RemoteAddr() string {\n\taddr := ctx.Req.Header.Get(\"X-Real-IP\")\n\tif len(addr) == 0 {\n\t\taddr = ctx.Req.Header.Get(\"X-Forwarded-For\")\n\t\tif addr == \"\" {\n\t\t\taddr = ctx.Req.RemoteAddr\n\t\t\tif i := strings.LastIndex(addr, \":\"); i > -1 {\n\t\t\t\taddr = addr[:i]\n\t\t\t}\n\t\t}\n\t}\n\treturn addr\n}", "reference": "// RemoteAddr returns more real IP address.", "generated": "// Returns the remote address from which this request was received.\n// If no X-Real-IP or X-Forwarded-For header is present,\n// it returns the IP address that sent the request to our server.\n// The returned value may be in the format \"ip:port\" if port information\n//"}
{"id": 3085, "code": "func (ctx *Context) GetCookie(name string) string {\n\tcookie, err := ctx.Req.Cookie(name)\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\tval, _ := url.QueryUnescape(cookie.Value)\n\treturn val\n}", "reference": "// GetCookie returns given cookie value from request header.", "generated": "// GetCookie returns the value of cookie by name.\n//\n// If no such cookie is found in request headers or cookies,\n// it will return empty string.\nfunc (c Context) GetCookie(name string) string { c.ctx.GetCookie(name); return \"\" }"}
{"id": 3090, "code": "func (ctx *Context) GetSecureCookie(key string) (string, bool) {\n\treturn ctx.GetSuperSecureCookie(defaultCookieSecret, key)\n}", "reference": "// GetSecureCookie returns given cookie value from request header with default secret string.", "generated": "// GetSecureCookie returns the value for the given secure cookie name.\n//\n// This method is similar to GetSuperSecureCookie but uses defaultCookieSecret\n// instead of superSecureCookieSecret if no secret was provided in the context.\nfunc (ctx *Context) GetSecureCookie(key string) (string, bool)"}
{"id": 3092, "code": "func (ctx *Context) GetSuperSecureCookie(secret, name string) (string, bool) {\n\tval := ctx.GetCookie(name)\n\tif val == \"\" {\n\t\treturn \"\", false\n\t}\n\n\ttext, err := hex.DecodeString(val)\n\tif err != nil {\n\t\treturn \"\", false\n\t}\n\n\tkey := pbkdf2.Key([]byte(secret), []byte(secret), 1000, 16, sha256.New)\n\ttext, err = com.AESGCMDecrypt(key, text)\n\treturn string(text), err == nil\n}", "reference": "// GetSuperSecureCookie returns given cookie value from request header with secret string.", "generated": "// GetSuperSecureCookie returns super secure cookie from context.\n//\n// The returned value is only valid for one request to this server.\n// If it's invalid or expired, return empty string.\nfunc (ctx *Context) GetSuperSecureCookie(secret, name string) (string, bool) {... }"}
{"id": 3127, "code": "func (app *App) ReloadConfig() error {\n\tapp.Lock()\n\tdefer app.Unlock()\n\n\tvar err error\n\tif err = app.configure(); err != nil {\n\t\treturn err\n\t}\n\n\truntime.GOMAXPROCS(app.Config.Common.MaxCPU)\n\n\tapp.Cache.SetMaxSize(app.Config.Cache.MaxSize)\n\tapp.Cache.SetWriteStrategy(app.Config.Cache.WriteStrategy)\n\tapp.Cache.SetTagsEnabled(app.Config.Tags.Enabled)\n\n\tif app.Persister != nil {\n\t\tapp.Persister.Stop()\n\t\tapp.Persister = nil\n\t}\n\n\tif app.Tags != nil {\n\t\tapp.Tags.Stop()\n\t\tapp.Tags = nil\n\t}\n\n\tapp.startPersister()\n\n\tif app.Collector != nil {\n\t\tapp.Collector.Stop()\n\t\tapp.Collector = nil\n\t}\n\n\tapp.Collector = NewCollector(app)\n\n\treturn nil\n}", "reference": "// ReloadConfig reloads some settings from config", "generated": "// ReloadConfig reloads all configuration settings for this application.\n//\n// This method is called when the user wants to change some setting in their config file,\n// or if they want to start up from scratch after having made changes manually.\n//\n// It stops any currently running collector, tags service, persister, cache writer"}
{"id": 3133, "code": "func (d *Duration) UnmarshalText(text []byte) error {\n\tvar err error\n\td.Duration, err = time.ParseDuration(string(text))\n\treturn err\n}", "reference": "// UnmarshalText from TOML", "generated": "// UnmarshalText parses duration from text format.\n//\n// The string is expected to be in one of the following formats: \"0\", \"+t\", \"-t\",\n// or any valid duration value like 1m2s3h4w5d6y7m8s9ms10us11ns"}
{"id": 3147, "code": "func (p *Points) Eq(other *Points) bool {\n\tif other == nil {\n\t\treturn false\n\t}\n\tif p.Metric != other.Metric {\n\t\treturn false\n\t}\n\tif p.Data == nil && other.Data == nil {\n\t\treturn true\n\t}\n\tif (p.Data == nil || other.Data == nil) && (p.Data != nil || other.Data != nil) {\n\t\treturn false\n\t}\n\tif len(p.Data) != len(other.Data) {\n\t\treturn false\n\t}\n\tfor i := 0; i < len(p.Data); i++ {\n\t\tif p.Data[i].Value != other.Data[i].Value {\n\t\t\treturn false\n\t\t}\n\t\tif p.Data[i].Timestamp != other.Data[i].Timestamp {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}", "reference": "// Eq points check", "generated": "// Eq checks if two Points objects have equal metric values.\n//\n// If both points do or don't contain data, they're considered equal.\n// However, if one point has data while the other doesn't,\n// it's only considered equal if their Data fields match exactly.\n// The timestamp for each value must also"}
{"id": 3152, "code": "func (app *App) Restore(storeFunc func(*points.Points), path string, rps int) {\n\tif rps > 0 {\n\t\tticker := persister.NewThrottleTicker(rps)\n\t\tdefer ticker.Stop()\n\n\t\tthrottledStoreFunc := func(p *points.Points) {\n\t\t\tfor i := 0; i < len(p.Data); i++ {\n\t\t\t\t<-ticker.C\n\t\t\t}\n\t\t\tstoreFunc(p)\n\t\t}\n\n\t\tapp.RestoreFromDir(path, throttledStoreFunc)\n\t} else {\n\t\tapp.RestoreFromDir(path, storeFunc)\n\t}\n}", "reference": "// Restore from dump.path", "generated": "// Restore restores points from disk to memory.\n//\n// If rate limiting is enabled, this will throttle writes by up to 'rps' per second,\n// allowing other goroutines to run without blocking. The throttling period is set\n// based on the number of items in each point's data slice. This ensures"}
{"id": 3183, "code": "func (client *Client) CreateComment(handle, message string) (*Comment, error) {\n\tvar out reqComment\n\tcomment := Comment{Message: String(message)}\n\tif len(handle) > 0 {\n\t\tcomment.Handle = String(handle)\n\t}\n\tif err := client.doJsonRequest(\"POST\", \"/v1/comments\", &comment, &out); err != nil {\n\t\treturn nil, err\n\t}\n\treturn out.Comment, nil\n}", "reference": "// CreateComment adds a new comment to the system.", "generated": "// Creates a new comment for a given handle or user ID.\n//\n// The created comment is returned in its entirety, including any additional metadata that was included in the request.\n// If no comments were found matching the provided handle, this will return nil instead of an empty struct. This can be used to check if a"}
{"id": 3185, "code": "func (client *Client) EditComment(id int, handle, message string) error {\n\tcomment := Comment{Message: String(message)}\n\tif len(handle) > 0 {\n\t\tcomment.Handle = String(handle)\n\t}\n\treturn client.doJsonRequest(\"PUT\", fmt.Sprintf(\"/v1/comments/%d\", id),\n\t\t&comment, nil)\n}", "reference": "// EditComment changes the message and possibly handle of a particular comment.", "generated": "// EditComment edits the given comment by setting its content to newHandle.\n//\n// If no Handle is provided then only the Message will be updated\n// if it has changed since last update. Otherwise nothing changes.\n// The returned error can indicate that the request was successful but\n// there were errors in parsing or sending"}
{"id": 3254, "code": "func (c *Check) GetTimestampOk() (string, bool) {\n\tif c == nil || c.Timestamp == nil {\n\t\treturn \"\", false\n\t}\n\treturn *c.Timestamp, true\n}", "reference": "// GetTimestampOk returns a tuple with the Timestamp field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetTimestampOk returns timestamp if it is set in Check object.\n// If check has no Timestamp field then return empty string and false value.\n// Otherwise return actual timestamp and true flag indicating that this was successful operation."}
{"id": 3256, "code": "func (c *Comment) GetRelatedId() int {\n\tif c == nil || c.RelatedId == nil {\n\t\treturn 0\n\t}\n\treturn *c.RelatedId\n}", "reference": "// GetRelatedId returns the RelatedId field if non-nil, zero value otherwise.", "generated": "// GetRelatedId returns related id if exists.\nfunc (c *Comment) GetRelatedId() int {... }"}
{"id": 3292, "code": "func (d *Downtime) GetRecurrence() Recurrence {\n\tif d == nil || d.Recurrence == nil {\n\t\treturn Recurrence{}\n\t}\n\treturn *d.Recurrence\n}", "reference": "// GetRecurrence returns the Recurrence field if non-nil, zero value otherwise.", "generated": "// GetRecurrence returns the recurrence rule for this downtime.\n// If no recurrence is set, it will return an empty Recurrence object."}
{"id": 3293, "code": "func (d *Downtime) GetRecurrenceOk() (Recurrence, bool) {\n\tif d == nil || d.Recurrence == nil {\n\t\treturn Recurrence{}, false\n\t}\n\treturn *d.Recurrence, true\n}", "reference": "// GetRecurrenceOk returns a tuple with the Recurrence field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetRecurrence returns recurrence information for this downtime.\n//\n// If no recurrence is set or if it's empty, return an empty Recurrence.\n// Otherwise, return the actual recurrence data.\nfunc (d *Downtime) GetRecurrenceOk() (Recurrence, bool) {... }"}
{"id": 3310, "code": "func (g *Graph) GetDefinition() GraphDefinition {\n\tif g == nil || g.Definition == nil {\n\t\treturn GraphDefinition{}\n\t}\n\treturn *g.Definition\n}", "reference": "// GetDefinition returns the Definition field if non-nil, zero value otherwise.", "generated": "// GetDefinition returns the graph definition for this node.\n// If no graph is defined or if it's set to zero, an empty graph definition will be returned."}
{"id": 3320, "code": "func (g *GraphDefinitionMarker) GetValOk() (json.Number, bool) {\n\tif g == nil || g.Val == nil {\n\t\treturn \"\", false\n\t}\n\treturn *g.Val, true\n}", "reference": "// GetValOk returns a tuple with the Val field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetValOk returns val if present in graph definition marker.\n// If no value is set then it will return empty json number along with error flag to indicate that there was no valid value found for this field.\n// This method should be used only when we have already checked whether or not the given GraphDef has been"}
{"id": 3325, "code": "func (g *GraphDefinitionRequest) GetStacked() bool {\n\tif g == nil || g.Stacked == nil {\n\t\treturn false\n\t}\n\treturn *g.Stacked\n}", "reference": "// GetStacked returns the Stacked field if non-nil, zero value otherwise.", "generated": "// GetStacked returns true if this graph definition request is stacked.\nfunc (g GraphDefinitionRequest) GetStacked() bool { return g.GetStacked() }"}
{"id": 3343, "code": "func (h *HostActionMute) GetEndTime() string {\n\tif h == nil || h.EndTime == nil {\n\t\treturn \"\"\n\t}\n\treturn *h.EndTime\n}", "reference": "// GetEndTime returns the EndTime field if non-nil, zero value otherwise.", "generated": "// GetEndTime returns the end time for this host action mute in ISO 8601 format.\n// If no end time is set or if HostActionMute has been deleted then it will return empty string."}
{"id": 3366, "code": "func (i *IntegrationGCPCreateRequest) GetClientX509CertURL() string {\n\tif i == nil || i.ClientX509CertURL == nil {\n\t\treturn \"\"\n\t}\n\treturn *i.ClientX509CertURL\n}", "reference": "// GetClientX509CertURL returns the ClientX509CertURL field if non-nil, zero value otherwise.", "generated": "// ClientX509CertURL returns URL for client X-509 certificate.\nfunc (i *IntegrationGCPCreateRequest) GetClientX509CertURL() string { return \"\" }  // Code here is just placeholder to make this format work; actual code should be provided in the \"code\" field below."}
{"id": 3375, "code": "func (i *IntegrationGCPCreateRequest) HasPrivateKeyID() bool {\n\tif i != nil && i.PrivateKeyID != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasPrivateKeyID returns a boolean if a field has been set.", "generated": "// HasPrivateKeyID returns whether this request has a private key ID set.\n// This is used to determine if we need to use GCE's API for creating keys or just create them locally in our own environment. If it is set then we will be using GCE's API; otherwise we'll do local creation."}
{"id": 3394, "code": "func (m *MetricMetadata) HasStatsdInterval() bool {\n\tif m != nil && m.StatsdInterval != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasStatsdInterval returns a boolean if a field has been set.", "generated": "// HasStatsdInterval returns whether this metric has statsd interval set.\n// If it is set then we can use that to determine if there's any data available for us,\n// otherwise we have no idea how often metrics were sampled so we just return 0.\nfunc (m *MetricMetadata) HasStatsd"}
{"id": 3423, "code": "func (o *Options) GetLockedOk() (bool, bool) {\n\tif o == nil || o.Locked == nil {\n\t\treturn false, false\n\t}\n\treturn *o.Locked, true\n}", "reference": "// GetLockedOk returns a tuple with the Locked field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetLockedOk returns whether this option is locked or not.\n//\n// If it's locked then its value will be set to true in any case,\n// otherwise its value will remain unchanged if it was previously unlocked.\n// The returned boolean indicates that we can safely return from the current goroutine without panicking.\n//"}
{"id": 3431, "code": "func (o *Options) GetQueryConfig() QueryConfig {\n\tif o == nil || o.QueryConfig == nil {\n\t\treturn QueryConfig{}\n\t}\n\treturn *o.QueryConfig\n}", "reference": "// GetQueryConfig returns the QueryConfig field if non-nil, zero value otherwise.", "generated": "// GetQueryConfig returns the query configuration for this options object.\n// If no query config is set in the Options struct, it will return an empty QueryConfig."}
{"id": 3444, "code": "func (o *Options) GetThresholdWindowsOk() (ThresholdWindows, bool) {\n\tif o == nil || o.ThresholdWindows == nil {\n\t\treturn ThresholdWindows{}, false\n\t}\n\treturn *o.ThresholdWindows, true\n}", "reference": "// GetThresholdWindowsOk returns a tuple with the ThresholdWindows field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetThresholdWindowsOk returns whether it is ok to proceed with threshold windows.\nfunc (o Options) GetThresholdWindowsOk() (ThresholdWindows, bool) { return }"}
{"id": 3465, "code": "func (r *Recurrence) GetUntilDateOk() (int, bool) {\n\tif r == nil || r.UntilDate == nil {\n\t\treturn 0, false\n\t}\n\treturn *r.UntilDate, true\n}", "reference": "// GetUntilDateOk returns a tuple with the UntilDate field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetUntilDate returns the duration until date in seconds.\n// If there is no recurrence rule set for this Recurrence object,\n// it will return zero value.\nGetUntilDateOk returns two values: int representing time in seconds since epoch that represents \"until\" date if exists; boolean indicating whether or not \"until"}
{"id": 3475, "code": "func (r *reqComment) HasComment() bool {\n\tif r != nil && r.Comment != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasComment returns a boolean if a field has been set.", "generated": "// HasComment returns whether this request has any comments.\n// If it is empty or no requests were given to process,\n// then there will be no comments in the result.\n// This method can also return true if the Request object was passed through without being processed by the router. In that case, all fields including Comments"}
{"id": 3483, "code": "func (r *reqGetTags) GetTagsOk() (TagMap, bool) {\n\tif r == nil || r.Tags == nil {\n\t\treturn TagMap{}, false\n\t}\n\treturn *r.Tags, true\n}", "reference": "// GetTagsOk returns a tuple with the Tags field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetTags returns tags for this request.\n//\n// Tags is a map[string]Tag that contains all tag names to values in this request.\n// The returned value will be empty if no tags were provided or if they have been removed from the request.\nvar GetTags = func(req reqGetTags) (*tag.Tag"}
{"id": 3485, "code": "func (r *Rule) GetThreshold() json.Number {\n\tif r == nil || r.Threshold == nil {\n\t\treturn \"\"\n\t}\n\treturn *r.Threshold\n}", "reference": "// GetThreshold returns the Threshold field if non-nil, zero value otherwise.", "generated": "// GetThreshold returns the threshold value for this rule.\n// If no threshold is set or if the Rule has been deleted,\n// it will return an empty string. Otherwise, it will be returned as a JSON number.\n// The format should match the expected output from the API endpoint that retrieves thresholds. For example: \""}
{"id": 3492, "code": "func (s *Screenboard) GetSharedOk() (bool, bool) {\n\tif s == nil || s.Shared == nil {\n\t\treturn false, false\n\t}\n\treturn *s.Shared, true\n}", "reference": "// GetSharedOk returns a tuple with the Shared field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetSharedOk returns whether this screen is shared or not.\n//\n// If it's shared, return ok to indicate that we can proceed with sharing,\n// otherwise return err to prevent further attempts at sharing.\n// The returned value indicates if there was any error during the operation.\nfunc (s Screenboard) GetShared"}
{"id": 3495, "code": "func (s *Series) GetAggrOk() (string, bool) {\n\tif s == nil || s.Aggr == nil {\n\t\treturn \"\", false\n\t}\n\treturn *s.Aggr, true\n}", "reference": "// GetAggrOk returns a tuple with the Aggr field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetAggrOk returns whether Agg is set to OK or not.\n//\n// If it's set to OK then we can get its value using GetAggr(). Otherwise,\n// return empty string and false indicating that this series has no valid aggregation rule defined for it yet.\nfunc (s Series) GetAg"}
{"id": 3518, "code": "func (s *SyntheticsDevice) GetIsMobileOk() (bool, bool) {\n\tif s == nil || s.IsMobile == nil {\n\t\treturn false, false\n\t}\n\treturn *s.IsMobile, true\n}", "reference": "// GetIsMobileOk returns a tuple with the IsMobile field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetIsMobileOk returns whether this device is mobile or not.\n//\n// If it's mobile, then IsMobile will be set to true; otherwise,\n// it'll return false. The second value returned indicates that we're\n// sure about our answer because we've checked all fields in SyntheticsDevice."}
{"id": 3522, "code": "func (s *SyntheticsDevice) HasUserAgent() bool {\n\tif s != nil && s.UserAgent != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasUserAgent returns a boolean if a field has been set.", "generated": "// HasUserAgent returns whether this device has user agent information set.\n// If it is set then we can use that to determine if there's any other info available for this synthetic device. Otherwise,\n// return false. This should be used in conjunction with IsSynthetic(). The two methods together will give us all"}
{"id": 3534, "code": "func (s *SyntheticsOptions) HasMinLocationFailed() bool {\n\tif s != nil && s.MinLocationFailed != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasMinLocationFailed returns a boolean if a field has been set.", "generated": "// HasMinLocationFailed returns whether min location failed is set to true.\nfunc (s *SyntheticsOptions) HasMinLocationFailed() bool {... }"}
{"id": 3541, "code": "func (s *SyntheticsRequest) GetMethod() string {\n\tif s == nil || s.Method == nil {\n\t\treturn \"\"\n\t}\n\treturn *s.Method\n}", "reference": "// GetMethod returns the Method field if non-nil, zero value otherwise.", "generated": "// Method returns the method name for this request.\n// If no method is specified in the input, it will be returned empty.\n// Otherwise, if there's already a method set using SetMethod(), that one will be used instead.\nfunc (s *SyntheticsRequest) GetMethod() string { return \"\" }"}
{"id": 3548, "code": "func (s *SyntheticsTest) GetConfigOk() (SyntheticsConfig, bool) {\n\tif s == nil || s.Config == nil {\n\t\treturn SyntheticsConfig{}, false\n\t}\n\treturn *s.Config, true\n}", "reference": "// GetConfigOk returns a tuple with the Config field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetConfig returns the synthetics config if it exists in the test case.\n// If no config is found or the test case has been deleted, return an empty Config.\nfunc (t *SyntheticsTest) GetConfigOk() (SyntheticsConfig, bool) {\n\tif t == nil || t.Config"}
{"id": 3551, "code": "func (s *SyntheticsTest) GetDeletedAtOk() (string, bool) {\n\tif s == nil || s.DeletedAt == nil {\n\t\treturn \"\", false\n\t}\n\treturn *s.DeletedAt, true\n}", "reference": "// GetDeletedAtOk returns a tuple with the DeletedAt field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// GetDeletedAt returns deleted_at field if present.\nGetDeletedAtOk is used to get the value from the struct's fields that represent the \"deleted_at\" attribute in the API output format. If this field exists it will return its string representation along with a boolean indicating whether or not the field was found. The"}
{"id": 3577, "code": "func (t *ThresholdCount) GetTimeAggregator() string {\n\tif t == nil || t.TimeAggregator == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.TimeAggregator\n}", "reference": "// GetTimeAggregator returns the TimeAggregator field if non-nil, zero value otherwise.", "generated": "// TimeAggregator returns time aggregator for this threshold count.\n// If no time aggregator is set it will return empty string.\n// This field can be used to specify how often should we update our counts,\n// e.g., 1 minute or every hour etc... It's useful when there are multiple thresholds that need different"}
{"id": 3579, "code": "func (t *ThresholdCount) HasTimeAggregator() bool {\n\tif t != nil && t.TimeAggregator != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasTimeAggregator returns a boolean if a field has been set.", "generated": "// HasTimeAggregator returns whether this threshold has time aggregator.\n//\n// Time aggregators allow for aggregation over multiple intervals in one go,\n// which is useful when dealing with large amounts of data that need to be processed\n// at once. This can significantly speed up processing times compared to calling\n// each interval individually"}
{"id": 3582, "code": "func (t *ThresholdCount) HasUnknown() bool {\n\tif t != nil && t.Unknown != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasUnknown returns a boolean if a field has been set.", "generated": "// HasUnknown returns whether this threshold has unknown values.\n// If it is set to Unknown, then all other thresholds in the same group will also be considered unknown,\n// unless they have been explicitly marked otherwise by another Threshold or Group.\n// This method should only return true if there's no way for any value within that"}
{"id": 3583, "code": "func (t *ThresholdCount) GetWarning() json.Number {\n\tif t == nil || t.Warning == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.Warning\n}", "reference": "// GetWarning returns the Warning field if non-nil, zero value otherwise.", "generated": "// Warning returns the warning threshold value in JSON format.\n// If no warning is set or this struct has been deleted, it will return an empty string. Otherwise,\n// it will be returned as a JSON number representing the current warning level. The unit for the\n// warning count depends on the type of ThresholdCount object"}
{"id": 3589, "code": "func (t *ThresholdWindows) GetRecoveryWindow() string {\n\tif t == nil || t.RecoveryWindow == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.RecoveryWindow\n}", "reference": "// GetRecoveryWindow returns the RecoveryWindow field if non-nil, zero value otherwise.", "generated": "// GetRecoveryWindow returns the recovery window for this threshold.\n// If no value is set or if it's zero-length, an empty string will be returned instead. The format expected by the API is \"X days\" where X is the number of days to wait before recovering from failure. For example: 3"}
{"id": 3597, "code": "func (t *TileDefRequest) HasQueryType() bool {\n\tif t != nil && t.QueryType != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasQueryType returns a boolean if a field has been set.", "generated": "// HasQueryType returns whether this request has query type set.\nfunc (t TileDefRequest) HasQueryType() bool { return t.HasQueryType() }"}
{"id": 3598, "code": "func (t *TileDefRequest) GetTextFilter() string {\n\tif t == nil || t.TextFilter == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.TextFilter\n}", "reference": "// GetTextFilter returns the TextFilter field if non-nil, zero value otherwise.", "generated": "// TextFilter returns text filter for this tile definition request.\n// If empty, no filtering is applied to tiles matching this request.\n// The returned value must be used in conjunction with TileDefinitionResponse.GetTilesMatched()\n// or TileDefinitionResponse.GetMatchingTiles().GetMatches() methods to get filtered results.\n// Note"}
{"id": 3604, "code": "func (t *TimeRange) GetLive() bool {\n\tif t == nil || t.Live == nil {\n\t\treturn false\n\t}\n\treturn *t.Live\n}", "reference": "// GetLive returns the Live field if non-nil, zero value otherwise.", "generated": "// GetLive returns true if this time range is live or has been updated since last check.\n// If it's not live but was previously checked for updates, then we will be notified when next update occurs,\n// so we can get its latest value from another source without having to recheck again immediately after that.\n//"}
{"id": 3606, "code": "func (t *TimeRange) HasLive() bool {\n\tif t != nil && t.Live != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasLive returns a boolean if a field has been set.", "generated": "// HasLive returns whether this time range has live data available.\n// If it is set to Live but empty, then there will be no live data for that time period,\n// even if other ranges have live data.  This method should only return true when\n// either Time or End is non-nil.  It"}
{"id": 3613, "code": "func (t *TimeseriesRequestStyle) GetLineType() string {\n\tif t == nil || t.LineType == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.LineType\n}", "reference": "// GetLineType returns the LineType field if non-nil, zero value otherwise.", "generated": "// LineType returns the line type for this request style.\n// If it is set to zero value or empty string, then no lines will be returned in the result.\n// Otherwise, only one line per time series will be included in the output.\nfunc (t *TimeseriesRequestStyle) SetLineType(v string"}
{"id": 3626, "code": "func (t *TraceServiceDefinition) GetShowBreakdownOk() (bool, bool) {\n\tif t == nil || t.ShowBreakdown == nil {\n\t\treturn false, false\n\t}\n\treturn *t.ShowBreakdown, true\n}", "reference": "// GetShowBreakdownOk returns a tuple with the ShowBreakdown field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// ShowBreakdown returns whether to show breakdowns in trace service definition.\n// If set to true, then all traces will be shown including those that have been\n// aggregated into other traces. This is useful for debugging purposes when\n// tracing across multiple services or applications. Otherwise only top level\n// traces will be"}
{"id": 3631, "code": "func (t *TraceServiceDefinition) GetShowErrors() bool {\n\tif t == nil || t.ShowErrors == nil {\n\t\treturn false\n\t}\n\treturn *t.ShowErrors\n}", "reference": "// GetShowErrors returns the ShowErrors field if non-nil, zero value otherwise.", "generated": "// ShowErrors returns whether to show errors in this trace service definition.\n// If true, error messages will be shown when tracing is enabled for this service,\n// otherwise they'll be ignored. This setting only affects how errors are displayed\n// within the trace itself; it doesn't affect any external logging or reporting that may"}
{"id": 3702, "code": "func (w *Widget) HasMustShowHits() bool {\n\tif w != nil && w.MustShowHits != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasMustShowHits returns a boolean if a field has been set.", "generated": "// MustHasHit returns whether this widget must show hits.\n//\n// If it is set to true then all widgets that have no \"must-show\" flag will be hidden,\n// regardless of their own hit count or other flags.  This can only be used for widgets\n// where there's one possible type of content"}
{"id": 3703, "code": "func (w *Widget) GetMustShowLatency() bool {\n\tif w == nil || w.MustShowLatency == nil {\n\t\treturn false\n\t}\n\treturn *w.MustShowLatency\n}", "reference": "// GetMustShowLatency returns the MustShowLatency field if non-nil, zero value otherwise.", "generated": "// MustGetShowLatency returns true if this widget must show latency information.\n// If it is set to false then no latency info will be shown in the UI for this widget,\n// but still some other widgets may display their own latency values based on internal state.\nfunc (w *Widget) MustGetShowLat"}
{"id": 3726, "code": "func (w *Widget) HasTileDef() bool {\n\tif w != nil && w.TileDef != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasTileDef returns a boolean if a field has been set.", "generated": "// HasTileDef returns whether this widget has a tile definition.\n// A TileDefinition is required for widgets that have tiles defined in their layout.\n// If no TileDefinition exists then it will return false. This method can be used to check if a widget should render its content or just display a placeholder image instead."}
{"id": 3747, "code": "func (w *WidgetConditionalFormat) HasImageUrl() bool {\n\tif w != nil && w.ImageUrl != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasImageUrl returns a boolean if a field has been set.", "generated": "// HasImageUrl returns whether this widget has an image URL set.\n// If it is set then the image will be displayed in the chart instead of text for conditional formatting rules that require images to display values or labels. The image must have been loaded before calling this method otherwise no error message will be returned if there's any"}
{"id": 3762, "code": "func (t *templateData) addArrayType(x *ast.ArrayType, receiverType, fieldName string) {\n\t// TODO: should we make this dynamic? Could handle more cases than string only\n\tvar eltType string\n\tswitch elt := x.Elt.(type) {\n\tcase *ast.Ident:\n\t\teltType = elt.String()\n\tdefault:\n\t\tlogf(\"addArrayType: type %q, field %q: unknown element type: %T %+v; skipping.\", receiverType, fieldName, elt, elt)\n\t\treturn\n\t}\n\n\tt.Accessors = append(t.Accessors, newAccessor(receiverType, fieldName, \"[]\"+eltType, \"nil\"))\n}", "reference": "// addArrayType adds an accessor for a array type for a given receiver and field", "generated": "// AddArray adds support for array types to template data.\n//\n// This is used by templates that have fields like `myField[0]`, where myField has type []int,\n// or `myField[len(myField)-1]`. The accessor will be created dynamically based on the length\n// of the"}
{"id": 3764, "code": "func (client *Client) UpdateDowntime(downtime *Downtime) error {\n\treturn client.doJsonRequest(\"PUT\", fmt.Sprintf(\"/v1/downtime/%d\", *downtime.Id),\n\t\tdowntime, nil)\n}", "reference": "// UpdateDowntime takes a downtime that was previously retrieved through some method\n// and sends it back to the server.", "generated": "// Update updates downtime information for this server.\n//\n// This method is used to update downtime information in the database\n// associated with this server's ID. The new downtimes will be applied at\n// the next scheduled maintenance time or immediately if it has already been reached.\n// If no schedule exists then the current uptime"}
{"id": 3768, "code": "func (k *APIKey) UnmarshalJSON(data []byte) error {\n\ttype Alias APIKey\n\taux := &struct {\n\t\tCreated *string `json:\"created,omitempty\"`\n\t\t*Alias\n\t}{\n\t\tAlias: (*Alias)(k),\n\t}\n\tif err := json.Unmarshal(data, &aux); err != nil {\n\t\treturn err\n\t}\n\n\tif created, err := time.Parse(createdTimeLayout, *aux.Created); err != nil {\n\t\treturn err\n\t} else {\n\t\tk.Created = &created\n\t}\n\n\treturn nil\n}", "reference": "// UnmarshalJSON is a custom method for handling datetime unmarshalling", "generated": "// UnmarshalJSON implements the JSON unmarshaling method for APIKey.\n//\n// This is used to convert data from a byte slice into an API key object.\n// The format should be similar to this example:\n//\n//  \"key\": \"your_api_key\",\n//  \"name\": \"Your Key Name\""}
{"id": 3770, "code": "func (client *Client) GetAPIKey(key string) (*APIKey, error) {\n\tvar out reqAPIKey\n\tif err := client.doJsonRequest(\"GET\", fmt.Sprintf(\"/v1/api_key/%s\", key), nil, &out); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn out.APIKey, nil\n}", "reference": "// GetAPIKey returns a single API key or error on failure", "generated": "// GetAPIKey retrieves information about API keys for this account.\n//\n// The returned value is in JSON format according to the request parameters specified above.\n// If no errors occurred during processing, it will be non-nil; otherwise, it's zero-value.\n// This method can only retrieve existing API keys that have been created"}
{"id": 3791, "code": "func (t *bufferedObjectStream) WriteObject(obj interface{}) error {\n\tt.mu.Lock()\n\tdefer t.mu.Unlock()\n\tif err := t.codec.WriteObject(t.w, obj); err != nil {\n\t\treturn err\n\t}\n\treturn t.w.Flush()\n}", "reference": "// WriteObject implements ObjectStream.", "generated": "// WriteObject writes object to stream.\n//\n// If this is called while writing another object in same call,\n// it will be ignored until previous one finished flushing.\n// This method should only be used for streaming large objects or\n// when encoding/decoding multiple small objects at once. For single\n// object use"}
{"id": 3794, "code": "func (r *Request) SetMeta(v interface{}) error {\n\tb, err := json.Marshal(v)\n\tif err != nil {\n\t\treturn err\n\t}\n\tr.Meta = (*json.RawMessage)(&b)\n\treturn nil\n}", "reference": "// SetMeta sets r.Meta to the JSON representation of v. If JSON\n// marshaling fails, it returns an error.", "generated": "// SetMeta sets meta data for this request.\n//\n// This is used to set metadata that will be sent in the HTTP headers or body,\n// but it's also useful when setting custom fields directly on the Request object.\n// The value can be any JSON-serializable type, including structs, maps, slices,"}
{"id": 3795, "code": "func (r *Response) SetResult(v interface{}) error {\n\tb, err := json.Marshal(v)\n\tif err != nil {\n\t\treturn err\n\t}\n\tr.Result = (*json.RawMessage)(&b)\n\treturn nil\n}", "reference": "// SetResult sets r.Result to the JSON representation of v. If JSON\n// marshaling fails, it returns an error.", "generated": "// SetResult sets the result field to v.\n//\n// If v is already JSON-serializable, it will be marshaled into a RawJSON slice,\n// otherwise an error will be returned.\n// \n// This method should only be called once; after setting this value, calling\n// Result() or other methods"}
{"id": 3804, "code": "func PickID(id ID) CallOption {\n\treturn callOptionFunc(func(r *Request) error {\n\t\tr.ID = id\n\t\treturn nil\n\t})\n}", "reference": "// PickID returns a call option which sets the ID on a request. Care must be\n// taken to ensure there are no conflicts with any previously picked ID, nor\n// with the default sequence ID.", "generated": "// PickID sets the ID for this request.\n//\n// The ID is used to identify which resource was requested by the client.\n// It can be set before sending the request or after receiving it from the server,\n// depending on how the client implements its HTTP connection management logic.\n// If no ID has been specified yet"}
{"id": 3863, "code": "func (c *Cursor) Backspace() {\n\ta := c.input\n\ti := c.Position\n\tif i == 0 {\n\t\t// Shrug\n\t\treturn\n\t}\n\tif i == len(a) {\n\t\tc.input = a[:i-1]\n\t} else {\n\t\tc.input = append(a[:i-1], a[i:]...)\n\t}\n\t// now it's pointing to the i+1th element\n\tc.Move(-1)\n}", "reference": "// Backspace removes the rune that precedes the cursor\n//\n// It handles being at the beginning or end of the row, and moves the cursor to\n// the appropriate position.", "generated": "// Backspace removes one character from the input string.\n//\n// If there is no characters left in the cursor position,\n// then all remaining characters will be removed.\n// The new cursor position points at the previous character or before if we're back at start.\n// This method should only be called when the current value has"}
{"id": 3870, "code": "func (p *Package) Type(name string) (t *Type) {\n\tt, _ = p.Members[name].(*Type)\n\treturn\n}", "reference": "// Type returns the package-level type of the specified name,\n// or nil if not found.\n//", "generated": "// Type returns the type associated with the given name.\n// If no member is found by that name, it will return nil.\n// This method should be used to get types from package members,\n// rather than directly accessing the Package's Members map. The\n// reason for this is that Packages can have arbitrary numbers of"}
{"id": 3892, "code": "func (b *builder) switchStmt(fn *Function, s *ast.SwitchStmt, label *lblock) {\n\t// We treat SwitchStmt like a sequential if-else chain.\n\t// Multiway dispatch can be recovered later by ssautil.Switches()\n\t// to those cases that are free of side effects.\n\tif s.Init != nil {\n\t\tb.stmt(fn, s.Init)\n\t}\n\tvar tag Value = vTrue\n\tif s.Tag != nil {\n\t\ttag = b.expr(fn, s.Tag)\n\t}\n\tdone := fn.newBasicBlock(\"switch.done\")\n\tif label != nil {\n\t\tlabel._break = done\n\t}\n\t// We pull the default case (if present) down to the end.\n\t// But each fallthrough label must point to the next\n\t// body block in source order, so we preallocate a\n\t// body block (fallthru) for the next case.\n\t// Unfortunately this makes for a confusing block order.\n\tvar dfltBody *[]ast.Stmt\n\tvar dfltFallthrough *BasicBlock\n\tvar fallthru, dfltBlock *BasicBlock\n\tncases := len(s.Body.List)\n\tfor i, clause := range s.Body.List {\n\t\tbody := fallthru\n\t\tif body == nil {\n\t\t\tbody = fn.newBasicBlock(\"switch.body\") // first case only\n\t\t}\n\n\t\t// Preallocate body block for the next case.\n\t\tfallthru = done\n\t\tif i+1 < ncases {\n\t\t\tfallthru = fn.newBasicBlock(\"switch.body\")\n\t\t}\n\n\t\tcc := clause.(*ast.CaseClause)\n\t\tif cc.List == nil {\n\t\t\t// Default case.\n\t\t\tdfltBody = &cc.Body\n\t\t\tdfltFallthrough = fallthru\n\t\t\tdfltBlock = body\n\t\t\tcontinue\n\t\t}\n\n\t\tvar nextCond *BasicBlock\n\t\tfor _, cond := range cc.List {\n\t\t\tnextCond = fn.newBasicBlock(\"switch.next\")\n\t\t\t// TODO(adonovan): opt: when tag==vTrue, we'd\n\t\t\t// get better code if we use b.cond(cond)\n\t\t\t// instead of BinOp(EQL, tag, b.expr(cond))\n\t\t\t// followed by If.  Don't forget conversions\n\t\t\t// though.\n\t\t\tcond := emitCompare(fn, token.EQL, tag, b.expr(fn, cond), cond.Pos())\n\t\t\temitIf(fn, cond, body, nextCond)\n\t\t\tfn.currentBlock = nextCond\n\t\t}\n\t\tfn.currentBlock = body\n\t\tfn.targets = &targets{\n\t\t\ttail:         fn.targets,\n\t\t\t_break:       done,\n\t\t\t_fallthrough: fallthru,\n\t\t}\n\t\tb.stmtList(fn, cc.Body)\n\t\tfn.targets = fn.targets.tail\n\t\temitJump(fn, done)\n\t\tfn.currentBlock = nextCond\n\t}\n\tif dfltBlock != nil {\n\t\temitJump(fn, dfltBlock)\n\t\tfn.currentBlock = dfltBlock\n\t\tfn.targets = &targets{\n\t\t\ttail:         fn.targets,\n\t\t\t_break:       done,\n\t\t\t_fallthrough: dfltFallthrough,\n\t\t}\n\t\tb.stmtList(fn, *dfltBody)\n\t\tfn.targets = fn.targets.tail\n\t}\n\temitJump(fn, done)\n\tfn.currentBlock = done\n}", "reference": "// switchStmt emits to fn code for the switch statement s, optionally\n// labelled by label.\n//", "generated": "Switch statement is treated as a sequence of conditional statements. The last condition will always match true, hence it's called \"default\". Each branch has its own basic block which contains all the associated statements. All branches except the default one have their corresponding break labels pointing at the following branch's start. In other words, they"}
{"id": 3913, "code": "func yaml_emitter_flush(emitter *yaml_emitter_t) bool {\n\tif emitter.write_handler == nil {\n\t\tpanic(\"write handler not set\")\n\t}\n\n\t// Check if the buffer is empty.\n\tif emitter.buffer_pos == 0 {\n\t\treturn true\n\t}\n\n\tif err := emitter.write_handler(emitter, emitter.buffer[:emitter.buffer_pos]); err != nil {\n\t\treturn yaml_emitter_set_writer_error(emitter, \"write error: \"+err.Error())\n\t}\n\temitter.buffer_pos = 0\n\treturn true\n}", "reference": "// Flush the output buffer.", "generated": "// Flush writes any remaining data to the underlying writer. If there's no more data,\n// it returns immediately without writing anything. This method should be called after\n// all YAML output has been written or flushed using Write(). It will also reset the\n// internal state for subsequent calls. The caller must ensure that the"}
{"id": 3930, "code": "func TCPDialCheck(addr string, timeout time.Duration) Check {\n\treturn func() error {\n\t\tconn, err := net.DialTimeout(\"tcp\", addr, timeout)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn conn.Close()\n\t}\n}", "reference": "// TCPDialCheck returns a Check that checks TCP connectivity to the provided\n// endpoint.", "generated": "// TCPDialCheck checks if a connection to the given address can be established.\n//\n// If successful, it returns true; otherwise, it panics after closing the connection.\n// The check is done using a dialer that will close immediately upon failure,\n// allowing for efficient use in performance-critical code paths where"}
{"id": 3934, "code": "func NewMetricsHandler(registry prometheus.Registerer, namespace string) Handler {\n\treturn &metricsHandler{\n\t\thandler:   NewHandler(),\n\t\tregistry:  registry,\n\t\tnamespace: namespace,\n\t}\n}", "reference": "// NewMetricsHandler returns a healthcheck Handler that also exposes metrics\n// into the provided Prometheus registry.", "generated": "// NewMetricsHandler returns a new metrics handler.\n//\n// This is used to register all metric handlers in the given\n// Prometheus Registry under the specified namespace.\nfunc (h *handler) NewMetricsHandler(registry prometheus.Registerer, namespace string) Handler {\n\treturn &metricsHandler{handler: h.handler, registry"}
{"id": 3938, "code": "func (p *Pinger) AddIP(ipaddr string) error {\n\taddr := net.ParseIP(ipaddr)\n\tif addr == nil {\n\t\treturn fmt.Errorf(\"%s is not a valid textual representation of an IP address\", ipaddr)\n\t}\n\tp.mu.Lock()\n\tp.addrs[addr.String()] = &net.IPAddr{IP: addr}\n\tif isIPv4(addr) {\n\t\tp.hasIPv4 = true\n\t} else if isIPv6(addr) {\n\t\tp.hasIPv6 = true\n\t}\n\tp.mu.Unlock()\n\treturn nil\n}", "reference": "// AddIP adds an IP address to Pinger. ipaddr arg should be a string like\n// \"192.0.2.1\".", "generated": "// AddIP adds an IPv4 or IPv6 address to this pinger.\n// If the given address already exists in the list,\n// it will be overwritten without any warning.\n// The returned value indicates whether the operation was successful.\n// It's up to caller to check for errors after calling this method.\n// This"}
{"id": 3943, "code": "func Substitute(s string, sub map[string]string) (buf string) {\n\tbuf = s\n\tvar keys []string\n\tfor k := range sub {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)\n\n\tfor _, key := range keys {\n\t\tbuf = strings.Replace(buf, key, sub[key], -1)\n\t}\n\treturn\n}", "reference": "// Substitute returns string with superseded all substrings from\n// provided substitution map. Substitution map will be applied in alphabetic\n// order. Many passes, on one substitution another one could apply.", "generated": "// Substitutes all occurrences in the given string's' for each value in the provided substitution dictionary.\n//\n// The values from the dictionary will be inserted into the original string at every occurrence,\n// replacing any existing matches. This process is repeated until no more substitutions can be made.\n//\n// For example, if"}
{"id": 3945, "code": "func Parse() error {\n\targs := os.Args\n\tif len(args) == 1 {\n\t\treturn nil\n\t}\n\n\t// Global flags.\n\tfset := flag.CommandLine\n\tfset.Usage = Usage\n\tout := fsetOutput(fset)\n\n\tif err := fset.Parse(args[1:]); err != nil {\n\t\treturn err\n\t}\n\n\t// Handle version request.\n\tif f := fset.Lookup(VersionBoolFlag); f != nil {\n\t\tif v, ok := f.Value.(flag.Getter); ok {\n\t\t\t// All values implemented by the flag package implement the flag.Getter interface.\n\t\t\tif b, ok := v.Get().(bool); ok && b {\n\t\t\t\t// The flag was defined as a bool and is set.\n\t\t\t\tprogram := programName(args[0])\n\t\t\t\tfmt.Fprintf(out, \"%s version %s %s/%s\\n\",\n\t\t\t\t\tprogram, buildinfo(),\n\t\t\t\t\truntime.GOOS, runtime.GOARCH)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n\n\t// No cmdflag.\n\tif fset.NArg() == 0 {\n\t\treturn nil\n\t}\n\n\t// Subcommand.\n\tidx := len(args) - fset.NArg()\n\ts := args[idx]\n\targs = args[idx+1:]\n\tfor _, sub := range subs {\n\t\tif sub.name != s {\n\t\t\tcontinue\n\t\t}\n\n\t\tfs, handler := sub.init(out)\n\t\tif err := fs.Parse(args); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn handler(args[len(args)-fs.NArg():]...)\n\t}\n\n\treturn fmt.Errorf(\"%s is not a valid cmdflag\", s)\n}", "reference": "// Parse parses the command line arguments including the global flags and, if any, the cmdflag and its flags.\n//\n// If the VersionBoolFlag is defined as a global boolean flag, then the program version is displayed and the program stops.", "generated": "Parse parses command-line arguments for this binary. It returns any errors encountered during parsing or processing. If no errors occur, it sets up output streams based on global flags and then calls the corresponding handler from the given subcommands. For each subcommand, it first initializes its associated flag set using init(), which may return additional"}
{"id": 3946, "code": "func (xxh XXHZero) Sum(b []byte) []byte {\n\th32 := xxh.Sum32()\n\treturn append(b, byte(h32), byte(h32>>8), byte(h32>>16), byte(h32>>24))\n}", "reference": "// Sum appends the current hash to b and returns the resulting slice.\n// It does not change the underlying hash state.", "generated": "// Sum returns the sum of this hash object's internal state represented by\n// b. The result is returned in big-endian order.\n//\n// This method should be called after all data has been written to the hash object,\n// but before any other methods have been invoked that modify its internal state.\n// If no"}
{"id": 3949, "code": "func (xxh *XXHZero) Sum32() uint32 {\n\th32 := uint32(xxh.totalLen)\n\tif h32 >= 16 {\n\t\th32 += rol1(xxh.v1) + rol7(xxh.v2) + rol12(xxh.v3) + rol18(xxh.v4)\n\t} else {\n\t\th32 += prime32_5\n\t}\n\n\tp := 0\n\tn := xxh.bufused\n\tbuf := xxh.buf\n\tfor n := n - 4; p <= n; p += 4 {\n\t\th32 += binary.LittleEndian.Uint32(buf[p:p+4]) * prime32_3\n\t\th32 = rol17(h32) * prime32_4\n\t}\n\tfor ; p < n; p++ {\n\t\th32 += uint32(buf[p]) * prime32_5\n\t\th32 = rol11(h32) * prime32_1\n\t}\n\n\th32 ^= h32 >> 15\n\th32 *= prime32_2\n\th32 ^= h32 >> 13\n\th32 *= prime32_3\n\th32 ^= h32 >> 16\n\n\treturn h32\n}", "reference": "// Sum32 returns the 32 bits Hash value.", "generated": "// Sum32 returns the sum of all bytes in this XXH object.\n//\n// The result is a 64-bit integer that can be used to identify objects or files,\n// but it's also very sensitive to changes in the input data. This means that if two\n// different inputs produce the same output, they"}
{"id": 3956, "code": "func (z *Writer) Write(buf []byte) (int, error) {\n\tif !z.Header.done {\n\t\tif err := z.writeHeader(); err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t}\n\tif debugFlag {\n\t\tdebug(\"input buffer len=%d index=%d\", len(buf), z.idx)\n\t}\n\n\tzn := len(z.data)\n\tvar n int\n\tfor len(buf) > 0 {\n\t\tif z.idx == 0 && len(buf) >= zn {\n\t\t\t// Avoid a copy as there is enough data for a block.\n\t\t\tif err := z.compressBlock(buf[:zn]); err != nil {\n\t\t\t\treturn n, err\n\t\t\t}\n\t\t\tn += zn\n\t\t\tbuf = buf[zn:]\n\t\t\tcontinue\n\t\t}\n\t\t// Accumulate the data to be compressed.\n\t\tm := copy(z.data[z.idx:], buf)\n\t\tn += m\n\t\tz.idx += m\n\t\tbuf = buf[m:]\n\t\tif debugFlag {\n\t\t\tdebug(\"%d bytes copied to buf, current index %d\", n, z.idx)\n\t\t}\n\n\t\tif z.idx < len(z.data) {\n\t\t\t// Buffer not filled.\n\t\t\tif debugFlag {\n\t\t\t\tdebug(\"need more data for compression\")\n\t\t\t}\n\t\t\treturn n, nil\n\t\t}\n\n\t\t// Buffer full.\n\t\tif err := z.compressBlock(z.data); err != nil {\n\t\t\treturn n, err\n\t\t}\n\t\tz.idx = 0\n\t}\n\n\treturn n, nil\n}", "reference": "// Write compresses data from the supplied buffer into the underlying io.Writer.\n// Write does not return until the data has been written.", "generated": "Write writes input into writer's internal state. It accumulates data until it reaches its capacity or when we need to compress a new block. After that, it calls compressBlock() which returns the number of bytes written out by this call. The returned value represents how many total bytes were written so far in this method."}
{"id": 3959, "code": "func (z *Writer) Close() error {\n\tif !z.Header.done {\n\t\tif err := z.writeHeader(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := z.Flush(); err != nil {\n\t\treturn err\n\t}\n\n\tif debugFlag {\n\t\tdebug(\"writing last empty block\")\n\t}\n\tif err := z.writeUint32(0); err != nil {\n\t\treturn err\n\t}\n\tif !z.NoChecksum {\n\t\tchecksum := z.checksum.Sum32()\n\t\tif debugFlag {\n\t\t\tdebug(\"stream checksum %x\", checksum)\n\t\t}\n\t\tif err := z.writeUint32(checksum); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// Close closes the Writer, flushing any unwritten data to the underlying io.Writer, but does not close the underlying io.Writer.", "generated": "// Close writes any remaining data to the underlying writer and closes it.\n// If this is the first call to Write or WriteWith, then no data has been written yet,\n// so we just close the stream without writing anything. Otherwise, we flush all\n// pending data before closing the stream. We also calculate and"}
{"id": 4014, "code": "func (d *FileSelectDialog) detectPath() {\n\tp := d.currPath\n\tif p == \"\" {\n\t\td.currPath, _ = os.Getwd()\n\t\treturn\n\t}\n\n\tp = filepath.Clean(p)\n\tfor {\n\t\t_, err := os.Stat(p)\n\t\tif err == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tdirUp := filepath.Dir(p)\n\t\tif dirUp == p {\n\t\t\tp, _ = os.Getwd()\n\t\t\tbreak\n\t\t}\n\n\t\tp = dirUp\n\t}\n\td.currPath = p\n}", "reference": "// Tries to find the best fit for the given path.\n// It goes up until it gets into the existing directory.\n// If all fails it returns working directory.", "generated": "// Detects the current path by walking up from the given file name.\n// If no file is specified, it uses the current working directory instead.\n// The detected path will be cleaned to remove any trailing slashes or redundant separators."}
{"id": 4018, "code": "func (d *dbCache) preload(firstRow, rowCount int) {\n\tif firstRow == d.firstRow && rowCount == d.rowCount {\n\t\t// fast path: view area is the same, return immediately\n\t\treturn\n\t}\n\n\t// slow path: refill cache\n\tfNames := []string{\"Jack\", \"Alisa\", \"Richard\", \"Paul\", \"Nicole\", \"Steven\", \"Jane\"}\n\tlNames := []string{\"Smith\", \"Catcher\", \"Stone\", \"White\", \"Black\"}\n\tposts := []string{\"Engineer\", \"Manager\", \"Janitor\", \"Driver\"}\n\tdeps := []string{\"IT\", \"Financial\", \"Support\"}\n\tsalary := []int{40000, 38000, 41000, 32000}\n\n\td.data = make([][]string, rowCount, rowCount)\n\tfor i := 0; i < rowCount; i++ {\n\t\tabsIndex := firstRow + i\n\t\td.data[i] = make([]string, columnInTable, columnInTable)\n\t\td.data[i][0] = fNames[absIndex%len(fNames)]\n\t\td.data[i][1] = lNames[absIndex%len(lNames)]\n\t\td.data[i][2] = fmt.Sprintf(\"%08d\", 100+absIndex)\n\t\td.data[i][3] = posts[absIndex%len(posts)]\n\t\td.data[i][4] = deps[absIndex%len(deps)]\n\t\td.data[i][5] = fmt.Sprintf(\"%d k/year\", salary[absIndex%len(salary)]/1000)\n\t}\n\n\t// do not forget to save the last values\n\td.firstRow = firstRow\n\td.rowCount = rowCount\n}", "reference": "// cache data from a new row span\n// It imitates a random data by selecting values from predefined arrays. Sizes\n// of all arrays should be different to make TableView data look more random", "generated": "// Preload loads data into dbCache from given range.\n//\n// If this method was called before for similar range, it returns without doing anything,\n// because we already have that data in memory. Otherwise, it fills up the entire table\n// by calling fillData() repeatedly until all rows fit inside the buffer."}
{"id": 4037, "code": "func PopClip() {\n\tif len(canvas.clipStack) == 0 {\n\t\treturn\n\t}\n\tc := canvas.clipStack[len(canvas.clipStack)-1]\n\tcanvas.clipStack = canvas.clipStack[:len(canvas.clipStack)-1]\n\tSetClipRect(c.x, c.y, c.w, c.h)\n}", "reference": "// PopClip restores saved with PushClip clipping window", "generated": "// PopClip removes the last clip from the stack if it exists. If no clips exist in the stack,\n// this has no effect. The current clipping rectangle is updated to reflect the new state.\n// This method should be called when the user wants to undo their most recent action that changed\n// the clipping region ("}
{"id": 4038, "code": "func InClipRect(x, y int) bool {\n\treturn x >= canvas.clipX && y >= canvas.clipY &&\n\t\tx < canvas.clipX+canvas.clipW &&\n\t\ty < canvas.clipY+canvas.clipH\n}", "reference": "// InClipRect returns true if x and y position is inside current clipping\n// rectangle", "generated": "// InClipRect checks if point (x,y) is within clip rectangle.\n//\n// Returns true if it's inside or at border; false otherwise.\n// Clip rectangle defined by: [clipX, clipX + clipWidth] for X-axis,\n//                            [clipY, clipY + clipHeight] for"}
{"id": 4049, "code": "func FillRect(x, y, w, h int, r rune) {\n\tx, y, w, h = clip(x, y, w, h)\n\tif w < 1 || y < -1 {\n\t\treturn\n\t}\n\n\tfor yy := y; yy < y+h; yy++ {\n\t\tfor xx := x; xx < x+w; xx++ {\n\t\t\tputCharUnsafe(xx, yy, r)\n\t\t}\n\t}\n}", "reference": "// FillRect paints the area with r character using the current colors", "generated": "// Fills rectangle at (x,y,w,h) with character 'r'. The coordinates are in pixel units.\n// If any part of the rectangle is outside the visible area, it will be clipped to fit within bounds."}
{"id": 4058, "code": "func (l *ListBox) SelectedItemText() string {\n\tif l.currSelection == -1 {\n\t\treturn \"\"\n\t}\n\n\treturn l.items[l.currSelection]\n}", "reference": "// SelectedItemText returns text of currently selected item or empty sting if nothing is\n// selected or ListBox is empty.", "generated": "// Returns the text for the currently selected item in this list box.\n// If no items have been added to the list or if there is no selection,\n// returns an empty string. The index returned by Items() refers\n// to the first element of the slice that represents all items in the\n// list box;"}
{"id": 4070, "code": "func ColorToString(attr term.Attribute) string {\n\tvar out string\n\n\trawClr := attr & 15\n\tif rawClr < 8 {\n\t\tfor k, v := range colorMap {\n\t\t\tif v == rawClr {\n\t\t\t\tout += k + \" \"\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tif attr&term.AttrBold != 0 {\n\t\tout += \"bold \"\n\t}\n\tif attr&term.AttrUnderline != 0 {\n\t\tout += \"underline \"\n\t}\n\tif attr&term.AttrReverse != 0 {\n\t\tout += \"reverse \"\n\t}\n\n\treturn strings.TrimSpace(out)\n}", "reference": "// ColorToString returns string representation of the attribute", "generated": "// ColorToString converts a given attribute to its corresponding human-readable representation.\n// The returned value is formatted in terms like'red', 'green' etc., for colors,\n// or 'bold', 'italic', 'underline', 'inverse' for other attributes.\n// For example: `ColorToString(term.ColorRed)` returns"}
{"id": 4074, "code": "func DeactivateControls(parent Control) {\n\tfor _, ctrl := range parent.Children() {\n\t\tif ctrl.Active() {\n\t\t\tctrl.SetActive(false)\n\t\t\tctrl.ProcessEvent(Event{Type: EventActivate, X: 0})\n\t\t}\n\n\t\tDeactivateControls(ctrl)\n\t}\n}", "reference": "// DeactivateControls makes all children of parent inactive", "generated": "// Deactivates all child controls in this control.\n//\n// This is used to deactivate any active controls when we want to\n// deactive our own control (e.g., during shutdown).\nfunc (c *Control) DeactivateControls() { DeactivateControls(c) }"}
{"id": 4089, "code": "func (c *CheckBox) SetAllow3State(enable bool) {\n\tif !enable && c.state == 2 {\n\t\tc.state = 0\n\t}\n\tc.allow3state = enable\n}", "reference": "// SetAllow3State sets if ComboBox should use 3 states. If the current\n// state is unknown and one disables Allow3State option then the current\n// value resets to off", "generated": "// SetAllow3State sets whether this checkbox can be in state 3.\n// If it is set to true then if the user clicks twice quickly,\n// the box will go from checked to unchecked instead of being left at half-checked.\n// This should only ever be called by the GUI code that creates the checkbox."}
{"id": 4109, "code": "func (b *ProgressBar) SecondaryColors() (term.Attribute, term.Attribute) {\n\treturn b.emptyFg, b.emptyBg\n}", "reference": "// SecondaryColors returns text and background colors for empty\n// part of the ProgressBar", "generated": "// Returns secondary colors for this progress bar.\n//\n// The primary color is returned by PrimaryColor(). This method returns two\n// attributes: one for foreground text to be used when no background is set,\n// and another for background text to be used when no foreground is set.\n// Both will have zero alpha value so"}
{"id": 4219, "code": "func NewMemoryKeyCacher(maxKeyAge time.Duration, maxCacheSize int) KeyCacher {\n\treturn &memoryKeyCacher{\n\t\tentries:      map[string]keyCacherEntry{},\n\t\tmaxKeyAge:    maxKeyAge,\n\t\tmaxCacheSize: maxCacheSize,\n\t}\n}", "reference": "// NewMemoryKeyCacher creates a new Keycacher interface with option\n// to set max age of cached keys and max size of the cache.", "generated": "// NewMemoryKeyCacher returns a new memory key cacher.\n//\n// The returned value is a struct that implements the KeyCacher interface.\n// It stores entries in memory for fast lookups but has limited capacity\n// to prevent excessive memory usage. If all cache slots are filled when\n// adding a new"}
{"id": 4226, "code": "func validColor(c string) bool {\n\tvalid := false\n\tif validColors[c] {\n\t\tvalid = true\n\t}\n\treturn valid\n}", "reference": "// validColor will make sure the given color is actually allowed", "generated": "// Returns whether c is a color.\n//\n// A color can be either \"red\", \"green\" or \"blue\".\nvar validColors = map[string]bool{\n\t\"red\":  true,\n\t\"green\": true,\n\t\"blue\":  true,\n}"}
{"id": 4230, "code": "func (s *Spinner) Reverse() {\n\ts.lock.Lock()\n\tdefer s.lock.Unlock()\n\tfor i, j := 0, len(s.chars)-1; i < j; i, j = i+1, j-1 {\n\t\ts.chars[i], s.chars[j] = s.chars[j], s.chars[i]\n\t}\n}", "reference": "// Reverse will reverse the order of the slice assigned to the indicator", "generated": "// Reverse reverses the characters in this spinner's string representation.\n// This is done by swapping each character from one end to another until they meet\n// or cross over. The result will be that all characters have been moved towards\n// their original position but now at the opposite ends. For example if we start"}
{"id": 4237, "code": "func NewMultiplex(con net.Conn, initiator bool) *Multiplex {\n\tmp := &Multiplex{\n\t\tcon:       con,\n\t\tinitiator: initiator,\n\t\tbuf:       bufio.NewReader(con),\n\t\tchannels:  make(map[streamID]*Stream),\n\t\tclosed:    make(chan struct{}),\n\t\tshutdown:  make(chan struct{}),\n\t\twrTkn:     make(chan struct{}, 1),\n\t\tnstreams:  make(chan *Stream, 16),\n\t}\n\n\tgo mp.handleIncoming()\n\n\tmp.wrTkn <- struct{}{}\n\n\treturn mp\n}", "reference": "// NewMultiplex creates a new multiplexer session.", "generated": "// Create a new multiplexer instance for handling multiple streams over one connection.\n//\n// The returned Multiplex object is initialized to listen for incoming connections from other processes.\n// It will handle all messages received until it's closed or shut down by another process.\n// After creation, start receiving data in separate goroutine using `"}
{"id": 4242, "code": "func (b Box) Round() (lat, lng float64) {\n\tx := maxDecimalPower(b.MaxLat - b.MinLat)\n\tlat = math.Ceil(b.MinLat/x) * x\n\tx = maxDecimalPower(b.MaxLng - b.MinLng)\n\tlng = math.Ceil(b.MinLng/x) * x\n\treturn\n}", "reference": "// Round returns a point inside the box, making an effort to round to minimal\n// precision.", "generated": "// Round returns rounded latitude and longitude values for this box.\n// The rounding is done in such way that it's possible to get all points inside\n// the original box by calling Unround(). This means that if we round lat/lng,\n// then unround them back, they will be equal to their original value"}
{"id": 4327, "code": "func (c *Client) DeleteCheckoutKey(account, repo, fingerprint string) error {\n\treturn c.request(\"DELETE\", fmt.Sprintf(\"project/%s/%s/checkout-key/%s\", account, repo, fingerprint), nil, nil, nil)\n}", "reference": "// DeleteCheckoutKey fetches the checkout key for the given project by fingerprint", "generated": "// DeleteCheckoutKey deletes a checkout key for a given repository in a project.\n//\n// This method is used to delete a specific checkout key from a GitLab\n// repository. The provided parameters must match those required by the API endpoint.\n// If successful, this operation returns no value; otherwise it will return an error"}
{"id": 4332, "code": "func (c *Client) Timing(bucket string, value interface{}) {\n\tif c.skip() {\n\t\treturn\n\t}\n\tc.conn.metric(c.prefix, bucket, value, \"ms\", c.rate, c.tags)\n}", "reference": "// Timing sends a timing value to a bucket.", "generated": "// Timing records a metric for this client's timing.\n//\n// This is used to track how long it takes to perform operations like requests,\n// responses, etc., which can be useful in monitoring or logging applications.\n// The returned time will include any errors that occurred during execution.\n// If no error was encountered then the"}
{"id": 4333, "code": "func (t Timing) Send(bucket string) {\n\tt.c.Timing(bucket, int(t.Duration()/time.Millisecond))\n}", "reference": "// Send sends the time elapsed since the creation of the Timing.", "generated": "// Send sends this timing to the given bucket.\n//\n// The duration is converted from milliseconds into seconds by dividing\n// it by 1000 before sending it in the time metric format.\n// This allows us to send both short durations like \"1ms\" or long ones like \"10s\"\n// without having to"}
{"id": 4348, "code": "func SpatialEntropy(match match.Match, turns int, shiftCount int) float64 {\n\tvar s, d float64\n\tif match.DictionaryName == \"qwerty\" || match.DictionaryName == \"dvorak\" {\n\t\t//todo: verify qwerty and dvorak have the same length and degree\n\t\ts = float64(len(adjacency.BuildQwerty().Graph))\n\t\td = adjacency.BuildQwerty().CalculateAvgDegree()\n\t} else {\n\t\ts = float64(keyPadStartingPositions)\n\t\td = keyPadAvgDegree\n\t}\n\n\tpossibilities := float64(0)\n\n\tlength := float64(len(match.Token))\n\n\t//TODO: Should this be <= or just < ?\n\t//Estimate the number of possible patterns w/ length L or less with t turns or less\n\tfor i := float64(2); i <= length+1; i++ {\n\t\tpossibleTurns := math.Min(float64(turns), i-1)\n\t\tfor j := float64(1); j <= possibleTurns+1; j++ {\n\t\t\tx := zxcvbnmath.NChoseK(i-1, j-1) * s * math.Pow(d, j)\n\t\t\tpossibilities += x\n\t\t}\n\t}\n\n\tentropy := math.Log2(possibilities)\n\t//add extra entropu for shifted keys. ( % instead of 5 A instead of a)\n\t//Math is similar to extra entropy for uppercase letters in dictionary matches.\n\n\tif S := float64(shiftCount); S > float64(0) {\n\t\tpossibilities = float64(0)\n\t\tU := length - S\n\n\t\tfor i := float64(0); i < math.Min(S, U)+1; i++ {\n\t\t\tpossibilities += zxcvbnmath.NChoseK(S+U, i)\n\t\t}\n\n\t\tentropy += math.Log2(possibilities)\n\t}\n\n\treturn entropy\n}", "reference": "// SpatialEntropy calculates the entropy for spatial matches", "generated": "SpatialEntropy calculates the spatial entropy given a match token, number of turns allowed,\nand shift count. It estimates the probability distribution over all possible tokens that can\nbe reached from the current position within the specified turn limit using the provided\ndictionary's graph structure. The result is then used to calculate the expected value of"}
{"id": 4354, "code": "func Null(in []byte, pos int) (int, error) {\n\tswitch in[pos] {\n\tcase 'n':\n\t\treturn expect(in, pos, n...)\n\t\treturn pos + 4, nil\n\tdefault:\n\t\treturn 0, errUnexpectedValue\n\t}\n}", "reference": "// Null verifies the contents of bytes provided is a null starting as pos", "generated": "// Null returns null value for given byte slice.\n//\n// It checks if current position is equal to \"null\". If it's true,\n// then it moves forward by four positions. Otherwise, it continues\n// checking from next character.\n//\n// Returns: The new position after processing or zero if no match found."}
{"id": 4404, "code": "func (b *Base64) SetBSON(raw bson.Raw) error {\n\tvar m bson.M\n\tif err := raw.Unmarshal(&m); err != nil {\n\t\treturn err\n\t}\n\n\tif data, ok := m[\"data\"].(string); ok {\n\t\t*b = Base64(data)\n\t\treturn nil\n\t}\n\n\treturn errors.New(\"couldn't unmarshal bson raw value as Base64\")\n}", "reference": "// SetBSON sets the Base64 from raw bson data", "generated": "// SetBSON sets the base64 encoded string from the given BSON Raw.\n// If it's present in the document then this will be set to that,\n// otherwise it'll return an error if there is no \"data\" field or its type isn't a string.\n// The returned value can only contain valid base"}
{"id": 4413, "code": "func (e *Email) UnmarshalEasyJSON(in *jlexer.Lexer) {\n\tif data := in.String(); in.Ok() {\n\t\t*e = Email(data)\n\t}\n}", "reference": "// UnmarshalEasyJSON sets the Email from a easyjson.Lexer", "generated": "// UnmarshalEasyJSON implements the unmarshaling interface for\n// easy JSON parsing.\n//\n// This is used to quickly parse simple email addresses from strings,\n// without having to implement full address validation logic.\nfunc (e *Email) UnmarshalEasyJSON(in *jlexer.Lexer) { }"}
{"id": 4422, "code": "func (u *IPv6) DeepCopy() *IPv6 {\n\tif u == nil {\n\t\treturn nil\n\t}\n\tout := new(IPv6)\n\tu.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new IPv6.", "generated": "// DeepCopy creates a deep copy of this IPv6 address.\n//\n// This is useful when we need to create multiple copies of the same IP address,\n// such as in tests where we want each test to have its own independent copy of\n// the original IP addresses used by the server.\nfunc (u *IPv"}
{"id": 4452, "code": "func (h *HexColor) DeepCopy() *HexColor {\n\tif h == nil {\n\t\treturn nil\n\t}\n\tout := new(HexColor)\n\th.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new HexColor.", "generated": "// DeepCopy creates a deep copy of this HexColor object.\n// This is useful for creating multiple copies of the same color that can be used independently without affecting each other's state. The returned value must be explicitly released when it is no longer needed to avoid memory leaks."}
{"id": 4466, "code": "func (t DateTime) MarshalJSON() ([]byte, error) {\n\tvar w jwriter.Writer\n\tt.MarshalEasyJSON(&w)\n\treturn w.BuildBytes()\n}", "reference": "// MarshalJSON returns the DateTime as JSON", "generated": "// MarshalJSON implements the json.Marshaler interface.\n//\n// This method is used to convert this object into JSON format for storage or transmission.\n// The result will be in the following format: \"2022-01-01T12:00:00Z\".\n// Note that it's recommended to use the EasyJSON"}
{"id": 4474, "code": "func (d *Duration) Scan(raw interface{}) error {\n\tswitch v := raw.(type) {\n\t// TODO: case []byte: // ?\n\tcase int64:\n\t\t*d = Duration(v)\n\tcase float64:\n\t\t*d = Duration(int64(v))\n\tcase nil:\n\t\t*d = Duration(0)\n\tdefault:\n\t\treturn fmt.Errorf(\"cannot sql.Scan() strfmt.Duration from: %#v\", v)\n\t}\n\n\treturn nil\n}", "reference": "// Scan reads a Duration value from database driver type.", "generated": "// Scan implements the Scanner method for duration values.\n// The format is \"int\" or \"float\". If it's \"strfmt.Duration\",\n// then we just return the value without doing any conversion,\n// since that would be redundant. We also support \"nil\"\n// which returns 0 seconds. This allows us"}
{"id": 4491, "code": "func (d *Date) DeepCopy() *Date {\n\tif d == nil {\n\t\treturn nil\n\t}\n\tout := new(Date)\n\td.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new Date.", "generated": "// DeepCopy copies all fields from this Date into another Date.\n// The recipient is responsible for ensuring that it has enough capacity to hold the copy.\n// If both values represent different dates in time zones other than UTC,\n// then they must be equal exactly; otherwise, one will be returned as false.\nfunc (d"}
{"id": 4522, "code": "func GrepNot(r string) Filter {\n\tre, err := regexp.Compile(r)\n\tif err != nil {\n\t\treturn FilterFunc(func(Arg) error { return err })\n\t}\n\treturn If(func(s string) bool { return !re.MatchString(s) })\n}", "reference": "// GrepNot emits every input x that does not match the regular expression r.", "generated": "// GrepNot returns a filter that matches strings which do NOT contain\n// the given regular expression pattern. The returned filter is\n// equivalent to filtering out all values for which re.match() would\n// match (i.e., it's like \"not grep\"). This can be used when we want\n// to"}
{"id": 4537, "code": "func FetchVersion(v discovery.ServerVersionInterface) (ret ServerVersion, err error) {\n\tversion, err := v.ServerVersion()\n\tif err != nil {\n\t\treturn ServerVersion{}, err\n\t}\n\treturn ParseVersion(version)\n}", "reference": "// FetchVersion fetches version information from discovery client, and parses", "generated": "// FetchVersion returns the version string from the given server.\n//\n// If there is no valid version in the provided server's Version(), it will return\n// an empty ServerVersion object along with an appropriate error message.\nfunc FetchVersion(v discovery.ServerVersionInterface) (ServerVersion, error) {... }"}
{"id": 4543, "code": "func (n ImageName) RegistryRepoName() string {\n\trepo := n.Repository\n\tif repo == \"\" {\n\t\trepo = \"library\"\n\t}\n\treturn fmt.Sprintf(\"%s/%s\", repo, n.Name)\n}", "reference": "// RegistryRepoName returns the \"repository\" as used in the registry URL", "generated": "// RegistryRepoName returns the registry repository name for this image.\n// If no Repository is set, it defaults to 'library'. Otherwise,\n// it uses the provided Repository and Name from the ImageName.\n// This method should be used when creating or updating Docker images in\n// the Docker Hub API. It's also"}
{"id": 4556, "code": "func MarkdownHelper(body string, help HelperContext) (template.HTML, error) {\n\tvar err error\n\tif help.HasBlock() {\n\t\tbody, err = help.Block()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\tb := github_flavored_markdown.Markdown([]byte(body))\n\treturn template.HTML(b), err\n}", "reference": "// Markdown converts the string into HTML using GitHub flavored markdown.", "generated": "// MarkdownHelper returns HTML from markdown body.\n//\n// If there is any block in the context it will be removed before returning the result.\nfunc MarkdownHelper(body string, help HelperContext) (template.HTML, error) { return }  // empty func declaration for code completion purposes only; do nothing! }"}
{"id": 4565, "code": "func (t *Template) Exec(ctx hctx.Context) (string, error) {\n\terr := t.Parse()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tev := compiler{\n\t\tctx:     ctx,\n\t\tprogram: t.program,\n\t}\n\n\ts, err := ev.compile()\n\treturn s, err\n}", "reference": "// Exec the template using the content and return the results", "generated": "// Execute executes this template's program in the given context.\n//\n// The result is returned as a string. If there was an error executing the\n// program, it will be returned instead of an empty string.\nfunc (t Template) Exec(ctx Context) (string, Error) { return t.Exec(hcontext.New"}
{"id": 4576, "code": "func hasPathPrefix(p string, s map[string]string) bool {\n\tfor prefix := range s {\n\t\tif strings.HasPrefix(p, prefix+\"/\") {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "reference": "// hasPathPrefix returns true if any of s is the prefix of p.", "generated": "// HasPathPrefix checks if p is a path that starts with any key in s.\n// This can be used to check for paths like \"/a/b\" against a set of prefixes \"b\", \"c\".\n//\n// If there's no match found, it returns false.\nfunc (s *Store) HasPath"}
{"id": 4588, "code": "func (a *Args) similar(r *Args, similar Similarity) bool {\n\tif a.Elided != r.Elided || len(a.Values) != len(r.Values) {\n\t\treturn false\n\t}\n\tif similar == AnyValue {\n\t\treturn true\n\t}\n\tfor i, l := range a.Values {\n\t\tswitch similar {\n\t\tcase ExactFlags, ExactLines:\n\t\t\tif l != r.Values[i] {\n\t\t\t\treturn false\n\t\t\t}\n\t\tdefault:\n\t\t\tif l.IsPtr() != r.Values[i].IsPtr() || (!l.IsPtr() && l != r.Values[i]) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\treturn true\n}", "reference": "// similar returns true if the two Args are equal or almost but not quite\n// equal.", "generated": "// similar checks if two Args have values that match each other according to the given similarity.\n// If any value is different from its counterpart in the second Arg, it returns false.\n// The comparison only considers whether both arguments point to the same object or not,\n// unless the similarity type allows for exact matching of flags/"}
{"id": 4597, "code": "func (s *Stack) merge(r *Stack) *Stack {\n\t// Assumes similar stacks have the same length.\n\tout := &Stack{\n\t\tCalls:  make([]Call, len(s.Calls)),\n\t\tElided: s.Elided,\n\t}\n\tfor i := range s.Calls {\n\t\tout.Calls[i] = s.Calls[i].merge(&r.Calls[i])\n\t}\n\treturn out\n}", "reference": "// merge merges two similar Stack, zapping out differences.", "generated": "// Merge two stack traces into one. The resulting trace is sorted by line number in ascending order.\n// If there's no overlap between the callsites, they're merged separately without merging their lines.\n// This method assumes that both input stacks have the same call count. It panics if this isn't true.\nfunc"}
{"id": 4624, "code": "func (b *base57) stringToNum(s string) (string, error) {\n\tn := big.NewInt(0)\n\n\tfor i := len(s) - 1; i >= 0; i-- {\n\t\tn.Mul(n, big.NewInt(b.alphabet.Length()))\n\n\t\tindex, err := b.alphabet.Index(string(s[i]))\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\n\t\tn.Add(n, big.NewInt(index))\n\t}\n\n\tx := fmt.Sprintf(\"%x\", n)\n\n\tif len(x) < 32 {\n\t\t// Pad the most significant bit (MSG) with 0 (zero) if the string is too short.\n\t\tx = strings.Repeat(\"0\", 32-len(x)) + x\n\t} else if len(x) > 32 {\n\t\treturn \"\", fmt.Errorf(\"UUID length overflow for %q\", s)\n\t}\n\n\treturn fmt.Sprintf(\"%s-%s-%s-%s-%s\", x[0:8], x[8:12], x[12:16], x[16:20], x[20:32]), nil\n}", "reference": "// stringToNum converts a string a number using the given alpabet.", "generated": "// StringToNum converts base-58 encoded UUID to its numerical representation in hexadecimal format. The result includes all four hyphens that define the structure of the UUID. If the input string is shorter than expected or contains invalid characters, it returns an empty string along with an appropriate error message."}
{"id": 4644, "code": "func (geoIndex *geoIndex) AddEntryAt(point Point) interface{} {\n\tsquare := cellOf(point, geoIndex.resolution)\n\n\tif _, ok := geoIndex.index[square]; !ok {\n\t\tgeoIndex.index[square] = geoIndex.newEntry()\n\t}\n\n\treturn geoIndex.index[square]\n}", "reference": "// AddEntryAt adds an entry if missing, returns the entry at specific position.", "generated": "// AddEntryAt adds point to index at given location.\n//\n// This method is used when adding points from external sources like\n// GeoJSON or other data formats that may contain multiple entries per square.\n// It ensures each entry in the index has only one associated point,\n// preventing duplicate entries for same coordinates.\n//"}
{"id": 4662, "code": "func BearingTo(p1, p2 Point) float64 {\n\tdLon := toRadians(p2.Lon() - p1.Lon())\n\n\tlat1 := toRadians(p1.Lat())\n\tlat2 := toRadians(p2.Lat())\n\n\ty := math.Sin(dLon) * math.Cos(lat2)\n\tx := math.Cos(lat1)*math.Sin(lat2) -\n\t\tmath.Sin(lat1)*math.Cos(lat2)*math.Cos(dLon)\n\tbrng := toDegrees(math.Atan2(y, x))\n\n\treturn brng\n}", "reference": "// BearingTo returns the bearing from p1 to p2", "generated": "// BearingTo returns bearing from point 1 to point 2 in degrees.\n// The points must be within [-180, +180] for longitude and [0,90] for latitude.\n// If both points have same coordinates (i.e., they're identical), it will return zero degree bearing.\n// Note:"}
{"id": 4720, "code": "func AddRelayTransport(ctx context.Context, h host.Host, upgrader *tptu.Upgrader, opts ...RelayOpt) error {\n\tn, ok := h.Network().(tpt.Network)\n\tif !ok {\n\t\treturn fmt.Errorf(\"%v is not a transport network\", h.Network())\n\t}\n\n\tr, err := NewRelay(ctx, h, upgrader, opts...)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// There's no nice way to handle these errors as we have no way to tear\n\t// down the relay.\n\t// TODO\n\tif err := n.AddTransport(r.Transport()); err != nil {\n\t\tlog.Error(\"failed to add relay transport:\", err)\n\t} else if err := n.Listen(r.Listener().Multiaddr()); err != nil {\n\t\tlog.Error(\"failed to listen on relay transport:\", err)\n\t}\n\treturn nil\n}", "reference": "// AddRelayTransport constructs a relay and adds it as a transport to the host network.", "generated": "AddRelayTransport adds a new Relay instance for the given Host. The Relay will be added to the Transport Network using its MultiAddress. If there was any issue adding or listening on this address it logs that information but continues running without stopping other transports in the same network. This can lead to unexpected behaviour when trying to"}
{"id": 4731, "code": "func NewServer() http.Handler {\n\tr := mux.NewRouter()\n\tr.Path(\"/hello\").Methods(\"GET\").HandlerFunc(handleHello)\n\treturn r\n}", "reference": "// NewServer makes a new example server.", "generated": "// NewServer returns a new HTTP server handler.\n//\n// The returned handler is configured to serve requests at path \"/hello\" using the handleHello function.\n// This allows for easy testing or demonstration of the hello endpoint without having to create a full web application.\nfunc (s *Service) NewServer() http.Handler {"}
{"id": 4742, "code": "func StringFindBetween(s, start, stop string) (between, remainder string, found bool) {\n\tbegin := strings.Index(s, start)\n\tif begin == -1 {\n\t\treturn \"\", s, false\n\t}\n\tbetween = s[begin+len(start):]\n\tend := strings.Index(between, stop)\n\tif end == -1 {\n\t\treturn \"\", s, false\n\t}\n\treturn between[:end], s[begin+len(start)+end+len(stop):], true\n}", "reference": "// StringFindBetween returns the string between the first occurrences of the tokens start and stop.\n// The remainder of the string after the stop token will be returned if found.\n// If the tokens couldn't be found, then the whole string will be returned as remainder.", "generated": "// StringFindBetween returns three values: the substring that is \"start\" followed by \"stop\", \n// the remaining part of the original string after removing this substring, and whether or not it was removed.\n// If there's no match for either'start' or'stop', then these return empty strings respectively,"}
{"id": 4755, "code": "func HTTPPostJSON(url string, data interface{}) error {\n\tb, err := json.MarshalIndent(data, \"\", \"  \")\n\tif err != nil {\n\t\treturn err\n\t}\n\tresponse, err := http.Post(url, \"application/json\", bytes.NewBuffer(b))\n\tif err == nil && (response.StatusCode < 200 || response.StatusCode > 299) {\n\t\terr = errors.New(response.Status)\n\t}\n\treturn err\n}", "reference": "// HTTPPostJSON marshalles data as JSON\n// and sends it as HTTP POST request to url.\n// If the response status code is not 200 OK,\n// then the status is returned as an error.", "generated": "// HTTPPostJSON sends JSON formatted data to the specified URL.\n//\n// The provided data is marshaled into a byte slice using MarshalIndent,\n// which adds indentation for readability but preserves the original structure.\n//\n// If the request fails or returns a non-2xx status code, it's wrapped in an Error object"}
{"id": 4764, "code": "func FileSize(filename string) int64 {\r\n\tinfo, err := os.Stat(filename)\r\n\tif err != nil {\r\n\t\treturn 0\r\n\t}\r\n\treturn info.Size()\r\n}", "reference": "// FileSize returns the size of a file or zero in case of an error.", "generated": "// Returns the size in bytes for the given file.\n//\n// If the file doesn't exist or can be accessed (e.g., due to permissions), it returns\n// zero. The error is ignored if present; instead, this method will return zero.\r\nfunc FileSize(filename string) int64 {\n\tinfo, err"}
{"id": 4781, "code": "func LoadTOMLBytes(conf interface{}, src []byte) error {\n\treturn loadConfigBytes(conf, src, nil, toml.Unmarshal)\n}", "reference": "// LoadTOMLBytes loads TOML bytes", "generated": "// LoadTOMLBytes loads TOML configuration from given byte slice.\n//\n// The returned value is stored in conf field if it's non-nil.\n//\n// If err!= nil, returns that error directly without storing anything into\n// conf.\nfunc (c *configLoader) LoadTOMLBytes(src []"}
{"id": 4787, "code": "func Crop(img image.Image, c Config) (image.Image, error) {\n\tmaxBounds := c.maxBounds(img.Bounds())\n\tsize := c.computeSize(maxBounds, image.Point{c.Width, c.Height})\n\tcr := c.computedCropArea(img.Bounds(), size)\n\tcr = img.Bounds().Intersect(cr)\n\n\tif c.Options&Copy == Copy {\n\t\treturn cropWithCopy(img, cr)\n\t}\n\tif dImg, ok := img.(subImageSupported); ok {\n\t\treturn dImg.SubImage(cr), nil\n\t}\n\treturn cropWithCopy(img, cr)\n}", "reference": "// Crop retrieves an image that is a\n// cropped copy of the original img.\n//\n// The crop is made given the informations provided in config.", "generated": "// Crop returns a cropped version of the given image.\n//\n// The cropping is done according to the provided config options.\n// If no copy option was specified in the configuration,\n// this method will return a new sub-image instead of copying the original one.\n// This can be more efficient if the caller doesn't need to"}
{"id": 4788, "code": "func (c Config) computeSize(bounds image.Rectangle, ratio image.Point) (p image.Point) {\n\tif c.Options&Ratio == Ratio {\n\t\t// Ratio option is on, so we take the biggest size available that fit the given ratio.\n\t\tif float64(ratio.X)/float64(bounds.Dx()) > float64(ratio.Y)/float64(bounds.Dy()) {\n\t\t\tp = image.Point{bounds.Dx(), (bounds.Dx() / ratio.X) * ratio.Y}\n\t\t} else {\n\t\t\tp = image.Point{(bounds.Dy() / ratio.Y) * ratio.X, bounds.Dy()}\n\t\t}\n\t} else {\n\t\tp = image.Point{ratio.X, ratio.Y}\n\t}\n\treturn\n}", "reference": "// computeSize retrieve the effective size of the cropped image.\n// It is defined by Height, Width, and Ratio option.", "generated": "// Compute the new point for the bounding box based on the provided ratio.\n// If the 'Ratio' option is enabled in the config, it will try to find the largest possible rectangle within the original one,\n// while maintaining the aspect ratio specified by the input ratio. Otherwise, it simply returns the exact points from the"}
{"id": 4790, "code": "func NewThen(command string, args ...string) Then {\n\treturn &gitCmd{command: command, args: args}\n}", "reference": "// NewThen creates a new Then command.", "generated": "// NewThen returns a new then command.\n//\n// The given command is executed if all previous commands in this chain\n// have succeeded or failed together (i.e., they were either both successful\n// or both unsuccessful). If any intermediate command fails, it will be\n// considered to have caused the entire pipeline to"}
{"id": 4792, "code": "func (g *gitCmd) Command() string {\n\treturn g.command + \" \" + strings.Join(g.args, \" \")\n}", "reference": "// Command returns the full command as configured in Caddyfile.", "generated": "// Command returns the command to be executed by this gitCommand.\n// The format is <command> [args].\n// If args is empty, it will return just the command without any arguments.\n// Otherwise, it will append all the given args after the last space in the command,\n// effectively joining them together into one"}
{"id": 4812, "code": "func (r *Repo) pull() error {\n\n\t// if not pulled, perform clone\n\tif !r.pulled {\n\t\treturn r.clone()\n\t}\n\n\t// if latest tag config is set\n\tif r.Branch == latestTag {\n\t\treturn r.checkoutLatestTag()\n\t}\n\n\tparams := append([]string{\"pull\"}, append(r.PullArgs, \"origin\", r.Branch)...)\n\tvar err error\n\tif err = r.gitCmd(params, r.Path); err == nil {\n\t\tr.pulled = true\n\t\tr.lastPull = time.Now()\n\t\tLogger().Printf(\"%v pulled.\\n\", r.URL)\n\t\tr.lastCommit, err = r.mostRecentCommit()\n\t}\n\treturn err\n}", "reference": "// pull performs git pull, or git clone if repository does not exist.", "generated": "// Pulls from remote repository.\n//\n// If branch has been updated since last pull, it will be checked out,\n// otherwise it will remain in current state. The most recent commit hash\n// returned by this method can then be used to verify that all changes have\n// been successfully applied locally. This operation may"}
{"id": 4815, "code": "func (r *Repo) Prepare() error {\n\t// check if directory exists or is empty\n\t// if not, create directory\n\tfs, err := gos.ReadDir(r.Path)\n\tif err != nil || len(fs) == 0 {\n\t\treturn gos.MkdirAll(r.Path, os.FileMode(0755))\n\t}\n\n\t// validate git repo\n\tisGit := false\n\tfor _, f := range fs {\n\t\tif f.IsDir() && f.Name() == \".git\" {\n\t\t\tisGit = true\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif isGit {\n\t\t// check if same repository\n\t\tvar repoURL string\n\t\tif repoURL, err = r.originURL(); err == nil {\n\t\t\tif strings.TrimSuffix(repoURL, \".git\") == strings.TrimSuffix(r.URL.Val(), \".git\") {\n\t\t\t\tr.pulled = true\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"cannot retrieve repo url for %v Error: %v\", r.Path, err)\n\t\t}\n\t\treturn fmt.Errorf(\"another git repo '%v' exists at %v\", repoURL, r.Path)\n\t}\n\treturn fmt.Errorf(\"cannot git clone into %v, directory not empty\", r.Path)\n}", "reference": "// Prepare prepares for a git pull\n// and validates the configured directory", "generated": "// Prepare checks that the given path is valid to be cloned from.\n// If it's already a Git repository, then we pull its latest commit,\n// otherwise we return an error indicating that another Git repository has been found in this location.\n// The method also creates the necessary directories if they don't exist yet. It"}
{"id": 4819, "code": "func (g *gitCmd) Stdin(stdin io.Reader) {\n\tg.Cmd.Stdin = stdin\n}", "reference": "// Stdin sets the process's standard input.", "generated": "// SetStdin sets the standard input for this command.\n//\n// This is used to capture output from other commands that may be run in parallel,\n// or when running git commands through pipes like 'grep' or'sed'.\n// If no reader is set, then the standard error will also become empty.\nfunc ("}
{"id": 4831, "code": "func (t TravisHook) handleSignature(r *http.Request, secret string) error {\n\tsignature := r.Header.Get(\"Authorization\")\n\tif signature == \"\" {\n\t\treturn errors.New(\"request sent no authorization signature\")\n\t}\n\tif secret == \"\" {\n\t\tLogger().Print(\"Unable to verify request signature. Secret not set in caddyfile!\\n\")\n\t\treturn nil\n\t}\n\n\tcontent := r.Header.Get(\"Travis-Repo-Slug\") + secret\n\thash := sha256.Sum256([]byte(content))\n\texpectedMac := hex.EncodeToString(hash[:])\n\tif signature != expectedMac {\n\t\tfmt.Println(signature, expectedMac)\n\t\treturn errors.New(\"Invalid authorization header\")\n\t}\n\treturn nil\n}", "reference": "// Check for an authorization signature in the request. Reject if not present. If validation required, check the sha", "generated": "Verify the Travis hook's signature is correct before processing its payload. If verification fails or if there is no Authorization header provided, return an appropriate error"}
{"id": 4833, "code": "func hookName(h hookHandler) string {\n\tfor name, handler := range handlers {\n\t\tif handler == h {\n\t\t\treturn name\n\t\t}\n\t}\n\treturn \"\"\n}", "reference": "// hookName returns the name of the hookHanlder h.", "generated": "// hookName returns the full name of the given hook handler.\n// If no matching handler is found in the list of registered hooks,\n// it will return an empty string. This can be used to construct a URL path for the hook.\n// For example: \"hookName(myHook)\" would result in \"/hooks/my"}
{"id": 4861, "code": "func (u *URL) Short() string {\n\tif u.Scheme == \"\" {\n\t\treturn \"\"\n\t}\n\n\ts := schemeMap[u.Scheme].Aliases[0]\n\n\tif u.Scheme == \"odbc\" || u.Scheme == \"oleodbc\" {\n\t\tn := u.Proto\n\t\tif v, ok := schemeMap[n]; ok {\n\t\t\tn = v.Aliases[0]\n\t\t}\n\t\ts += \"+\" + n\n\t} else if u.Proto != \"tcp\" {\n\t\ts += \"+\" + u.Proto\n\t}\n\n\ts += \":\"\n\n\tif u.User != nil {\n\t\tif un := u.User.Username(); un != \"\" {\n\t\t\ts += un + \"@\"\n\t\t}\n\t}\n\n\tif u.Host != \"\" {\n\t\ts += u.Host\n\t}\n\n\tif u.Path != \"\" && u.Path != \"/\" {\n\t\ts += u.Path\n\t}\n\n\tif u.Opaque != \"\" {\n\t\ts += u.Opaque\n\t}\n\n\treturn s\n}", "reference": "// Short provides a short description of the user, host, and database.", "generated": "// Short returns a short URL for this one. The format is similar to that returned by\n// http://short.url/... but it's more compact. It includes only the protocol,\n// host, path, query parameters, and opaque data from the original URL.\n// If there was no user or password in the"}
{"id": 4873, "code": "func (e *hdbError) Error() string {\n\tif e.stmtNo != -1 {\n\t\treturn fmt.Sprintf(\"SQL %s %d - %s (statement no: %d)\", e.errorLevel, e.errorCode, e.errorText, e.stmtNo)\n\t}\n\treturn fmt.Sprintf(\"SQL %s %d - %s\", e.errorLevel, e.errorCode, e.errorText)\n}", "reference": "// Error implements the Error interface.", "generated": "// Error returns error message for this hdb.Error object.\n//\n// The format is similar to SQL error messages returned by HDB database\n// library in C language. It includes level, code, text, statement number if available,\n// or just the general error message without any additional information. This can be used"}
{"id": 4883, "code": "func StringSize(s string) int {\n\tn := 0\n\tfor _, r := range s {\n\t\tn += RuneLen(r)\n\t}\n\treturn n\n}", "reference": "// StringSize is like Size with a string as parameter.", "generated": "// StringSize returns the length in bytes for the given string.\n//\n// This is used to determine how much memory will be required when storing or sending\n// this string over a network connection. It's more efficient than using len() because it\n// takes into account any non-ASCII characters that require multiple bytes per"}
{"id": 4887, "code": "func On() bool {\n\ttracer.mu.RLock()\n\ton := tracer.on\n\ttracer.mu.RUnlock()\n\treturn on\n}", "reference": "// On returns if tracing methods output is active.", "generated": "// Returns whether tracing is enabled or not.\nfunc (t *Tracer) On() bool { return t.On }"}
{"id": 4913, "code": "func (r *Reader) ReadUint32() uint32 {\n\tif r.err != nil {\n\t\treturn 0\n\t}\n\tvar n int\n\tn, r.err = io.ReadFull(r.rd, r.b[:4])\n\tr.cnt += n\n\tif r.err != nil {\n\t\treturn 0\n\t}\n\treturn binary.LittleEndian.Uint32(r.b[:4])\n}", "reference": "// ReadUint32 reads and returns an uint32.", "generated": "// ReadUint32 reads up to four bytes from the reader into a uint32.\n//\n// If there is no more data in the stream, it returns zero.\n// The error returned by this method indicates whether any errors occurred during reading,\n// or if the end was reached before enough data could be read for a valid"}
{"id": 4918, "code": "func (r *Reader) ReadCesu8(size int) []byte {\n\tif r.err != nil {\n\t\treturn nil\n\t}\n\tp := make([]byte, size)\n\tvar n int\n\tn, r.err = io.ReadFull(r.rd, p)\n\tr.cnt += n\n\tif r.err != nil {\n\t\treturn nil\n\t}\n\tr.tr.Reset()\n\tif n, _, r.err = r.tr.Transform(p, p, true); r.err != nil { // inplace transformation\n\t\treturn nil\n\t}\n\treturn p[:n]\n}", "reference": "// ReadCesu8 reads a size CESU-8 encoded byte sequence and returns an UTF-8 byte slice.", "generated": "// ReadCesu8 reads up to'size' bytes from the reader into a byte slice.\n//\n// If there is no more data in the stream, it returns an empty byte slice.\n// The returned byte slice may be modified by the Transform method if necessary,\n// but this will only happen for internal use"}
{"id": 4923, "code": "func (w *Writer) Write(p []byte) {\n\tif w.err != nil {\n\t\treturn\n\t}\n\tw.wr.Write(p)\n}", "reference": "// Write writes the contents of p.", "generated": "// Write writes data to writer.\n//\n// If err is set in Writer, it will be returned immediately without writing any data.\nfunc (w *Writer) Write(p []byte) error { return w.writeWithErr(w.err, p); }"}
{"id": 4938, "code": "func (c *Connector) Locale() string {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\treturn c.locale\n}", "reference": "// Locale returns the locale of the connector.", "generated": "// Returns the locale used by this connector.\n// The value is set when the connector was created using NewConnectorWithLocale().\n// If no locale has been specified, returns \"en_US\". This field can be changed after creation,\n// but it will only affect future requests to this connector. Existing connections remain unchanged.\nfunc"}
{"id": 4942, "code": "func (c *Connector) SetTLSConfig(tlsConfig *tls.Config) error {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.tlsConfig = tlsConfig\n\treturn nil\n}", "reference": "// SetTLSConfig sets the TLS configuration of the connector.", "generated": "// SetTLSConfig sets the TLS configuration for this connector.\n//\n// This method is used to set up the connection's SSL/TLS settings before making any connections.\n// The provided config will be applied when establishing new connections using this connector.\n// If no TLS configuration has been specified yet, calling this method without providing a"}
{"id": 4958, "code": "func Slice(arr []byte, count int) [][]byte {\n\n\tsliceCount := len(arr) / count\n\tresult := make([][]byte, sliceCount)\n\n\tfor i := 0; i < sliceCount; i++ {\n\t\tstart := i * count\n\t\tend := i*count + count\n\n\t\tresult[i] = arr[start:end]\n\t}\n\n\treturn result\n}", "reference": "// Slice is splitting input byte array into slice of subarrays. Each of count length.", "generated": "// Slice splits the given byte array into slices based on the specified length.\n//\n// The resulting slices will be used to store data in memory efficiently,\n// allowing for faster access times compared to using arrays or other types that require more overhead.\n//\n// This is particularly useful when working with large amounts of binary data where performance"}
{"id": 4965, "code": "func Decode(data string) ([]byte,error) {\n\tdata = strings.Replace(data, \"-\", \"+\", -1) // 62nd char of encoding\n\tdata = strings.Replace(data, \"_\", \"/\", -1) // 63rd char of encoding\n\t\n\tswitch(len(data) % 4) { // Pad with trailing '='s\n\t\tcase 0:             // no padding\n\t\tcase 2: data+=\"==\"  // 2 pad chars\n\t\tcase 3:\tdata+=\"=\"   // 1 pad char\t\t\n\t}\n\t\t\n\treturn base64.StdEncoding.DecodeString(data)\n}", "reference": "// Decode decodes base64url string to byte array", "generated": "// Decode decodes a Base64 encoded byte slice.\n//\n// The input is expected to be in URL-safe format (i.e., it contains only A-Z,\n// a-z, 0-9, +, /).\n//\n// If the length of the decoded bytes is less than the original length by at least"}
{"id": 4969, "code": "func DerivePBKDF2(password, salt []byte, iterationCount, keyBitLength int, h hash.Hash) []byte {\n\n\tprf := hmac.New(func() hash.Hash { return h }, password)\n\thLen := prf.Size()\n\tdkLen := keyBitLength >> 3 //size of derived key in bytes\n\n\tl := int(math.Ceil(float64(dkLen) / float64(hLen))) // l = CEIL (dkLen / hLen)\n\tr := dkLen - (l-1)*hLen\n\n\t// 1. If dkLen > (2^32 - 1) * hLen, output \"derived key too long\" and stop.\n\tif dkLen > MaxInt {\n\t\tpanic(fmt.Sprintf(\"kdf.DerivePBKDF2: expects derived key size to be not more that (2^32-1) bits, but was requested %v bits.\", keyBitLength))\n\t}\n\n\tdk := make([]byte, 0, dkLen)\n\n\tfor i := 0; i < l; i++ {\n\n\t\tt := f(salt, iterationCount, i+1, prf) // T_l = F (P, S, c, l)\n\n\t\tif i == (l - 1) {\n\t\t\tt = t[:r]\n\t\t} // truncate last block to r bits\n\n\t\tdk = append(dk, t...) // DK = T_1 || T_2 ||  ...  || T_l<0..r-1>\n\t}\n\n\treturn dk\n}", "reference": "// DerivePBKDF2 implements Password Based Key Derivation Function 2, RFC 2898. Derives key of keyBitLength size, given password, salt, iteration count and hash function", "generated": "// DerivePBKDF2 derives a PBKDF2-derived key from given parameters using HMAC-SHA256 for hashing.\n//\n// The resulting key is truncated if its length exceeds maxKeySize.\n//\n// Parameters:\n//   password     [string] Password used by user.\n//   salt         [string]"}
{"id": 4970, "code": "func ReadPrivate(raw []byte) (key *ecdsa.PrivateKey,err error) {\n\tvar encoded *pem.Block\n\n\tif encoded, _ = pem.Decode(raw); encoded == nil {\n\t\treturn nil, errors.New(\"Ecc.ReadPrivate(): Key must be PEM encoded PKCS1 or PKCS8 EC private key\")\n\t}\n\n\tvar parsedKey interface{}\n\n\tif parsedKey,err=x509.ParseECPrivateKey(encoded.Bytes);err!=nil {\n\t\tif parsedKey, err = x509.ParsePKCS8PrivateKey(encoded.Bytes);err!=nil {\n\t\t\treturn nil,err\n\t\t}\n\t}\n\n\tvar ok bool\n\t\t\n\tif key,ok=parsedKey.(*ecdsa.PrivateKey);!ok {\n\t\treturn nil, errors.New(\"Ecc.ReadPrivate(): Key is not valid *ecdsa.PrivateKey\")\n\t}\n\t\n\treturn key,nil\n}", "reference": "// ReadPrivate loads ecdsa.PrivateKey from given PKCS1 or PKCS8 blobs", "generated": "// ReadPrivate reads raw data into an ecDSA PrivateKey.\n//\n// The input should be either a PEM-encoded PKCS#1 or #2 EC private key,\n// or a PEM-encoded PKCS#8 EC private key in DER format.\n//\n// If the input is neither of these formats, it returns an"}
{"id": 4978, "code": "func (c *Consumer) TailingLogs(appGuid, authToken string) (<-chan *events.LogMessage, <-chan error) {\n\treturn c.tailingLogs(appGuid, authToken, true)\n}", "reference": "// TailingLogs listens indefinitely for log messages only; other event types\n// are dropped.\n// Whenever an error is encountered, the error will be sent down the error\n// channel and TailingLogs will attempt to reconnect up to 5 times.  After\n// five failed reconnection attempts, TailingLogs will give up and close the\n// error and LogMessage channels.\n//\n// If c is closed, the returned channels will both be closed.\n//\n// Errors must be drained from the returned error channel for it to continue\n// retrying; if they are not drained, the connection attempts will hang.", "generated": "// TailingLogs returns two channels: one for log messages and another\n// for errors that occur while tailing logs.\n//\n// The returned channel is closed when there's no more new log message to read from\n// the consumer or if it encounters any error during logging process.\nfunc (c *Consumer) T"}
{"id": 4980, "code": "func (c *Consumer) Stream(appGuid string, authToken string) (outputChan <-chan *events.Envelope, errorChan <-chan error) {\n\treturn c.runStream(appGuid, authToken, true)\n}", "reference": "// Stream listens indefinitely for all log and event messages.\n//\n// Messages are presented in the order received from the loggregator server.\n// Chronological or other ordering is not guaranteed. It is the responsibility\n// of the consumer of these channels to provide any desired sorting mechanism.\n//\n// Whenever an error is encountered, the error will be sent down the error\n// channel and Stream will attempt to reconnect indefinitely.", "generated": "// Run stream for given app guid and auth token.\n//\n// Returns output channel to receive envelopes from consumer\n// and error channel if any errors occur during processing.\nfunc (c *Consumer) runStream(appGuid string, authToken string, isStreaming bool) (<-chan *events.Envelope, <-chan error)"}
{"id": 5001, "code": "func (d *Dataset) Snapshot(name string, recursive bool) (*Dataset, error) {\n\targs := make([]string, 1, 4)\n\targs[0] = \"snapshot\"\n\tif recursive {\n\t\targs = append(args, \"-r\")\n\t}\n\tsnapName := fmt.Sprintf(\"%s@%s\", d.Name, name)\n\targs = append(args, snapName)\n\t_, err := zfs(args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn GetDataset(snapName)\n}", "reference": "// Snapshot creates a new ZFS snapshot of the receiving dataset, using the\n// specified name.  Optionally, the snapshot can be taken recursively, creating\n// snapshots of all descendent filesystems in a single, atomic operation.", "generated": "// Snap takes a snapshot of this dataset or its sub-datasets if specified.\n// The resulting dataset is returned by reference to allow for further manipulation.\n// If no argument is given then all data in the parent will be preserved,\n// otherwise only that part which was modified since the last snapshot will be saved.\n// Note"}
{"id": 5017, "code": "func DialWithTimeout(url string, timeout time.Duration) (*Session, error) {\n\tinfo, err := ParseURL(url)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tinfo.Timeout = timeout\n\treturn DialWithInfo(info)\n}", "reference": "// DialWithTimeout works like Dial, but uses timeout as the amount of time to\n// wait for a server to respond when first connecting and also on follow up\n// operations in the session. If timeout is zero, the call may block\n// forever waiting for a connection to be made.\n//\n// See SetSyncTimeout for customizing the timeout for the session.", "generated": "// DialWithTimeout returns a new session for the given URL.\n//\n// If no timeout is specified (i.e., 0), it will be set to the default value returned by\n// NewDefaultDialer(). The dialer used in this call must support setting timeouts; otherwise,\n// an error will be"}
{"id": 5025, "code": "func (s *Session) LogoutAll() {\n\ts.m.Lock()\n\tfor _, cred := range s.creds {\n\t\tif s.masterSocket != nil {\n\t\t\ts.masterSocket.Logout(cred.Source)\n\t\t}\n\t\tif s.slaveSocket != nil {\n\t\t\ts.slaveSocket.Logout(cred.Source)\n\t\t}\n\t}\n\ts.creds = s.creds[0:0]\n\ts.m.Unlock()\n}", "reference": "// LogoutAll removes all established authentication credentials for the session.", "generated": "// LogoutAll closes all connections to remote servers for this session.\n// This is useful when we want to close multiple sessions at once or\n// after some error has occurred that requires us to log out from any server,\n// but only if there's more than one connection open. If no other\n// credentials exist in"}
{"id": 5048, "code": "func (q *Query) LogReplay() *Query {\n\tq.m.Lock()\n\tq.op.flags |= flagLogReplay\n\tq.m.Unlock()\n\treturn q\n}", "reference": "// LogReplay enables an option that optimizes queries that are typically\n// made on the MongoDB oplog for replaying it. This is an internal\n// implementation aspect and most likely uninteresting for other uses.\n// It has seen at least one use case, though, so it's exposed via the API.", "generated": "// LogReplay sets the log replay flag to true for this query.\n// This is used by the server when it needs to replay queries from a previous run,\n// such as during recovery or replication. The client will see these logs in its\n// output but they won't be included in any results returned to the"}
{"id": 5071, "code": "func tokenFor(t *transaction) token {\n\tnonce := t.Nonce\n\tif nonce == \"\" {\n\t\tnonce = newNonce()\n\t}\n\treturn token(t.Id.Hex() + \"_\" + nonce)\n}", "reference": "// tokenFor returns a unique transaction token that\n// is composed by t's id and a nonce. If t already has\n// a nonce assigned to it, it will be used, otherwise\n// a new nonce will be generated.", "generated": "// Token returns a unique identifier for this transaction.\n//\n// The returned ID is guaranteed to be different from any other transaction's\n// ID that has been created since the last time we generated IDs (i.e., it will\n// never collide). This means that if two transactions have the same hash,\n// they must"}
{"id": 5073, "code": "func (r *Runner) Run(ops []Op, id bson.ObjectId, info interface{}) (err error) {\n\tconst efmt = \"error in transaction op %d: %s\"\n\tfor i := range ops {\n\t\top := &ops[i]\n\t\tif op.C == \"\" || op.Id == nil {\n\t\t\treturn fmt.Errorf(efmt, i, \"C or Id missing\")\n\t\t}\n\t\tchanges := 0\n\t\tif op.Insert != nil {\n\t\t\tchanges++\n\t\t}\n\t\tif op.Update != nil {\n\t\t\tchanges++\n\t\t}\n\t\tif op.Remove {\n\t\t\tchanges++\n\t\t}\n\t\tif changes > 1 {\n\t\t\treturn fmt.Errorf(efmt, i, \"more than one of Insert/Update/Remove set\")\n\t\t}\n\t\tif changes == 0 && op.Assert == nil {\n\t\t\treturn fmt.Errorf(efmt, i, \"none of Assert/Insert/Update/Remove set\")\n\t\t}\n\t}\n\tif id == \"\" {\n\t\tid = bson.NewObjectId()\n\t}\n\n\t// Insert transaction sooner rather than later, to stay on the safer side.\n\tt := transaction{\n\t\tId:    id,\n\t\tOps:   ops,\n\t\tState: tpreparing,\n\t\tInfo:  info,\n\t}\n\tif err = r.tc.Insert(&t); err != nil {\n\t\treturn err\n\t}\n\tif err = flush(r, &t); err != nil {\n\t\treturn err\n\t}\n\tif t.State == taborted {\n\t\treturn ErrAborted\n\t} else if t.State != tapplied {\n\t\tpanic(fmt.Errorf(\"invalid state for %s after flush: %q\", &t, t.State))\n\t}\n\treturn nil\n}", "reference": "// Run creates a new transaction with ops and runs it immediately.\n// The id parameter specifies the transaction id, and may be written\n// down ahead of time to later verify the success of the change and\n// resume it, when the procedure is interrupted for any reason. If\n// empty, a random id will be generated.\n// The info parameter, if not nil, is included under the \"i\"\n// field of the transaction document.\n//\n// Operations across documents are not atomically applied, but are\n// guaranteed to be eventually all applied in the order provided or\n// all aborted, as long as the affected documents are only modified\n// through transactions. If documents are simultaneously modified\n// by transactions and out of transactions the behavior is undefined.\n//\n// If Run returns no errors, all operations were applied successfully.\n// If it returns ErrAborted, one or more operations can't be applied\n// and the transaction was entirely aborted with no changes performed.\n// Otherwise, if the transaction is interrupted while running for any\n// reason, it may be resumed explicitly or by attempting to apply\n// another transaction on any of the documents targeted by ops, as\n// long as the interruption was made after the transaction document\n// itself was inserted. Run Resume with the obtained transaction id\n// to confirm whether the transaction was applied or not.\n//\n// Any number of transactions may be run concurrently, with one\n// runner or many.", "generated": "Run runs all operations within this runner's context. It returns any errors that occur during execution. If no transactions were run, it will return nil. The operation is executed using the tc.Run method which takes care of running the actual database query. After executing each operation, we call Flush() to ensure consistency across different databases"}
{"id": 5076, "code": "func SetChaos(c Chaos) {\n\tchaosSetting = c\n\tchaosEnabled = c.KillChance > 0 || c.SlowdownChance > 0\n}", "reference": "// SetChaos sets the failure injection parameters to c.", "generated": "// SetChaos sets chaos settings for this service.\n//\n// This is used to set up kill chance or slowdown chance in case of failure,\n// which can be useful during testing or development.\n// The default value will always return true if there's any chance at all that it might fail.\nfunc (s *Service"}
{"id": 5099, "code": "func NewObjectIdWithTime(t time.Time) ObjectId {\n\tvar b [12]byte\n\tbinary.BigEndian.PutUint32(b[:4], uint32(t.Unix()))\n\treturn ObjectId(string(b[:]))\n}", "reference": "// NewObjectIdWithTime returns a dummy ObjectId with the timestamp part filled\n// with the provided number of seconds from epoch UTC, and all other parts\n// filled with zeroes. It's not safe to insert a document with an id generated\n// by this method, it is useful only for queries to find documents with ids\n// generated before or after the specified timestamp.", "generated": "// NewObjectIdWithTime returns a new ObjectID that is based on the given Unix timestamp.\n// The resulting ID will be unique for each second since epoch (January 1st, 1970).\n// This method can only be used to create IDs from timestamps before January 19th, 2038,\n//"}
{"id": 5102, "code": "func (id ObjectId) Time() time.Time {\n\t// First 4 bytes of ObjectId is 32-bit big-endian seconds from epoch.\n\tsecs := int64(binary.BigEndian.Uint32(id.byteSlice(0, 4)))\n\treturn time.Unix(secs, 0)\n}", "reference": "// Time returns the timestamp part of the id.\n// It's a runtime error to call this method with an invalid id.", "generated": "// Time returns the Unix timestamp for this object's creation date in UTC,\n// which corresponds to its first four bytes being a 32 bit integer representing\n// seconds since January 1st, 1970 at midnight GMT. This value will be set when\n// creating new objects or updating existing ones that have been"}
{"id": 5107, "code": "func hasMinOf(top interface{}, current interface{}, field interface{}, param string) bool {\n\n\treturn isGte(top, current, field, param)\n}", "reference": "// min tests whether a variable value is larger or equal to a given\n// number. For number types, it's a simple lesser-than test; for\n// strings it tests the number of characters whereas for maps\n// and slices it tests the number of items.", "generated": "// hasMin returns true if top >= current for given parameter.\n//\n// This method checks whether value in 'top' object matches minimum required\n// condition specified by 'param'. If it's so then this method will return\n// true; otherwise false.\n//\n// The comparison logic used here is based on Go language"}
{"id": 5109, "code": "func Connect() {\n\turi := os.Getenv(\"MONGODB_URL\")\n\n\tif len(uri) == 0 {\n\t\turi = MongoDBUrl\n\t}\n\n\tmongo, err := mgo.ParseURL(uri)\n\ts, err := mgo.Dial(uri)\n\tif err != nil {\n\t\tfmt.Printf(\"Can't connect to mongo, go error %v\\n\", err)\n\t\tpanic(err.Error())\n\t}\n\ts.SetSafe(&mgo.Safe{})\n\tfmt.Println(\"Connected to\", uri)\n\tSession = s\n\tMongo = mongo\n}", "reference": "// Connect connects to mongodb", "generated": "// Connect establishes connection to MongoDB server.\n//\n// If MONGODB_URL environment variable is set it will be used for connecting,\n// otherwise default URL from MongoDBUrl constant will be used.\n// Connection is established using mgo package which provides safe way to interact\n// with MongoDB database. Session object holds current session state while"}
{"id": 5112, "code": "func (file *GridFile) SetChunkSize(bytes int) {\n\tfile.assertMode(gfsWriting)\n\tdebugf(\"GridFile %p: setting chunk size to %d\", file, bytes)\n\tfile.m.Lock()\n\tfile.doc.ChunkSize = bytes\n\tfile.m.Unlock()\n}", "reference": "// SetChunkSize sets size of saved chunks.  Once the file is written to, it\n// will be split in blocks of that size and each block saved into an\n// independent chunk document.  The default chunk size is 256kb.\n//\n// It is a runtime error to call this function once the file has started\n// being written to.", "generated": "// SetChunkSize sets the number of bytes per chunk for this GridFile.\n// The default is 4096KB; if set to zero, then all data will be stored in one large block,\n// which can lead to performance issues when writing or reading from disk.\n//\n// Note that changing the chunk size after"}
{"id": 5120, "code": "func (file *GridFile) Read(b []byte) (n int, err error) {\n\tfile.assertMode(gfsReading)\n\tfile.m.Lock()\n\tdebugf(\"GridFile %p: reading at offset %d into buffer of length %d\", file, file.offset, len(b))\n\tdefer file.m.Unlock()\n\tif file.offset == file.doc.Length {\n\t\treturn 0, io.EOF\n\t}\n\tfor err == nil {\n\t\ti := copy(b, file.rbuf)\n\t\tn += i\n\t\tfile.offset += int64(i)\n\t\tfile.rbuf = file.rbuf[i:]\n\t\tif i == len(b) || file.offset == file.doc.Length {\n\t\t\tbreak\n\t\t}\n\t\tb = b[i:]\n\t\tfile.rbuf, err = file.getChunk()\n\t}\n\treturn n, err\n}", "reference": "// Read reads into b the next available data from the file and\n// returns the number of bytes written and an error in case\n// something wrong happened.  At the end of the file, n will\n// be zero and err will be set to os.EOF.\n//\n// The parameters and behavior of this function turn the file\n// into an io.Reader.", "generated": "// Read reads data from this GridFile's underlying stream into the given byte slice.\n//\n// The number of bytes read is returned along with any errors that occurred during\n// the operation. If no more data can be read without blocking or returning an I/O\n// error, then zero will be written to the first"}
{"id": 5123, "code": "func invertAttributes(windowsMode uint16) uint16 {\n\treturn (COMMON_LVB_MASK & windowsMode) | ((FOREGROUND_MASK & windowsMode) << 4) | ((BACKGROUND_MASK & windowsMode) >> 4)\n}", "reference": "// invertAttributes inverts the foreground and background colors of a Windows attributes value", "generated": "// Invert attributes for given window mode.\n//\n// This is used to convert between common LVB mask and foreground/background\n// masks in Windows API calls. The result will be either all bits set or none,\n// depending on whether there was any overlap between original modes.\nfunc InvertAttributes(windowsMode uint16"}
{"id": 5157, "code": "func (s *SegmentStack) Peek() int64 {\n\tif s.Len() == 0 {\n\t\treturn rootSegment\n\t}\n\treturn s.s[s.Len()-1]\n}", "reference": "// Peek returns id from the top of the stack. It returns rootSegment if the stack is empty.", "generated": "// Peek returns the value at the top segment without removing it.\n// If there is no stack, return rootSegment. Otherwise,\n// return the last element in the stack. The returned value will be removed from the stack when next is called."}
{"id": 5171, "code": "func (t *tx) StartExternal(host, name string) error {\n\tt.mtx.Lock()\n\tdefer t.mtx.Unlock()\n\n\tid, err := t.Tracer.BeginExternalSegment(t.id, t.ss.Peek(), host, name)\n\tif err != nil {\n\t\treturn err\n\t}\n\tt.ss.Push(id)\n\treturn nil\n}", "reference": "// StartExternal starts an external segment.", "generated": "// StartExternal starts tracing for external service calls.\n//\n// This method is used to start tracing when calling services outside this transaction,\n// such as making HTTP requests or sending messages over AMQP channels.\n//\n// The returned ID can be passed back into Tracer.End() once the call has completed.\n// If there's"}
{"id": 5186, "code": "func NewClusterWithHost(hosts ...*URI) *Cluster {\n\tcluster := DefaultCluster()\n\tfor _, host := range hosts {\n\t\tcluster.AddHost(host)\n\t}\n\treturn cluster\n}", "reference": "// NewClusterWithHost returns a cluster with the given URIs.", "generated": "// NewClusterWithHost returns a new Cluster instance initialized from given URIs.\n// The returned cluster is configured to connect to all provided hosts in parallel,\n// allowing for concurrent execution across multiple nodes if needed. If no URI is\n// passed, it defaults to the default cluster configuration (i.e., local node)."}
{"id": 5206, "code": "func (idx *Index) BatchQuery(queries ...PQLQuery) *PQLBatchQuery {\n\tstringQueries := make([]string, 0, len(queries))\n\thasKeys := false\n\tfor _, query := range queries {\n\t\tserializedQuery := query.Serialize()\n\t\thasKeys = hasKeys || serializedQuery.HasWriteKeys()\n\t\tstringQueries = append(stringQueries, serializedQuery.String())\n\t}\n\treturn &PQLBatchQuery{\n\t\tindex:   idx,\n\t\tqueries: stringQueries,\n\t\thasKeys: hasKeys,\n\t}\n}", "reference": "// BatchQuery creates a batch query with the given queries.", "generated": "// BatchQuery creates a new PQLBatchQuery from multiple PQLQuery instances.\n// The returned batch query can be executed using Index.BatchExecute() or Index.Execute().\n// If any of the input queries have WriteKey(), they will all be written to disk during execution.\n// Otherwise, only read-only operations will occur"}
{"id": 5218, "code": "func OptFieldTypeMutex(cacheType CacheType, cacheSize int) FieldOption {\n\treturn func(options *FieldOptions) {\n\t\toptions.fieldType = FieldTypeMutex\n\t\toptions.cacheType = cacheType\n\t\toptions.cacheSize = cacheSize\n\t}\n}", "reference": "// OptFieldTypeMutex adds a mutex field.", "generated": "// OptFieldTypeMutex sets field type to Mutex and options for caching.\n//\n// Options must be set before calling this method. The following fields will override their default values if they exist in options:\n//\n// - fieldType: Set to Mutex (default).\n// - cacheType: Use specified cache type or use default one based"}
{"id": 5230, "code": "func (f *Field) Rows() *PQLRowsQuery {\n\ttext := fmt.Sprintf(\"Rows(field='%s')\", f.name)\n\treturn NewPQLRowsQuery(text, f.index, nil)\n}", "reference": "// Rows creates a Rows query with defaults", "generated": "// Rows returns a PQL query that selects all rows from this field.\n// The returned query is used to select data for a given row in the table.\n// This method can be called multiple times without any side effects,\n// but it will always return the same result set if no other queries have been\n// executed"}
{"id": 5261, "code": "func OptClientConnectTimeout(timeout time.Duration) ClientOption {\n\treturn func(options *ClientOptions) error {\n\t\toptions.ConnectTimeout = timeout\n\t\treturn nil\n\t}\n}", "reference": "// OptClientConnectTimeout is the maximum time to connect in nanoseconds.", "generated": "// OptClientConnectTimeout sets the connection timeout for the client.\n//\n// This option is used to set the maximum amount of time that the client will wait before giving up waiting for a connection.\n//\n// If this value is 0 or negative, then there is no limit on how long the client can take to connect"}
{"id": 5271, "code": "func OptImportThreadCount(count int) ImportOption {\n\treturn func(options *ImportOptions) error {\n\t\toptions.threadCount = count\n\t\treturn nil\n\t}\n}", "reference": "// OptImportThreadCount is the number of goroutines allocated for import.", "generated": "// OptImportThreadCount sets the number of threads to use for importing.\n//\n// This option is used when calling import() or importWithConfig(). The default value is 1,\n// which means that only one thread will be used for importing. If set to -1, no threading\n// will occur at all"}
{"id": 5282, "code": "func NewValueIterator(format Format, reader io.Reader) *Iterator {\n\treturn NewIterator(reader, FieldValueUnmarshaller(format))\n}", "reference": "// NewValueIterator creates a new iterator for value data.", "generated": "// NewValueIterator returns a new ValueIterator that reads from the given\n// format-specific unmarshaller.\n//\n// The returned iterator is initialized to read from the provided Reader,\n// which must be non-nil. If it's nil, the iterator will panic when first called.\n// Otherwise, the Reader may be closed at"}
{"id": 5287, "code": "func elementsFromLine(config *Config, line string) []interface{} {\n\tseparated := strings.Split(line, config.Delim)\n\telements := make([]interface{}, len(separated))\n\tfor i, field := range separated {\n\t\tvalue := field\n\t\tif !config.NoTrim {\n\t\t\tvalue = strings.TrimSpace(field)\n\t\t}\n\n\t\t// Apply the empty value, if configured.\n\t\tif value == \"\" && config.Empty != \"\" {\n\t\t\tvalue = config.Empty\n\t\t}\n\t\telements[i] = value\n\t}\n\treturn elements\n}", "reference": "// elementsFromLine returns a list of elements, each representing a single\n// item which will belong to a column of output.", "generated": "// ElementsFromLine returns a slice of values from a given input line,\n// formatted according to the provided Config struct settings. The returned\n// slice is always non-nil; it may be empty or contain only one element.\n// If no delimiter was specified in the configuration (i.e., Delim is 0),"}
{"id": 5306, "code": "func postEOFCheck(c *Cmp, r io.Reader, buf []byte) bool {\n\ttmpLR, isLR := r.(*io.LimitedReader)\n\tif isLR {\n\t\t// If the limit wasn't reached, then we don't need to check for\n\t\t// more data after the EOF\n\t\tif tmpLR.N > 0 {\n\t\t\treturn true\n\t\t}\n\n\t\t// Use the internal Reader for checking for more data\n\t\tr = tmpLR.R\n\t} else {\n\t\tc.debugf(\"compareReader: A type assertion of LimitedReader unexpectedly failed\\n\")\n\t}\n\n\t// Attempt to read more bytes from the original readers, to determine\n\t// if we should return an error for exceeding the MaxSize read limit.\n\tn, _ := readPartial(c, r, buf, 0, len(buf))\n\treturn n == 0\n}", "reference": "// postEOFCheck returns false if there is more data in a LimitedReader after\n// hitting EOF", "generated": "// postEOFCheck checks whether there's any remaining data in the reader that was\n// passed into compareReaders(). It returns false when no additional data can be\n// found (i.e., it has been exhausted), or true otherwise. This method will only\n// work correctly if the input reader implements io.Read"}
{"id": 5311, "code": "func exist(file string) (bool, error) {\n\t_, err := os.Stat(file)\n\tif err != nil {\n\t\tif err == os.ErrNotExist {\n\t\t\treturn false, nil\n\t\t}\n\t\treturn false, err\n\t}\n\treturn true, nil\n}", "reference": "// exist checks if the file exists.", "generated": "// Exist checks if file exists.\n//\n// If it doesn't exist, returns false without any errors.\n// Otherwise, returns true along with no error unless there's another OS-related issue."}
{"id": 5340, "code": "func (e *edit) Comment(reLine []string) error {\n\tallReSearch := make([]*regexp.Regexp, len(reLine))\n\n\tfor i, v := range reLine {\n\t\tif re, err := regexp.Compile(v); err != nil {\n\t\t\treturn err\n\t\t} else {\n\t\t\tallReSearch[i] = re\n\t\t}\n\t}\n\n\tif _, err := e.file.Seek(0, os.SEEK_SET); err != nil {\n\t\treturn err\n\t}\n\n\tchar := []byte(e.CommentChar + \" \")\n\tisNew := false\n\tbuf := new(bytes.Buffer)\n\n\t// Check every line.\n\tfor {\n\t\tline, err := e.buf.ReadBytes('\\n')\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\n\t\tfor _, v := range allReSearch {\n\t\t\tif v.Match(line) {\n\t\t\t\tline = append(char, line...)\n\n\t\t\t\tif !isNew {\n\t\t\t\t\tisNew = true\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif _, err = buf.Write(line); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif isNew {\n\t\treturn e.rewrite(buf.Bytes())\n\t}\n\treturn nil\n}", "reference": "// Comment inserts the comment character in lines that mach any regular expression\n// in reLine.", "generated": "// Comment returns the file's content without lines that match any regular expression in reLine,\n// then writes it back to the original position. If no matching lines were found, it will rewrite the entire\n// buffer if there was only one non-matching line or more than one non-matching line but they don't"}
{"id": 5384, "code": "func Run(command string) (output []byte, err error) {\n\toutput, _, err = RunWithMatch(command)\n\treturn\n}", "reference": "// Run executes external commands just like RunWithMatch, but does not return\n// the boolean `match`.", "generated": "// Run runs the command.\n//\n// If no match is found in the list of commands, it returns nil output and an error.\nfunc RunWithMatch(command string) ([]byte, int, error) {\n\tfor i := range matches {\n\t\tif strings.Contains(match[i].Command, command) || strings.HasPrefix(match[i"}
{"id": 5387, "code": "func (i *info) GroupHas(p ...perm) bool {\n\tmode := i.fi.Mode()\n\n\tfor _, v := range p {\n\t\tswitch v {\n\t\tcase R:\n\t\t\tif mode&modeRGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase W:\n\t\t\tif mode&modeWGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase X:\n\t\t\tif mode&modeXGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\treturn true\n}", "reference": "// GroupHas reports whether the group has all given permissions.", "generated": "// GroupHas returns whether this info has all permissions in group.\n//\n// This is used to determine if we can create a new file or directory that will be owned by us,\n// but may have other users' files/directories inside it. If any user's permission is missing from\n// our own set of"}
{"id": 5393, "code": "func ChPasswd(user string, key []byte) error {\n\tshadow, err := LookupShadow(user)\n\tif err != nil {\n\t\treturn err\n\t}\n\tshadow.Passwd(key)\n\n\treturn edit(user, shadow)\n}", "reference": "// == Change passwd\n// ChPasswd updates passwd.\n// The passwd must be supplied in clear-text.", "generated": "// ChPasswd changes the password for user.\n//\n// It first looks up the user's shadow entry in the database,\n// then updates its Passwd field to point at the new encrypted\n// password. Finally it calls Edit() to update the underlying data store.\n// If any errors occur during this process they will"}
{"id": 5399, "code": "func parseGroup(row string) (*Group, error) {\n\tfields := strings.Split(row, \":\")\n\tif len(fields) != 4 {\n\t\treturn nil, rowError{_GROUP_FILE, row}\n\t}\n\n\tgid, err := strconv.Atoi(fields[2])\n\tif err != nil {\n\t\treturn nil, atoiError{_GROUP_FILE, row, \"GID\"}\n\t}\n\n\treturn &Group{\n\t\tName:     fields[0],\n\t\tpassword: fields[1],\n\t\tGID:      gid,\n\t\tUserList: strings.Split(fields[3], \",\"),\n\t}, nil\n}", "reference": "// parseGroup parses the row of a group.", "generated": "// ParseGroup parses a group from a line in the file.\n//\n// The format is <name>:<password>:<gid>,:<userlist>. For example:\n// user:x:1000:user1,user2,user3\n// admin:x:2000:admin1,admin2,admin3\n//"}
{"id": 5450, "code": "func (c *CallService) Create(ctx context.Context, data url.Values) (*Call, error) {\n\tcall := new(Call)\n\terr := c.client.CreateResource(ctx, callsPathPart, data, call)\n\treturn call, err\n}", "reference": "// Initiate a new Call.", "generated": "// Create creates a new Call resource in the server.\n//\n// The request body must contain all required fields for creating a Call instance.\n// If any field is missing from the request body, it will be set to its default value.\n// For more information about this endpoint see [Create](https://github.com/opens"}
{"id": 5453, "code": "func (c *CallService) GetNextCallsInRange(start time.Time, end time.Time, nextPageURI string) CallPageIterator {\n\tif nextPageURI == \"\" {\n\t\tpanic(\"nextpageuri is empty\")\n\t}\n\titer := NewNextPageIterator(c.client, callsPathPart)\n\titer.SetNextPageURI(types.NullString{Valid: true, String: nextPageURI})\n\treturn &callDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetNextCallsInRange retrieves the page at the nextPageURI and continues\n// retrieving pages until any results are found in the range given by start or\n// end, or we determine there are no more records to be found in that range.\n//\n// If CallPage is non-nil, it will have at least one result.", "generated": "// GetNextCallsInRange returns a new iterator for all call records in the given date range.\n// The returned iterator will yield one page at a time until it reaches the next page URI or\n// there are no more pages to return. If there's only one record in this iteration then we'll\n// get another"}
{"id": 5455, "code": "func (c *CallService) GetRecordingsIterator(callSid string, data url.Values) *RecordingPageIterator {\n\tif data == nil {\n\t\tdata = url.Values{}\n\t}\n\t// Cheat - hit the Recordings list view with a filter instead of\n\t// GET /calls/CA123/Recordings. The former is probably more reliable\n\tdata.Set(\"CallSid\", callSid)\n\treturn c.client.Recordings.GetPageIterator(data)\n}", "reference": "// GetRecordings returns an iterator of recording pages for this Call.\n// Note there may be more than one Page of results.", "generated": "// GetRecordingsIterator returns a new iterator for retrieving recordings.\n// This method will return all available records if no CallSid parameter was provided,\n// otherwise it will only retrieve those associated to this specific call Sid.\n// Note that we're using the \"GetPageIterator\" helper which allows us to get multiple pages at"}
{"id": 5461, "code": "func (r *KeyService) Delete(ctx context.Context, sid string) error {\n\treturn r.client.DeleteResource(ctx, keyPathPart, sid)\n}", "reference": "// Delete the Key with the given sid. If the Key has already been\n// deleted, or does not exist, Delete returns nil. If another error or a\n// timeout occurs, the error is returned.", "generated": "// Delete deletes a resource by ID.\n//\n// This is used to delete resources that have been created but no longer needed,\n// such as keys or certificates. The client will automatically retry if\n// necessary until it succeeds. If there's already another request in progress\n// for this operation, then we'll return an"}
{"id": 5462, "code": "func (a *AlertService) GetAlertsInRange(start time.Time, end time.Time, data url.Values) AlertPageIterator {\n\tif start.After(end) {\n\t\tpanic(\"start date is after end date\")\n\t}\n\td := url.Values{}\n\tif data != nil {\n\t\tfor k, v := range data {\n\t\t\td[k] = v\n\t\t}\n\t}\n\td.Del(\"Page\") // just in case\n\tif start != Epoch {\n\t\tstartFormat := start.UTC().Format(time.RFC3339)\n\t\td.Set(\"StartDate\", startFormat)\n\t}\n\tif end != HeatDeath {\n\t\t// If you specify \"StartTime<=YYYY-MM-DD\", the *latest* result returned\n\t\t// will be midnight (the earliest possible second) on DD. We want all\n\t\t// of the results for DD so we need to specify DD+1 in the API.\n\t\t//\n\t\t// TODO validate midnight-instant math more closely, since I don't think\n\t\t// Twilio returns the correct results for that instant.\n\t\tendFormat := end.UTC().Format(time.RFC3339)\n\t\td.Set(\"EndDate\", endFormat)\n\t}\n\titer := NewPageIterator(a.client, d, alertPathPart)\n\treturn &alertDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetAlertsInRange gets an Iterator containing conferences in the range\n// [start, end), optionally further filtered by data. GetAlertsInRange\n// panics if start is not before end. Any date filters provided in data will\n// be ignored. If you have an end, but don't want to specify a start, use\n// twilio.Epoch for start. If you have a start, but don't want to specify an\n// end, use twilio.HeatDeath for end.\n//\n// Assumes that Twilio returns resources in chronological order, latest\n// first. If this assumption is incorrect, your results will not be correct.\n//\n// Returned AlertPages will have at most PageSize results, but may have fewer,\n// based on filtering.", "generated": "Get alerts within a specified date range. The request can include optional parameters like StartDate or EndDate which override the default values from the URL query string. This method also supports specifying both StartTime and EndTime by passing them separately instead of using the DateRange parameter. Note that if only one of these two dates/time"}
{"id": 5466, "code": "func (d Direction) Friendly() string {\n\tswitch d {\n\tcase DirectionOutboundReply:\n\t\treturn \"Reply\"\n\tcase DirectionOutboundCall:\n\t\treturn \"Outgoing (from call)\"\n\tcase DirectionOutboundAPI:\n\t\treturn \"Outgoing (from API)\"\n\tcase DirectionInbound:\n\t\treturn \"Incoming\"\n\tcase DirectionOutboundDial:\n\t\treturn \"Outgoing (via Dial)\"\n\tcase DirectionTrunkingTerminating:\n\t\treturn \"Trunking (terminating)\"\n\tcase DirectionTrunkingOriginating:\n\t\treturn \"Trunking (originating)\"\n\tdefault:\n\t\treturn string(d)\n\t}\n}", "reference": "// Friendly prints out a friendly version of the Direction, following the\n// example shown in the Twilio Dashboard.", "generated": "// Friendly returns a friendly name for this direction.\n// This is used in UIs to display directions in human-readable format,\n// rather than technical names like 'DirectionOutboundReply'.\n//\n// For example: if we have two outgoing calls from different APIs\n// that both reply back to us, they will be displayed"}
{"id": 5468, "code": "func (m *MessageService) GetPage(ctx context.Context, data url.Values) (*MessagePage, error) {\n\titer := m.GetPageIterator(data)\n\treturn iter.Next(ctx)\n}", "reference": "// GetPage returns a single page of resources. To retrieve multiple pages, use\n// GetPageIterator.", "generated": "// GetPage returns a MessagePage object for the given page number.\n// If no message is found at that page, it will return nil along\n// with any errors encountered during iteration.\n//\n// The caller must close the returned iterator when done to free up resources.\nfunc (m *MessageService) GetPage(ctx"}
{"id": 5470, "code": "func (c *MessageService) GetNextMessagesInRange(start time.Time, end time.Time, nextPageURI string) MessagePageIterator {\n\tif nextPageURI == \"\" {\n\t\tpanic(\"nextpageuri is empty\")\n\t}\n\titer := NewNextPageIterator(c.client, messagesPathPart)\n\titer.SetNextPageURI(types.NullString{Valid: true, String: nextPageURI})\n\treturn &messageDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetNextMessagesInRange retrieves the page at the nextPageURI and continues\n// retrieving pages until any results are found in the range given by start or\n// end, or we determine there are no more records to be found in that range.\n//\n// If MessagePage is non-nil, it will have at least one result.", "generated": "// GetNextMessagesInRange returns a new iterator for getting next pages\n// of messages in range [start;end). The returned iterator will be used to get\n// all subsequent pages until it yields no more results.\n//\n// If there's already another page being fetched from this service, then\n// GetNextMessages"}
{"id": 5486, "code": "func (r *ApplicationService) Delete(ctx context.Context, sid string) error {\n\treturn r.client.DeleteResource(ctx, applicationPathPart, sid)\n}", "reference": "// Delete the Application with the given sid. If the Application has already been\n// deleted, or does not exist, Delete returns nil. If another error or a\n// timeout occurs, the error is returned.", "generated": "// Delete deletes the specified resource from the server.\n//\n// The client must be authenticated to delete resources in this service.\n// If no authentication is present or if it fails for any reason,\n// the request will fail immediately without attempting\n// to send the request to the server.\n// \n// This method returns nil upon"}
{"id": 5490, "code": "func (ipn *IncomingNumberService) BuyNumber(phoneNumber string) (*IncomingPhoneNumber, error) {\n\tdata := url.Values{\"PhoneNumber\": []string{phoneNumber}}\n\treturn ipn.NumberPurchasingService.Create(context.Background(), data)\n}", "reference": "// BuyNumber attempts to buy the provided phoneNumber and returns it if\n// successful.", "generated": "// BuyNumber purchases a number for the given phone number.\n//\n// The service will return the purchased number if it was successfully\n// created or nil otherwise.\nfunc (p *IncomingNumberService) BuyNumber(ctx context.Context, phoneNumber string) (*IncomingPhoneNumber, error) { return p.NumberPurchasingService"}
{"id": 5517, "code": "func (m *Messenger) DeleteGetStartedButton() error {\n\tresult, err := m.changeThreadSettings(http.MethodDelete, &threadSettings{\n\t\tType:  settingTypeCallToActions,\n\t\tState: threadStateNew,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\tif result.Result != \"Successfully deleted all new_thread's CTAs\" {\n\t\treturn fmt.Errorf(\"Error occured while deleting get started button, invalid result: %s\", result.Result)\n\t}\n\treturn nil\n}", "reference": "// DeleteGetStartedButton delets a button set by SetGetStartedButton", "generated": "// DeleteGetStartedButton deletes the Get Started Button from the Messenger settings.\n//\n// This method is used to remove the call-to-action for getting started in the messenger.\n// It returns an error if there was any issue during deletion or if the delete operation failed. If successful it will return nil.\n// The returned value"}
{"id": 5523, "code": "func pushNumberValue(L *lua.State, a interface{}, t1, t2 reflect.Type) {\n\tv := reflect.ValueOf(a)\n\tisComplex := unsizedKind(v) == reflect.Complex128\n\tmt := cNumberMeta\n\tif isComplex {\n\t\tmt = cComplexMeta\n\t}\n\tif t1 == t2 || isPredeclaredType(t2) {\n\t\tmakeValueProxy(L, v.Convert(t1), mt)\n\t} else if isPredeclaredType(t1) {\n\t\tmakeValueProxy(L, v.Convert(t2), mt)\n\t} else if isComplex {\n\t\tcomplexType := reflect.TypeOf(0i)\n\t\tmakeValueProxy(L, v.Convert(complexType), cComplexMeta)\n\t} else {\n\t\tL.PushNumber(valueToNumber(L, v))\n\t}\n}", "reference": "// pushNumberValue pushes the number resulting from an arithmetic operation.\n//\n// At least one operand must be a proxy for this function to be called. See the\n// main documentation for the conversion rules.", "generated": "// PushNumber pushes a number value onto the stack.\n//\n// The type must be either int or float64 (or complex). If it's already declared,\n// then this will simply return without doing anything. Otherwise, we create a new\n// proxy for that type to ensure correct handling in future calls. This also"}
{"id": 5556, "code": "func (d *digest) Sum(in []byte) []byte {\n\ts := d.Sum64()\n\tin = append(in, byte(s))\n\tin = append(in, byte(s>>8))\n\tin = append(in, byte(s>>16))\n\tin = append(in, byte(s>>24))\n\tin = append(in, byte(s>>32))\n\tin = append(in, byte(s>>40))\n\tin = append(in, byte(s>>48))\n\tin = append(in, byte(s>>56))\n\treturn in\n}", "reference": "// Encode in little endian", "generated": "// Sum returns the sum of this digest and another slice.\n//\n// The result is returned as two 64-bit integers: first for each byte,\n// then for each pair of bytes, etc., until all bits have been used up.\n// This allows us to compute checksums that can be verified by computing\n//"}
{"id": 5562, "code": "func FindPerformancePrice(productPackage datatypes.Product_Package, priceCategory string) (datatypes.Product_Item_Price, error) {\n\tfor _, item := range productPackage.Items {\n\t\tfor _, price := range item.Prices {\n\t\t\t// Only collect prices from valid location groups.\n\t\t\tif price.LocationGroupId != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif !hasCategory(price.Categories, priceCategory) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn price, nil\n\t\t}\n\t}\n\treturn datatypes.Product_Item_Price{}, bosherr.Error(\"Unable to find price for performance storage\")\n}", "reference": "// Find the price in the given package that has the specified category", "generated": "FindProductItemPrices returns all available prices in the given category that can be used by the Performance Storage service. The returned list is sorted by lowest cost first. If no matching products exist, it will return an empty Product Item Price object. This method only considers categories where there exists at least one price per product package."}
{"id": 5571, "code": "func (o *OrderVMByFilterParams) WithBody(body *models.VMFilter) *OrderVMByFilterParams {\n\to.SetBody(body)\n\treturn o\n}", "reference": "// WithBody adds the body to the order Vm by filter params", "generated": "// SetBody sets the body field to be used for this request.\nfunc (p *OrderVMByFilterParams) SetBody(v models.VMFilter) *OrderVMByFilterParams { p.body = v; return p }"}
{"id": 5572, "code": "func (c *FakeClient) Delete(instanceID string) error {\n\tc.DeleteCalled = true\n\treturn c.DeleteErr\n}", "reference": "// Delete deletes the instance settings for a given instance ID.", "generated": "// Delete deletes the specified instance from the cluster.\n//\n// If no errors occur during deletion, this method returns nil. Otherwise,\n// it returns any non-nil error that occurred while deleting the instance.\nfunc (c *ClusterClient) Delete(instanceID string) error { return c.FakeDelete(c.FakeDeleteError"}
{"id": 5599, "code": "func (o *UpdateVMWithStateParams) WithBody(body *models.VMState) *UpdateVMWithStateParams {\n\to.SetBody(body)\n\treturn o\n}", "reference": "// WithBody adds the body to the update Vm with state params", "generated": "// SetBody sets the body field to be set in the request.\n// Note: empty value is allowed, so use \"body := models.NewVMState();\" if you want to avoid calling this method.\n// Use methods like WithField() or direct fields assignment To set multiple model values at once. For example,"}
{"id": 5601, "code": "func (o *AddVMParams) WithTimeout(timeout time.Duration) *AddVMParams {\n\to.SetTimeout(timeout)\n\treturn o\n}", "reference": "// WithTimeout adds the timeout to the add Vm params", "generated": "// Set timeout for VM creation operation.\n//\n// If set to zero value or negative number, it will be ignored by server.\nfunc (p *AddVMParams) Timeout(t time.Duration) *AddVMParams {\n\tp.Timeout = t\n\treturn p\n}"}
{"id": 5606, "code": "func (o *ListVMParams) WithContext(ctx context.Context) *ListVMParams {\n\to.SetContext(ctx)\n\treturn o\n}", "reference": "// WithContext adds the context to the list Vm params", "generated": "// SetContext sets the Context for this ListVMParams object.\n//\n// More info: https://kubernetes.io/docs/reference/policy-apis/#list-virtual-machine-params-context\n// +operatorIDs go-k8s-api.ListVirtualMachineParams.ListVirtualMachineParamsContext\nfunc (o *ListVMParams"}
{"id": 5626, "code": "func (pk PrivKeyLedgerSecp256k1) getPubKey() (key PubKey, err error) {\n\tdev, err := getLedger()\n\tif err != nil {\n\t\treturn key, fmt.Errorf(\"cannot connect to Ledger device - error: %v\", err)\n\t}\n\tkey, err = pubkeyLedgerSecp256k1(dev, pk.Path)\n\tif err != nil {\n\t\treturn key, fmt.Errorf(\"please open Cosmos app on the Ledger device - error: %v\", err)\n\t}\n\treturn key, err\n}", "reference": "// getPubKey reads the pubkey the ledger itself\n// since this involves IO, it may return an error, which is not exposed\n// in the PubKey interface, so this function allows better error handling", "generated": "// GetPublic returns public key from ledger.\nfunc (pk PrivKeyLedgerSecp256k1) GetPublic() (*PrivKeyLedgerSecp256k1, error) {\n\tpubKey, err := pk.getPubKey()\n\n\tif err == ErrNoDeviceFound || err == ErrInvalidPath {"}
{"id": 5656, "code": "func (kb dbKeybase) ImportPubKey(name string, armor string) (err error) {\n\tbz := kb.db.Get(infoKey(name))\n\tif len(bz) > 0 {\n\t\treturn errors.New(\"Cannot overwrite data for name \" + name)\n\t}\n\tpubBytes, err := unarmorPubKeyBytes(armor)\n\tif err != nil {\n\t\treturn\n\t}\n\tpubKey, err := crypto.PubKeyFromBytes(pubBytes)\n\tif err != nil {\n\t\treturn\n\t}\n\tkb.writeOfflineKey(pubKey, name)\n\treturn\n}", "reference": "// ImportPubKey imports ASCII-armored public keys.\n// Store a new Info object holding a public key only, i.e. it will\n// not be possible to sign with it as it lacks the secret key.", "generated": "// ImportPubKey imports a public key into KeyBase.\n//\n// If there is already a record in the database named by this parameter,\n// it will be overwritten. Otherwise, if no such entry exists, one will be created.\n// The imported key must have been previously armored using ArmorPublicKey().\n// This method returns"}
{"id": 5660, "code": "func CompareHashAndPassword(hashedPassword, password []byte) error {\n\tp, err := newFromHash(hashedPassword)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\totherHash, err := bcrypt(password, p.cost, p.salt)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\totherP := &hashed{otherHash, p.salt, p.cost, p.major, p.minor}\n\tif subtle.ConstantTimeCompare(p.Hash(), otherP.Hash()) == 1 {\n\t\treturn nil\n\t}\n\n\treturn ErrMismatchedHashAndPassword\n}", "reference": "// CompareHashAndPassword compares a bcrypt hashed password with its possible\n// plaintext equivalent. Returns nil on success, or an error on failure.", "generated": "// CompareHashAndPassword compares two passwords by hashing one to match against another.\n//\n// The hashedPassword is expected to be in format returned from Hash(). If it's already been\n// compared before (i.e., its hash has been used for authentication), then this comparison will\n// return immediately without doing any work because"}
{"id": 5696, "code": "func doDemangle(out *bufio.Writer, name string) {\n\tskip := 0\n\tif name[0] == '.' || name[0] == '$' {\n\t\tskip++\n\t}\n\tif *stripUnderscore && name[skip] == '_' {\n\t\tskip++\n\t}\n\tresult := demangle.Filter(name[skip:], options()...)\n\tif result == name[skip:] {\n\t\tout.WriteString(name)\n\t} else {\n\t\tif name[0] == '.' {\n\t\t\tout.WriteByte('.')\n\t\t}\n\t\tout.WriteString(result)\n\t}\n}", "reference": "// Demangle a string just as the GNU c++filt program does.", "generated": "// DoDemangle writes the given C symbol to out in its demangled form.\n// If stripUnderscores is true, underscores at the beginning or end of the\n// input will be removed before demangling. The first character after any\n// leading underscore (if present), if it's a dot, will"}
{"id": 5707, "code": "func (s *Sentinel) defaultPool(addr string) *redis.Pool {\n\treturn &redis.Pool{\n\t\tMaxIdle:     3,\n\t\tMaxActive:   10,\n\t\tWait:        true,\n\t\tIdleTimeout: 240 * time.Second,\n\t\tDial: func() (redis.Conn, error) {\n\t\t\treturn s.Dial(addr)\n\t\t},\n\t\tTestOnBorrow: func(c redis.Conn, t time.Time) error {\n\t\t\t_, err := c.Do(\"PING\")\n\t\t\treturn err\n\t\t},\n\t}\n}", "reference": "// defaultPool returns a connection pool to one Sentinel. This allows\n// us to call concurrent requests to Sentinel using connection Do method.", "generated": "// DefaultPool returns a Redis pool for connecting to Sentinel.\n//\n// The returned pool is configured to have up to three idle connections at any given moment,\n// but no more than ten active connections in total. It will wait indefinitely if there's only one connection available.\n// If all other options fail, it will return"}
{"id": 5723, "code": "func (c *Client) CompareAndSwap(item *Item) error {\n\treturn c.populateOne(cmdSet, item, item.casid)\n}", "reference": "// CompareAndSwap writes the given item that was previously returned\n// by Get, if the value was neither modified or evicted between the\n// Get and the CompareAndSwap calls. The item's Key should not change\n// between calls but all other item fields may differ. ErrCASConflict\n// is returned if the value was modified in between the\n// calls. ErrNotStored is returned if the value was evicted in between\n// the calls.", "generated": "// CompareAndSwap attempts to update the given Item by comparing its current CAS ID\n// against the provided value. If they match, it updates the Item's data using the new\n// CAS ID; otherwise, returns an error.\n//\n// This is similar to Update but uses CAS instead for atomicity guarantees. It"}
{"id": 5736, "code": "func Ticker(ticker <-chan time.Time, procfunc gp.ProcessFunc) gp.Process {\n\treturn gp.Go(callOnTicker(ticker, procfunc))\n}", "reference": "// Ticker calls the given ProcessFunc every time the ticker fires.\n// This is sequentially rate limited, only one call will be in-flight at a time.", "generated": "// callOnTicker runs funcproc when ticked by ticker.\n//\n// If ticker is nil or closed, it will be ignored.\nfunc callOnTicker(ticker <-chan time.Time, procfunc gp.ProcessFunc) gp.Process {\n\treturn func() (gp.Status, error) {\n\t\tselect {\n\t\tcase t :="}
{"id": 5746, "code": "func (a *API) FetchCheck(cid CIDType) (*Check, error) {\n\tif cid == nil || *cid == \"\" {\n\t\treturn nil, fmt.Errorf(\"Invalid check CID [none]\")\n\t}\n\n\tcheckCID := string(*cid)\n\n\tmatched, err := regexp.MatchString(config.CheckCIDRegex, checkCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !matched {\n\t\treturn nil, fmt.Errorf(\"Invalid check CID [%s]\", checkCID)\n\t}\n\n\tresult, err := a.Get(checkCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] fetch check, received JSON: %s\", string(result))\n\t}\n\n\tcheck := new(Check)\n\tif err := json.Unmarshal(result, check); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn check, nil\n}", "reference": "// FetchCheck retrieves check with passed cid.", "generated": "// Fetch returns Check data from API server for given check ID.\n//\n// If debug mode is enabled, it logs fetched result to console.\n//\n// Returns nil if no match found or invalid input provided.\n// Otherwise, returns pointer to newly created Check struct containing retrieved information,\n// along with any errors encountered during process."}
{"id": 5747, "code": "func (a *API) FetchChecks() (*[]Check, error) {\n\tresult, err := a.Get(config.CheckPrefix)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar checks []Check\n\tif err := json.Unmarshal(result, &checks); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &checks, nil\n}", "reference": "// FetchChecks retrieves all checks available to the API Token.", "generated": "// FetchChecks fetches all check configurations from the API.\n//\n// This method returns a slice of Check objects that represent the current configuration for each check in the system.\n// The result is returned wrapped in a pointer to allow it to be used by functions like GetConfig which expect this format.\n// If there's any"}
{"id": 5752, "code": "func (a *API) FetchGraph(cid CIDType) (*Graph, error) {\n\tif cid == nil || *cid == \"\" {\n\t\treturn nil, fmt.Errorf(\"Invalid graph CID [none]\")\n\t}\n\n\tgraphCID := string(*cid)\n\n\tmatched, err := regexp.MatchString(config.GraphCIDRegex, graphCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !matched {\n\t\treturn nil, fmt.Errorf(\"Invalid graph CID [%s]\", graphCID)\n\t}\n\n\tresult, err := a.Get(graphCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] fetch graph, received JSON: %s\", string(result))\n\t}\n\n\tgraph := new(Graph)\n\tif err := json.Unmarshal(result, graph); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn graph, nil\n}", "reference": "// FetchGraph retrieves graph with passed cid.", "generated": "// FetchGraph returns a Graph object from the given CID.\n//\n// The returned Graph is unmarshaled into its internal fields using the provided result data.\n// If there's no match for the given CID in the API cache or if fetching fails,\n// it will return an empty Graph struct along with any errors encountered during"}
{"id": 5786, "code": "func (a *API) FetchAnnotations() (*[]Annotation, error) {\n\tresult, err := a.Get(config.AnnotationPrefix)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar annotations []Annotation\n\tif err := json.Unmarshal(result, &annotations); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &annotations, nil\n}", "reference": "// FetchAnnotations retrieves all annotations available to the API Token.", "generated": "// FetchAnnotations returns all annotation values for this API.\n//\n// Annotations can be used to store arbitrary data that is specific to each request or\n// response in the API. The key must start with config.AnnotationPrefix.\n//\n// If no annotations exist, it will return an empty slice. This method should only be called"}
{"id": 5815, "code": "func (m *CirconusMetrics) NewHistogram(metric string) *Histogram {\n\tm.hm.Lock()\n\tdefer m.hm.Unlock()\n\n\tif hist, ok := m.histograms[metric]; ok {\n\t\treturn hist\n\t}\n\n\thist := &Histogram{\n\t\tname: metric,\n\t\thist: circonusllhist.New(),\n\t}\n\n\tm.histograms[metric] = hist\n\n\treturn hist\n}", "reference": "// NewHistogram returns a histogram instance.", "generated": "// NewHistogram returns a new Histogram for the given metric name.\n// If a histogram already exists for this metric, it is returned instead of creating one.\n// The metrics must be registered before calling this method to avoid panic."}
{"id": 5847, "code": "func (a *API) CreateRuleSet(cfg *RuleSet) (*RuleSet, error) {\n\tif cfg == nil {\n\t\treturn nil, fmt.Errorf(\"Invalid rule set config [nil]\")\n\t}\n\n\tjsonCfg, err := json.Marshal(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] create rule set, sending JSON: %s\", string(jsonCfg))\n\t}\n\n\tresp, err := a.Post(config.RuleSetPrefix, jsonCfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\truleset := &RuleSet{}\n\tif err := json.Unmarshal(resp, ruleset); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn ruleset, nil\n}", "reference": "// CreateRuleSet creates a new rule set.", "generated": "// Creates or updates a RuleSet in the API server.\n//\n// If no ID is provided, it will be generated automatically by the server.\n// The new configuration must match one that has been previously created,\n// otherwise this call will return an error.\n// This method returns the newly created RuleSet object if successful."}
{"id": 5860, "code": "func (a *API) DeleteWorksheet(cfg *Worksheet) (bool, error) {\n\tif cfg == nil {\n\t\treturn false, fmt.Errorf(\"Invalid worksheet config [nil]\")\n\t}\n\treturn a.DeleteWorksheetByCID(CIDType(&cfg.CID))\n}", "reference": "// DeleteWorksheet deletes passed worksheet.", "generated": "// DeleteWorksheet deletes a given Worksheet by its CID.\n//\n// If the provided configuration is valid but has no associated data,\n// this method returns true without any errors.\n// Otherwise it will return false along with an appropriate error message.\n// The deletion operation itself may fail due to various reasons such as\n// permissions issues"}
{"id": 5865, "code": "func (a *API) CreateContactGroup(cfg *ContactGroup) (*ContactGroup, error) {\n\tif cfg == nil {\n\t\treturn nil, fmt.Errorf(\"Invalid contact group config [nil]\")\n\t}\n\n\tjsonCfg, err := json.Marshal(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] create contact group, sending JSON: %s\", string(jsonCfg))\n\t}\n\n\tresult, err := a.Post(config.ContactGroupPrefix, jsonCfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tgroup := &ContactGroup{}\n\tif err := json.Unmarshal(result, group); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn group, nil\n}", "reference": "// CreateContactGroup creates a new contact group.", "generated": "// Creates a new Contact Group based on provided configuration.\n//\n// The returned result is stored in local storage for future reference.\n// If there's any errors during creation process it will be logged to debug log,\n// but still returns non-nil value so caller can handle this situation if needed.\n// In case of success,"}
{"id": 5890, "code": "func NewEllipticSigner(alg Algorithm, curve elliptic.Curve) func(Store, crypto.Hash) (Signer, error) {\n\tcurveBitSize := curve.Params().BitSize\n\n\t// precompute curve key len\n\tkeyLen := curveBitSize / 8\n\tif curveBitSize%8 > 0 {\n\t\tkeyLen++\n\t}\n\n\treturn func(store Store, hash crypto.Hash) (Signer, error) {\n\t\tvar ok bool\n\t\tvar privRaw, pubRaw interface{}\n\t\tvar priv *ecdsa.PrivateKey\n\t\tvar pub *ecdsa.PublicKey\n\n\t\t// check private key\n\t\tif privRaw, ok = store.PrivateKey(); ok {\n\t\t\tif priv, ok = privRaw.(*ecdsa.PrivateKey); !ok {\n\t\t\t\treturn nil, ErrInvalidPrivateKey\n\t\t\t}\n\n\t\t\t// check curve type matches private key curve type\n\t\t\tif curveBitSize != priv.Curve.Params().BitSize {\n\t\t\t\treturn nil, ErrInvalidPrivateKeySize\n\t\t\t}\n\t\t}\n\n\t\t// check public key\n\t\tif pubRaw, ok = store.PublicKey(); ok {\n\t\t\tif pub, ok = pubRaw.(*ecdsa.PublicKey); !ok {\n\t\t\t\treturn nil, ErrInvalidPublicKey\n\t\t\t}\n\t\t}\n\n\t\t// check that either a private or public key has been provided\n\t\tif priv == nil && pub == nil {\n\t\t\treturn nil, ErrMissingPrivateOrPublicKey\n\t\t}\n\n\t\treturn &EccSigner{\n\t\t\talg:    alg,\n\t\t\tcurve:  curve,\n\t\t\thash:   hash,\n\t\t\tpriv:   priv,\n\t\t\tpub:    pub,\n\t\t\tkeyLen: keyLen,\n\t\t}, nil\n\t}\n}", "reference": "// NewEllipticSigner creates an Elliptic Curve Signer for the specified curve.", "generated": "NewEllipticSigner returns a new EllipticSigner instance given an algorithm, curve, and a store containing keys for signing.\nThe returned signers can be used to generate signatures using the specified algorithm and curve. The signature is generated from the input data by hashing it first and then computing the ECDSA"}
{"id": 5907, "code": "func FromFile(path string, opts ...Option) (*GServiceAccount, error) {\n\tbuf, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn FromJSON(buf, opts...)\n}", "reference": "// FromFile loads Google service account credentials from a reader.", "generated": "// File loads a service account from file.\n//\n// The path is expected to be in JSON format (e.g., \"path/to/service_account.json\").\n// If successful, it returns a *GServiceAccount object that can be used for authentication purposes.\n// Errors will include any errors encountered while reading or parsing the file"}
{"id": 5932, "code": "func PostEZCountTime(statName, ezkey string, count int, timestamp int64) error {\n\treturn DefaultReporter.PostEZCountTime(statName, ezkey, count, timestamp)\n}", "reference": "// Using the EZ API, posts a count to a stat at a specific time using DefaultReporter.", "generated": "// PostEZCountTime reports that the given number of players have played\n// for at least 'count' seconds in the last 'timestamp'. The player is considered to be playing if they were\n// actively engaged (i.e., their game was running). If no such time has been reported yet,\n// this will"}
{"id": 5952, "code": "func (s Scan) AddHosts(hosts ...string) Scan {\n\ts.configHosts = append(s.configHosts, hosts...)\n\treturn s\n}", "reference": "// AddHosts adds a list of hosts to the list of hosts to be scanned", "generated": "// Adds one or more hostnames to scan for. The hostname must be in the format \"hostname:port\". If no port is specified,\n// it will default to 22 if SSH protocol is used; otherwise, it defaults to TCP port 80.\n//\n// Example:\n//   s.AddHosts(\"example"}
{"id": 5955, "code": "func (s Scan) SetPorts(ports ...uint16) Scan {\n\ts.configPorts = ports\n\treturn s\n}", "reference": "// SetPorts sets the ports that wil be used", "generated": "// SetPorts sets multiple port numbers to be used for scanning.\n//\n// The returned scan is modified in-place; no new scan object is created.\n// Multiple calls can set different port ranges or single specific ports,\n// but they must all use the same protocol family.\n// If any call fails due to insufficient available network"}
{"id": 5964, "code": "func (otp HOTP) Counter() uint64 {\n\tcounter := binary.BigEndian.Uint64(otp.counter[:])\n\treturn counter\n}", "reference": "// Counter returns the HOTP's 8-byte counter as an unsigned 64-bit\n// integer.", "generated": "// Counter returns the current value of the OTP's internal counter.\n// The returned value is in big-endian byte order. If the counter has wrapped around,\n// it will be reset to 0. This method should only be called once per second if possible.\n// Otherwise, use GetCounterWithTimeToReset instead"}
{"id": 5967, "code": "func (otp *HOTP) URL(label string) string {\n\tsecret := base32.StdEncoding.EncodeToString(otp.Key)\n\tu := url.URL{}\n\tv := url.Values{}\n\tu.Scheme = \"otpauth\"\n\tu.Host = \"hotp\"\n\tu.Path = label\n\tv.Add(\"secret\", secret)\n\tv.Add(\"counter\", fmt.Sprintf(\"%d\", otp.Counter()))\n\tu.RawQuery = v.Encode()\n\treturn u.String()\n}", "reference": "// URL returns a suitable URL, such as for the Google Authenticator\n// app. The label is used by these apps to identify the service to\n// which this OTP belongs. The digits value is ignored by the Google\n// authenticator app, and is therefore elided in the resulting URL.", "generated": "// URL returns a URL that can be used to authenticate using this HOTP instance.\n// The counter is set when the method is called for the first time; subsequent calls will return URLs pointing to different counters,\n// allowing multiple users or devices to use the same key without interfering with each other's authentication attempts.\n// For"}
{"id": 5975, "code": "func Marshal(otp *HOTP) ([]byte, error) {\n\tvar asnHOTP struct {\n\t\tKey     []byte\n\t\tCounter *big.Int\n\t\tDigits  int\n\t}\n\tasnHOTP.Key = otp.Key[:]\n\tasnHOTP.Counter = new(big.Int).SetUint64(otp.Counter())\n\tasnHOTP.Digits = otp.Digits\n\treturn asn1.Marshal(asnHOTP)\n}", "reference": "// Marshal serialises an HOTP key value as a DER-encoded byte slice.", "generated": "// Marshal returns the HOTP key in ASN.1 format.\n//\n// The returned value is a byte slice that can be used to encode the HOTP key into a binary data stream,\n// such as a network packet or file. This encoding scheme allows for efficient transmission over networks\n// without requiring additional overhead from serialization"}
{"id": 5981, "code": "func (pool *ReaderPool) Get(r io.Reader) (reader io.Reader, release func()) {\n\t// don't export a ThrottlerReader to prevent users changing the rate\n\t// and expecting their change to be respected, since we might modify\n\t// the rate under their feet\n\n\t// make the initial rate be 0, the actual rate is\n\t// set in the call to `setSharedRates`.\n\trd := ThrottledReader(r, 0, pool.maxBurst)\n\n\tpool.mu.Lock()\n\tpool.givenOut[rd] = struct{}{}\n\tpool.setSharedRates()\n\tpool.mu.Unlock()\n\n\treturn rd, func() {\n\t\tpool.mu.Lock()\n\t\tdelete(pool.givenOut, rd)\n\t\tpool.setSharedRates()\n\t\tpool.mu.Unlock()\n\t}\n}", "reference": "// Get a throttled reader that wraps r.", "generated": "Get returns a throttling reader that will only read from r up until its burst limit.\nThe returned value must be released by calling Release when done reading from it,\nso that the given out map can track how many readers have been created so far.\nThis ensures that no more than maxBurst concurrent reads occur at any"}
{"id": 6002, "code": "func JsonFile(path string) (Typed, error) {\n\tdata, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn Json(data)\n}", "reference": "// Create a Typed helper from the JSON within a file", "generated": "// JsonFile reads JSON data from file path.\n//\n// Returns Typed if successful or nil otherwise.\nfunc JsonFile(path string) (Typed, error) { return Json(ioutil.ReadFile(path)) }"}
{"id": 6018, "code": "func (t Typed) TimeMust(key string) time.Time {\n\ttt, exists := t.TimeIf(key)\n\tif exists == false {\n\t\tpanic(\"expected time.Time value for \" + key)\n\t}\n\treturn tt\n}", "reference": "// Returns a time.Time or panics", "generated": "// Time returns the typed field if it is present in the map.\n//\n// If the type is a pointer to a struct, then this method will return nil instead,\n// unless there's already a non-nil value associated with that name.\n//\n// The returned value must be of the same type as the original field."}
{"id": 6025, "code": "func (t Typed) BoolsOr(key string, d []bool) []bool {\n\tn, ok := t.BoolsIf(key)\n\tif ok {\n\t\treturn n\n\t}\n\treturn d\n}", "reference": "// Returns an slice of boolean, or the specified slice", "generated": "// BoolsOr returns all booleans in this typed value if key is present,\n// otherwise it returns the given default values.\n//\n// If key is present but no boolean was found for that key, then\n// the returned slice will be empty. The length of the result can never\n// exceed the number of"}
{"id": 6037, "code": "func NewWorker(logger log.Logger, db *reform.DB, ethBack eth.Backend,\n\tgasConc *GasConf, pscAddr common.Address, payAddr string,\n\tpwdGetter data.PWDGetter, countryConf *country.Config,\n\tdecryptKeyFunc data.ToPrivateKeyFunc, eptConf *ept.Config,\n\ttorHostname string, somcClientBuilder somc.ClientBuilderInterface) (*Worker, error) {\n\n\tl := logger.Add(\"type\", \"proc/worker.Worker\")\n\n\tabi, err := abi.JSON(\n\t\tstrings.NewReader(contract.PrivatixServiceContractABI))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\teptService, err := ept.New(db, logger, payAddr, eptConf.Timeout)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &Worker{\n\t\tabi:               abi,\n\t\tlogger:            l,\n\t\tdb:                db,\n\t\tdecryptKeyFunc:    decryptKeyFunc,\n\t\tgasConf:           gasConc,\n\t\tept:               eptService,\n\t\tethBack:           ethBack,\n\t\tpscAddr:           pscAddr,\n\t\tpwdGetter:         pwdGetter,\n\t\tcountryConfig:     countryConf,\n\t\ttorHostName:       data.FromBytes([]byte(torHostname)),\n\t\tsomcClientBuilder: somcClientBuilder,\n\t}, nil\n}", "reference": "// NewWorker returns new instance of worker.", "generated": "// NewWorker creates a new worker instance.\n//\n// The returned Worker is responsible for processing Privatix service requests from\n// Ethereum nodes in parallel using goroutines. Each request will be processed by\n// multiple workers concurrently to maximize throughput while maintaining privacy.\n// A single worker can process one or more requests at any"}
{"id": 6089, "code": "func AddWithDelay(q Queue, tx *reform.TX,\n\tjobType, relatedType, relatedID, creator string,\n\tdelay time.Duration) error {\n\treturn AddWithDataAndDelay(q, tx,\n\t\tjobType, relatedType, relatedID, creator, &struct{}{}, delay)\n}", "reference": "// AddWithDelay is convenience method to add a job with given data delay.", "generated": "// AddWithDelay adds a new job to the queue after a specified delay.\n//\n// The given transaction is used for this operation. If it's nil or already\n// committed, no data will be written into the database.\n//\n// This method returns immediately if the current transaction has been committed.\n// It also allows"}
{"id": 6115, "code": "func NewFileLogger(conf *FileConfig) (Logger, io.Closer, error) {\n\tnow := time.Now()\n\tif conf.UTC {\n\t\tnow = now.UTC()\n\t}\n\n\tfile, err := os.OpenFile(\n\t\ttimeutil.Strftime(&now, conf.Filename),\n\t\tos.O_APPEND|os.O_CREATE|os.O_WRONLY, conf.FileMode)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tlogger, err := NewWriterLogger(conf.WriterConfig, file)\n\tif err != nil {\n\t\tfile.Close()\n\t\treturn nil, nil, err\n\t}\n\n\treturn logger, file, nil\n}", "reference": "// NewFileLogger creates a new file logger.", "generated": "// NewFileLogger returns a new FileLogger instance.\n//\n// The returned Logger is used to log messages in the format specified by the\n// WriterConfig. If the UTC flag is set, then all timestamps will be written in\n// UTC timezone. Otherwise they will be localised according to the system's\n//"}
{"id": 6138, "code": "func (b *backendInstance) EthBalanceAt(ctx context.Context,\n\towner common.Address) (*big.Int, error) {\n\tctx2, cancel := b.addTimeout(ctx)\n\tdefer cancel()\n\n\treturn b.conn.ethClient().BalanceAt(ctx2, owner, nil)\n}", "reference": "// EthBalanceAt returns the wei balance of the given account.", "generated": "// EthBalanceAt returns the balance at address.\n//\n// This is used to get the current balance for any given account in\n// Ethereum network. The returned value will be updated if there's new data available from\n// the underlying blockchain provider.\n//\n// Note that this method may return stale values due to the nature"}
{"id": 6147, "code": "func (w *Worker) keyFromChannelData(logger log.Logger,\n\tchannel string) (data.Base64String, error) {\n\tch, err := w.channel(logger, channel)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\toffering, err := w.offering(logger, ch.Offering)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tkey, err := data.ChannelKey(ch.Client, ch.Agent,\n\t\tch.Block, offering.Hash)\n\t// internal\n\tif err != nil {\n\t\tlogger.Add(\"channel\", ch, \"offering\", offering).Error(err.Error())\n\t\treturn \"\", ErrInternal\n\t}\n\treturn data.FromBytes(key), nil\n}", "reference": "// keyFromChannelData returns the unique channel identifier\n// used in a Privatix Service Contract.", "generated": "// keyFromChannelData returns the base64 encoded key for given Channel.\n//\n// The returned value is used to identify the specific block in the BlockStore that contains the message from this channel.\n// If there's no such block then it will return empty Base64String.\nfunc (w *Worker) keyFromChannel"}
{"id": 6157, "code": "func (w *Worker) AgentAfterOfferingDelete(job *data.Job) error {\n\tlogger := w.logger.Add(\n\t\t\"method\", \"AgentAfterOfferingDelete\", \"job\", job)\n\n\toffering, err := w.relatedOffering(\n\t\tlogger, job, data.JobAgentAfterOfferingDelete)\n\tif err != nil {\n\t\treturn err\n\t}\n\toffering.Status = data.OfferRemoved\n\n\tif err := w.saveRecord(logger, w.db.Querier, offering); err != nil {\n\t\treturn err\n\t}\n\n\tagent, err := w.account(logger, offering.Agent)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn w.addJob(logger, nil,\n\t\tdata.JobAccountUpdateBalances, data.JobAccount, agent.ID)\n}", "reference": "// AgentAfterOfferingDelete set offering status to `remove`", "generated": "// AgentAfterOfferingDelete is called after deleting an offer.\n//\n// It updates the related account's balance by removing all offered amounts from it.\n// If there were no offers to remove, then nothing happens.\n// The method also logs that this operation was performed for the given job ID.\n// Finally, if any"}
{"id": 6177, "code": "func (m *Monitor) VerifyChannelsForInactivity() error {\n\tquery := `\n              SELECT channels.id::text\n\t\tFROM channels\n                     LEFT JOIN sessions ses\n                     ON channels.id = ses.channel\n                     LEFT JOIN offerings offer\n                     ON channels.offering = offer.id\n                     INNER JOIN accounts acc\n                     ON channels.agent = acc.eth_addr\n               WHERE channels.service_status IN ('pending', 'active', 'suspended')\n                 AND channels.channel_status NOT IN ('pending')\n                 AND acc.in_use\n               GROUP BY channels.id, offer.max_inactive_time_sec\n              HAVING GREATEST(MAX(ses.last_usage_time), channels.service_changed_time) +\n\t      (offer.max_inactive_time_sec * INTERVAL '1 second') < now();`\n\n\treturn m.processEachChannel(query, m.terminateService)\n}", "reference": "// VerifyChannelsForInactivity scans all channels, that are not terminated,\n// and terminates those of them, who are staying inactive too long.", "generated": "// VerifyChannelsForInactivity checks if any channel has been inactive for more than its maximum allowed inactivity time.\n// If so, it terminates that service to prevent further usage by other users. The termination is done using the terminateService method,\n// which takes care of stopping all active services associated with the terminated account."}
{"id": 6235, "code": "func New(db *reform.DB, logger log.Logger, payAddr string,\n\ttimeout uint) (*Service, error) {\n\treturn &Service{\n\t\tdb:      db,\n\t\tmsgChan: make(chan *req),\n\t\tpayAddr: payAddr,\n\t\ttimeout: time.Duration(timeout) * time.Millisecond,\n\t\tlogger:  logger.Add(\"type\", \"messages/ept.Service\"),\n\t}, nil\n}", "reference": "// New function for initialize the service for generating\n// the Endpoint Message.", "generated": "// New returns new Service instance.\n//\n// The returned service is initialized to listen for messages from the database.\n// It also starts listening for incoming requests at the specified address.\n// If there's no timeout set, it will wait indefinitely until all messages have been processed or closed.\n// Otherwise, it will close after the"}
{"id": 6244, "code": "func BytesToUint32(b []byte) (uint32, error) {\n\tif len(b) != 4 {\n\t\treturn 0, fmt.Errorf(\"wrong len\")\n\t}\n\treturn binary.BigEndian.Uint32(b), nil\n}", "reference": "// BytesToUint32 using big endian.", "generated": "// BytesToUint32 converts a byte slice to uint32.\n//\n// The input must be exactly four bytes long in big-endian order.\n// If it's too short or wrong length, returns zero and an error message.\n// Otherwise, it returns the converted value without any errors.\n// This is useful for converting"}
{"id": 6251, "code": "func ChannelKey(client, agent HexString, block uint32,\n\tofferingHash HexString) ([]byte, error) {\n\tclientAddr, err := HexToAddress(client)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tagentAddr, err := HexToAddress(agent)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\thash, err := base64.URLEncoding.DecodeString(\n\t\tstrings.TrimSpace(string(offeringHash)))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tblockBytes := Uint32ToBytes(block)\n\n\treturn crypto.Keccak256(clientAddr.Bytes(),\n\t\tagentAddr.Bytes(), blockBytes[:],\n\t\tcommon.BytesToHash(hash).Bytes()), nil\n}", "reference": "// ChannelKey returns the unique channel identifier\n// used in a Privatix Service Contract.", "generated": "// ChannelKey returns a key for a channel given client address, offering hash,\n// block number, and agent address.\n//\n// The returned key is used to identify channels in the blockchain database.\n// It's generated by hashing all three parameters together using Keccak-256.\n// This ensures that two different sets of parameters"}
{"id": 6280, "code": "func PanicHunter() {\n\tif panicIgnore {\n\t\treturn\n\t}\n\n\tif err := recover(); err != nil {\n\t\tif enable && notifier != nil {\n\t\t\tnotifier.NotifySync(\n\t\t\t\terrors.New(err, 3), true,\n\t\t\t\tmetadata([]data.HexString{defaultAccEth}))\n\t\t}\n\t\tpanic(err)\n\t}\n}", "reference": "// PanicHunter catches panic, in case of an enabled reporter.", "generated": "// PanicHandler is used to catch panics in the application.\n//\n// If enabled (see EnablePanicHandler) it will call the provided Notifier's Notify method when a panic occurs.\n// The error message passed to this handler should be formatted using errors.New(). This allows for easy formatting of the error string."}
{"id": 6291, "code": "func (m *Marshaller) MarshalRaw(bs []byte) {\n\tif m.Error != nil {\n\t\treturn\n\t}\n\tif len(m.Data) < m.offset+len(bs) {\n\t\tm.Error = io.ErrShortBuffer\n\t\treturn\n\t}\n\n\tm.offset += copy(m.Data[m.offset:], bs)\n}", "reference": "// MarshalRaw copies the raw bytes to the buffer, without a size prefix or\n// padding. This is suitable for appending data already in XDR format from\n// another source.", "generated": "// MarshalRaw writes raw data to the underlying buffer.\n//\n// This method is used when we need to marshal some value that doesn't fit into our marshaled format,\n// like for example a byte slice or a string. It's also useful if we want to add padding bytes at the end\n// of the message"}
{"id": 6293, "code": "func (m *Marshaller) MarshalBytes(bs []byte) {\n\tif m.Error != nil {\n\t\treturn\n\t}\n\tif len(m.Data) < m.offset+4+len(bs)+Padding(len(bs)) {\n\t\tm.Error = io.ErrShortBuffer\n\t\treturn\n\t}\n\n\tm.MarshalUint32(uint32(len(bs)))\n\tm.offset += copy(m.Data[m.offset:], bs)\n\tm.offset += copy(m.Data[m.offset:], padBytes[:Padding(len(bs))])\n}", "reference": "// MarshalString appends the bytes to the buffer, with a size prefix and\n// correct padding.", "generated": "// MarshalBytes marshals data into bytes. The length is stored in 4 bytes at offset.\n// If there's no error, it will return without doing anything else. Otherwise,\n// it sets Error to ErrShortBuffer if buffer size was too small for the given data.\n// It also pads the output byte slice"}
{"id": 6308, "code": "func Prefix(prefix string, p AssetPipeline) AssetPipeline {\n\tif prefix == \"\" {\n\t\treturn p\n\t}\n\n\treturn &prefixPipeline{\n\t\tprefix:        prefix,\n\t\tAssetPipeline: p,\n\t}\n}", "reference": "// Prefix returns an AssetPipeline that prefixes URLs with the\n// given string", "generated": "// Prefix returns a new pipeline that starts with the given prefix.\n// If no prefix is provided, it's equivalent to calling Pipeline().\n//\n// The returned pipeline will be prefixed by all pipelines in the original asset pipeline.\n// This allows for more flexible construction of complex pipelines from simpler ones.\n// For example, if we"}
{"id": 6327, "code": "func Map(ss []string, callback func(string) string) []string {\n\tnewStrings := make([]string, len(ss))\n\tfor i, s := range ss {\n\t\tnewStrings[i] = callback(s)\n\t}\n\n\treturn newStrings\n}", "reference": "// Map returns a slice containing all the elements of ss\n// after applying the callback function to each one", "generated": "// Maps each element in the given slice to its transformed version by applying the provided transformation.\n//\n// The returned slice is created from scratch; it's not modified in-place like some other functions might do.\n// This allows for more predictable side effects when working with slices that need to be preserved intact,\n// such as those"}
{"id": 6383, "code": "func SelectMany(subject Enumerable, toMany Unfolder) Enumerable {\n\treturn selectManyer{\n\t\toriginal: subject,\n\t\ttoMany:   toMany,\n\t}\n}", "reference": "// SelectMany allows for unfolding of values.", "generated": "// SelectMany returns a new enumerable that selects many items from each item in\n// the original enumerable.\n//\n// The returned enumerable is created by unfolding all items in the original\n// enumerable into one-to-many relationships using the provided unfolder.\ntype SelectMany struct {\n\toriginal  Enumerable\n\ttoMany    Unfolder"}
{"id": 6400, "code": "func (stack *Stack) IsEmpty() bool {\n\tstack.key.RLock()\n\tdefer stack.key.RUnlock()\n\treturn stack.underlyer == nil || stack.underlyer.IsEmpty()\n}", "reference": "// IsEmpty tests the Stack to determine if it is populate or not.", "generated": "// IsEmpty returns true if this Stack is empty.\n// Otherwise it will return false. This method should be called only when\n// there's no other way to check whether the stack is empty or not. If we need\n// to frequently call this method then consider using Pop(). It has same effect but\n//"}
{"id": 6407, "code": "func (list *LinkedList) Enumerate(cancel <-chan struct{}) Enumerator {\n\tretval := make(chan interface{})\n\n\tgo func() {\n\t\tlist.key.RLock()\n\t\tdefer list.key.RUnlock()\n\t\tdefer close(retval)\n\n\t\tcurrent := list.first\n\t\tfor current != nil {\n\t\t\tselect {\n\t\t\tcase retval <- current.payload:\n\t\t\t\tbreak\n\t\t\tcase <-cancel:\n\t\t\t\treturn\n\t\t\t}\n\t\t\tcurrent = current.next\n\t\t}\n\t}()\n\n\treturn retval\n}", "reference": "// Enumerate creates a new instance of Enumerable which can be executed on.", "generated": "// Enumerate returns an enumerator that yields each item in this linked list.\n// The returned channel is closed when all items have been yielded or if cancellation occurs.\n// This method can be used to iterate over the elements without having to store them in memory,\n// but it may consume more resources than storing the entire collection because"}
{"id": 6415, "code": "func (list *LinkedList) Sort(comparator Comparator) error {\n\tlist.key.Lock()\n\tdefer list.key.Unlock()\n\tvar err error\n\tlist.first, err = mergeSort(list.first, comparator)\n\tif err != nil {\n\t\treturn err\n\t}\n\tlist.last = findLast(list.first)\n\treturn err\n}", "reference": "// Sort rearranges the positions of the entries in this list so that they are\n// ascending.", "generated": "// Sort sorts this linked list in ascending order according to the given comparator.\n//\n// The sorting is done by recursively splitting the list into two halves until each half has one element,\n// then merging them back together while maintaining sorted order.\n//\n// If there's already only one node left after initial split, it will be"}
{"id": 6420, "code": "func merge(left, right *llNode, comparator Comparator) (first *llNode, err error) {\n\tcurLeft := left\n\tcurRight := right\n\n\tvar last *llNode\n\n\tappendResults := func(updated *llNode) {\n\t\tif last == nil {\n\t\t\tlast = updated\n\t\t} else {\n\t\t\tlast.next = updated\n\t\t\tlast = last.next\n\t\t}\n\t\tif first == nil {\n\t\t\tfirst = last\n\t\t}\n\t}\n\n\tfor curLeft != nil && curRight != nil {\n\t\tvar res int\n\t\tif res, err = comparator(curLeft.payload, curRight.payload); nil != err {\n\t\t\tbreak // Don't return, stitch the remaining elements back on.\n\t\t} else if res < 0 {\n\t\t\tappendResults(curLeft)\n\t\t\tcurLeft = curLeft.next\n\t\t} else {\n\t\t\tappendResults(curRight)\n\t\t\tcurRight = curRight.next\n\t\t}\n\t}\n\n\tif curLeft != nil {\n\t\tappendResults(curLeft)\n\t}\n\tif curRight != nil {\n\t\tappendResults(curRight)\n\t}\n\treturn\n}", "reference": "// merge takes two sorted lists and merges them into one sorted list.\n// Behavior is undefined when you pass a non-sorted list as `left` or `right`", "generated": "// Merge two sorted linked lists into one sorted list using O(n + m) time complexity,\n// where n is the length of the first list and m is the length of the second list.\n//\n// The merged result will be in ascending order according to the provided comparison function.\n// If either input list has duplicate values"}
{"id": 6439, "code": "func (l *List) Remove(pos uint) (interface{}, bool) {\n\tl.key.Lock()\n\tdefer l.key.Unlock()\n\n\tif pos > uint(len(l.underlyer)) {\n\t\treturn nil, false\n\t}\n\tretval := l.underlyer[pos]\n\tl.underlyer = append(l.underlyer[:pos], l.underlyer[pos+1:]...)\n\treturn retval, true\n}", "reference": "// Remove retreives a value from this List and shifts all other values.", "generated": "// Remove removes item at given position from list.\n// Returns removed value or nil if no such element exists in list. If removal is successful returns true; otherwise - false."}
{"id": 6484, "code": "func (h *Handler) Rule(r rule.Rule) *Handler {\n\tif r == nil {\n\t\t// if nothing passed then use the allow-everyting rule\n\t\tr = rule.Satisfied()\n\t}\n\th.rule = r\n\n\treturn h\n}", "reference": "// Rule sets the ruleset for this handler.\n//\n// returns itself.", "generated": "// Rule sets up a new handler for this request based on the given rules.\n// If no rules is provided it will be set to the default \"allow everything\" rule.\n// The returned Handler can now handle requests that match any of these rules,\n// or none at all. It's safe to call multiple times in"}
{"id": 6515, "code": "func (c Client) CreateUser(email string, password string) (*user, error) {\n\tparams := map[string]interface{}{\n\t\t\"user[email]\":    email,\n\t\t\"user[password]\": password,\n\t}\n\tholder := userHolder{}\n\tif err := c.Post(\"users\", params, &holder); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := checkApiErrors(holder.response, \"CreateUser\"); err != nil {\n\t\treturn nil, err\n\t}\n\treturn &holder.User, nil\n}", "reference": "// CreateUser creates a new user given an email and password", "generated": "// Create creates a new User object given its Email address.\n//\n// The provided Password is hashed before being stored in the database.\n// If no hash is specified for the created User, it will be generated automatically when first logged-in to this account.\n// This method returns *nil* if there was any problem creating or"}
{"id": 6523, "code": "func (c Client) GetTransfers(page int) (*transfers, error) {\n\tparams := map[string]int{\n\t\t\"page\": page,\n\t}\n\tholder := transfersHolder{}\n\tif err := c.Get(\"transfers\", params, &holder); err != nil {\n\t\treturn nil, err\n\t}\n\ttransfers := transfers{\n\t\tpaginationStats: holder.paginationStats,\n\t}\n\t// Remove one layer of nesting\n\tfor _, t := range holder.Transfers {\n\t\ttransfers.Transfers = append(transfers.Transfers, t.Transfer)\n\t}\n\treturn &transfers, nil\n}", "reference": "// GetTransfers get transfers associated with an account", "generated": "// Get returns all Transfers for this client.\n//\n// The returned Transfer is paginated by default; if no pagination parameters were provided in the request,\n// then it will be empty. If there was only one item requested, that single transfer will also be returned.\n// Otherwise, the first element of the result slice"}
{"id": 6531, "code": "func (d *SerialDispatcher) DispatchOptional(cmd interface{}) (err error) {\n\td.mutex.RLock()\n\tdefer d.mutex.RUnlock()\n\n\terr = d.Dispatch(cmd)\n\tswitch err.(type) {\n\tcase *NoHandlerFoundError:\n\t\treturn nil\n\tdefault:\n\t\treturn err\n\t}\n}", "reference": "// DispatchOptional implements `Dispatcher.DispatchOptional`", "generated": "// DispatchOptional dispatches the given command to its handler if it exists.\n// If no such handler is found, returns NoHandlerFoundError which will be ignored by\n// subsequent calls to this method until another command is dispatched successfully.\n// This allows for multiple commands being sent in quick succession without blocking,\n// but still"}
{"id": 6532, "code": "func NewParallelDispatcher(handlers []Handler) Dispatcher {\n\treturn &ParallelDispatcher{\n\t\thandlers: handlers,\n\t\tmutex:    sync.RWMutex{},\n\t}\n}", "reference": "// NewParallelDispatcher creates a new PrallelDispatcher with the given handlers", "generated": "// NewParallelDispatcher creates a new parallel dispatcher that dispatches requests to multiple handlers in parallel.\n// The returned dispatcher is safe for concurrent access by multiple goroutines. It uses a mutex internally\n// to protect its internal state from being accessed concurrently while it's iterating over the handler list.\n// This allows other goroutines"}
{"id": 6537, "code": "func (l *listener) Accept() (transport.Conn, error) {\n\tif c, ok := <-l.incoming; ok {\n\t\treturn c.conn, c.err\n\t}\n\treturn nil, fmt.Errorf(\"listener is closed\")\n}", "reference": "// Accept waits for and returns the next connection to the listener.", "generated": "// Accept returns a new connection from this listener's incoming channel.\n// If the listener has been closed or there are no more connections to be made,\n// it will return an error instead. The returned Conn should be used immediately;\n// if it fails, the underlying error can be retrieved using its Error method.\n// This"}
{"id": 6557, "code": "func NewCommand(name string, args ...string) *Command {\n\treturn &Command{\n\t\tname: name,\n\t\targs: args,\n\t}\n}", "reference": "// NewCommand creates a new Livestatus command instance.", "generated": "// NewCommand creates a new command instance.\n//\n// The returned Command is ready to be executed by calling its Execute method.\n// If no arguments were provided for this command, it will execute without any\n// additional parameters passed in from the CLI or environment variables.\n// Otherwise, all provided argument values must match exactly one"}
{"id": 6564, "code": "func (r Record) GetSlice(column string) ([]interface{}, error) {\n\tv, err := r.getKey(reflect.Slice, column)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trv := reflect.ValueOf(v)\n\tn := rv.Len()\n\tout := make([]interface{}, n)\n\n\tfor i := 0; i < n; i++ {\n\t\tout[i] = rv.Index(i).Interface()\n\t}\n\n\treturn out, nil\n}", "reference": "// GetSlice returns a slice of interface value for a specific column.", "generated": "// GetSlice returns a slice from this record's key value.\n//\n// This is used to get all values for a given field in a single operation,\n// which can be more efficient than calling Get() multiple times or using\n// GetMap(). It also allows us to return errors if any individual keys fail.\n//"}
{"id": 6588, "code": "func RemoveSvcAcknowledgement(\n\thost_name string,\n\tservice_description string,\n) *livestatus.Command {\n\treturn livestatus.NewCommand(\n\t\t\"REMOVE_SVC_ACKNOWLEDGEMENT\",\n\t\tstringifyArg(\"host_name\", \"string\", host_name),\n\t\tstringifyArg(\"service_description\", \"string\", service_description),\n\t)\n}", "reference": "// RemoveSvcAcknowledgement creates a new \"REMOVE_SVC_ACKNOWLEDGEMENT\" Nagios command.\n//\n// This removes the problem acknowledgement for a particular service.\n//\n// Once the acknowledgement has been removed, notifications can once again be sent out for the given service.", "generated": "// Removes acknowledgement for given service from specified host.\n// This command is used to remove acknowledgement for specific services\n// that were previously acknowledged by this node in Livestand protocol.\n// It's called when we want to stop listening for new messages about certain\n// service (e.g., after it was removed). The"}
{"id": 6615, "code": "func NewCmdWithRunner(cmdName string, runner func()) (*CmdWithRunner, error) {\n\tif cmdName == \"\" {\n\t\treturn nil, errors.New(\"cmdName cannot be blank\")\n\t}\n\n\tfor _, r := range cmdName {\n\t\tif unicode.IsSpace(r) {\n\t\t\treturn nil, errors.Errorf(\"cmdName cannot contain whitespace: %q\", cmdName)\n\t\t}\n\t}\n\n\treturn &CmdWithRunner{\n\t\tcmdName: cmdName,\n\t\trunner:  runner,\n\t}, nil\n}", "reference": "// NewCmdWithRunner creates a new CmdWithRunner for the provided name and runner. Returns an error if the provided name\n// is not a legal command name.", "generated": "// NewCmdWithRunner creates a new CmdWithRunner from a given command name.\n//\n// The returned Command is wrapped in a Runner that will execute it when called.\n// If the provided command name contains any non-alphanumeric characters or spaces,\n// an error is returned. Otherwise, a valid Command is created and passed"}
{"id": 6617, "code": "func importBreakPaths(file *ast.File) []string {\n\tvar output []string\n\n\tfor _, decl := range file.Decls {\n\t\tif gen, ok := decl.(*ast.GenDecl); ok && gen.Tok == token.IMPORT {\n\t\t\tfor srcIndex, currSpec := range gen.Specs {\n\t\t\t\tif srcIndex > 0 {\n\t\t\t\t\t// if there was a previous element, check if the group has changed\n\t\t\t\t\tcurrGroup := importGroup(importPath(currSpec))\n\t\t\t\t\tprevGroup := importGroup(importPath(gen.Specs[srcIndex-1]))\n\t\t\t\t\tif currGroup != prevGroup {\n\t\t\t\t\t\t// if group has changed, add path to the output\n\t\t\t\t\t\toutput = append(output, importPath(gen.Specs[srcIndex]))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// assume that only one import token block exists\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn output\n}", "reference": "// importBreakPaths returns a slice that contains the import paths before which a line breaks should be inserted.", "generated": "// Import break paths from given ast.File.\n//\n// This is used for generating go.mod files in case we need to generate multiple\n// imports at once (e.g., when importing all dependencies). It's also useful\n// during code generation where it might be necessary to include some specific\n// packages or modules even"}
{"id": 6619, "code": "func SupplierWithPrependedArgs(s CmderSupplier, argsFunc func(cmd Cmd) []string) CmderSupplier {\n\treturn func(cmd Cmd) (Cmder, error) {\n\t\tr, err := s(cmd)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn CmderWithPrependedArgs(r, argsFunc(cmd)...), nil\n\t}\n}", "reference": "// SupplierWithPrependedArgs returns a new Supplier that invokes the provided supplier and returns the result of calling\n// RunnerWithPrependedArgs on the returned runner with the result of applying the provided \"argsFunc\" function to the\n// provided command.", "generated": "// SupplierWithPrependedArgs returns a supplier that prepends arguments to each command.\n// The argument list is generated by calling the provided function for each cmd in the chain,\n// which must return a slice of strings representing the arguments needed for the given cmd.\n//\n// This can be used when commands need different sets"}
{"id": 6633, "code": "func (t *Timer) ServeHTTP(w http.ResponseWriter, req *http.Request) {\n\n\treq.ParseForm()\n\tsortBy := req.Form.Get(\"sort\")\n\n\tstats := &Stats{}\n\tstats.SortBy = strings.ToLower(sortBy)\n\tstats.Generated = time.Now()\n\tstats.UpTime = fmt.Sprintf(\"%s\", stats.Generated.Sub(t.Since))\n\t// Read access OK for map?\n\tstats.Result = make([]*Stat, 0, len(t.routes))\n\tfor k, v := range t.routes {\n\t\tstat := &Stat{}\n\t\tstat.Route = k\n\t\tstat.Count = v.Count\n\t\tstat.Tot = v.Tot\n\t\tstat.Avg = time.Duration(int64(v.Tot) / v.Count)\n\t\tstat.AvgAfter = time.Duration(int64(v.AfterTot) / v.Count)\n\t\tstat.AvgBefore = time.Duration(int64(v.BeforeTot) / v.Count)\n\t\tstat.Max = v.Max\n\t\tstat.Min = v.Min\n\t\tstats.Result = append(stats.Result, stat)\n\t}\n\tsort.Sort(sort.Reverse(stats))\n\tjsonData, _ := json.Marshal(stats)\n\tw.Write(jsonData)\n}", "reference": "// For serving statistics", "generated": "Serve HTTP endpoint to return current statistics about all routes in timer. The request should contain \"sort\" parameter that can be used to sort results by different criteria: total requests or average latency after/before first request. If no sorting is specified then it will default to sorted by total number of requests. Response format is JSON"}
{"id": 6638, "code": "func RectFromSphere(c Vec3, r float32) Rectangle {\n\treturn RectWHD(c[0]-r, c[1]-r, c[2]-r, 2*r, 2*r, 2*r)\n}", "reference": "// RectFromSphere returns the minimum rectangle that contains the circle of\n// center c and radius r.", "generated": "// Returns rectangle that bounds sphere centered at given point.\n// The radius is used to determine half width/height depth in all directions\n// from center. This method returns same result as SphereToRect but without\n// need for additional calculations (sphere's bounding box). It can be faster,\n// especially when dealing with"}
{"id": 6640, "code": "func (r Rectangle) Size() Vec3 {\n\treturn Vec3{\n\t\tr.Max[0] - r.Min[0],\n\t\tr.Max[1] - r.Min[1],\n\t\tr.Max[2] - r.Min[2],\n\t}\n}", "reference": "// Size returns r's width, height and depth.", "generated": "// Size returns the size vector for this rectangle in 3D space.\n// The returned value is calculated by subtracting Min from Max along each dimension,\n// effectively giving us the length/width/height of the bounding box that encloses\n// all points within this rectangle's bounds. This can be used to determine"}
{"id": 6645, "code": "func (r Rectangle) In(s Rectangle) bool {\n\tif r.Empty() {\n\t\treturn true\n\t}\n\t// Note that r.Max is an exclusive bound for r, so that r.In(s)\n\t// does not require that r.Max.In(s).\n\treturn s.Min[0] <= r.Min[0] && r.Max[0] <= s.Max[0] &&\n\t\ts.Min[1] <= r.Min[1] && r.Max[1] <= s.Max[1]\n}", "reference": "// In reports whether Rectangle r is contained in s.", "generated": "// In returns whether rectangle contains another rectangle.\n//\n// The rectangles must be in the same coordinate system; i.e., both have their origin at 0,\n// 0 or one has its origin shifted by some amount but all other coordinates relative to it remain unchanged.\n//\n// This method checks if any point within either"}
{"id": 6647, "code": "func ApproxEpsilon(x, y float64, eps float64) bool {\n\treturn math.Abs(x-y) < eps*(1.0+math.Max(math.Abs(x), math.Abs(y)))\n}", "reference": "// ApproxEpsilon returns true if x ~= y, using provided epsilon value.", "generated": "// Returns true if x is approximately equal to y within epsilon.\n// This method uses the definition from https://en.wikipedia.org/wiki/Approximate_equality#Epsilon-equal_to\n// which states that two numbers x and y are said to be \"approximately\" or \"close enough\"\n// (x \u2248 y"}
{"id": 6650, "code": "func (v Vec3) Copy(dst Vec3) {\n\tdst[0] = v[0]\n\tdst[1] = v[1]\n\tdst[2] = v[2]\n}", "reference": "// Vec3 methods\n// Copy copies the 3 vector components into dst.", "generated": "// Copy copies all elements from src into dst.\n//\n// This is similar to copy(src[:], dst), but it's more efficient because\n// we don't need to create a new slice for the destination vector.\n// Instead, we just modify the existing slice in-place.\nfunc (src *Vec3) Copy"}
{"id": 6703, "code": "func (c *Client) LoadBalancer(identifier string) (*LoadBalancer, error) {\n\tlb := new(LoadBalancer)\n\t_, err := c.MakeApiRequest(\"GET\", \"/1.0/load_balancers/\"+identifier, nil, lb)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn lb, err\n}", "reference": "// LoadBalancer retrieves a detailed view of one load balancer", "generated": "// LoadBalancer loads information about load balancer identifier.\n//\n// This method returns a pointer to newly created LoadBalancer struct if successful,\n// or an error message describing failure reason otherwise. The returned value is\n// populated from server's response data. If there was no error during request but\n// the client cannot parse"}
{"id": 6730, "code": "func FromURL(src *url.URL, w io.Writer, options Options) error {\n\thttpClient := getHTTPClient(options)\n\tvar (\n\t\terr  error\n\t\tresp *http.Response\n\t)\n\tdownloader := func() error {\n\t\tresp, err = httpClient.Get(src.String())\n\t\tif err != nil {\n\t\t\treturn &retriableError{errors.Wrap(err, \"Temporary download error\")}\n\t\t}\n\t\tif resp.StatusCode != http.StatusOK {\n\t\t\tdefer func() { _ = resp.Body.Close() }() // #nosec\n\t\t\treturn errors.Errorf(\"received invalid status code: %d (expected %d)\", resp.StatusCode, http.StatusOK)\n\t\t}\n\t\treturn nil\n\t}\n\tretries := options.Retries\n\tif retries == 0 {\n\t\tretries = 5\n\t}\n\tif err = retryAfter(retries, downloader, options.RetryInterval); err != nil {\n\t\treturn errors.Wrap(err, \"download failed\")\n\t}\n\tdefer func() { _ = resp.Body.Close() }() // #nosec\n\n\tvar (\n\t\tvalidator checksumValidator\n\n\t\treader io.Reader = resp.Body\n\t)\n\n\tif options.ProgressBars != nil && resp.ContentLength > 0 {\n\t\tbar := newProgressBar(resp.ContentLength, options.ProgressBars.MaxWidth, options.ProgressBars.Writer)\n\t\tbar.Start()\n\t\treader = bar.NewProxyReader(reader)\n\t\tdefer func() {\n\t\t\t<-time.After(bar.RefreshRate)\n\t\t\tfmt.Println()\n\t\t}()\n\t}\n\n\tvalidator, reader, err = createValidatorReader(reader, options.ChecksumHash, httpClient, options.Checksum, path.Base(src.Path))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, err = io.Copy(w, reader); err != nil {\n\t\treturn errors.Wrap(err, \"failed to copy contents\")\n\t}\n\n\tif !validator.validate() {\n\t\treturn errors.New(\"checksum validation failed\")\n\t}\n\n\treturn nil\n}", "reference": "// FromURL downloads the specified `src` URL to `w` writer using\n// the specified `Options`.", "generated": "// FromURL downloads content from URL using HTTP client.\n//\n// The downloaded data is written into writer. If progress bars are requested,\n// they will be displayed during downloading process. After successful download,\n// it's checked if provided hash matches actual one by validator. In case of failure,\n// an error message is returned"}
{"id": 6733, "code": "func RandomSecret(length int, rnd *rand.Rand) string {\n\tif 0 <= length {\n\t\tlength = 10\n\t}\n\tsecret := make([]byte, length)\n\tfor i, _ := range secret {\n\t\tsecret[i] = byte(rnd.Int31() % 256)\n\t}\n\treturn base32.StdEncoding.EncodeToString(secret)\n}", "reference": "// Generate a Random secret encoded as a b32 string\n// If the length is <= 0, a default length of 10 bytes will\n// be used, which will generate a secret of length 16.", "generated": "// Returns a random secret key in Base32 format.\n//\n// The returned value is guaranteed to be unique for each call,\n// but it's also possible that two calls return identical values due\n// to the limited entropy available from /dev/urandom (or similar).\nfunc NewRandomSecretGenerator() SecretGenerator {"}
{"id": 6758, "code": "func (a *AddrBook) RemoveAddress(addr *NetAddress) {\n\ta.mtx.Lock()\n\tdefer a.mtx.Unlock()\n\tka := a.addrLookup[addr.String()]\n\tif ka == nil {\n\t\treturn\n\t}\n\tlog.Info(\"Remove address from book\", \"addr\", addr)\n\ta.removeFromAllBuckets(ka)\n}", "reference": "// RemoveAddress removes the address from the book.", "generated": "// RemoveAddress removes the given NetAddress from all buckets in this AddressBook.\n// If the address is already removed, it has no effect. The caller must ensure that\n// only one goroutine accesses the mutex at any time to avoid deadlocks. This method\n// logs information about each removal operation for debugging purposes"}
{"id": 6767, "code": "func (na *NetAddress) Dial() (net.Conn, error) {\n\tconn, err := net.Dial(\"tcp\", na.String())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn conn, nil\n}", "reference": "// Dial calls net.Dial on the address.", "generated": "// Dial establishes a connection to the given NetAddress.\n//\n// The returned Conn is closed when it's no longer needed by the caller,\n// regardless of whether there was an error or success in establishing the dial.\n// If an error occurs during dialing, this method returns that same error.\n// Otherwise, if successful"}
{"id": 6778, "code": "func LogOnPanic(id int64, err interface{}, stacktrace []string, _ *http.Request) {\n\tlogMutex.Lock()\n\tdefer logMutex.Unlock()\n\n\tlog.Printf(\"panic=%016x message=%v\\n\", id, err)\n\tfor _, line := range stacktrace {\n\t\tlog.Printf(\"panic=%016x %s\", id, line)\n\t}\n}", "reference": "// LogOnPanic logs the given panic and its stacktrace, prefixing each line with\n// the panic ID.", "generated": "// LogOnPanic logs panic information to the server's internal logging system.\n//\n// The provided error is logged along with its ID (a unique identifier for\n// each request). If there was no error in this call, then only the panic\n// ID will be recorded. Additionally, if any additional context about"}
{"id": 6791, "code": "func (hub *hub) getChannel(name string) *channel {\n\thub.Lock()\n\tdefer hub.Unlock()\n\tcn, ok := hub.channels[name]\n\tif ok {\n\t\treturn cn\n\t}\n\tcn = makeChannel(hub, name)\n\thub.channels[name] = cn\n\tgo cn.start()\n\treturn cn\n}", "reference": "// GetChannel gets or creates new pubsub channel.", "generated": "// Get returns channel by its name.\n//\n// If there is no such channel in current context then it will be created,\n// started and returned to caller.\n// \n// The given channel can't exist at same time for different contexts.\n// It's used only once per context.\n// \n// This method should be"}
{"id": 6814, "code": "func (c *Client) Push(value interface{}, params map[string]string) (*Client, error) {\n\tbody, err := json.Marshal(value)\n\tif err != nil {\n\t\tlog.Printf(\"%v\\n\", err)\n\t\treturn nil, err\n\t}\n\n\tres, err := c.api.Call(\"POST\", c.Url, c.Auth, body, params)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar r map[string]string\n\n\terr = json.Unmarshal(res, &r)\n\tif err != nil {\n\t\tlog.Printf(\"%v\\n\", err)\n\t\treturn nil, err\n\t}\n\n\tret := &Client{\n\t\tapi:   c.api,\n\t\tAuth:  c.Auth,\n\t\tUrl:   c.Url + \"/\" + r[\"name\"],\n\t\tvalue: value}\n\n\treturn ret, nil\n}", "reference": "// Push creates a new value under the current root url.\n// A populated pointer with that value is also returned.", "generated": "//Push sends data to the server.\n//\n//This is used for sending messages from clients to servers or other services that support this API endpoint.\n//\n//The returned Client object will be updated automatically when it's called again after being created by New(). The URL in the new client can then be accessed via its Url field"}
{"id": 6821, "code": "func (t *trace) Finish() {\n\tif t.err {\n\t\tincrError(t)\n\t}\n\tincr(t)\n\tduration(t)\n\tif t.err {\n\t\tincrError(t)\n\t}\n\tt.trace.Finish()\n}", "reference": "// Finish declares that this trace is complete.\n// The trace should not be used after calling this method.", "generated": "// Finish marks the end of this trace. If there was any error during tracing,\n// it will be recorded in the Error field. The duration is also calculated\n// based on when Start was called. Finally, if there's still some errors left to report,\n// they're incremented again before calling the parent Trace's"}
{"id": 6843, "code": "func (c *Client) PushLinkToChannel(tag, title, u, body string) error {\n\tdata := Link{\n\t\tTag:   tag,\n\t\tType:  \"link\",\n\t\tTitle: title,\n\t\tURL:   u,\n\t\tBody:  body,\n\t}\n\treturn c.Push(\"/pushes\", data)\n}", "reference": "// PushLinkToChannel pushes a link with a title and url to a specific PushBullet device.", "generated": "// Push sends a new link to the specified channel.\n//\n// The push is sent immediately without any delay or caching.\n// If there's already a pending push for this URL in the same\n// time window, it will be overwritten by the latest one.\n// This method returns nil if successful; otherwise, it returns"}
{"id": 6852, "code": "func (c *cachedLoader) MustGetString(key string) string {\n\tb, err := c.Get(key)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"Could not fetch config (%s) %v\", key, err))\n\t}\n\n\tvar s string\n\terr = json.Unmarshal(b, &s)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"Could not unmarshal config (%s) %v\", key, err))\n\t}\n\n\treturn s\n}", "reference": "// MustGetString fetches the config and parses it into a string.  Panics on failure.", "generated": "// MustGetString returns the value for the given key from cache.\n//\n// If no cached value is found or if it cannot be parsed into a string,\n// this method will panic. Otherwise, it simply returns the stored string.\n// This should only be called by methods that handle errors properly to avoid panics."}
{"id": 6870, "code": "func (e *execStreamerBuilder) Exe(exe string) ExecStreamerBuilder {\n\te.d.Exe = exe\n\treturn e\n}", "reference": "//Exe sets the Exe", "generated": "// Exe sets the executable to run in this streamer builder.\n// The default is \"go\". If set to \"\", no command will be executed before running the program.\n// This method returns itself for chaining. It's recommended that only one of Exe or Cmd is used at any time,\n// because setting both"}
{"id": 6884, "code": "func (w *Window) setCell(x, y int, c Cell) {\n\tc.dirty = true\n\tpos := x + (y * w.x)\n\tif pos < len(w.backingStore) {\n\t\tw.backingStore[pos] = c\n\t}\n}", "reference": "// setCell sets the content of the window cell at the x and y coordinate.\n// setCell shall be called from queue context.", "generated": "// Set cell at position in window backing store.\n//\n// This is used to update the internal state of the Window when it's being drawn,\n// but only if we're actually drawing something into this particular window.\n// Otherwise, just mark that the cell needs updating by setting its dirty flag.\nfunc (w *Window"}
{"id": 6896, "code": "func Deinit() {\n\twait := make(chan interface{})\n\tQueue(func() {\n\t\ttermbox.Close()\n\t\tfocus = nil\n\t\tprevFocus = nil\n\t\twindows = make(map[int]*Window) // toss all windows\n\n\t\trawMtx.Lock()\n\t\ttermRaw = false\n\t\trawMtx.Unlock()\n\n\t\twait <- true\n\t})\n\t<-wait\n}", "reference": "// Deinit switches the terminal back to cooked mode and it terminates managed\n// window mode.  Init must be called again if a switch is required again.\n// Deinit shall be called on application exit; failing to do so may leave the\n// terminal corrupted.  If that does happen typing \"reset\" on the shell usually\n// fixes this problem.", "generated": "// Deinit cleans up resources after focus is lost or when exiting.\n// It closes termbox, resets window map to empty, sets raw mode flag back,\n// and waits for any pending operations before returning. This ensures that\n// no further input/output can be processed while in this state. After calling\n// De"}
{"id": 6933, "code": "func (d *Derive) Update(v float64) {\n\tp := atomic.SwapUint64(&d.value, math.Float64bits(v))\n\td.rate.Update(v - math.Float64frombits(p))\n}", "reference": "// Update update rate value based on the stored previous value.", "generated": "// Update updates the value to v if it is different from its current\n// value. If the new value is equal to the old one then no update occurs.\n// The rate will be updated accordingly based on whether or not this was\n// actually an actual change in value. This ensures that we don't get too"}
{"id": 6934, "code": "func (r *Reservoir) Snapshot() Distribution {\n\th := newHistogram(defaultHistogramSize)\n\tr.m.Lock()\n\th = r.hist.Copy(h)\n\tr.m.Unlock()\n\treturn h\n}", "reference": "// Snapshot returns a Distribution", "generated": "// Snapshot returns a snapshot of this reservoir's distribution.\n// The returned histogram is a copy of the current state,\n// so it can be safely used outside of this goroutine without affecting its internal state.\n// Note that if there were any ongoing updates to the reservoir while creating the snapshot,\n// those changes will still occur"}
{"id": 6957, "code": "func (s *Set) RemoveAll(values ...interface{}) {\n\ts.Lock()\n\tdefer s.Unlock()\n\tfor _, value := range values {\n\t\tdelete(s.m, value)\n\t}\n}", "reference": "// RemoveAll removes all values from the set if they exist in the set.", "generated": "// Removes all elements from set that match any given value.\n//\n// This is similar to Set.Remove() but removes multiple matching\n// elements at once instead of one by one. It's more efficient for large sets,\n// especially when removing many identical elements in quick succession.\n// However, it may be slower than calling"}
{"id": 6980, "code": "func (s *Server) SendRequest(connID string, method string, params interface{}, resHandler func(ctx *ResCtx) error) (reqID string, err error) {\n\tif !s.running.Load().(bool) {\n\t\treturn \"\", errors.New(\"use of closed server\")\n\t}\n\n\tif conn, ok := s.conns.GetOk(connID); ok {\n\t\treqID, err = conn.(*Conn).SendRequest(method, params, resHandler)\n\t\t// todo: only log in debug mode?\n\t\tlog.Printf(\"server: send-request: connID: %v, reqID: %v, method: %v, params: %#v, err (if any): %v\", connID, reqID, method, params, err)\n\t\treturn\n\t}\n\n\treturn \"\", fmt.Errorf(\"connection with requested ID: %v does not exist\", connID)\n}", "reference": "// SendRequest sends a JSON-RPC request through the connection denoted by the connection ID with an auto generated request ID.\n// resHandler is called when a response is returned.", "generated": "// SendRequest sends request to specified connection.\n//\n// If there is no active connections for given id it returns error.\n// In case if connection exists but has been already stopped or disconnected,\n// this function will return nil instead of returning actual error message.\n// This way we can handle such cases more easily when calling our"}
{"id": 6996, "code": "func (r *Router) Request(route string, handler func(ctx *neptulon.ReqCtx) error) {\n\tr.routes[route] = handler\n}", "reference": "// Request adds a new request route registry.", "generated": "// RegisterRequest registers a new request route.\n//\n// The provided route is used to identify which handler should be called when this\n// router receives a request for that specific URL path. This method must only be\n// called once per given route; attempting to register multiple handlers for the same\n// route will result in"}
{"id": 7042, "code": "func (c *Conn) setConn(ws *websocket.Conn) error {\n\tc.ws.Store(ws)\n\tc.connected.Store(true)\n\tif err := ws.SetDeadline(time.Now().Add(c.deadline)); err != nil {\n\t\treturn fmt.Errorf(\"conn: error while setting websocket connection deadline: %v\", err)\n\t}\n\treturn nil\n}", "reference": "// Reuse an established websocket.Conn.", "generated": "// Set sets up a new WebSocket connection to be used for sending messages.\n// The given conn is stored in c.connStore so it can be retrieved later when needed,\n// e.g., during message processing or cleanup. If this method returns an error,\n// then no further operations should be performed until the next call to"}
{"id": 7046, "code": "func (r *MockReadWriteCloser) Read(p []byte) (n int, err error) {\n\n\tif err = r.ReadErr; err == nil {\n\t\tr.BytesRead = p\n\t\tn = len(p)\n\t}\n\treturn\n}", "reference": "//Read - satisfies reader interface", "generated": "// Read reads up to n bytes from this reader into destination p.\n// If there is no more data available then it returns 0 for both n and Err.\n// The returned value can be used in conjunction with ReadAt or ReadFrom to read at specific byte offsets within the buffer. It will return immediately if any"}
{"id": 7078, "code": "func (m *MACMaskArg) MarshalBinary() ([]byte, error) {\n\t// Must indicate correct number of directives\n\tif int(m.DirCount) != len(m.Directives) {\n\t\treturn nil, ErrorBadArgumentParameter\n\t}\n\n\t// Allocate byte slice for argument and all directives\n\tb := make([]byte, macMaskArgLen+(directiveLen*m.DirCount))\n\n\t// 1 byte reserved\n\n\tb[1] = uint8(m.Command)\n\tb[2] = uint8(m.Error)\n\tb[3] = m.DirCount\n\n\t// Marshal each directive into binary and copy into byte slice\n\t// after argument\n\tn := 4\n\tfor _, d := range m.Directives {\n\t\tdb, err := d.MarshalBinary()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tcopy(b[n:n+directiveLen], db)\n\t\tn += directiveLen\n\t}\n\n\treturn b, nil\n}", "reference": "// MarshalBinary allocates a byte slice containing the data from a MACMaskArg.\n//\n// If m.DirCount does not indicate the actual length of m.Directives, or\n// a Directive is malformed, ErrorBadArgumentParameter is returned.", "generated": "// Marshal returns marshaled MAC Mask Arg in bytes.\n//\n// The returned value is always non-nil. If there was an error during\n// serialization it will be reported via Err(). This method must return\n// exactly one byte per command type plus two additional bytes to\n// specify the length of the arguments list followed"}
{"id": 7086, "code": "func (s *CORSHandler) CreatePreflight(routes Routes) Routes {\n\tlist := make(Routes, 0, len(routes))\n\thList := make(map[string]*CORSPreflight, len(routes))\n\tfor _, v := range routes {\n\t\tpreflight, ok := hList[v.Path]\n\t\tif !ok {\n\t\t\tpreflight = &CORSPreflight{\n\t\t\t\t*s,\n\t\t\t\tmake([]string, 0, 1),\n\t\t\t\tv.MustAuth,\n\t\t\t}\n\t\t\thList[v.Path] = preflight\n\t\t}\n\n\t\tpreflight.Methods = append(preflight.Methods, v.Method)\n\t\tif v.MustAuth {\n\t\t\tpreflight.UseCredentials = true\n\t\t}\n\t}\n\n\tfor k, v := range hList {\n\t\tlist = append(list, Route{\n\t\t\tName:       \"\",\n\t\t\tMethod:     DEFAULT_CORS_PREFLIGHT_METHOD,\n\t\t\tPath:       k,\n\t\t\tMustAuth:   v.UseCredentials,\n\t\t\tActionFunc: v.ServeHTTP,\n\t\t})\n\t}\n\treturn list\n}", "reference": "// CreatePreflight creates HTTP routes that handles pre-flight requests.", "generated": "// Creates CORS Preflight handler for given route.\n//\n// This method creates new CORSPreflight instance per each path in provided routes.\n// Each created CORSPreflight is added to internal handlers map by its path key.\n// Then all instances from this map are converted into standard HTTP route format.\n// Resulting"}
{"id": 7097, "code": "func (b *RefCountBox) Alloc() (DB, error) {\n\tb.Lock()\n\tdefer b.Unlock()\n\n\tif b.db.DB == nil {\n\t\tif b.DataPath == nil {\n\t\t\treturn DB{}, errorsp.WithStacks(ErrBoxDataPathNotSpecified)\n\t\t}\n\t\tvar db DB\n\t\tvar err error\n\t\tif b.OpenFunc == nil {\n\t\t\tdb, err = Open(b.DataPath(), 0644, nil)\n\t\t} else {\n\t\t\tdb, err = b.OpenFunc(b.DataPath())\n\t\t}\n\t\tif err != nil {\n\t\t\treturn DB{}, errorsp.WithStacks(err)\n\t\t}\n\t\tb.db, b.count = db, 0\n\t}\n\tb.count++\n\treturn b.db, nil\n}", "reference": "// Alloc opens a DB if not openned yet. It adds a reference if already openned.", "generated": "// Allocate returns a new database object that is associated with this box.\n// The returned database will be automatically closed when it goes out of scope,\n// unless explicitly passed to another method or stored in a variable for later use.\n// If no data path has been specified then an error will be returned. Otherwise,\n// if"}
{"id": 7105, "code": "func ToSSN(theString, delimiter string) (string, error) {\n\tf := New(theString)\n\tf.removeNonDigits()\n\n\tif f.length != 9 {\n\t\treturn \"\", errors.New(\"string needs to be 9 digits for Social Security Numbers\")\n\t}\n\n\tvar buffer bytes.Buffer\n\tcount := 0\n\n\tfor _, i := range f.theString {\n\t\tcount++\n\n\t\tbuffer.WriteString(string(i))\n\n\t\tif count == 3 || count == 5 {\n\t\t\tbuffer.WriteString(delimiter)\n\t\t}\n\t}\n\treturn buffer.String(), nil\n}", "reference": "// ToSSN will format the provided string as a SSN.", "generated": "// ToSSN converts a given string into a format that can be used by SSNs.\n//\n// The input must contain exactly nine digits in order to form valid US social security numbers.\n// If it is less than or equal to three characters long then there will be no separator between each group,\n// if more than"}
{"id": 7113, "code": "func (c *Config) OptionMap(section string) map[string]string {\n\toptions := make(map[string]string)\n\tfor _, sect := range c.sections {\n\t\tif sect.name == section {\n\t\t\tfor _, opt := range sect.options {\n\t\t\t\toptions[opt.name] = opt.value\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t}\n\treturn options\n}", "reference": "// OptionMap returns the map option => value for a given section.", "generated": "// OptionMap returns all option values for given configuration section.\n// If no matching section is found, it will return empty map.\n// Options must be in format \"name=value\". For example: \"database.host=localhost\".\n// The returned value can be used to construct database connection URL or other similar strings.\n// This method"}
{"id": 7121, "code": "func Convert(val interface{}, targetType reflect.Type) reflect.Value {\n\tvalue := reflect.ValueOf(val)\n\tif !value.IsValid() {\n\t\treturn reflect.Zero(targetType)\n\t}\n\n\tvalType := value.Type()\n\tif valType.ConvertibleTo(targetType) {\n\t\treturn value.Convert(targetType)\n\t}\n\n\t//fmt.Printf(\"Value type is %v, emptyInterfaceType is %v, equals %v\\n\", valType, emptyInterfaceType, valType == emptyInterfaceType)\n\tinterfaceVal := value.Interface()\n\n\tswitch realVal := interfaceVal.(type) {\n\tcase float64:\n\t\treturn reflect.ValueOf(realVal).Convert(targetType)\n\tcase []interface{}:\n\t\t// val is of type []interface{}, try to convert to typ\n\t\tsliceSize := len(realVal)\n\t\ttargetSlice := reflect.MakeSlice(targetType, 0, sliceSize)\n\t\telemType := targetType.Elem()\n\t\tfor i := 0; i < sliceSize; i++ {\n\t\t\ttargetSlice = reflect.Append(targetSlice, Convert(value.Index(i), elemType))\n\t\t}\n\t\treturn targetSlice\n\t}\n\n\tpanic(fmt.Errorf(\"convert from type %v to %v failed: %v\", valType, targetType, value))\n}", "reference": "// try to convert value to target type, panic if fail", "generated": "// Convert converts a given value into another format.\n//\n// The conversion can be done in two ways:\n// - If both types have the same underlying type (e.g., int -> *int or string -> *string),\n//   then it's simply a copy operation using the Value method.\n// - Otherwise, if"}
{"id": 7123, "code": "func Filter(l LogBackend, r Ruler) LogBackend {\n\treturn &filter{\n\t\tLogBackend: l,\n\t\tr:          r,\n\t}\n}", "reference": "// Filter creates a new filter with rules r for l backend.", "generated": "// Filter returns a new log backend that filters logs based on the given ruler.\ntype filter struct {\n\tlogBackend *LogBackend\n\tr         *Ruler\n}\n\nfunc (f *filter) Write(p []byte) error {\n\tif f.r == nil ||!f.logBackend.Write(p) {\n\t\treturn errors.New"}
{"id": 7139, "code": "func (cn *ContentNegotiator) getEncoder(req *http.Request) Encoder {\n\tvar result = cn.DefaultEncoder\n\taccept := req.Header.Get(\"Accept\")\n\n\tfor k, v := range cn.encoderMap {\n\t\tif strings.Contains(accept, k) {\n\t\t\tresult = v\n\t\t\tbreak\n\t\t}\n\t}\n\treturn result\n}", "reference": "// getEncoder parses the Accept header an returns the appropriate encoder to use", "generated": "// GetEncoder returns the encoder to use for encoding responses based on the Accept header.\n// If no specific content type is specified in the Accept header, it falls back to the default encoder. The ContentNegotiator's internal map of encoders can be used to override this logic if needed."}
{"id": 7148, "code": "func DefaultServiceConfig() ServiceConfig {\n\treturn ServiceConfig{\n\t\t// Dependencies.\n\t\tBackoffFactory: func() Backoff {\n\t\t\treturn &backoff.StopBackOff{}\n\t\t},\n\t\tRandFactory: rand.Int,\n\n\t\t// Settings.\n\t\tRandReader: rand.Reader,\n\t\tTimeout:    1 * time.Second,\n\t}\n}", "reference": "// DefaultServiceConfig provides a default configuration to create a new random\n// service by best effort.", "generated": "// Returns default service configuration for this package. This is used to\n// configure services that use this package's dependencies (e.g., HTTP clients).\n// The returned config includes back-off factories, random number generators,\n// timeouts, etc. These values can be overridden by calling NewClientWithConfig()\n// when creating new"}
{"id": 7222, "code": "func (logger *Logger) Log(level Level, a ...interface{}) {\n\tlogger.log(level, \"\", a...)\n}", "reference": "// Log logs provided message.", "generated": "// Log logs messages at different levels.\n//\n// The log level is one of: Debug, Info, Warning, Error\n// If no message is provided, it will be logged without any prefix.\n// Otherwise, the first argument is prefixed by \"log:\", followed by the second,\n// which contains the formatted string to"}
{"id": 7234, "code": "func (e *Entry) getChildEntry(pat string) *Entry {\n\tfor _, entry := range e.entries {\n\t\tif pat == entry.Pattern() {\n\t\t\treturn entry\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// getChildEntry returns a child Entry that matches the given pattern string.", "generated": "// Child returns child Entry for given pattern.\n//\n// If no matching entries found then return nil.\nfunc (e *Entry) Child(pattern string) (*Entry, error) {\n\tchildE, err := e.getChildEntry(pattern)\n\tif err!= nil || childE == nil {\n\t\treturn nil, fmt.Errorf(\"no"}
{"id": 7263, "code": "func routeSplitFunc(data []byte, atEOF bool) (int, []byte, error) {\n\tif atEOF || data == nil {\n\t\treturn 0, nil, io.EOF\n\t}\n\n\tr, _ := utf8.DecodeRune(data)\n\n\t// matcher\n\tif r == '<' {\n\t\ti := bytes.IndexRune(data, '>')\n\t\tif i == -1 {\n\t\t\treturn 0, nil, NoClosingBracket\n\t\t}\n\t\treturn (i + 1), data[:(i + 1)], nil\n\t}\n\n\t// one char\n\tif len(data) == 1 {\n\t\treturn 1, data, nil\n\t}\n\n\t// should ignore first '/'\n\tslashIndex := bytes.IndexRune(data[1:], '/')\n\tif slashIndex != -1 {\n\t\tslashIndex++\n\t}\n\n\tmatchIndex := bytes.IndexRune(data, '<')\n\n\t// remaining string would be a static entry\n\tif slashIndex == -1 && matchIndex == -1 {\n\t\treturn len(data), data, nil\n\t}\n\n\t// split by '<'\n\t// return data before '<'\n\tif matchIndex != -1 && (slashIndex == -1 || slashIndex > matchIndex) {\n\t\treturn matchIndex, data[:matchIndex], nil\n\t}\n\n\t// split by '/'\n\t// return data before '/' including '/'\n\treturn slashIndex + 1, data[:(slashIndex + 1)], nil\n}", "reference": "// routeSplitFunc is the SplitFunc to scan url pattern.", "generated": "routeSplitFunc splits a URL into parts based on slashes or angle brackets.\nIt returns three values: \n- The length of the part that was matched,\n- A slice containing the matched part,\n- An optional error if there is no more input to process. If this value is non-nil, it indicates end-of-file"}
{"id": 7282, "code": "func (s *Image) Run(cfg *RunConfig) (*Container, error) {\n\targs := make([]string, 0, len(cfg.Options)+len(cfg.Args)+1)\n\targs = append(args, cfg.Options...)\n\targs = append(args, s.name)\n\targs = append(args, cfg.Args...)\n\n\tout, err := s.docker.Run(\"run\", args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcontainer := &Container{\n\t\tdocker: s.docker,\n\t\tid:     strings.TrimSpace(out),\n\t}\n\tif container.id == \"\" {\n\t\treturn nil, UnexpectedOutputError(\n\t\t\t\"Unexpected empty output when running docker container\")\n\t}\n\n\treturn container, nil\n}", "reference": "// Run creates a new Docker container as defined by current image and container\n// template.\n//\n// Returns ExternalCmdError or UnexpectedOutputError on error.", "generated": "// Run runs the Docker image in detached mode.\n//\n// The command to run is constructed from the options provided by the user and any additional arguments that were passed into this method.\n// If no options or arguments are specified then only the name of the image will be used for the command.\n// This means that if there"}
{"id": 7285, "code": "func (s NetworkSettings) PortAt(index int) (string, *HostPublish) {\n\tcounter := 0\n\tfor k, v := range s.Ports {\n\t\tif counter != index {\n\t\t\tcounter++\n\t\t\tcontinue\n\t\t}\n\n\t\treturn k, v\n\t}\n\n\treturn \"\", nil\n}", "reference": "// PortAt returns expose and publish port information at especified index.", "generated": "// PortAt returns port at given index in network settings.\n//\n// If no ports exist for this setting it will return empty string and nil host publish.\nfunc (n NetworkSettings) PortAt(i int) (*PortInfo, error) {\n\tp, err := n.PortAt(i)\n\tif p == \"\" || err"}
{"id": 7297, "code": "func (tx Tx) ForEachGob(folders [][]byte, f func(Bucket, bytesp.Slice, interface{}) error) error {\n\treturn tx.ForEach(folders, func(b Bucket, k, bs bytesp.Slice) error {\n\t\tvar v interface{}\n\t\tif err := gob.NewDecoder(&bs).Decode(&v); err != nil {\n\t\t\treturn errorsp.WithStacksAndMessage(err, \"decoding %d bytes value for key %q failed\", len(bs), string(k))\n\t\t}\n\t\treturn errorsp.WithStacks(f(b, k, v))\n\t})\n}", "reference": "// ForEach iterates over all key values of a folder, decode non-nil values using gob.", "generated": "// ForEachGob iterates over all keys in each bucket using Golang's built-in\n// encoding/gob package to decode values from byte slices into interfaces.\n//\n// The given callback is called once per decoded value; it returns any errors that occur during decoding or processing,\n// which will be propagated up through"}
{"id": 7310, "code": "func (handler *WriteHandler) Handle(record *Record) error {\n\t_, err := handler.Writer.Write([]byte(handler.Formatter.Format(record) + \"\\n\"))\n\treturn err\n}", "reference": "// Handle writes all provided log records to writer provided during creation.", "generated": "// Write writes the record to the writer in the format specified by the formatter.\n// If there is no output stream attached, it returns nil immediately without writing anything.\n// The returned value indicates whether any data was written or if an I/O error occurred while doing so. In case of success,\n// this will be true"}
