{"id": 24, "code": "func (c *ServiceDiscoveryConfig) Validate() error {\n\tfor _, cfg := range c.AzureSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in azure_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.ConsulSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in consul_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.DNSSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in dns_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.EC2SDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in ec2_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.FileSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in file_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.GCESDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in gce_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.KubernetesSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in kubernetes_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.MarathonSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in marathon_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.NerveSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in nerve_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.OpenstackSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in openstack_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.ServersetSDConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in serverset_sd_configs\")\n\t\t}\n\t}\n\tfor _, cfg := range c.StaticConfigs {\n\t\tif cfg == nil {\n\t\t\treturn errors.New(\"empty or null section in static_configs\")\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// Validate validates the ServiceDiscoveryConfig.", "generated": "The service discovery configuration is a collection of config files that are used to determine the type and size/type-of attributes for each module within the application's runtime environment. The default value is an array containing all modules with at least one attribute named \"module\" . This can be changed by setting this option on the command"}
{"id": 36, "code": "func NewDiscovery(conf SDConfig, logger log.Logger) (*Discovery, error) {\n\trt, err := config_util.NewRoundTripperFromConfig(conf.HTTPClientConfig, \"marathon_sd\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif len(conf.AuthToken) > 0 {\n\t\trt, err = newAuthTokenRoundTripper(conf.AuthToken, rt)\n\t} else if len(conf.AuthTokenFile) > 0 {\n\t\trt, err = newAuthTokenFileRoundTripper(conf.AuthTokenFile, rt)\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\td := &Discovery{\n\t\tclient:     &http.Client{Transport: rt},\n\t\tservers:    conf.Servers,\n\t\tappsClient: fetchApps,\n\t}\n\td.Discovery = refresh.NewDiscovery(\n\t\tlogger,\n\t\t\"marathon\",\n\t\ttime.Duration(conf.RefreshInterval),\n\t\td.refresh,\n\t)\n\treturn d, nil\n}", "reference": "// NewDiscovery returns a new Marathon Discovery.", "generated": "// Create a Discovery session for the specified protocol and port to be used as an authentication token in order notify clients of changes made by their peers (see below).\n // This is done using `newSession` which will create two sessions with different protocols on each side; one being created when all peer-to--"}
{"id": 50, "code": "func (d *Discovery) shouldWatch(name string, tags []string) bool {\n\treturn d.shouldWatchFromName(name) && d.shouldWatchFromTags(tags)\n}", "reference": "// shouldWatch returns whether the service of the given name should be watched.", "generated": "This method returns a Discovery object that will watch for the specified tag in an array of strings and return it if found or not returned by this call. The name argument is optional but can be any number from 0 to 255 inclusive as long as there are no non-null characters present within each element; otherwise all elements must"}
{"id": 52, "code": "func (d *Discovery) getDatacenter() error {\n\t// If the datacenter was not set from clientConf, let's get it from the local Consul agent\n\t// (Consul default is to use local node's datacenter if one isn't given for a query).\n\tif d.clientDatacenter != \"\" {\n\t\treturn nil\n\t}\n\n\tinfo, err := d.client.Agent().Self()\n\tif err != nil {\n\t\tlevel.Error(d.logger).Log(\"msg\", \"Error retrieving datacenter name\", \"err\", err)\n\t\trpcFailuresCount.Inc()\n\t\treturn err\n\t}\n\n\tdc, ok := info[\"Config\"][\"Datacenter\"].(string)\n\tif !ok {\n\t\terr := errors.Errorf(\"invalid value '%v' for Config.Datacenter\", info[\"Config\"][\"Datacenter\"])\n\t\tlevel.Error(d.logger).Log(\"msg\", \"Error retrieving datacenter name\", \"err\", err)\n\t\treturn err\n\t}\n\n\td.clientDatacenter = dc\n\treturn nil\n}", "reference": "// Get the local datacenter if not specified.", "generated": "The Datastore API provides an interface that allows you access and manipulate data in your database using SQLite3 or other similar databases such as MongoDB/SQL Server with no additional configuration required by any of these APIs. The following example shows how this can be used on some servers without having to configure anything else at all"}
{"id": 64, "code": "func (ls Labels) HashForLabels(names ...string) uint64 {\n\tb := make([]byte, 0, 1024)\n\n\tfor _, v := range ls {\n\t\tfor _, n := range names {\n\t\t\tif v.Name == n {\n\t\t\t\tb = append(b, v.Name...)\n\t\t\t\tb = append(b, sep)\n\t\t\t\tb = append(b, v.Value...)\n\t\t\t\tb = append(b, sep)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn xxhash.Sum64(b)\n}", "reference": "// HashForLabels returns a hash value for the labels matching the provided names.", "generated": "Hash for labels is a hash function that returns the number of strings in an array and its indices as well to be used by all functions within it including those defined above with no parameters or return values set at runtime using lhs-labels . The following example uses this hashing algorithm which can also perform other operations such like"}
{"id": 117, "code": "func ParseExpr(input string) (Expr, error) {\n\tp := newParser(input)\n\n\texpr, err := p.parseExpr()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = p.typecheck(expr)\n\treturn expr, err\n}", "reference": "// ParseExpr returns the expression parsed from the input.", "generated": "Parsec parses the input and returns an ExPr object with a parser that accepts any of the following values as arguments:\nExpr : String , Error : Boolean , Type : Int , Description . The expr argument is optional or null if no parse fails to find it in its scope. If this option exists"}
{"id": 129, "code": "func (p *parser) expectOneOf(exp1, exp2 ItemType, context string) item {\n\ttoken := p.next()\n\tif token.typ != exp1 && token.typ != exp2 {\n\t\tp.errorf(\"unexpected %s in %s, expected %s or %s\", token.desc(), context, exp1.desc(), exp2.desc())\n\t}\n\treturn token\n}", "reference": "// expectOneOf consumes the next token and guarantees it has one of the required types.", "generated": "The parser expects one of the following items to be present at a given time and returns an error if it does not match any other value for that particular type :\ntype ValueError = None , // Error handling only when there is no matching element return nil\n func parseValueFromExponent(value []string): Exp"}
{"id": 133, "code": "func (p *parser) expectType(node Node, want ValueType, context string) {\n\tt := p.checkType(node)\n\tif t != want {\n\t\tp.errorf(\"expected type %s in %s, got %s\", documentedType(want), context, documentedType(t))\n\t}\n}", "reference": "// expectType checks the type of the node and raises an error if it\n// is not of the expected type.", "generated": "The parser checks if the node is a valid Type , and returns an error for that value . If it does not return an error, then no further processing of this function will be performed on the element or its contents until all other elements are returned as expected by parseTree() . The result may contain any number between 0"}
{"id": 145, "code": "func New(minSize, maxSize int, factor float64, makeFunc func(int) interface{}) *Pool {\n\tif minSize < 1 {\n\t\tpanic(\"invalid minimum pool size\")\n\t}\n\tif maxSize < 1 {\n\t\tpanic(\"invalid maximum pool size\")\n\t}\n\tif factor < 1 {\n\t\tpanic(\"invalid factor\")\n\t}\n\n\tvar sizes []int\n\n\tfor s := minSize; s <= maxSize; s = int(float64(s) * factor) {\n\t\tsizes = append(sizes, s)\n\t}\n\n\tp := &Pool{\n\t\tbuckets: make([]sync.Pool, len(sizes)),\n\t\tsizes:   sizes,\n\t\tmake:    makeFunc,\n\t}\n\n\treturn p\n}", "reference": "// New returns a new Pool with size buckets for minSize to maxSize\n// increasing by the given factor.", "generated": "The newpool() function returns a Pool object that implements the following methods and functions for creating pools of different types (see below). The default is to use an array with no elements or arrays as parameters in order not be confused by other implementations which do not implement these features at all! This method will return any number of"}
{"id": 165, "code": "func sendAlerts(s sender, externalURL string) rules.NotifyFunc {\n\treturn func(ctx context.Context, expr string, alerts ...*rules.Alert) {\n\t\tvar res []*notifier.Alert\n\n\t\tfor _, alert := range alerts {\n\t\t\ta := &notifier.Alert{\n\t\t\t\tStartsAt:     alert.FiredAt,\n\t\t\t\tLabels:       alert.Labels,\n\t\t\t\tAnnotations:  alert.Annotations,\n\t\t\t\tGeneratorURL: externalURL + strutil.TableLinkForExpression(expr),\n\t\t\t}\n\t\t\tif !alert.ResolvedAt.IsZero() {\n\t\t\t\ta.EndsAt = alert.ResolvedAt\n\t\t\t} else {\n\t\t\t\ta.EndsAt = alert.ValidUntil\n\t\t\t}\n\t\t\tres = append(res, a)\n\t\t}\n\n\t\tif len(alerts) > 0 {\n\t\t\ts.Send(res...)\n\t\t}\n\t}\n}", "reference": "// sendAlerts implements the rules.NotifyFunc for a Notifier.", "generated": "// Send notifications to the specified URL and return an error if no response is received from it // or returns nil otherwise. This function accepts two arguments for each notification type (default :nil , optional :true ) that will be sent in one of three ways; either as JSON payload with all fields returned by `send`"}
{"id": 166, "code": "func (g *RuleGroups) Validate() (errs []error) {\n\tset := map[string]struct{}{}\n\n\tfor _, g := range g.Groups {\n\t\tif g.Name == \"\" {\n\t\t\terrs = append(errs, errors.Errorf(\"Groupname should not be empty\"))\n\t\t}\n\n\t\tif _, ok := set[g.Name]; ok {\n\t\t\terrs = append(\n\t\t\t\terrs,\n\t\t\t\terrors.Errorf(\"groupname: \\\"%s\\\" is repeated in the same file\", g.Name),\n\t\t\t)\n\t\t}\n\n\t\tset[g.Name] = struct{}{}\n\n\t\tfor i, r := range g.Rules {\n\t\t\tfor _, err := range r.Validate() {\n\t\t\t\tvar ruleName string\n\t\t\t\tif r.Alert != \"\" {\n\t\t\t\t\truleName = r.Alert\n\t\t\t\t} else {\n\t\t\t\t\truleName = r.Record\n\t\t\t\t}\n\t\t\t\terrs = append(errs, &Error{\n\t\t\t\t\tGroup:    g.Name,\n\t\t\t\t\tRule:     i,\n\t\t\t\t\tRuleName: ruleName,\n\t\t\t\t\tErr:      err,\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t}\n\n\treturn errs\n}", "reference": "// Validate validates all rules in the rule groups.", "generated": "This function checks if a group exists and returns an error message when it does so. If no such condition occurs, then this method will return nil . The default value of false means that there are none specified for any given member or field name; otherwise, all members must have been created with at least one entry to their"}
{"id": 182, "code": "func (r *AlertingRule) SetHealth(health RuleHealth) {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\tr.health = health\n}", "reference": "// SetHealth sets the current health of the alerting rule.", "generated": "// Sets the Health of a rule to be set by the user, or nil if no rules are found for that action.\n // This is useful when you want to prevent an error from happening while setting up new policies and/or checking whether existing policy settings have been changed in any way."}
{"id": 185, "code": "func (r *AlertingRule) SetEvaluationDuration(dur time.Duration) {\n\tr.mtx.Lock()\n\tdefer r.mtx.Unlock()\n\tr.evaluationDuration = dur\n}", "reference": "// SetEvaluationDuration updates evaluationDuration to the duration it took to evaluate the rule on its last evaluation.", "generated": "// Sets the evaluation duration of a rule to be set by the user, using an optional value for `duration`. The default is 0 seconds and can only affect rules that are not yet in use or have been changed since their initial release.\n// This function returns true if this action has already occurred on any given day"}
{"id": 197, "code": "func (g *Group) GetEvaluationDuration() time.Duration {\n\tg.mtx.Lock()\n\tdefer g.mtx.Unlock()\n\treturn g.evaluationDuration\n}", "reference": "// GetEvaluationDuration returns the time in seconds it took to evaluate the rule group.", "generated": "This method returns the elapsed duration of the given group, or nil if no such grouping exists for that particular period. The default is 0 . If a Group has been created with an empty value and its members are not specified in this way, then it will be returned as undefined , otherwise return None ; see below on how"}
{"id": 199, "code": "func (g *Group) GetEvaluationTimestamp() time.Time {\n\tg.mtx.Lock()\n\tdefer g.mtx.Unlock()\n\treturn g.evaluationTimestamp\n}", "reference": "// GetEvaluationTimestamp returns the time the last evaluation of the rule group took place.", "generated": "This function returns the current evaluation timestamp of the group, and optionally a reference to an instance of GObject . The value returned is used as part for debugging purposes only if it has been set in this way before execution started or otherwise specified by any other method on the target object's runtime environment variable that was called with no"}
{"id": 212, "code": "func (w *WALWatcher) Start() {\n\tw.setMetrics()\n\tlevel.Info(w.logger).Log(\"msg\", \"starting WAL watcher\", \"queue\", w.name)\n\n\tgo w.loop()\n}", "reference": "// Start the WALWatcher.", "generated": "This method is used to start a new WAIT client and wait for the next event from its queue before returning it back, or if there are no events in that loop already waiting on this thread at all time. It returns an error message when any of these conditions occur; otherwise, they return nil . The default behavior"}
{"id": 225, "code": "func (sd *StaticProvider) Run(ctx context.Context, ch chan<- []*targetgroup.Group) {\n\t// We still have to consider that the consumer exits right away in which case\n\t// the context will be canceled.\n\tselect {\n\tcase ch <- sd.TargetGroups:\n\tcase <-ctx.Done():\n\t}\n\tclose(ch)\n}", "reference": "// Run implements the Worker interface.", "generated": "/** The Context is a wrapper around an object of type staticProvider . It provides access to all objects within it and returns true if they are not present or false otherwise. */\n/** Returns whether this method has been called successfully by calling `run` on any given target group for each element returned from `context`. If"}
{"id": 228, "code": "func NewDiscovery(\n\tsrvs []string,\n\ttimeout time.Duration,\n\tpaths []string,\n\tlogger log.Logger,\n\tpf func(data []byte, path string) (model.LabelSet, error),\n) (*Discovery, error) {\n\tif logger == nil {\n\t\tlogger = log.NewNopLogger()\n\t}\n\n\tconn, _, err := zk.Connect(\n\t\tsrvs, timeout,\n\t\tfunc(c *zk.Conn) {\n\t\t\tc.SetLogger(treecache.NewZookeeperLogger(logger))\n\t\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tupdates := make(chan treecache.ZookeeperTreeCacheEvent)\n\tsd := &Discovery{\n\t\tconn:    conn,\n\t\tupdates: updates,\n\t\tsources: map[string]*targetgroup.Group{},\n\t\tparse:   pf,\n\t\tlogger:  logger,\n\t}\n\tfor _, path := range paths {\n\t\tsd.treeCaches = append(sd.treeCaches, treecache.NewZookeeperTreeCache(conn, path, updates, logger))\n\t}\n\treturn sd, nil\n}", "reference": "// NewDiscovery returns a new discovery along Zookeeper parses with\n// the given parse function.", "generated": "// Create a new Discovery object for the given model and its attributes in Zookeepedia's Tree cache event // to allow logging of changes made by other models or their descendants on this node if it is not already created from an existing root Node instance with no children nodes that are still present at runtime; otherwise create"}
{"id": 244, "code": "func (q *querier) Select(p *storage.SelectParams, matchers ...*labels.Matcher) (storage.SeriesSet, storage.Warnings, error) {\n\tquery, err := ToQuery(q.mint, q.maxt, matchers, p)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tremoteReadGauge := remoteReadQueries.WithLabelValues(q.client.Name())\n\tremoteReadGauge.Inc()\n\tdefer remoteReadGauge.Dec()\n\n\tres, err := q.client.Read(q.ctx, query)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn FromQueryResult(res), nil, nil\n}", "reference": "// Select implements storage.Querier and uses the given matchers to read series\n// sets from the Client.", "generated": "The QuerySpecifier provides a simple way to specify the type of queries that should be performed on an object by specifying its serialization and metadata properties in order for it's data to appear as if they were written using SQLite or other similar database technologies such AsyncDB . The specifiers are defined with sql-spec"}
{"id": 298, "code": "func NewRegexp(s string) (Regexp, error) {\n\tregex, err := regexp.Compile(\"^(?:\" + s + \")$\")\n\treturn Regexp{\n\t\tRegexp:   regex,\n\t\toriginal: s,\n\t}, err\n}", "reference": "// NewRegexp creates a new anchored Regexp and returns an error if the\n// passed-in regular expression does not compile.", "generated": "New rematch is a new match for the given strings and returns an empty list of matches if no matching elements are found in it. It can be used to replace any existing matched element with another one or as part thereof without having to use `new` again at all times. The returned value will not contain anything that"}
{"id": 303, "code": "func (sp *scrapePool) reload(cfg *config.ScrapeConfig) error {\n\ttargetScrapePoolReloads.Inc()\n\tstart := time.Now()\n\n\tsp.mtx.Lock()\n\tdefer sp.mtx.Unlock()\n\n\tclient, err := config_util.NewClientFromConfig(cfg.HTTPClientConfig, cfg.JobName)\n\tif err != nil {\n\t\ttargetScrapePoolReloadsFailed.Inc()\n\t\treturn errors.Wrap(err, \"error creating HTTP client\")\n\t}\n\tsp.config = cfg\n\toldClient := sp.client\n\tsp.client = client\n\n\tvar (\n\t\twg              sync.WaitGroup\n\t\tinterval        = time.Duration(sp.config.ScrapeInterval)\n\t\ttimeout         = time.Duration(sp.config.ScrapeTimeout)\n\t\tlimit           = int(sp.config.SampleLimit)\n\t\thonorLabels     = sp.config.HonorLabels\n\t\thonorTimestamps = sp.config.HonorTimestamps\n\t\tmrc             = sp.config.MetricRelabelConfigs\n\t)\n\n\tfor fp, oldLoop := range sp.loops {\n\t\tvar (\n\t\t\tt       = sp.activeTargets[fp]\n\t\t\ts       = &targetScraper{Target: t, client: sp.client, timeout: timeout}\n\t\t\tnewLoop = sp.newLoop(scrapeLoopOptions{\n\t\t\t\ttarget:          t,\n\t\t\t\tscraper:         s,\n\t\t\t\tlimit:           limit,\n\t\t\t\thonorLabels:     honorLabels,\n\t\t\t\thonorTimestamps: honorTimestamps,\n\t\t\t\tmrc:             mrc,\n\t\t\t})\n\t\t)\n\t\twg.Add(1)\n\n\t\tgo func(oldLoop, newLoop loop) {\n\t\t\toldLoop.stop()\n\t\t\twg.Done()\n\n\t\t\tgo newLoop.run(interval, timeout, nil)\n\t\t}(oldLoop, newLoop)\n\n\t\tsp.loops[fp] = newLoop\n\t}\n\n\twg.Wait()\n\toldClient.CloseIdleConnections()\n\ttargetReloadIntervalLength.WithLabelValues(interval.String()).Observe(\n\t\ttime.Since(start).Seconds(),\n\t)\n\treturn nil\n}", "reference": "// reload the scrape pool with the given scrape configuration. The target state is preserved\n// but all scrape loops are restarted with the new scrape configuration.\n// This method returns after all scrape loops that were stopped have stopped scraping.", "generated": "// This function is used to check if a connection has been established and return the current status of that connected pool or an empty one for any other reason than being closed by this thread. // The default value will be false otherwise it returns true when no connections are found in its queue; see below on how to set up"}
{"id": 332, "code": "func NewDiscovery(conf *SDConfig, logger log.Logger) *Discovery {\n\tif logger == nil {\n\t\tlogger = log.NewNopLogger()\n\t}\n\n\tdisc := &Discovery{\n\t\tpaths:      conf.Files,\n\t\tinterval:   time.Duration(conf.RefreshInterval),\n\t\ttimestamps: make(map[string]float64),\n\t\tlogger:     logger,\n\t}\n\tfileSDTimeStamp.addDiscoverer(disc)\n\treturn disc\n}", "reference": "// NewDiscovery returns a new file discovery for the given paths.", "generated": "// Create a new Discovery instance for the specified file descriptor and logging status (default is None).\n // This will be used to create an initial discovery of all files in the directory that are not already created by this method. The default value is 0 if no existing directories exist or 1 otherwise. If any other values have"}
{"id": 349, "code": "func (r *ewmaRate) tick() {\n\tnewEvents := atomic.LoadInt64(&r.newEvents)\n\tatomic.AddInt64(&r.newEvents, -newEvents)\n\tinstantRate := float64(newEvents) / r.interval.Seconds()\n\n\tr.mutex.Lock()\n\tdefer r.mutex.Unlock()\n\n\tif r.init {\n\t\tr.lastRate += r.alpha * (instantRate - r.lastRate)\n\t} else {\n\t\tr.init = true\n\t\tr.lastRate = instantRate\n\t}\n}", "reference": "// tick assumes to be called every r.interval.", "generated": "// Initializes the new events and returns an array of all existing event types that are available for use in this method.\n // The initializer is a mutable object with no methods or properties to be called from within it; any changes made by calling init will not affect its state until after initialization. This can cause"}
{"id": 390, "code": "func (a *Args) GetBool(key string) bool {\n\tswitch b2s(a.Peek(key)) {\n\t// Support the same true cases as strconv.ParseBool\n\t// See: https://github.com/golang/go/blob/4e1b11e2c9bdb0ddea1141eed487be1a626ff5be/src/strconv/atob.go#L12\n\t// and Y and Yes versions.\n\tcase \"1\", \"t\", \"T\", \"true\", \"TRUE\", \"True\", \"y\", \"yes\", \"Y\", \"YES\", \"Yes\":\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}", "reference": "// GetBool returns boolean value for the given key.\n//\n// true is returned for \"1\", \"t\", \"T\", \"true\", \"TRUE\", \"True\", \"y\", \"yes\", \"Y\", \"YES\", \"Yes\",\n// otherwise false is returned.", "generated": "This function returns a list of strings that are either True or False, depending on whether they contain an argument to getBools() . The returned values can be any number between 0-255 inclusive in order from 1 through 255 inclusive for each character pair present within this range. If no arguments exist then return None , otherwise"}
{"id": 420, "code": "func (cc *LBClient) DoTimeout(req *Request, resp *Response, timeout time.Duration) error {\n\tdeadline := time.Now().Add(timeout)\n\treturn cc.get().DoDeadline(req, resp, deadline)\n}", "reference": "// DoTimeout calculates deadline and calls DoDeadline on the least loaded client", "generated": "This method returns a new instance of LB Client that is used to perform the following actions on requests and responses from clients in order for them not only be able access their own resources but also receive information about those available at any given moment by requesting or responding directly via HTTP/1DP request with an exception being provided when it"}
{"id": 430, "code": "func (ctx *RequestCtx) TLSConnectionState() *tls.ConnectionState {\n\ttlsConn, ok := ctx.c.(connTLSer)\n\tif !ok {\n\t\treturn nil\n\t}\n\tstate := tlsConn.ConnectionState()\n\treturn &state\n}", "reference": "// TLSConnectionState returns TLS connection state.\n//\n// The function returns nil if the underlying connection isn't tls.Conn.\n//\n// The returned state may be used for verifying TLS version, client certificates,\n// etc.", "generated": "// Initializes the connection state and returns a new string representing its contents in bytes of length 0x0A00 .\n // The initial value is an array containing all strings that are to be returned by TLS for each session or buffer-local key pair used as input; this will return null if no such keys exist"}
{"id": 453, "code": "func (s *Server) Serve(ln net.Listener) error {\n\tvar lastOverflowErrorTime time.Time\n\tvar lastPerIPErrorTime time.Time\n\tvar c net.Conn\n\tvar err error\n\n\ts.mu.Lock()\n\t{\n\t\tif s.ln != nil {\n\t\t\ts.mu.Unlock()\n\t\t\treturn ErrAlreadyServing\n\t\t}\n\n\t\ts.ln = ln\n\t\ts.done = make(chan struct{})\n\t}\n\ts.mu.Unlock()\n\n\tmaxWorkersCount := s.getConcurrency()\n\ts.concurrencyCh = make(chan struct{}, maxWorkersCount)\n\twp := &workerPool{\n\t\tWorkerFunc:      s.serveConn,\n\t\tMaxWorkersCount: maxWorkersCount,\n\t\tLogAllErrors:    s.LogAllErrors,\n\t\tLogger:          s.logger(),\n\t\tconnState:       s.setState,\n\t}\n\twp.Start()\n\n\t// Count our waiting to accept a connection as an open connection.\n\t// This way we can't get into any weird state where just after accepting\n\t// a connection Shutdown is called which reads open as 0 because it isn't\n\t// incremented yet.\n\tatomic.AddInt32(&s.open, 1)\n\tdefer atomic.AddInt32(&s.open, -1)\n\n\tfor {\n\t\tif c, err = acceptConn(s, ln, &lastPerIPErrorTime); err != nil {\n\t\t\twp.Stop()\n\t\t\tif err == io.EOF {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\ts.setState(c, StateNew)\n\t\tatomic.AddInt32(&s.open, 1)\n\t\tif !wp.Serve(c) {\n\t\t\tatomic.AddInt32(&s.open, -1)\n\t\t\ts.writeFastError(c, StatusServiceUnavailable,\n\t\t\t\t\"The connection cannot be served because Server.Concurrency limit exceeded\")\n\t\t\tc.Close()\n\t\t\ts.setState(c, StateClosed)\n\t\t\tif time.Since(lastOverflowErrorTime) > time.Minute {\n\t\t\t\ts.logger().Printf(\"The incoming connection cannot be served, because %d concurrent connections are served. \"+\n\t\t\t\t\t\"Try increasing Server.Concurrency\", maxWorkersCount)\n\t\t\t\tlastOverflowErrorTime = time.Now()\n\t\t\t}\n\n\t\t\t// The current server reached concurrency limit,\n\t\t\t// so give other concurrently running servers a chance\n\t\t\t// accepting incoming connections on the same address.\n\t\t\t//\n\t\t\t// There is a hope other servers didn't reach their\n\t\t\t// concurrency limits yet :)\n\t\t\t//\n\t\t\t// See also: https://github.com/valyala/fasthttp/pull/485#discussion_r239994990\n\t\t\tif s.SleepWhenConcurrencyLimitsExceeded > 0 {\n\t\t\t\ttime.Sleep(s.SleepWhenConcurrencyLimitsExceeded)\n\t\t\t}\n\t\t}\n\t\tc = nil\n\t}\n}", "reference": "// Serve serves incoming connections from the given listener.\n//\n// Serve blocks until the given listener returns permanent error.", "generated": "This function returns true if all pending requests for TCP or UDP sockets have been accepted by this client and false otherwise; in that case they will not receive new messages until either of these conditions has occurred before receiving them from another socket provider's network interface handler . If both condition values were met during processing then no further request was"}
{"id": 480, "code": "func (req *Request) SetBodyString(body string) {\n\treq.RemoveMultipartFormFiles()\n\treq.closeBodyStream()\n\treq.bodyBuffer().SetString(body)\n}", "reference": "// SetBodyString sets request body.", "generated": "This method is used to close the body buffer and return the new String object from the request, or if no response was received by this call it returns a nil value for any error encountered during processing of that form file in which an exception occurred due either to insufficient information about its type at runtime such as missing fields on some"}
{"id": 511, "code": "func (h *ResponseHeader) SetCookie(cookie *Cookie) {\n\th.cookies = setArgBytes(h.cookies, cookie.Key(), cookie.Cookie(), argsHasValue)\n}", "reference": "// SetCookie sets the given response cookie.\n//\n// It is save re-using the cookie after the function returns.", "generated": "Set Cookie is a wrapper around the HTTP request header and returns an object that contains all cookies for this server's session in JSON format as well with optional additional information about how to handle them later on when needed by other clients or servers using it from within their own application codebase . The default value of nil means no response"}
{"id": 513, "code": "func (h *ResponseHeader) DelCookie(key string) {\n\th.cookies = delAllArgs(h.cookies, key)\n}", "reference": "// DelCookie removes cookie under the given key from response header.\n//\n// Note that DelCookie doesn't remove the cookie from the client.\n// Use DelClientCookie instead.", "generated": "This method returns a Cookie object that contains the cookie information for each request and its associated headers in JSON format. The returned cookies are then passed to this function as an argument which can be used by any of your application's methods or functions provided it is called with appropriate parameters such like \"cookie\" , \"headers\", etc"}
{"id": 517, "code": "func (h *ResponseHeader) PeekBytes(key []byte) []byte {\n\th.bufKV.key = append(h.bufKV.key[:0], key...)\n\tnormalizeHeaderKey(h.bufKV.key, h.disableNormalizing)\n\treturn h.peek(h.bufKV.key)\n}", "reference": "// PeekBytes returns header value for the given key.\n//\n// Returned value is valid until the next call to ResponseHeader.\n// Do not store references to returned value. Make copies instead.", "generated": "This method is used to check if a header has been read from a buffer and return the value of that byte as an integer or unsigned int . The returned result will be either 0 , 1 : zero bytes in size for all headers except those with no padding at offset 16384 ; otherwise it returns nil which means nothing happens"}
{"id": 525, "code": "func (h *RequestHeader) WriteTo(w io.Writer) (int64, error) {\n\tn, err := w.Write(h.Header())\n\treturn int64(n), err\n}", "reference": "// WriteTo writes request header to w.\n//\n// WriteTo implements io.WriterTo interface.", "generated": "This method returns a string representation of the request header and an optional message to be sent when it is received by the client or server in response for processing purposes. The returned value will contain information about how many bytes have been read from the requested data stream before being processed into this object as well if any errors occurred during its"}
{"id": 536, "code": "func (c *Cookie) Expire() time.Time {\n\texpire := c.expire\n\tif expire.IsZero() {\n\t\texpire = CookieExpireUnlimited\n\t}\n\treturn expire\n}", "reference": "// Expire returns cookie expiration time.\n//\n// CookieExpireUnlimited is returned if cookie doesn't expire", "generated": "This method creates a new cookie that is used to create the expiration date and expires it for use in future sessions, or returns an error if no cookies are created at all by this call. The default value of nil means nothing will be returned from any session creation attempt until either end-of\u2013session has been reached;"}
{"id": 537, "code": "func (c *Cookie) SetValue(value string) {\n\tc.value = append(c.value[:0], value...)\n}", "reference": "// SetValue sets cookie value.", "generated": "Set Value is a wrapper around the Cookie object, which can be used to create new values for any of its properties and methods in an array or list context using set() . The default implementation uses c::set as it does not provide access to all objects that are created by this method; however, if you want"}
{"id": 577, "code": "func (mx *Mux) Patch(pattern string, handlerFn http.HandlerFunc) {\n\tmx.handle(mPATCH, pattern, handlerFn)\n}", "reference": "// Patch adds the route `pattern` that matches a PATCH http method to\n// execute the `handlerFn` http.HandlerFunc.", "generated": "Patch is a patch function that returns an error if the given path does not match any of its parameters or nil otherwise. It can be used to check for missing files and directories in your system's PATH environment variable by calling mpatch() . The default value will return true when no matching paths are found on this target file"}
{"id": 579, "code": "func (mx *Mux) Put(pattern string, handlerFn http.HandlerFunc) {\n\tmx.handle(mPUT, pattern, handlerFn)\n}", "reference": "// Put adds the route `pattern` that matches a PUT http method to\n// execute the `handlerFn` http.HandlerFunc.", "generated": "This function returns a list of strings that are matched against the given URL and handlers for each match in an HTTP request or response body respectively. The returned lists can be used to create new URLs with different attributes such as \"http://\" , \"https\", etc., but they must not contain any special characters like \"/\"."}
{"id": 600, "code": "func SearchArticles(w http.ResponseWriter, r *http.Request) {\n\trender.RenderList(w, r, NewArticleListResponse(articles))\n}", "reference": "// SearchArticles searches the Articles data for a matching article.\n// It's just a stub, but you get the idea.", "generated": "This method returns a list of all the articles that have been found in an article's search history and contains information about each one as well (including any missing content). The returned List is then sorted by its contents based on whether it has already existed for at least two days or not since last searching was performed. If no"}
{"id": 603, "code": "func UpdateArticle(w http.ResponseWriter, r *http.Request) {\n\tarticle := r.Context().Value(\"article\").(*Article)\n\n\tdata := &ArticleRequest{Article: article}\n\tif err := render.Bind(r, data); err != nil {\n\t\trender.Render(w, r, ErrInvalidRequest(err))\n\t\treturn\n\t}\n\tarticle = data.Article\n\tdbUpdateArticle(article.ID, article)\n\n\trender.Render(w, r, NewArticleResponse(article))\n}", "reference": "// UpdateArticle updates an existing Article in our persistent store.", "generated": "// Create a new Article object with the following properties and methods to update it in an appropriate way for each request :\n// // The name of the resource that is being updated (e., \"articles\") -> w . Name , // A string containing all articles from this page's database as well Async func main()"}
{"id": 605, "code": "func adminRouter() chi.Router {\n\tr := chi.NewRouter()\n\tr.Use(AdminOnly)\n\tr.Get(\"/\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(\"admin: index\"))\n\t})\n\tr.Get(\"/accounts\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(\"admin: list accounts..\"))\n\t})\n\tr.Get(\"/users/{userId}\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(fmt.Sprintf(\"admin: view user id %v\", chi.URLParam(r, \"userId\"))))\n\t})\n\treturn r\n}", "reference": "// A completely separate router for administrator routes", "generated": "This method returns a new RoutingContext object that contains the routing information for each route in an existing RouteBuilder . The routes are passed to this interface as parameters and can be used by any of the methods provided with the Router class or its own constructor (see below). This is useful when you want your router to use"}
{"id": 606, "code": "func AdminOnly(next http.Handler) http.Handler {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\tisAdmin, ok := r.Context().Value(\"acl.admin\").(bool)\n\t\tif !ok || !isAdmin {\n\t\t\thttp.Error(w, http.StatusText(http.StatusForbidden), http.StatusForbidden)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t})\n}", "reference": "// AdminOnly middleware restricts access to just administrators.", "generated": "This method is used to ensure that the user agent does not attempt access control over a resource in an arbitrary manner (e., by using HTTP/1). It can be useful for managing requests from multiple sources or as part of other actions such and such-like; it also allows you specify which source code should execute when"}
{"id": 612, "code": "func DefaultCompress(next http.Handler) http.Handler {\n\treturn Compress(flate.DefaultCompression)(next)\n}", "reference": "// DefaultCompress is a middleware that compresses response\n// body of predefined content types to a data format based\n// on Accept-Encoding request header. It uses a default\n// compression level.\n// DEPRECATED", "generated": "Default compresses the current buffer to a specified size, and returns an error if it is not found in that range or otherwise fails with no response from any of its handlers (i.,e.: nil). The default compression method defaults for all buffers except those which are already compressed by other methods such as compress() . If"}
{"id": 623, "code": "func canonicalHostedZone(hostname string) string {\n\tfor suffix, zone := range canonicalHostedZones {\n\t\tif strings.HasSuffix(hostname, suffix) {\n\t\t\treturn zone\n\t\t}\n\t}\n\n\treturn \"\"\n}", "reference": "// canonicalHostedZone returns the matching canonical zone for a given hostname.", "generated": "This is a wrapper around the default hostnames for all zones in an existing network (see below). It uses local hosts to create new ones and then returns them as well if they exist or not at any point during their lifetime. The name of the Zone object will be used when creating it from scratch; this can also"}
{"id": 629, "code": "func InMemoryWithLogging() InMemoryOption {\n\treturn func(p *InMemoryProvider) {\n\t\tp.OnApplyChanges = func(changes *plan.Changes) {\n\t\t\tfor _, v := range changes.Create {\n\t\t\t\tlog.Infof(\"CREATE: %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.UpdateOld {\n\t\t\t\tlog.Infof(\"UPDATE (old): %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.UpdateNew {\n\t\t\t\tlog.Infof(\"UPDATE (new): %v\", v)\n\t\t\t}\n\t\t\tfor _, v := range changes.Delete {\n\t\t\t\tlog.Infof(\"DELETE: %v\", v)\n\t\t\t}\n\t\t}\n\t}\n}", "reference": "// InMemoryWithLogging injects logging when ApplyChanges is called", "generated": "// Create a new log file with the following contents in it and add them to the existing logs for each update of this logger // This is called logging when an error occurs while creating or deleting a Logger object from its current location; if there are no errors encountered during creation/deleting that would cause any issues"}
{"id": 656, "code": "func (sc *serviceSource) filterByAnnotations(services []*v1.Service) ([]*v1.Service, error) {\n\tlabelSelector, err := metav1.ParseToLabelSelector(sc.annotationFilter)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tselector, err := metav1.LabelSelectorAsSelector(labelSelector)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// empty filter returns original list\n\tif selector.Empty() {\n\t\treturn services, nil\n\t}\n\n\tfilteredList := []*v1.Service{}\n\n\tfor _, service := range services {\n\t\t// convert the service's annotations to an equivalent label selector\n\t\tannotations := labels.Set(service.Annotations)\n\n\t\t// include service if its annotations match the selector\n\t\tif selector.Matches(annotations) {\n\t\t\tfilteredList = append(filteredList, service)\n\t\t}\n\t}\n\n\treturn filteredList, nil\n}", "reference": "// filterByAnnotations filters a list of services by a given annotation selector.", "generated": "filter by annotation is a simple way of filtering out all annotated fields from any given field in order for each type and class that it contains. It can be used as follows: Filter By Annotation - This method filters only those types with which you have access or are interested; otherwise this will not work at ALL!"}
{"id": 658, "code": "func (p *Plan) Calculate() *Plan {\n\tt := newPlanTable()\n\n\tfor _, current := range filterRecordsForPlan(p.Current) {\n\t\tt.addCurrent(current)\n\t}\n\tfor _, desired := range filterRecordsForPlan(p.Desired) {\n\t\tt.addCandidate(desired)\n\t}\n\n\tchanges := &Changes{}\n\tchanges.Create = t.getCreates()\n\tchanges.Delete = t.getDeletes()\n\tchanges.UpdateNew, changes.UpdateOld = t.getUpdates()\n\tfor _, pol := range p.Policies {\n\t\tchanges = pol.Apply(changes)\n\t}\n\n\tplan := &Plan{\n\t\tCurrent: p.Current,\n\t\tDesired: p.Desired,\n\t\tChanges: changes,\n\t}\n\n\treturn plan\n}", "reference": "// Calculate computes the actions needed to move current state towards desired\n// state. It then passes those changes to the current policy for further\n// processing. It returns a copy of Plan with the changes populated.", "generated": "// Create a list of all the possible values for an existing Plan and update it with its corresponding value if necessary.\n // This function is used to create lists that are not currently in use by any other program or service on disk. It returns nil when no such item exists. func NewPlane(name string):"}
{"id": 662, "code": "func NewTargets(target ...string) Targets {\n\tt := make(Targets, 0, len(target))\n\tt = append(t, target...)\n\treturn t\n}", "reference": "// NewTargets is a convenience method to create a new Targets object from a vararg of strings", "generated": "New Targs is a new string representation of the current targets. It contains all strings that are currently in use and any other characters (including those used by default). The name should be short enough to avoid confusion with \"new\" or \"old\". Parameters :\nArgs :\nTarget : A list containing names for each"}
{"id": 721, "code": "func NewRfc2136Provider(host string, port int, zoneName string, insecure bool, keyName string, secret string, secretAlg string, axfr bool, domainFilter DomainFilter, dryRun bool, actions rfc2136Actions) (Provider, error) {\n\tsecretAlgChecked, ok := tsigAlgs[secretAlg]\n\tif !ok && !insecure {\n\t\treturn nil, errors.Errorf(\"%s is not supported TSIG algorithm\", secretAlg)\n\t}\n\n\tr := &rfc2136Provider{\n\t\tnameserver:   net.JoinHostPort(host, strconv.Itoa(port)),\n\t\tzoneName:     dns.Fqdn(zoneName),\n\t\tinsecure:     insecure,\n\t\tdomainFilter: domainFilter,\n\t\tdryRun:       dryRun,\n\t\taxfr:         axfr,\n\t}\n\tif actions != nil {\n\t\tr.actions = actions\n\t} else {\n\t\tr.actions = r\n\t}\n\n\tif !insecure {\n\t\tr.tsigKeyName = dns.Fqdn(keyName)\n\t\tr.tsigSecret = secret\n\t\tr.tsigSecretAlg = secretAlgChecked\n\t}\n\n\tlog.Infof(\"Configured RFC2136 with zone '%s' and nameserver '%s'\", r.zoneName, r.nameserver)\n\treturn r, nil\n}", "reference": "// NewRfc2136Provider is a factory function for OpenStack rfc2136 providers", "generated": "// Initializes the new RFC2137 provider for use in a remote server using an existing client-side API // that has been created by another service or application to provide access control over it's own protocol implementation; this method provides only one way of accessing its interface if you are running other services on your local network"}
{"id": 734, "code": "func (p *AWSSDProvider) RegisterInstance(service *sd.Service, ep *endpoint.Endpoint) error {\n\tfor _, target := range ep.Targets {\n\t\tlog.Infof(\"Registering a new instance \\\"%s\\\" for service \\\"%s\\\" (%s)\", target, *service.Name, *service.Id)\n\n\t\tattr := make(map[string]*string)\n\n\t\tif ep.RecordType == endpoint.RecordTypeCNAME {\n\t\t\tif p.isAWSLoadBalancer(target) {\n\t\t\t\tattr[sdInstanceAttrAlias] = aws.String(target)\n\t\t\t} else {\n\t\t\t\tattr[sdInstanceAttrCname] = aws.String(target)\n\t\t\t}\n\t\t} else if ep.RecordType == endpoint.RecordTypeA {\n\t\t\tattr[sdInstanceAttrIPV4] = aws.String(target)\n\t\t} else {\n\t\t\treturn fmt.Errorf(\"invalid endpoint type (%v)\", ep)\n\t\t}\n\n\t\tif !p.dryRun {\n\t\t\t_, err := p.client.RegisterInstance(&sd.RegisterInstanceInput{\n\t\t\t\tServiceId:  service.Id,\n\t\t\t\tAttributes: attr,\n\t\t\t\tInstanceId: aws.String(p.targetToInstanceID(target)),\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}", "reference": "// RegisterInstance creates a new instance in given service.", "generated": "// Initializes the AwssdProvider class and returns an array of instances that are registered with this provider // using its name as their primary key pair to initialize it in order from most to least likely return values based on `awssdsdk` data attributes var wcs : AWSDSDK , dns :"}
{"id": 769, "code": "func canonicalizeDomainName(d string) string {\n\tif !strings.HasSuffix(d, \".\") {\n\t\td += \".\"\n\t}\n\treturn strings.ToLower(d)\n}", "reference": "// converts domain name to FQDN", "generated": "This function returns a dictionary of domain names that are valid for the given name and suffixes in use by default when creating an application or service using DNS (or any other type). The following example creates two domains named ns1.example.com and ns2 . Each is created with one unique prefix to distinguish it from"}
{"id": 772, "code": "func addEndpoint(ep *endpoint.Endpoint, recordSets map[string]*recordSet, delete bool) {\n\tkey := fmt.Sprintf(\"%s/%s\", ep.DNSName, ep.RecordType)\n\trs := recordSets[key]\n\tif rs == nil {\n\t\trs = &recordSet{\n\t\t\tdnsName:    canonicalizeDomainName(ep.DNSName),\n\t\t\trecordType: ep.RecordType,\n\t\t\tnames:      make(map[string]bool),\n\t\t}\n\t}\n\tif rs.zoneID == \"\" {\n\t\trs.zoneID = ep.Labels[designateZoneID]\n\t}\n\tif rs.recordSetID == \"\" {\n\t\trs.recordSetID = ep.Labels[designateRecordSetID]\n\t}\n\tfor _, rec := range strings.Split(ep.Labels[designateOriginalRecords], \"\\000\") {\n\t\tif _, ok := rs.names[rec]; !ok && rec != \"\" {\n\t\t\trs.names[rec] = true\n\t\t}\n\t}\n\ttargets := ep.Targets\n\tif ep.RecordType == endpoint.RecordTypeCNAME {\n\t\ttargets = canonicalizeDomainNames(targets)\n\t}\n\tfor _, t := range targets {\n\t\trs.names[t] = !delete\n\t}\n\trecordSets[key] = rs\n}", "reference": "// adds endpoint into recordset aggregation, loading original values from endpoint labels first", "generated": "// Add endpoints to the database and create a new one for each of them (see below).\n // This is done by adding an entry in db-name with name \"example\" as its first field; this will be used when creating records from existing databases or if there are no other fields available at all on"}
{"id": 787, "code": "func (ms *dedupSource) Endpoints() ([]*endpoint.Endpoint, error) {\n\tresult := []*endpoint.Endpoint{}\n\tcollected := map[string]bool{}\n\n\tendpoints, err := ms.source.Endpoints()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, ep := range endpoints {\n\t\tidentifier := ep.DNSName + \" / \" + ep.Targets.String()\n\n\t\tif _, ok := collected[identifier]; ok {\n\t\t\tlog.Debugf(\"Removing duplicate endpoint %s\", ep)\n\t\t\tcontinue\n\t\t}\n\n\t\tcollected[identifier] = true\n\t\tresult = append(result, ep)\n\t}\n\n\treturn result, nil\n}", "reference": "// Endpoints collects endpoints from its wrapped source and returns them without duplicates.", "generated": "The destination of the source is a string containing an array of strings that are to be used as delimiters for future use in applications where it may not fit within existing code or data structures and should instead only contain one character at a time when needed by application developers who wish their programs can access them from other sources such"}
{"id": 791, "code": "func (sdr *AWSSDRegistry) ApplyChanges(changes *plan.Changes) error {\n\tfilteredChanges := &plan.Changes{\n\t\tCreate:    changes.Create,\n\t\tUpdateNew: filterOwnedRecords(sdr.ownerID, changes.UpdateNew),\n\t\tUpdateOld: filterOwnedRecords(sdr.ownerID, changes.UpdateOld),\n\t\tDelete:    filterOwnedRecords(sdr.ownerID, changes.Delete),\n\t}\n\n\tsdr.updateLabels(filteredChanges.Create)\n\tsdr.updateLabels(filteredChanges.UpdateNew)\n\tsdr.updateLabels(filteredChanges.UpdateOld)\n\tsdr.updateLabels(filteredChanges.Delete)\n\n\treturn sdr.provider.ApplyChanges(filteredChanges)\n}", "reference": "// ApplyChanges filters out records not owned the External-DNS, additionally it adds the required label\n// inserted in the AWS SD instance as a CreateID field", "generated": "The AWSDRgrant method provides a way to create and update the current state of an existing policy or database in order for it's users/controllers accesses to be updated by its administrators without having any additional user interaction with that data being made available through other methods such as registry entries etc.. The following example"}
{"id": 800, "code": "func createDiskImage(dest string, size int, r io.Reader) error {\n\t// Convert a raw image from stdin to the dest VMDK image.\n\tsizeBytes := int64(size) << 20 // usually won't fit in 32-bit int (max 2GB)\n\t// FIXME: why isn't this just using the vbm*() functions?\n\tcmd := exec.Command(vboxManageCmd, \"convertfromraw\", \"stdin\", dest,\n\t\tfmt.Sprintf(\"%d\", sizeBytes), \"--format\", \"VMDK\")\n\n\tlog.Debug(cmd)\n\n\tif os.Getenv(\"MACHINE_DEBUG\") != \"\" {\n\t\tcmd.Stdout = os.Stdout\n\t\tcmd.Stderr = os.Stderr\n\t}\n\n\tstdin, err := cmd.StdinPipe()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Starting command\")\n\n\tif err := cmd.Start(); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Copying to stdin\")\n\n\tn, err := io.Copy(stdin, r)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Filling zeroes\")\n\n\t// The total number of bytes written to stdin must match sizeBytes, or\n\t// VBoxManage.exe on Windows will fail. Fill remaining with zeros.\n\tif left := sizeBytes - n; left > 0 {\n\t\tif err := zeroFill(stdin, left); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tlog.Debug(\"Closing STDIN\")\n\n\t// cmd won't exit until the stdin is closed.\n\tif err := stdin.Close(); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Debug(\"Waiting on cmd\")\n\n\treturn cmd.Wait()\n}", "reference": "// createDiskImage makes a disk image at dest with the given size in MB. If r is\n// not nil, it will be read as a raw disk image to convert from.", "generated": "The CreateDisk Image function creates an array of images that can be used as disk partitions for creating and deleting disks within your system's virtual machine environment. This allows youto use any file format suchas .zip , *.tarx , etc., without having access control over which files are created by default when running Disk Manager"}
{"id": 802, "code": "func (n *hostOnlyNetwork) SaveIPv4(vbox VBoxManager) error {\n\tif n.IPv4.IP != nil && n.IPv4.Mask != nil {\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tlog.Warn(\"Windows might ask for the permission to configure a network adapter. Sometimes, such confirmation window is minimized in the taskbar.\")\n\t\t}\n\n\t\tif err := vbox.vbm(\"hostonlyif\", \"ipconfig\", n.Name, \"--ip\", n.IPv4.IP.String(), \"--netmask\", net.IP(n.IPv4.Mask).String()); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}", "reference": "// SaveIPv4 changes the ipv4 configuration of the host-only network.", "generated": "This function returns an IPv6 address that can be used as host only if it has been configured with --ip . If no ip configuration was specified and this option exists, then all hosts will have their IP addresses set up by default on Windows Vista or later versions of Microsoft's operating system; otherwise, they are not allowed"}
{"id": 821, "code": "func (d *Driver) Restart() error {\n\tcs := d.client()\n\t_, err := cs.RequestWithContext(context.TODO(), &egoscale.RebootVirtualMachine{\n\t\tID: d.ID,\n\t})\n\n\treturn err\n}", "reference": "// Restart reboots the existing VM instance.", "generated": "This method returns a new virtual machine that is restarted by the driver and can be used to resume any existing Virtual Machine created with this call without having to create an additional VM or restore it from scratch using DLLs provided in Driver's configuration file for each of its drivers . The returned object will contain all necessary information"}
{"id": 822, "code": "func (d *Driver) Remove() error {\n\tclient := d.client()\n\n\t// Destroy the SSH key from CloudStack\n\tif d.KeyPair != \"\" {\n\t\tkey := &egoscale.SSHKeyPair{Name: d.KeyPair}\n\t\tif err := client.DeleteWithContext(context.TODO(), key); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Destroy the virtual machine\n\tif d.ID != \"\" {\n\t\tvm := &egoscale.VirtualMachine{ID: d.ID}\n\t\tif err := client.DeleteWithContext(context.TODO(), vm); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tlog.Infof(\"The Anti-Affinity group and Security group were not removed\")\n\n\treturn nil\n}", "reference": "// Remove destroys the VM instance and the associated SSH key.", "generated": "This function removes the remote hostname of a user, or any other name that is associated with it by default in an attempt to prevent unauthorized access on its network interface using DNS servers for localhosts without their permission. The following example deletes all users who are connected via DHCP server IP addresses within 10 hops after they"}
{"id": 823, "code": "func (d *Driver) getCloudInit() ([]byte, error) {\n\tvar err error\n\tif d.UserDataFile != \"\" {\n\t\td.UserData, err = ioutil.ReadFile(d.UserDataFile)\n\t}\n\n\treturn d.UserData, err\n}", "reference": "// Build a cloud-init user data string that will install and run\n// docker.", "generated": "// Initializes the Cloud Init process and returns a new instance of Driver with an initializer for each user data file that is created by this driver in order to initialize it asynchronously from within Windows PowerShell on startup.\n// This method will be called once every 10 seconds or so when using Microsoft Edge's \"Start"}
{"id": 834, "code": "func deviceFlowAuth(oauthCfg azure.OAuthConfig, clientID, resource string) (*azure.ServicePrincipalToken, error) {\n\tcl := oauthClient()\n\tdeviceCode, err := azure.InitiateDeviceAuth(&cl, oauthCfg, clientID, resource)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to start device auth: %v\", err)\n\t}\n\tlog.Debug(\"Retrieved device code.\", logutil.Fields{\n\t\t\"expires_in\": to.Int64(deviceCode.ExpiresIn),\n\t\t\"interval\":   to.Int64(deviceCode.Interval),\n\t})\n\n\t// Example message: \u201cTo sign in, open https://aka.ms/devicelogin and enter\n\t// the code 0000000 to authenticate.\u201d\n\tlog.Infof(\"Microsoft Azure: %s\", to.String(deviceCode.Message))\n\n\ttoken, err := azure.WaitForUserCompletion(&cl, deviceCode)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Failed to complete device auth: %v\", err)\n\t}\n\n\tspt, err := azure.NewServicePrincipalTokenFromManualToken(oauthCfg, clientID, resource, *token)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"Error constructing service principal token: %v\", err)\n\t}\n\treturn spt, nil\n}", "reference": "// deviceFlowAuth prints a message to the screen for user to take action to\n// consent application on a browser and in the meanwhile the authentication\n// endpoint is polled until user gives consent, denies or the flow times out.\n// Returned token must be saved.", "generated": "The Azur API provides a simple way for users of Microsoft Azure services (including those that are not registered with an account or have no user credentials). The following example shows how this can be used as a starting point when creating new accounts on Windows Server 2012 R2 using PowerShell cmdlets from within Visual Studio 2013 . This"}
{"id": 842, "code": "func (c *ComputeUtil) staticAddress() (string, error) {\n\t// is the address a name?\n\tisName, err := regexp.MatchString(\"[a-z]([-a-z0-9]*[a-z0-9])?\", c.address)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tif !isName {\n\t\treturn c.address, nil\n\t}\n\n\t// resolve the address by name\n\texternalAddress, err := c.service.Addresses.Get(c.project, c.region(), c.address).Do()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn externalAddress.Address, nil\n}", "reference": "// staticAddress returns the external static IP address.", "generated": "This function returns an Address object that contains all of the addresses in the project's Project directory and their corresponding subdirectories as well with no additional information about which projects are being created or updated to be used for purposes other than those specified here. The default value will return None if there was any change made since this call"}
{"id": 849, "code": "func (c *ComputeUtil) startInstance() error {\n\top, err := c.service.Instances.Start(c.project, c.zone, c.instanceName).Do()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tlog.Infof(\"Waiting for instance to start.\")\n\treturn c.waitForRegionalOp(op.Name)\n}", "reference": "// startInstance starts the instance.", "generated": "This method is used when the application starts with a new project and stops after it has started using an existing one or more instances of ComputesUtils.\nThe following example shows how to use this approach in production code without any additional dependencies on runtime resources such as libraries that are not available from other applications at compile time"}
{"id": 867, "code": "func osDiskStorageContainerURL(account *storage.AccountProperties, vmName string) string {\n\treturn fmt.Sprintf(\"%s%s/\", to.String(account.PrimaryEndpoints.Blob), osDiskStorageContainerName(vmName))\n}", "reference": "// osDiskStorageContainerURL crafts a URL with a trailing slash pointing\n// to the full Azure Blob Container URL for given VM name.", "generated": "This method returns a container URL for the storage account that is used in an OS disk drive (or any other device). The returned URI can be either local or remote and must contain at least one of the following fields :\nThe primary endpoints are specified as strings . This field specifies which devices should store their data on"}
{"id": 892, "code": "func (d *Driver) Create() error {\n\tlog.Infof(\"Generating SSH Key\")\n\n\tif err := ssh.GenerateSSHKey(d.GetSSHKeyPath()); err != nil {\n\t\treturn err\n\t}\n\n\tlog.Infof(\"Creating host...\")\n\n\tc, err := newComputeUtil(d)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif err := c.openFirewallPorts(d); err != nil {\n\t\treturn err\n\t}\n\n\tif d.UseExisting {\n\t\treturn c.configureInstance(d)\n\t}\n\treturn c.createInstance(d)\n}", "reference": "// Create creates a GCE VM instance acting as a docker host.", "generated": "// Generates a keypair for the specified port and creates an instance of that protocol to use as its default gateway on all ports in this network interface.\n // This is done by creating two instances with different namespaces based upon their respective protocols being created using createHostPortNamespace().\n// The first one will"}
{"id": 908, "code": "func (d *Driver) Restart() error {\n\tif err := d.checkLegacyDriver(true); err != nil {\n\t\treturn err\n\t}\n\n\t// NOTE(ahmetalpbalkan) Azure will always keep the VM in Running state\n\t// during the restart operation. Hence we rely on returned async operation\n\t// polling to make sure the reboot is waited upon.\n\tc, err := d.newAzureClient()\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn c.RestartVirtualMachine(d.ResourceGroup, d.naming().VM())\n}", "reference": "// Restart reboots the virtual machine instance.", "generated": "This method returns a new virtual machine that can be used as an asynchronous backup or restore service for Windows XP and later versions of Microsoft Visual Studio 2003/2008 R2 SP1 with no additional dependencies required by any other operating system version prior-installed at this time. The default value was 0xFFFFFFF . This"}
{"id": 914, "code": "func (d *Driver) Start() error {\n\tif err := cmd(\"Hyper-V\\\\Start-VM\", d.MachineName); err != nil {\n\t\treturn err\n\t}\n\n\tip, err := d.waitForIP()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\td.IPAddress = ip\n\n\treturn nil\n}", "reference": "// Start starts an host", "generated": "// Initializes the VM to start with a default IP address and returns an empty string if it is not already set up for this purpose.\n // This function will be called when all of its parameters are passed in as arguments.\n// The initial value should contain no more than one argument or two values that can't"}
{"id": 921, "code": "func (d *BaseDriver) GetSSHUsername() string {\n\tif d.SSHUser == \"\" {\n\t\td.SSHUser = DefaultSSHUser\n\t}\n\treturn d.SSHUser\n}", "reference": "// GetSSHUsername returns the ssh user name, root if not specified", "generated": "// Initializes the SSI key for this user and returns it to a local storage device if necessary.\n // This function is used by default when creating new SSH keys, but can be overridden with an explicit call to\n#define DEFAULT_SYSKEY(username): #define DEVICE_DELE"}
{"id": 937, "code": "func NewDriver(machineName, storePath string) drivers.Driver {\n\tlog.Debug(\"Instantiating Rackspace driver.\", map[string]string{\"machineName\": machineName})\n\n\tinner := openstack.NewDerivedDriver(machineName, storePath)\n\tdriver := &Driver{\n\t\tDriver: inner,\n\t}\n\tinner.SetClient(&Client{\n\t\tdriver: driver,\n\t})\n\n\treturn driver\n}", "reference": "// NewDriver instantiates a Rackspace driver.", "generated": "This is a new Driver class that implements the newly created interface of the existing Routing API and provides access to all routing data in an arbitrary format (i.,e.: JSON). The underlying implementation will be used for creating routes from any given hostname or port number as well; this method does not provide additional functionality such"}
{"id": 945, "code": "func (d *Driver) GetCreateFlags() []mcnflag.Flag {\n\treturn []mcnflag.Flag{\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_CPU_COUNT\",\n\t\t\tName:   \"vmwarevsphere-cpu-count\",\n\t\t\tUsage:  \"vSphere CPU number for docker VM\",\n\t\t\tValue:  defaultCpus,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_MEMORY_SIZE\",\n\t\t\tName:   \"vmwarevsphere-memory-size\",\n\t\t\tUsage:  \"vSphere size of memory for docker VM (in MB)\",\n\t\t\tValue:  defaultMemory,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_DISK_SIZE\",\n\t\t\tName:   \"vmwarevsphere-disk-size\",\n\t\t\tUsage:  \"vSphere size of disk for docker VM (in MB)\",\n\t\t\tValue:  defaultDiskSize,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_BOOT2DOCKER_URL\",\n\t\t\tName:   \"vmwarevsphere-boot2docker-url\",\n\t\t\tUsage:  \"vSphere URL for boot2docker image\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER\",\n\t\t\tName:   \"vmwarevsphere-vcenter\",\n\t\t\tUsage:  \"vSphere IP/hostname for vCenter\",\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER_PORT\",\n\t\t\tName:   \"vmwarevsphere-vcenter-port\",\n\t\t\tUsage:  \"vSphere Port for vCenter\",\n\t\t\tValue:  defaultSDKPort,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_USERNAME\",\n\t\t\tName:   \"vmwarevsphere-username\",\n\t\t\tUsage:  \"vSphere username\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_PASSWORD\",\n\t\t\tName:   \"vmwarevsphere-password\",\n\t\t\tUsage:  \"vSphere password\",\n\t\t},\n\t\tmcnflag.StringSliceFlag{\n\t\t\tEnvVar: \"VSPHERE_NETWORK\",\n\t\t\tName:   \"vmwarevsphere-network\",\n\t\t\tUsage:  \"vSphere network where the docker VM will be attached\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATASTORE\",\n\t\t\tName:   \"vmwarevsphere-datastore\",\n\t\t\tUsage:  \"vSphere datastore for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATACENTER\",\n\t\t\tName:   \"vmwarevsphere-datacenter\",\n\t\t\tUsage:  \"vSphere datacenter for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_FOLDER\",\n\t\t\tName:   \"vmwarevsphere-folder\",\n\t\t\tUsage:  \"vSphere folder for the docker VM. This folder must already exist in the datacenter.\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_POOL\",\n\t\t\tName:   \"vmwarevsphere-pool\",\n\t\t\tUsage:  \"vSphere resource pool for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_HOSTSYSTEM\",\n\t\t\tName:   \"vmwarevsphere-hostsystem\",\n\t\t\tUsage:  \"vSphere compute resource where the docker VM will be instantiated. This can be omitted if using a cluster with DRS.\",\n\t\t},\n\t\tmcnflag.StringSliceFlag{\n\t\t\tEnvVar: \"VSPHERE_CFGPARAM\",\n\t\t\tName:   \"vmwarevsphere-cfgparam\",\n\t\t\tUsage:  \"vSphere vm configuration parameters (used for guestinfo)\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_CLOUDINIT\",\n\t\t\tName:   \"vmwarevsphere-cloudinit\",\n\t\t\tUsage:  \"vSphere cloud-init file or url to set in the guestinfo\",\n\t\t},\n\t}\n}", "reference": "// GetCreateFlags registers the flags this driver adds to\n// \"docker-machine create\"", "generated": "Code:\nfunc (d *Driver) GetCreateFlags() []mcnflag.Flag {\n\treturn []mcnflag.Flag{\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_CPU_COUNT\",\n\t\t\tName:   \"vmwarevsphere-cpu-count\",\n\t\t\tUsage:  \"vSphere CPU number for docker VM\",\n\t\t\tValue:  defaultCpus,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_MEMORY_SIZE\",\n\t\t\tName:   \"vmwarevsphere-memory-size\",\n\t\t\tUsage:  \"vSphere size of memory for docker VM (in MB)\",\n\t\t\tValue:  defaultMemory,\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_DISK_SIZE\",\n\t\t\tName:   \"vmwarevsphere-disk-size\",\n\t\t\tUsage:  \"vSphere size of disk for docker VM (in MB)\",\n\t\t\tValue:  defaultDiskSize,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_BOOT2DOCKER_URL\",\n\t\t\tName:   \"vmwarevsphere-boot2docker-url\",\n\t\t\tUsage:  \"vSphere URL for boot2docker image\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER\",\n\t\t\tName:   \"vmwarevsphere-vcenter\",\n\t\t\tUsage:  \"vSphere IP/hostname for vCenter\",\n\t\t},\n\t\tmcnflag.IntFlag{\n\t\t\tEnvVar: \"VSPHERE_VCENTER_PORT\",\n\t\t\tName:   \"vmwarevsphere-vcenter-port\",\n\t\t\tUsage:  \"vSphere Port for vCenter\",\n\t\t\tValue:  defaultSDKPort,\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_USERNAME\",\n\t\t\tName:   \"vmwarevsphere-username\",\n\t\t\tUsage:  \"vSphere username\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_PASSWORD\",\n\t\t\tName:   \"vmwarevsphere-password\",\n\t\t\tUsage:  \"vSphere password\",\n\t\t},\n\t\tmcnflag.StringSliceFlag{\n\t\t\tEnvVar: \"VSPHERE_NETWORK\",\n\t\t\tName:   \"vmwarevsphere-network\",\n\t\t\tUsage:  \"vSphere network where the docker VM will be attached\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATASTORE\",\n\t\t\tName:   \"vmwarevsphere-datastore\",\n\t\t\tUsage:  \"vSphere datastore for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_DATACENTER\",\n\t\t\tName:   \"vmwarevsphere-datacenter\",\n\t\t\tUsage:  \"vSphere datacenter for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_FOLDER\",\n\t\t\tName:   \"vmwarevsphere-folder\",\n\t\t\tUsage:  \"vSphere folder for the docker VM. This folder must already exist in the datacenter.\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_POOL\",\n\t\t\tName:   \"vmwarevsphere-pool\",\n\t\t\tUsage:  \"vSphere resource pool for docker VM\",\n\t\t},\n\t\tmcnflag.StringFlag{\n\t\t\tEnvVar: \"VSPHERE_HOSTSYSTEM\",\n\t\t\tName:   \"vmwarevsphere-hostsystem\",\n\t\t\tUsage:  \"h"}
{"id": 963, "code": "func (v *View) Data() interface{} {\n\tv.dataLock.RLock()\n\tdefer v.dataLock.RUnlock()\n\treturn v.data\n}", "reference": "// Data returns the most-recently-received data from Consul for this View.", "generated": "This method is used to lock the data in a view, and then return it when no further operations are performed on that object by calling this methods with an empty value of nil . The following example shows how you can use these functions for locking objects using one or more locks without any additional information about their contents being available at"}
{"id": 1020, "code": "func NewKVListQuery(s string) (*KVListQuery, error) {\n\tif s != \"\" && !KVListQueryRe.MatchString(s) {\n\t\treturn nil, fmt.Errorf(\"kv.list: invalid format: %q\", s)\n\t}\n\n\tm := regexpMatch(KVListQueryRe, s)\n\treturn &KVListQuery{\n\t\tstopCh: make(chan struct{}, 1),\n\t\tdc:     m[\"dc\"],\n\t\tprefix: m[\"prefix\"],\n\t}, nil\n}", "reference": "// NewKVListQuery parses a string into a dependency.", "generated": "New k v list query for the specified KVM namespace and a new VDB entry to be created in order of priority (default is \"priority\" if no matching VM exists). The default value is 0 . If this option is not set, all queries will fail with an empty match record or null , unless they are"}
{"id": 1021, "code": "func NewDedupManager(config *config.DedupConfig, clients *dep.ClientSet, brain *template.Brain, templates []*template.Template) (*DedupManager, error) {\n\td := &DedupManager{\n\t\tconfig:    config,\n\t\tclients:   clients,\n\t\tbrain:     brain,\n\t\ttemplates: templates,\n\t\tleader:    make(map[*template.Template]<-chan struct{}),\n\t\tlastWrite: make(map[*template.Template]uint64),\n\t\tupdateCh:  make(chan struct{}, 1),\n\t\tstopCh:    make(chan struct{}),\n\t}\n\treturn d, nil\n}", "reference": "// NewDedupManager creates a new Dedup manager", "generated": "New DEDUP Manager is a new interface for the builtin client set and brains template functions that are used to create an instance of this class in order not only from scratch but also as part or after initialization (see below). It provides two methods which can be called on any object created by using its constructor method;"}
{"id": 1045, "code": "func NewVaultReadQuery(s string) (*VaultReadQuery, error) {\n\ts = strings.TrimSpace(s)\n\ts = strings.Trim(s, \"/\")\n\tif s == \"\" {\n\t\treturn nil, fmt.Errorf(\"vault.read: invalid format: %q\", s)\n\t}\n\n\tsecretURL, err := url.Parse(s)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &VaultReadQuery{\n\t\tstopCh:      make(chan struct{}, 1),\n\t\trawPath:     secretURL.Path,\n\t\tqueryValues: secretURL.Query(),\n\t}, nil\n}", "reference": "// NewVaultReadQuery creates a new datacenter dependency.", "generated": "// This function reads the contents of the vault read query and returns a new VACUUM object with all keys in it for each key that is not an existing vaults entry or any other value returned by this method (i., e..).\n // The default values are used to store information about how many entries"}
{"id": 1057, "code": "func (c *Child) Kill() {\n\tlog.Printf(\"[INFO] (child) killing process\")\n\tc.Lock()\n\tdefer c.Unlock()\n\tc.kill()\n}", "reference": "// Kill sends the kill signal to the child process and waits for successful\n// termination. If no kill signal is defined, the process is killed with the\n// most aggressive kill signal. If the process does not gracefully stop within\n// the provided KillTimeout, the process is force-killed. If a splay was\n// provided, this function will sleep for a random period of time between 0 and\n// the provided splay value to reduce the thundering herd problem. This function\n// does not return any errors because it guarantees the process will be dead by\n// the return of the function call.", "generated": "This function is called when a child processes an object, and returns the value of that instance's lock state if it was killed or not by another thread in its chain. It also calls kill on any other threads who are waiting for this to happen before calling terminate(). The exception handler will be invoked whenever there has been no"}
{"id": 1064, "code": "func NewRunner(config *config.Config, dry, once bool) (*Runner, error) {\n\tlog.Printf(\"[INFO] (runner) creating new runner (dry: %v, once: %v)\", dry, once)\n\n\trunner := &Runner{\n\t\tconfig: config,\n\t\tdry:    dry,\n\t\tonce:   once,\n\t}\n\n\tif err := runner.init(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn runner, nil\n}", "reference": "// NewRunner accepts a slice of TemplateConfigs and returns a pointer to the new\n// Runner and any error that occurred during creation.", "generated": "New Runner creates a new runner and returns it as an object with the following properties :\n// The name of the running process to run from; // A string that identifies its status in terms suchas \"running\", or if no state is available for this task \u2013 any other value will be returned by the caller } Description"}
{"id": 1102, "code": "func base64URLDecode(s string) (string, error) {\n\tv, err := base64.URLEncoding.DecodeString(s)\n\tif err != nil {\n\t\treturn \"\", errors.Wrap(err, \"base64URLDecode\")\n\t}\n\treturn string(v), nil\n}", "reference": "// base64URLDecode decodes the given string as a URL-safe base64 string.", "generated": "The Base32 encoding of the URL decoded by base64urldecodes to a UTF-8 encoded representation that is used for decoding in Windows XP and later versions as well; it can be converted into an ASCII or Unicode character using either standard input format such like text/plain , binary output formats including hexadec"}
{"id": 1107, "code": "func in(l, v interface{}) (bool, error) {\n\tlv := reflect.ValueOf(l)\n\tvv := reflect.ValueOf(v)\n\n\tswitch lv.Kind() {\n\tcase reflect.Array, reflect.Slice:\n\t\t// if the slice contains 'interface' elements, then the element needs to be extracted directly to examine its type,\n\t\t// otherwise it will just resolve to 'interface'.\n\t\tvar interfaceSlice []interface{}\n\t\tif reflect.TypeOf(l).Elem().Kind() == reflect.Interface {\n\t\t\tinterfaceSlice = l.([]interface{})\n\t\t}\n\n\t\tfor i := 0; i < lv.Len(); i++ {\n\t\t\tvar lvv reflect.Value\n\t\t\tif interfaceSlice != nil {\n\t\t\t\tlvv = reflect.ValueOf(interfaceSlice[i])\n\t\t\t} else {\n\t\t\t\tlvv = lv.Index(i)\n\t\t\t}\n\n\t\t\tswitch lvv.Kind() {\n\t\t\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\t\t\tswitch vv.Kind() {\n\t\t\t\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\n\t\t\t\t\tif vv.Int() == lvv.Int() {\n\t\t\t\t\t\treturn true, nil\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase reflect.Float32, reflect.Float64:\n\t\t\t\tswitch vv.Kind() {\n\t\t\t\tcase reflect.Float32, reflect.Float64:\n\t\t\t\t\tif vv.Float() == lvv.Float() {\n\t\t\t\t\t\treturn true, nil\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tcase reflect.String:\n\t\t\t\tif vv.Type() == lvv.Type() && vv.String() == lvv.String() {\n\t\t\t\t\treturn true, nil\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\tcase reflect.String:\n\t\tif vv.Type() == lv.Type() && strings.Contains(lv.String(), vv.String()) {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\n\treturn false, nil\n}", "reference": "// in searches for a given value in a given interface.", "generated": "The following example demonstrates how a string can contain an array of values and return one or more objects that are not part by reference from any other object within the same collection as specified above. The resulting value is returned when all items have been retrieved using reflection based on their types rather than being passed through multiple methods such for instance"}
{"id": 1110, "code": "func parseBool(s string) (bool, error) {\n\tif s == \"\" {\n\t\treturn false, nil\n\t}\n\n\tresult, err := strconv.ParseBool(s)\n\tif err != nil {\n\t\treturn false, errors.Wrap(err, \"parseBool\")\n\t}\n\treturn result, nil\n}", "reference": "// parseBool parses a string into a boolean", "generated": "// This function parses a list of strings and returns an array containing the parsed values for each element in the given range. The returned value is then converted to binary representation using StrConvertTo Binary() .\n // Note that this method does not return any information about whether or NOT it has been used before; if"}
{"id": 1111, "code": "func parseFloat(s string) (float64, error) {\n\tif s == \"\" {\n\t\treturn 0.0, nil\n\t}\n\n\tresult, err := strconv.ParseFloat(s, 10)\n\tif err != nil {\n\t\treturn 0, errors.Wrap(err, \"parseFloat\")\n\t}\n\treturn result, nil\n}", "reference": "// parseFloat parses a string into a base 10 float", "generated": "// This function parses the float64 and returns a value of type int32 . The return values are returned as an array with all fields in their respective order from left to right; if there is no field that matches any given name or number then it will be converted into its corresponding integer representation by calling this method on"}
{"id": 1132, "code": "func (c *cache) Delete(k string) {\n\tc.mu.Lock()\n\tv, evicted := c.delete(k)\n\tc.mu.Unlock()\n\tif evicted {\n\t\tc.onEvicted(k, v)\n\t}\n}", "reference": "// Delete an item from the cache. Does nothing if the key is not in the cache.", "generated": "// This function deletes the cache object from memory and returns it to the caller if no other caches exist or are available for use in a future call // with an existing one at this time.\nDescription of usage :\n// The delete method is called when all cached objects have been deleted by `CacheDelete`. It"}
{"id": 1133, "code": "func (c *cache) DeleteExpired() {\n\tvar evictedItems []keyAndValue\n\tnow := time.Now().UnixNano()\n\tc.mu.Lock()\n\tfor k, v := range c.items {\n\t\t// \"Inlining\" of expired\n\t\tif v.Expiration > 0 && now > v.Expiration {\n\t\t\tov, evicted := c.delete(k)\n\t\t\tif evicted {\n\t\t\t\tevictedItems = append(evictedItems, keyAndValue{k, ov})\n\t\t\t}\n\t\t}\n\t}\n\tc.mu.Unlock()\n\tfor _, v := range evictedItems {\n\t\tc.onEvicted(v.key, v.value)\n\t}\n}", "reference": "// Delete all expired items from the cache.", "generated": "The delete function deletes an item from the cache and returns it to the caller for execution in a newline-terminated buffer with no trailing whitespace or spaces between its contents; this is called by default when deleting items that are not already deleted but have been removed due on some other reason such as being lost during"}
{"id": 1137, "code": "func djb33(seed uint32, k string) uint32 {\n\tvar (\n\t\tl = uint32(len(k))\n\t\td = 5381 + seed + l\n\t\ti = uint32(0)\n\t)\n\t// Why is all this 5x faster than a for loop?\n\tif l >= 4 {\n\t\tfor i < l-4 {\n\t\t\td = (d * 33) ^ uint32(k[i])\n\t\t\td = (d * 33) ^ uint32(k[i+1])\n\t\t\td = (d * 33) ^ uint32(k[i+2])\n\t\t\td = (d * 33) ^ uint32(k[i+3])\n\t\t\ti += 4\n\t\t}\n\t}\n\tswitch l - i {\n\tcase 1:\n\tcase 2:\n\t\td = (d * 33) ^ uint32(k[i])\n\tcase 3:\n\t\td = (d * 33) ^ uint32(k[i])\n\t\td = (d * 33) ^ uint32(k[i+1])\n\tcase 4:\n\t\td = (d * 33) ^ uint32(k[i])\n\t\td = (d * 33) ^ uint32(k[i+1])\n\t\td = (d * 33) ^ uint32(k[i+2])\n\t}\n\treturn d ^ (d >> 16)\n}", "reference": "// djb2 with better shuffling. 5x faster than FNV with the hash.Hash overhead.", "generated": "This function creates an array of random numbers. The first number in the list must be at least one digit long and contains no more digits or less than zero if it has any remaining bits left to add up. If there are fewer then two integers that contain exactly three characters each with equal length they will not create anything new"}
{"id": 1143, "code": "func (m *MockTaskEngine) MarshalJSON() ([]byte, error) {\n\tret := m.ctrl.Call(m, \"MarshalJSON\")\n\tret0, _ := ret[0].([]byte)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// MarshalJSON mocks base method", "generated": "The marshaled JSON object is a string representation of the current state of the task engine and can be used to retrieve information about its status or progress in any order that it wishes for execution by calling MockingOptions . The default value returned from this method will always return nil if no action was taken on an attempt at executing"}
{"id": 1149, "code": "func (mr *MockImageManagerMockRecorder) AddAllImageStates(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"AddAllImageStates\", reflect.TypeOf((*MockImageManager)(nil).AddAllImageStates), arg0)\n}", "reference": "// AddAllImageStates indicates an expected call of AddAllImageStates", "generated": "This method returns a mutable array of image states that are added to the Mocks collection by calling addAllImages() . The returned state is then passed as an argument to all images in the list and can be used for any operations on them or just return nil if no operation was performed at this point. This implementation"}
{"id": 1150, "code": "func (m *MockImageManager) GetImageStateFromImageName(arg0 string) (*image.ImageState, bool) {\n\tret := m.ctrl.Call(m, \"GetImageStateFromImageName\", arg0)\n\tret0, _ := ret[0].(*image.ImageState)\n\tret1, _ := ret[1].(bool)\n\treturn ret0, ret1\n}", "reference": "// GetImageStateFromImageName mocks base method", "generated": "The Mocks class provides a method to retrieve the image state from the specified ImageState object and return it as an array of images with all associated metadata for each element in the list returned by this call. The following example shows how to use these methods on multiple Images using one or more parameters that are not provided at runtime"}
{"id": 1181, "code": "func (mr *MockContainerMetadataResolverMockRecorder) ResolveContainer(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"ResolveContainer\", reflect.TypeOf((*MockContainerMetadataResolver)(nil).ResolveContainer), arg0)\n}", "reference": "// ResolveContainer indicates an expected call of ResolveContainer", "generated": "This method returns a mutable container metadata resolver that can be used to resolve the specified Mocks and Recorders in any order desired by the user agent or service provider for which the returned value is stored. The return type of this function depends on whether it has been called with an optional argument specifying its default implementation as"}
{"id": 1183, "code": "func NewTaskResponse(taskARN string,\n\tstate dockerstate.TaskEngineState,\n\tecsClient api.ECSClient,\n\tcluster string,\n\taz string,\n\tcontainerInstanceArn string,\n\tpropagateTags bool) (*TaskResponse, error) {\n\ttask, ok := state.TaskByArn(taskARN)\n\tif !ok {\n\t\treturn nil, errors.Errorf(\"v2 task response: unable to find task '%s'\", taskARN)\n\t}\n\n\tresp := &TaskResponse{\n\t\tCluster:          cluster,\n\t\tTaskARN:          task.Arn,\n\t\tFamily:           task.Family,\n\t\tRevision:         task.Version,\n\t\tDesiredStatus:    task.GetDesiredStatus().String(),\n\t\tKnownStatus:      task.GetKnownStatus().String(),\n\t\tAvailabilityZone: az,\n\t}\n\n\ttaskCPU := task.CPU\n\ttaskMemory := task.Memory\n\tif taskCPU != 0 || taskMemory != 0 {\n\t\ttaskLimits := &LimitsResponse{}\n\t\tif taskCPU != 0 {\n\t\t\ttaskLimits.CPU = &taskCPU\n\t\t}\n\t\tif taskMemory != 0 {\n\t\t\ttaskLimits.Memory = &taskMemory\n\t\t}\n\t\tresp.Limits = taskLimits\n\t}\n\n\tif timestamp := task.GetPullStartedAt(); !timestamp.IsZero() {\n\t\tresp.PullStartedAt = aws.Time(timestamp.UTC())\n\t}\n\tif timestamp := task.GetPullStoppedAt(); !timestamp.IsZero() {\n\t\tresp.PullStoppedAt = aws.Time(timestamp.UTC())\n\t}\n\tif timestamp := task.GetExecutionStoppedAt(); !timestamp.IsZero() {\n\t\tresp.ExecutionStoppedAt = aws.Time(timestamp.UTC())\n\t}\n\tcontainerNameToDockerContainer, ok := state.ContainerMapByArn(task.Arn)\n\tif !ok {\n\t\tseelog.Warnf(\"V2 task response: unable to get container name mapping for task '%s'\",\n\t\t\ttask.Arn)\n\t\treturn resp, nil\n\t}\n\n\teni := task.GetTaskENI()\n\tfor _, dockerContainer := range containerNameToDockerContainer {\n\t\tcontainerResponse := newContainerResponse(dockerContainer, eni, state)\n\t\tresp.Containers = append(resp.Containers, containerResponse)\n\t}\n\n\tif propagateTags {\n\t\tpropagateTagsToMetadata(state, ecsClient, containerInstanceArn, taskARN, resp)\n\t}\n\n\treturn resp, nil\n}", "reference": "// NewTaskResponse creates a new response object for the task", "generated": "New Task Response (new TaskResponse). Create a newly created Docker Container with the following properties and methods :\n// // The default value is \"true\" if no containers are found in this list of tasks or false otherwise. func main () {\n\u0013escription createContainerWithDefaultProperties(&credentials, c"}
{"id": 1195, "code": "func (m *MockTime) After(arg0 time.Duration) <-chan time.Time {\n\tret := m.ctrl.Call(m, \"After\", arg0)\n\tret0, _ := ret[0].(<-chan time.Time)\n\treturn ret0\n}", "reference": "// After mocks base method", "generated": "The following example creates a new thread that waits for the specified duration to expire and returns an error message when it does not have any valid arguments or if no timeout has been set on this instance of Mocks::Wait . The default value is 0 , which means all threads will be waiting until they are done with their tasks"}
{"id": 1200, "code": "func (mr *MockTimeMockRecorder) Sleep(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Sleep\", reflect.TypeOf((*MockTime)(nil).Sleep), arg0)\n}", "reference": "// Sleep indicates an expected call of Sleep", "generated": "sleep is a method that returns an Mocks time object for the specified duration of sleep . It can be used to perform any operations on data or other objects in memory without having to call it directly from within your application code. The default value will return nil if no operation has been performed and false otherwise. This function also"}
{"id": 1205, "code": "func (mr *MockTimerMockRecorder) Stop() *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"Stop\", reflect.TypeOf((*MockTimer)(nil).Stop))\n}", "reference": "// Stop indicates an expected call of Stop", "generated": "This method is called when the Mocks are stopped by a handler that returns nil . The return value of this call will be returned as an error message if it was not handled properly or otherwise ignored in any way during execution. This function can also optionally use `stop` to stop all handlers from executing on their own and"}
{"id": 1216, "code": "func (imageState *ImageState) AddImageName(imageName string) {\n\timageState.lock.Lock()\n\tdefer imageState.lock.Unlock()\n\tif !imageState.HasImageName(imageName) {\n\t\tseelog.Infof(\"Adding image name- %v to Image state- %v\", imageName, imageState.Image.ImageID)\n\t\timageState.Image.Names = append(imageState.Image.Names, imageName)\n\t}\n}", "reference": "// AddImageName adds image name to image state", "generated": "The init method of the Initialize function is used for initializing images and creating new ones from existing one's data structures in order that they can be loaded into a single file or directory on disk by using an array with names as parameters instead thereof. The initialization process will then initialize all available files within this instance so it"}
{"id": 1254, "code": "func copyMetricsMetadata(metadata *ecstcs.MetricsMetadata, fin bool) *ecstcs.MetricsMetadata {\n\treturn &ecstcs.MetricsMetadata{\n\t\tCluster:           aws.String(*metadata.Cluster),\n\t\tContainerInstance: aws.String(*metadata.ContainerInstance),\n\t\tIdle:              aws.Bool(*metadata.Idle),\n\t\tMessageId:         aws.String(*metadata.MessageId),\n\t\tFin:               aws.Bool(fin),\n\t}\n}", "reference": "// copyMetricsMetadata creates a new MetricsMetadata object from a given MetricsMetadata object.\n// It copies all the fields from the source object to the new object and sets the 'Fin' field\n// as specified by the argument.", "generated": "// Copy metadata from the cluster to the specified bucket and return it as a string if no matching data is found in that block of records // or otherwise fails with an error message when attempting this method on any other node within its own chain. This can be used for creating new instances at runtime without having accesses into existing"}
{"id": 1285, "code": "func (cgroup *CgroupResource) Create() error {\n\terr := cgroup.setupTaskCgroup()\n\tif err != nil {\n\t\tseelog.Criticalf(\"Cgroup resource [%s]: unable to setup cgroup root: %v\", cgroup.taskARN, err)\n\t\treturn err\n\t}\n\treturn nil\n}", "reference": "// Create creates cgroup root for the task", "generated": "This method creates a task that will create the CGroup Resource and then execute it on its own if necessary. The Task is created by calling init(ctx context). If no tasks are specified in this call, all of them must be executed before executing any other methods or functions within the scope of the current session. This"}
{"id": 1293, "code": "func NewECRFactory(acceptInsecureCert bool) ECRFactory {\n\treturn &ecrFactory{\n\t\thttpClient: httpclient.New(roundtripTimeout, acceptInsecureCert),\n\t}\n}", "reference": "// NewECRFactory returns an ECRFactory capable of producing ECRSDK clients", "generated": "This method creates a new ECRI instance that accepts an insecure certificate and returns the secure cert as specified in RFC 6455 (RFC 7443). The security certificates are stored on the server side of this application using TLS 1.2 or later for authentication purposes. This is done by creating two instances with different credentials to store"}
{"id": 1313, "code": "func (err CannotStopContainerError) IsRetriableError() bool {\n\tif _, ok := err.FromError.(NoSuchContainerError); ok {\n\t\treturn false\n\t}\n\n\treturn true\n}", "reference": "// IsRetriableError returns a boolean indicating whether the call that\n// generated the error can be retried.\n// When stopping a container, most errors that we can get should be\n// considered retriable. However, in the case where the container is\n// already stopped or doesn't exist at all, there's no sense in\n// retrying.", "generated": "// This function is called when the container fails to stop or if it does not return an error message // and returns a status code of 0 for no such container exception in this case. The default value will be nil .\n// If there are any errors that cannot occur within one second after calling func(err Error)"}
{"id": 1327, "code": "func (m *MockEC2MetadataClient) DefaultCredentials() (*ec2.RoleCredentials, error) {\n\tret := m.ctrl.Call(m, \"DefaultCredentials\")\n\tret0, _ := ret[0].(*ec2.RoleCredentials)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// DefaultCredentials mocks base method", "generated": "The default credentials for the metadata client are used to store and retrieve information about a user's profile in Mockspec or other similar applications that use it as an authentication mechanism by providing them with their own key-value pairs from within JSON objects of which they can be queried using any API provided on behalf thereof; this"}
{"id": 1340, "code": "func (mr *MockClientSDKMockRecorder) DescribeTags(arg0 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"DescribeTags\", reflect.TypeOf((*MockClientSDK)(nil).DescribeTags), arg0)\n}", "reference": "// DescribeTags indicates an expected call of DescribeTags", "generated": "This method returns a list of tags that describe the current state of the MocksDB and its associated metadata collection for each tag in the record call. The returned value is an array containing all tagged fields from which to retrieve information about this field or any other data contained within it; if there are no such records then these"}
{"id": 1352, "code": "func (agent *ecsAgent) setClusterInConfig(previousCluster string) error {\n\t// TODO Handle default cluster in a sane and unified way across the codebase\n\tconfiguredCluster := agent.cfg.Cluster\n\tif configuredCluster == \"\" {\n\t\tseelog.Debug(\"Setting cluster to default; none configured\")\n\t\tconfiguredCluster = config.DefaultClusterName\n\t}\n\tif previousCluster != configuredCluster {\n\t\terr := clusterMismatchError{\n\t\t\tfmt.Errorf(clusterMismatchErrorFormat, previousCluster, configuredCluster),\n\t\t}\n\t\tseelog.Criticalf(\"%v\", err)\n\t\treturn err\n\t}\n\tagent.cfg.Cluster = previousCluster\n\tseelog.Infof(\"Restored cluster '%s'\", agent.cfg.Cluster)\n\n\treturn nil\n}", "reference": "// setClusterInConfig sets the cluster name in the config object based on\n// previous state. It returns an error if there's a mismatch between the\n// the current cluster name with what's restored from the cluster state", "generated": "The configuration of an Agent is used as follows: The name of the Cluster that will be created by this command-line tool when it runs on its own instance of EC2 or other distributed storage devices running with ESXi host OS X 10.6+ installed at boot time from within VMware's Virtual Machine Manager environment variable"}
{"id": 1377, "code": "func handleInvalidParamException(err error, events *list.List, eventToSubmit *list.Element) {\n\tif utils.IsAWSErrorCodeEqual(err, ecs.ErrCodeInvalidParameterException) {\n\t\tevent := eventToSubmit.Value.(*sendableEvent)\n\t\tseelog.Warnf(\"TaskHandler: Event is sent with invalid parameters; just removing: %s\", event.toString())\n\t\tevents.Remove(eventToSubmit)\n\t}\n}", "reference": "// handleInvalidParamException removes the event from event queue when its parameters are\n// invalid to reduce redundant API call", "generated": "The handling of an exception in the form \"task handler: Exception\" can be used to specify a specific type or method for which it should not receive any exceptions from other methods that are called by this task (e., if there were no such callbacks). The following example shows how one could use these types of handlers"}
{"id": 1402, "code": "func NewJitteredTicker(ctx context.Context, start, end time.Duration) <-chan time.Time {\n\tticker := make(chan time.Time, 1)\n\n\tgo func() {\n\t\tdefer close(ticker)\n\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn\n\t\t\tdefault:\n\t\t\t\ttime.Sleep(randomDuration(start, end))\n\t\t\t\tsendNow(ticker)\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn ticker\n}", "reference": "// NewJitteredTicker works like a time.Ticker except with randomly distributed ticks\n// between start and end duration.", "generated": "New jitter ticks a new tiddler in the current buffer and returns it to the caller for execution when no other changes have occurred or if any of its properties are changed by this method. The default behavior is that all values returned from Ticker will be used as an initializer value (i.,e.: nil )."}
{"id": 1411, "code": "func (m *MockECSClient) GetResourceTags(arg0 string) ([]*ecs.Tag, error) {\n\tret := m.ctrl.Call(m, \"GetResourceTags\", arg0)\n\tret0, _ := ret[0].([]*ecs.Tag)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// GetResourceTags mocks base method", "generated": "The method returns a list of tags that are used to identify the resource tag in an ECNS request and return it as its value when called with no arguments or nil otherwise returned. The methods can be invoked from any command line interface using either `curl` , which is provided by default for all commands except those defined"}
{"id": 1417, "code": "func (m *MockSaveableOption) AddSaveable(arg0 string, arg1 statemanager.Saveable) statemanager.Option {\n\tret := m.ctrl.Call(m, \"AddSaveable\", arg0, arg1)\n\tret0, _ := ret[0].(statemanager.Option)\n\treturn ret0\n}", "reference": "// AddSaveable mocks base method", "generated": "This method returns a new saveable option that can be used to create an existing saved file or restore the current one from another program using MockingOptions . The options are stored in variables named after their names and must not contain any special characters such as '*' , which is equivalent for all other types of saving operations"}
{"id": 1440, "code": "func (state *DockerTaskEngineState) TaskByArn(arn string) (*apitask.Task, bool) {\n\tstate.lock.RLock()\n\tdefer state.lock.RUnlock()\n\n\treturn state.taskByArn(arn)\n}", "reference": "// TaskByArn returns a task for a given ARN", "generated": "// This is a task that will be executed when the user logs in to Docker and starts using docker-compose upstart . The default value of this function should be nil if not specified otherwise.\n/**\n* A callback for logging out from an existing container or running on another host with no connection at all;"}
{"id": 1448, "code": "func (state *DockerTaskEngineState) AddTaskIPAddress(addr string, taskARN string) {\n\tstate.lock.Lock()\n\tdefer state.lock.Unlock()\n\n\tstate.ipToTask[addr] = taskARN\n}", "reference": "// AddTaskIPAddress adds ip adddress for a task arn into the state", "generated": "// This is a Task Engine State that will be used to lock the specified address in an attempt at locking up all of its peers for future use. // The Lock method must not return any value from this instance or it may fail if there are no peer-to--peer connections available and/or other reasons beyond self"}
{"id": 1457, "code": "func (c *Container) GetKnownStatus() apicontainerstatus.ContainerStatus {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.KnownStatusUnsafe\n}", "reference": "// GetKnownStatus returns the known status of the container", "generated": "This method returns the status of the container, if any, and optionally a list containing all known issues that have been reported to it by this user or its associated service provider in connection with an API call from within Container . The returned Status object is used as part for subsequent calls on other containers using similar methods such at runtime"}
{"id": 1458, "code": "func (c *Container) SetKnownStatus(status apicontainerstatus.ContainerStatus) {\n\tc.lock.Lock()\n\tdefer c.lock.Unlock()\n\n\tc.KnownStatusUnsafe = status\n\tc.updateAppliedStatusUnsafe(status)\n}", "reference": "// SetKnownStatus sets the known status of the container and update the container\n// applied status", "generated": "// Initializes the container and sets known status for this application, if any.\n // This method is called when a notification has been received from an app that does not have its own set of notifications or nil .\n func initAppliedStatusUnsirable () error { log.Fatal(\"Notification failed to"}
{"id": 1466, "code": "func (c *Container) ShouldPullWithExecutionRole() bool {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.RegistryAuthentication != nil &&\n\t\tc.RegistryAuthentication.Type == AuthTypeECR &&\n\t\tc.RegistryAuthentication.ECRAuthData != nil &&\n\t\tc.RegistryAuthentication.ECRAuthData.UseExecutionRole\n}", "reference": "// ShouldPullWithExecutionRole returns whether this container has its own ECR credentials", "generated": "// This function should pull the execution role from the registry and return it to the caller if necessary.\n // The callback is called when a new session has been created, or an error occurs while doing so. If this fails, the user will be prompted for a password reset after each successful login attempt. Note that in"}
{"id": 1497, "code": "func (c *Container) GetV3EndpointID() string {\n\tc.lock.RLock()\n\tdefer c.lock.RUnlock()\n\n\treturn c.V3EndpointID\n}", "reference": "// GetV3EndpointID returns the v3 endpoint id of container", "generated": "This method returns the endpoints of a container, which are passed to this function as an argument in order for it not return null . The returned value is then used by all methods that call getV2endpointer , and any other functions returning from setv4 or v5 EndPointIDs provided with containers using these"}
{"id": 1507, "code": "func (secret *ASMSecretResource) retrieveASMSecretValue(apiSecret apicontainer.Secret, iamCredentials credentials.IAMRoleCredentials, wg *sync.WaitGroup, errorEvents chan error) {\n\tdefer wg.Done()\n\n\tasmClient := secret.asmClientCreator.NewASMClient(apiSecret.Region, iamCredentials)\n\tseelog.Infof(\"ASM secret resource: retrieving resource for secret %v in region %s for task: [%s]\", apiSecret.ValueFrom, apiSecret.Region, secret.taskARN)\n\t//for asm secret, ValueFrom can be arn or name\n\tsecretValue, err := asm.GetSecretFromASM(apiSecret.ValueFrom, asmClient)\n\tif err != nil {\n\t\terrorEvents <- fmt.Errorf(\"fetching secret data from AWS Secrets Manager in region %s: %v\", apiSecret.Region, err)\n\t\treturn\n\t}\n\n\tsecret.lock.Lock()\n\tdefer secret.lock.Unlock()\n\n\t// put secret value in secretData\n\tsecretKey := apiSecret.GetSecretResourceCacheKey()\n\tsecret.secretData[secretKey] = secretValue\n}", "reference": "// retrieveASMSecretValue reads secret value from cache first, if not exists, call GetSecretFromASM to retrieve value\n// AWS secrets Manager", "generated": "The ASMX service provides a secure and private key exchange between the user's local storage account with an external server that is not compromised by any third party services such to allow access without having their personal information exposed on-premises through other means of authentication using AES encryption keys provided via TLS/SSL certificates issued directly against your"}
{"id": 1516, "code": "func handleInactivityTimeout(reader io.ReadCloser, timeout time.Duration, cancelRequest func(), canceled *uint32) (io.ReadCloser, chan<- struct{}) {\n\tdone := make(chan struct{})\n\tproxyReader := &proxyReader{ReadCloser: reader}\n\tgo func() {\n\t\tvar lastCallCount uint64\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-time.After(timeout):\n\t\t\tcase <-done:\n\t\t\t\treturn\n\t\t\t}\n\t\t\tcurCallCount := proxyReader.callCount()\n\t\t\tif curCallCount == lastCallCount {\n\t\t\t\tatomic.AddUint32(canceled, 1)\n\t\t\t\tcancelRequest()\n\t\t\t\treturn\n\t\t\t}\n\t\t\tlastCallCount = curCallCount\n\t\t}\n\t}()\n\treturn proxyReader, done\n}", "reference": "// When pulling an image, the docker api will pull and then subsequently unzip the downloaded artifacts. Docker does\n// not separate the \"pull\" from the \"unpack\" step. What this means is that this timeout doesn't 'tick' while unpacking\n// the downloaded files. This only causes noticeable impact with large files, but we should investigate improving this.", "generated": "The callback function is called when the user logs in to a new session and closes an existing one by calling this method on it with no arguments or nil . The default behavior of all other methods that return true will be undefined if there are any errors encountered during logging out from within their own threading context; otherwise they may"}
{"id": 1519, "code": "func (imageManager *dockerImageManager) RemoveContainerReferenceFromImageState(container *apicontainer.Container) error {\n\t// the image state has been updated, save the new state\n\tdefer imageManager.saver.ForceSave()\n\t// this lock is for reading image states and finding the one that the container belongs to\n\timageManager.updateLock.RLock()\n\tdefer imageManager.updateLock.RUnlock()\n\tif container.ImageID == \"\" {\n\t\treturn fmt.Errorf(\"Invalid container reference: Empty image id\")\n\t}\n\n\t// Find image state that this container is part of, and remove the reference\n\timageState, ok := imageManager.getImageState(container.ImageID)\n\tif !ok {\n\t\treturn fmt.Errorf(\"Cannot find image state for the container to be removed\")\n\t}\n\t// Found matching ImageState\n\treturn imageState.RemoveContainerReference(container)\n}", "reference": "// RemoveContainerReferenceFromImageState removes container reference from the corresponding imageState object", "generated": "The Docker images are created by docker-images , which can then use them as a wrapper around their own containers or other applications using an API such like http://api.docker.io/v1/filesystem . The following example creates two different instances in each application with its respective metadata set up so they will"}
{"id": 1540, "code": "func (td *TransitionDependenciesMap) UnmarshalJSON(b []byte) error {\n\tdepMap := make(map[apicontainerstatus.ContainerStatus]TransitionDependencySet)\n\terr := json.Unmarshal(b, &depMap)\n\tif err == nil {\n\t\t*td = depMap\n\t\treturn nil\n\t}\n\tseelog.Debugf(\"Unmarshal 'TransitionDependencySet': %s, not a map: %v\", string(b), err)\n\t// Unmarshal to deprecated 'TransitionDependencySet' and then convert to a map\n\ttdSet := TransitionDependencySet{}\n\tif err := json.Unmarshal(b, &tdSet); err != nil {\n\t\treturn errors.Wrapf(err,\n\t\t\t\"Unmarshal 'TransitionDependencySet': does not comply with any of the dependency types\")\n\t}\n\tfor _, dep := range tdSet.ContainerDependencies {\n\t\tdependentStatus := dep.DependentStatus\n\t\t// no need for DependentStatus field anymore, since it becomes the map's key\n\t\tdep.DependentStatus = 0\n\t\tif _, ok := depMap[dependentStatus]; !ok {\n\t\t\tdepMap[dependentStatus] = TransitionDependencySet{}\n\t\t}\n\t\tdeps := depMap[dependentStatus]\n\t\tdeps.ContainerDependencies = append(deps.ContainerDependencies, dep)\n\t\tdepMap[dependentStatus] = deps\n\t}\n\t*td = depMap\n\treturn nil\n}", "reference": "// UnmarshalJSON decodes the TransitionDependencySet tag in the JSON encoded string\n// into the TransitionDependenciesMap object", "generated": "The transitive mapping is used in order that all dependencies are resolved before they can be added or removed from an existing Transitional Dictionary Map . The default value will always return true if there was already one such dictionary at some point during its lifetime. This allows you specify which type of data should have been included"}
{"id": 1543, "code": "func NewMockCgroup(ctrl *gomock.Controller) *MockCgroup {\n\tmock := &MockCgroup{ctrl: ctrl}\n\tmock.recorder = &MockCgroupMockRecorder{mock}\n\treturn mock\n}", "reference": "// NewMockCgroup creates a new mock instance", "generated": "NewMutex is a mutable, immutable object that can be used to create new Mutecks and other objects from existing Mocks or Cgroups . It provides the following properties for use in your own custom implementations of mocking methods (see below):\n\n```\nThe `newmutate()`, `new"}
{"id": 1579, "code": "func (m *MockSecretsManagerAPI) DeleteResourcePolicyWithContext(arg0 aws.Context, arg1 *secretsmanager.DeleteResourcePolicyInput, arg2 ...request.Option) (*secretsmanager.DeleteResourcePolicyOutput, error) {\n\tvarargs := []interface{}{arg0, arg1}\n\tfor _, a := range arg2 {\n\t\tvarargs = append(varargs, a)\n\t}\n\tret := m.ctrl.Call(m, \"DeleteResourcePolicyWithContext\", varargs...)\n\tret0, _ := ret[0].(*secretsmanager.DeleteResourcePolicyOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// DeleteResourcePolicyWithContext mocks base method", "generated": "delete resource policy with context and return value of the specified interface or nil if no action is taken by this method to delete it from the cache. This can be useful for debugging purposes when using an external API that does not support deleting resources in order-to-deleteration mode such as HTTP/HTTPS requests"}
{"id": 1595, "code": "func (m *MockSecretsManagerAPI) ListSecretVersionIds(arg0 *secretsmanager.ListSecretVersionIdsInput) (*secretsmanager.ListSecretVersionIdsOutput, error) {\n\tret := m.ctrl.Call(m, \"ListSecretVersionIds\", arg0)\n\tret0, _ := ret[0].(*secretsmanager.ListSecretVersionIdsOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// ListSecretVersionIds mocks base method", "generated": "The list of secret versions in the specified security key is a string containing an integer number representing the version numbers for each level and optionally one or more levels that are not supported by any other authentication scheme on this system; it can be used to identify which keys have been compromised using cryptographic hash functions such as SHA-256 hashes"}
{"id": 1612, "code": "func (m *MockSecretsManagerAPI) RotateSecret(arg0 *secretsmanager.RotateSecretInput) (*secretsmanager.RotateSecretOutput, error) {\n\tret := m.ctrl.Call(m, \"RotateSecret\", arg0)\n\tret0, _ := ret[0].(*secretsmanager.RotateSecretOutput)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// RotateSecret mocks base method", "generated": "The rotating secret is a mutable string that can be used to store the key and value of any given ciphertext in an array or dictionary with keys as strings for use by other applications such As A KeyStore , B CipherTextProvider , C CryptographicKeystore , D EncryptionContext . The default implementation uses"}
{"id": 1616, "code": "func (m *MockSecretsManagerAPI) TagResourceRequest(arg0 *secretsmanager.TagResourceInput) (*request.Request, *secretsmanager.TagResourceOutput) {\n\tret := m.ctrl.Call(m, \"TagResourceRequest\", arg0)\n\tret0, _ := ret[0].(*request.Request)\n\tret1, _ := ret[1].(*secretsmanager.TagResourceOutput)\n\treturn ret0, ret1\n}", "reference": "// TagResourceRequest mocks base method", "generated": "// This method returns a string of the requested resource information and an array of strings to be returned by this request for each tag in the response. The return value is nil if no tags are found or null otherwise.\n func (s *SocksManager API ) ReturnResponseFromTag{}, s int , err error"}
{"id": 1628, "code": "func (manager *metadataManager) parseMetadataAtContainerCreate(task *apitask.Task, containerName string) Metadata {\n\treturn Metadata{\n\t\tcluster: manager.cluster,\n\t\ttaskMetadata: TaskMetadata{\n\t\t\tcontainerName:          containerName,\n\t\t\ttaskARN:                task.Arn,\n\t\t\ttaskDefinitionFamily:   task.Family,\n\t\t\ttaskDefinitionRevision: task.Version,\n\t\t},\n\t\tcontainerInstanceARN:  manager.containerInstanceARN,\n\t\tmetadataStatus:        MetadataInitial,\n\t\tavailabilityZone:      manager.availabilityZone,\n\t\thostPublicIPv4Address: manager.hostPublicIPv4Address,\n\t}\n}", "reference": "// parseMetadataAtContainerCreate gathers metadata from task and cluster configurations\n// then packages it for JSON Marshaling. We use this version to get data\n// available prior to container creation\n// Since we accept incomplete metadata fields, we should not return\n// errors here and handle them at this or the above stage.", "generated": "// This is a metadata creation service for the Container class that implements this interface and provides access to all of its properties in an array or list format. // The API does not provide any methods on these objects; instead it uses one method called `create` which returns information about each property set by the constructor as well if"}
{"id": 1649, "code": "func (m *MockTaskResource) Cleanup() error {\n\tret := m.ctrl.Call(m, \"Cleanup\")\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// Cleanup mocks base method", "generated": "This method cleans up the task resource and returns a new Task object with an empty value for each of its arguments. The returned objects are then used to perform cleanup on any errors that may have occurred during execution. This is useful when you want your tasks to be run in parallel or if they need more than one thread at"}
{"id": 1669, "code": "func (f *factory) GetClient(version dockerclient.DockerVersion) (sdkclient.Client, error) {\n\tfor _, v := range getWindowsReplaceableVersions() {\n\t\tif v == version {\n\t\t\tversion = minDockerAPIVersion\n\t\t\tbreak\n\t\t}\n\t}\n\treturn f.getClient(version)\n}", "reference": "// GetClient will replace some versions of Docker on Windows. We need this because\n// agent assumes that it can always call older versions of the docker API.", "generated": "This function returns a list of all the Windows versions that have been replaced by Docker containers in an attempt to replace them with new ones from other sources such as Git or NPM repositories and/or local storage devices like CDN servers etc.. The following example shows how this works using npm-replacement tools for Linux"}
{"id": 1739, "code": "func (task *Task) GetExecutionCredentialsID() string {\n\ttask.lock.RLock()\n\tdefer task.lock.RUnlock()\n\n\treturn task.ExecutionCredentialsID\n}", "reference": "// GetExecutionCredentialsID gets the credentials ID for the task", "generated": "This method returns a list of credentials that are associated with the specified execution context, and optionally an optional callback function to be called when executing this credential on behalf or as part thereof. The following example is equivalent to calling Task . ExecuteCmdlet( \"execution_credits\", func(ctx *Task)) :"}
{"id": 1757, "code": "func (task *Task) RecordExecutionStoppedAt(container *apicontainer.Container) {\n\tif !container.Essential {\n\t\treturn\n\t}\n\tif container.GetKnownStatus() != apicontainerstatus.ContainerStopped {\n\t\treturn\n\t}\n\t// If the essential container is stopped, set the ExecutionStoppedAt timestamp\n\tnow := time.Now()\n\tok := task.SetExecutionStoppedAt(now)\n\tif !ok {\n\t\t// ExecutionStoppedAt was already recorded. Nothing to left to do here\n\t\treturn\n\t}\n\tseelog.Infof(\"Task [%s]: recording execution stopped time. Essential container [%s] stopped at: %s\",\n\t\ttask.Arn, container.Name, now.String())\n}", "reference": "// RecordExecutionStoppedAt checks if this is an essential container stopped\n// and set the task executionStoppedAt timestamps", "generated": "This method returns a Task that has been started by an application running on the specified host and terminated with an error message if it failed. The default value of this function will be nil . This can also be used as a placeholder for other methods in which you may want to call another process or perform some operations without having access"}
{"id": 1767, "code": "func (task *Task) getPIDMode() string {\n\ttask.lock.RLock()\n\tdefer task.lock.RUnlock()\n\n\treturn task.PIDMode\n}", "reference": "// Retrieves a Task's PIDMode", "generated": "This method is called when the Task object has been created and locked by a thread, or if no lock was found in that instance of the class at all. It returns an error message indicating whether it should be used to create new locks for this operation on any given target system with respect not only to locking but also other"}
{"id": 1793, "code": "func (healthStatus *ContainerHealthStatus) UnmarshalJSON(b []byte) error {\n\t*healthStatus = ContainerHealthUnknown\n\n\tif strings.ToLower(string(b)) == \"null\" {\n\t\treturn nil\n\t}\n\tif b[0] != '\"' || b[len(b)-1] != '\"' {\n\t\treturn errors.New(\"container health status unmarshal: status must be a string or null; Got \" + string(b))\n\t}\n\n\tstrStatus := string(b[1 : len(b)-1])\n\tswitch strStatus {\n\tcase \"UNKNOWN\":\n\t// The health status is already set to ContainerHealthUnknown initially\n\tcase \"HEALTHY\":\n\t\t*healthStatus = ContainerHealthy\n\tcase \"UNHEALTHY\":\n\t\t*healthStatus = ContainerUnhealthy\n\tdefault:\n\t\treturn errors.New(\"container health status unmarshal: unrecognized status: \" + string(b))\n\t}\n\treturn nil\n}", "reference": "// UnmarshalJSON overrides the logic for parsing the JSON-encoded container health data", "generated": "The container healthstatus is an array of unordered lists containing the following elements, separated by commas and spaces between them: name, description , type . If no element contains any information about this list, it will not contain anything useful for debugging purposes. It can also include items that are missing from other containers in order"}
{"id": 1797, "code": "func (m *MockDockerClient) APIVersion() (dockerclient.DockerVersion, error) {\n\tret := m.ctrl.Call(m, \"APIVersion\")\n\tret0, _ := ret[0].(dockerclient.DockerVersion)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// APIVersion mocks base method", "generated": "The Docker client uses the docker-compose command to create a container for running containers on an external host or port of your choice and then calls its own API with parameters that are passed through as arguments in order from most recently created instances to least recent ones by default. The following example shows how this works using Mocks"}
{"id": 1807, "code": "func (m *MockDockerClient) ListContainers(arg0 context.Context, arg1 bool, arg2 time.Duration) dockerapi.ListContainersResponse {\n\tret := m.ctrl.Call(m, \"ListContainers\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(dockerapi.ListContainersResponse)\n\treturn ret0\n}", "reference": "// ListContainers mocks base method", "generated": "List containers is a container that contains the following items in its list of dependencies :\ncontainerName string The name and description for the Docker client to use as an API key or service provider . This can be any URL , hostname , port number , etc. If no parameters are provided by this parameter it will return nil"}
{"id": 1823, "code": "func (mtask *managedTask) waitForHostResources() {\n\tif mtask.StartSequenceNumber == 0 {\n\t\t// This is the first transition on this host. No need to wait\n\t\treturn\n\t}\n\tif mtask.GetDesiredStatus().Terminal() {\n\t\t// Task's desired status is STOPPED. No need to wait in this case either\n\t\treturn\n\t}\n\n\tseelog.Infof(\"Managed task [%s]: waiting for any previous stops to complete. Sequence number: %d\",\n\t\tmtask.Arn, mtask.StartSequenceNumber)\n\n\tothersStoppedCtx, cancel := context.WithCancel(mtask.ctx)\n\tdefer cancel()\n\n\tgo func() {\n\t\tmtask.taskStopWG.Wait(mtask.StartSequenceNumber)\n\t\tcancel()\n\t}()\n\n\tfor !mtask.waitEvent(othersStoppedCtx.Done()) {\n\t\tif mtask.GetDesiredStatus().Terminal() {\n\t\t\t// If we end up here, that means we received a start then stop for this\n\t\t\t// task before a task that was expected to stop before it could\n\t\t\t// actually stop\n\t\t\tbreak\n\t\t}\n\t}\n\tseelog.Infof(\"Managed task [%s]: wait over; ready to move towards status: %s\",\n\t\tmtask.Arn, mtask.GetDesiredStatus().String())\n}", "reference": "// waitForHostResources waits for host resources to become available to start\n// the task. This involves waiting for previous stops to complete so the\n// resources become free.", "generated": "This method waits until an event has been dispatched and returns nil if no current state exists or false otherwise. It does not return true unless there are other pending tasks awaiting execution by default. The following example shows how to use these methods with managed-task .\nExample 1: WaitOver :\n/**\n* A simple"}
{"id": 1857, "code": "func (m *MockWebsocketConn) ReadMessage() (int, []byte, error) {\n\tret := m.ctrl.Call(m, \"ReadMessage\")\n\tret0, _ := ret[0].(int)\n\tret1, _ := ret[1].([]byte)\n\tret2, _ := ret[2].(error)\n\treturn ret0, ret1, ret2\n}", "reference": "// ReadMessage mocks base method", "generated": "This method reads a message from the socket and returns an int or error if it is not found in response to any of the following conditions:\n\nA string containing information about what was sent; A byte indicating whether this received data for that purpose has been returned by another process on its own server with no connection issues caused when"}
{"id": 1890, "code": "func (engine *DockerTaskEngine) isTaskManaged(arn string) bool {\n\tengine.tasksLock.RLock()\n\tdefer engine.tasksLock.RUnlock()\n\t_, ok := engine.managedTasks[arn]\n\treturn ok\n}", "reference": "// isTaskManaged checks if task for the corresponding arn is present", "generated": "// This function will lock the task manager for a specified number of seconds if it has been managed by an external service or otherwise not handled in any way before being run. // The default value should be nil to avoid confusion with other locks that are used on Task Manager objects and may cause issues when running asynchronously;"}
{"id": 1896, "code": "func (engine *DockerTaskEngine) sweepTask(task *apitask.Task) {\n\tfor _, cont := range task.Containers {\n\t\terr := engine.removeContainer(task, cont)\n\t\tif err != nil {\n\t\t\tseelog.Debugf(\"Task engine [%s]: unable to remove old container [%s]: %v\",\n\t\t\t\ttask.Arn, cont.Name, err)\n\t\t}\n\t\t// Internal container(created by ecs-agent) state isn't recorded\n\t\tif cont.IsInternal() {\n\t\t\tcontinue\n\t\t}\n\t\terr = engine.imageManager.RemoveContainerReferenceFromImageState(cont)\n\t\tif err != nil {\n\t\t\tseelog.Errorf(\"Task engine [%s]: Unable to remove container [%s] reference from image state: %v\",\n\t\t\t\ttask.Arn, cont.Name, err)\n\t\t}\n\t}\n\n\t// Clean metadata directory for task\n\tif engine.cfg.ContainerMetadataEnabled {\n\t\terr := engine.metadataManager.Clean(task.Arn)\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Task engine [%s]: clean task metadata failed: %v\", task.Arn, err)\n\t\t}\n\t}\n\tengine.saver.Save()\n}", "reference": "// sweepTask deletes all the containers associated with a task", "generated": "The following code snippet is a simple wrapper around the Docker Task Engine API and provides an easy way of cleaning up existing tasks in order that they can be reused without having any additional dependencies on other containers or services running within it. The method returns true if all current jobs are cleaned successfully; false otherwise when no job has been"}
{"id": 1906, "code": "func (engine *DockerTaskEngine) updateTaskUnsafe(task *apitask.Task, update *apitask.Task) {\n\tmanagedTask, ok := engine.managedTasks[task.Arn]\n\tif !ok {\n\t\tseelog.Criticalf(\"Task engine [%s]: ACS message for a task we thought we managed, but don't!  Aborting.\",\n\t\t\ttask.Arn)\n\t\treturn\n\t}\n\t// Keep the lock because sequence numbers cannot be correct unless they are\n\t// also read in the order addtask was called\n\t// This does block the engine's ability to ingest any new events (including\n\t// stops for past tasks, ack!), but this is necessary for correctness\n\tupdateDesiredStatus := update.GetDesiredStatus()\n\tseelog.Debugf(\"Task engine [%s]: putting update on the acs channel: [%s] with seqnum [%d]\",\n\t\ttask.Arn, updateDesiredStatus.String(), update.StopSequenceNumber)\n\tmanagedTask.emitACSTransition(acsTransition{\n\t\tdesiredStatus: updateDesiredStatus,\n\t\tseqnum:        update.StopSequenceNumber,\n\t})\n\tseelog.Debugf(\"Task engine [%s]: update taken off the acs channel: [%s] with seqnum [%d]\",\n\t\ttask.Arn, updateDesiredStatus.String(), update.StopSequenceNumber)\n}", "reference": "// updateTaskUnsafe determines if a new transition needs to be applied to the\n// referenced task, and if needed applies it. It should not be called anywhere\n// but from 'AddTask' and is protected by the tasksLock lock there.", "generated": "This function updates the ACS queue of an asynchronous Task object and returns it asynchronously if no other thread has been started or stopped by that time. The callback will return nil when all threads have exited from their current state; otherwise, its value may be returned immediately after each call to initDelegate . If there"}
{"id": 1918, "code": "func (m *MockFileSystem) Copy(arg0 io.Writer, arg1 io.Reader) (int64, error) {\n\tret := m.ctrl.Call(m, \"Copy\", arg0, arg1)\n\tret0, _ := ret[0].(int64)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// Copy mocks base method", "generated": "copy() copies the contents of a file to an arbitrary location in memory and returns it as its result if any errors occurred while copying or writing data from the specified directory into the given buffer using copy(). The default is nil . If no files are copied at all then this function will return null , otherwise set errno_"}
{"id": 1919, "code": "func (m *MockFileSystem) Exit(arg0 int) {\n\tm.ctrl.Call(m, \"Exit\", arg0)\n}", "reference": "// Exit mocks base method", "generated": "// This function exits the MOCKFILE system process and returns a list of exit status codes for all processes that exited from it in this case. The default is 0 if no error occurred or 1 otherwise.\n func () m { // Return an empty string to be used as input when exiting with nil return []byte"}
{"id": 1920, "code": "func (m *MockFileSystem) MkdirAll(arg0 string, arg1 os.FileMode) error {\n\tret := m.ctrl.Call(m, \"MkdirAll\", arg0, arg1)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// MkdirAll mocks base method", "generated": "This function returns a list of all the files in the specified directory and its contents if any are found or not included by calling mkdirall() . If no file is present it will return nil , otherwise an empty array containing only one entry for that particular pathname can be returned to set up some sort-of mapping"}
{"id": 1937, "code": "func (m *MockTaskEngineState) AllTasks() []*task.Task {\n\tret := m.ctrl.Call(m, \"AllTasks\")\n\tret0, _ := ret[0].([]*task.Task)\n\treturn ret0\n}", "reference": "// AllTasks mocks base method", "generated": "This method returns a Task object that contains all tasks and the associated task state information for each of those objects in its context. The default is nil . This can be used to specify an optional callback function or any other value which will return true if no such event occurred during execution. If this option is specified then it defaults"}
{"id": 1948, "code": "func (containerType ContainerType) String() string {\n\tfor str, contType := range stringToContainerType {\n\t\tif contType == containerType {\n\t\t\treturn str\n\t\t}\n\t}\n\n\treturn \"NORMAL\"\n}", "reference": "// String converts the container type enum to a string", "generated": "// This method returns a list of strings. The first element is the name and last one is the type. It can be used to specify which elements are returned by this function. // Example usage for an array with two names in it :\npackage main import (stringify, os, pathname ) func () []"}
{"id": 1959, "code": "func (f *factory) GetClient(version dockerclient.DockerVersion) (sdkclient.Client, error) {\n\treturn f.getClient(version)\n}", "reference": "// GetClient on linux will simply return the cached client from the map", "generated": "This function returns the version of the Docker client that is running on a given host and optionally provides an optional service name to be used for authentication purposes in order not only when using this API but also if it has been configured as such by default or otherwise specified with --service-name . The services provided are defined here so"}
{"id": 2002, "code": "func (engine *DockerStatsEngine) removeContainer(dockerID string) {\n\tengine.lock.Lock()\n\tdefer engine.lock.Unlock()\n\n\t// Make sure that this container belongs to a task.\n\ttask, err := engine.resolver.ResolveTask(dockerID)\n\tif err != nil {\n\t\tseelog.Debugf(\"Could not map container to task, ignoring, err: %v, id: %s\", err, dockerID)\n\t\treturn\n\t}\n\n\t_, taskExists := engine.tasksToContainers[task.Arn]\n\tif !taskExists {\n\t\tseelog.Debugf(\"Container not being watched, id: %s\", dockerID)\n\t\treturn\n\t}\n\n\t// task arn exists in map.\n\tcontainer, containerExists := engine.tasksToContainers[task.Arn][dockerID]\n\tif !containerExists {\n\t\t// container arn does not exist in map.\n\t\tseelog.Debugf(\"Container not being watched, id: %s\", dockerID)\n\t\treturn\n\t}\n\n\tengine.doRemoveContainerUnsafe(container, task.Arn)\n}", "reference": "// removeContainer deletes the container from the map of containers being watched.\n// It also stops the periodic usage data collection for the container.", "generated": "The Docker API provides an interface for removing containers from the cluster and performing operations on them without having to create new instances of it or modify existing ones by calling deactivate(). This is useful when you want your application to be able run as many tasks concurrently with other applications running locally but also have multiple processes waiting at once while"}
{"id": 2004, "code": "func (engine *DockerStatsEngine) taskContainerMetricsUnsafe(taskArn string) ([]*ecstcs.ContainerMetric, error) {\n\tcontainerMap, taskExists := engine.tasksToContainers[taskArn]\n\tif !taskExists {\n\t\treturn nil, fmt.Errorf(\"Task not found\")\n\t}\n\n\tvar containerMetrics []*ecstcs.ContainerMetric\n\tfor _, container := range containerMap {\n\t\tdockerID := container.containerMetadata.DockerID\n\t\t// Check if the container is terminal. If it is, make sure that it is\n\t\t// cleaned up properly. We might sometimes miss events from docker task\n\t\t// engine and this helps in reconciling the state. The tcs client's\n\t\t// GetInstanceMetrics probe is used as the trigger for this.\n\t\tif engine.stopTrackingContainerUnsafe(container, taskArn) {\n\t\t\tcontinue\n\t\t}\n\n\t\tif !container.statsQueue.enoughDatapointsInBuffer() &&\n\t\t\t!container.statsQueue.resetThresholdElapsed(queueResetThreshold) {\n\t\t\tseelog.Debugf(\"Stats not ready for container %s\", dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Container is not terminal. Get CPU stats set.\n\t\tcpuStatsSet, err := container.statsQueue.GetCPUStatsSet()\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Error getting cpu stats, err: %v, container: %v\", err, dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\t// Get memory stats set.\n\t\tmemoryStatsSet, err := container.statsQueue.GetMemoryStatsSet()\n\t\tif err != nil {\n\t\t\tseelog.Warnf(\"Error getting memory stats, err: %v, container: %v\", err, dockerID)\n\t\t\tcontinue\n\t\t}\n\n\t\tcontainerMetrics = append(containerMetrics, &ecstcs.ContainerMetric{\n\t\t\tCpuStatsSet:    cpuStatsSet,\n\t\t\tMemoryStatsSet: memoryStatsSet,\n\t\t})\n\n\t}\n\n\treturn containerMetrics, nil\n}", "reference": "// taskContainerMetricsUnsafe gets all container metrics for a task arn.", "generated": "This function creates a Docker statistics queue to store data about containers on disk or networked devices using an API called metrics . It also provides access control over how many times each time you need these services installed by your application when running with -d , --force-cache , etc.. This service can be configured via configuration options"}
{"id": 2025, "code": "func NewNamedError(err error) *DefaultNamedError {\n\tif namedErr, ok := err.(NamedError); ok {\n\t\treturn &DefaultNamedError{Err: namedErr.Error(), Name: namedErr.ErrorName()}\n\t}\n\treturn &DefaultNamedError{Err: err.Error()}\n}", "reference": "// NewNamedError creates a NamedError.", "generated": "New Naming Error is a new type of error that can be used to identify errors in the system and provide information about what went wrong or how it was handled by an application (e., for example, if you are using Windows PowerShell). It provides some useful features such as warning messages when something goes awry while running"}
{"id": 2037, "code": "func (r *eventLogReceiver) ReceiveMessage(message string, level seelog.LogLevel, context seelog.LogContextInterface) error {\n\tswitch level {\n\tcase seelog.DebugLvl, seelog.InfoLvl:\n\t\treturn eventLog.Info(eventLogID, message)\n\tcase seelog.WarnLvl:\n\t\treturn eventLog.Warning(eventLogID, message)\n\tcase seelog.ErrorLvl, seelog.CriticalLvl:\n\t\treturn eventLog.Error(eventLogID, message)\n\t}\n\treturn nil\n}", "reference": "// ReceiveMessage receives a log line from seelog and emits it to the Windows event log", "generated": "// This is a log handler that sends messages to the specified events and logs them back in if they are not received by any other logging system or otherwise ignored. // The default value is false for non-logging purposes only. func main() {}\n\n\nvar logger = new Logger(); var requestHandler := get"}
{"id": 2051, "code": "func (m *MockIOUtil) WriteFile(arg0 string, arg1 []byte, arg2 os.FileMode) error {\n\tret := m.ctrl.Call(m, \"WriteFile\", arg0, arg1, arg2)\n\tret0, _ := ret[0].(error)\n\treturn ret0\n}", "reference": "// WriteFile mocks base method", "generated": "This function writes a file to the console using Mocking I/O and returns an object that contains all of the information required for writing it back in time with no errors or warnings thrown by default. It is used as part-of any write operation on files created from within this program without requiring additional configuration before running its"}
{"id": 2052, "code": "func (mr *MockIOUtilMockRecorder) WriteFile(arg0, arg1, arg2 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"WriteFile\", reflect.TypeOf((*MockIOUtil)(nil).WriteFile), arg0, arg1, arg2)\n}", "reference": "// WriteFile indicates an expected call of WriteFile", "generated": "This function writes a file to the console using MOCKIO and returns an error if it fails. The return value is nil . If this call succeeds, then writeFile will be called with no errors returned by `write` method of record type or otherwise ignored in any subsequent calls on that data structure for which there was"}
{"id": 2060, "code": "func NewVolumesResponse(dockerContainer *apicontainer.DockerContainer) []VolumeResponse {\n\tcontainer := dockerContainer.Container\n\tvar resp []VolumeResponse\n\n\tvolumes := container.GetVolumes()\n\n\tfor _, volume := range volumes {\n\t\tvolResp := VolumeResponse{\n\t\t\tDockerName:  volume.Name,\n\t\t\tSource:      volume.Source,\n\t\t\tDestination: volume.Destination,\n\t\t}\n\n\t\tresp = append(resp, volResp)\n\t}\n\treturn resp\n}", "reference": "// NewVolumesResponse creates VolumeResponse for a container", "generated": "// Create a new Docker Container and create the Volumes response object for each of the containers in the list below.\n // This is used to generate an initial bucket that contains all available data from any given batch (or if there are no buckets at all). The default value is 0 . If this parameter is set to"}
{"id": 2062, "code": "func NewPublishMetricsRequest(metadata *MetricsMetadata, taskMetrics []*TaskMetric) *PublishMetricsRequest {\n\treturn &PublishMetricsRequest{\n\t\tMetadata:    metadata,\n\t\tTaskMetrics: taskMetrics,\n\t\tTimestamp:   aws.Time(time.Now()),\n\t}\n}", "reference": "// NewPublishMetricsRequest creates a PublishMetricsRequest object.", "generated": "NewMetaService is a service that provides the Metabase API for publishing metrics to an application using JSON and XML format (JSON/XML). It can be used as part of any other services provided by this library or in conjunction with it from within your own app's UI framework such like AppCompat . The name \""}
{"id": 2092, "code": "func (m *MockCNI) AddNetworkList(arg0 *libcni.NetworkConfigList, arg1 *libcni.RuntimeConf) (types.Result, error) {\n\tret := m.ctrl.Call(m, \"AddNetworkList\", arg0, arg1)\n\tret0, _ := ret[0].(types.Result)\n\tret1, _ := ret[1].(error)\n\treturn ret0, ret1\n}", "reference": "// AddNetworkList mocks base method", "generated": "The add network list function adds a new NetworkConfig to the specified interface and returns an array of interfaces that are available for use in this implementation. The default is nil . This method can be used with any number or multiple networks as long it does not return null , which means no additional information about each connection will ever appear"}
{"id": 2094, "code": "func (mr *MockCNIMockRecorder) DelNetwork(arg0, arg1 interface{}) *gomock.Call {\n\treturn mr.mock.ctrl.RecordCallWithMethodType(mr.mock, \"DelNetwork\", reflect.TypeOf((*MockCNI)(nil).DelNetwork), arg0, arg1)\n}", "reference": "// DelNetwork indicates an expected call of DelNetwork", "generated": "This method returns a record of the specified protocol type and optionally an optional string representation to be used for subsequent calls with this call handler in order that it can return any value from its chain if necessary. The returned records are then passed as arguments into MockingQueue . This is useful when you want to use multiple chains on"}
{"id": 2114, "code": "func (v *StackSwitcher) native() *C.GtkStackSwitcher {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkStackSwitcher(p)\n}", "reference": "// native returns a pointer to the underlying GtkStackSwitcher.", "generated": "This method is a wrapper around the Gdk.Gobject interface, which provides an object-oriented way to create and manipulate objects in any language that supports it. It also allows you access to all of its methods by calling them directly from within your codebase without having to write anything special into their source files or recomp"}
{"id": 2116, "code": "func (v *ComboBoxText) native() *C.GtkComboBoxText {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkComboBoxText(p)\n}", "reference": "// native returns a pointer to the underlying GtkComboBoxText.", "generated": "This is a wrapper around the GdkCombability interface, which provides an implementation of Combo Box Text . It uses this to provide accessor methods for all types that can be used in conjunction with other wrappers such as Object , String , and so on. The method returns true if it has been called successfully"}
{"id": 2124, "code": "func (v *Variant) GetString() string {\n\tvar len C.gsize\n\tgc := C.g_variant_get_string(v.native(), &len)\n\tdefer C.g_free(C.gpointer(gc))\n\treturn C.GoStringN((*C.char)(gc), (C.int)(len))\n}", "reference": "// GetString returns the string value of the variant.", "generated": "This function returns a Go String object that contains the strings of an array, and is used to create new instances for each element in the list or set by calling getInstance(). The returned value can be any number from 0 through 255 inclusive as long it's not null . This method also provides accessor methods on all elements"}
{"id": 2143, "code": "func (v *StyleContext) native() *C.GtkStyleContext {\n\tif v == nil || v.Object == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkStyleContext(p)\n}", "reference": "// native returns a pointer to the underlying GtkStyleContext.", "generated": "This method returns a GdkStyle object that implements the style context interface, and provides access to all of its methods in this class as well with no additional information about their type or implementation details at runtime. The default behavior is for any gdk-style objects provided by an existing application which does not implement these interfaces directly"}
{"id": 2148, "code": "func (m *Matrix) InitRotate(radians float64) {\n\tC.cairo_matrix_init_rotate(m.native(), C.double(radians))\n}", "reference": "// InitRotate initializes a matrix with the given rotation", "generated": "This function is used to initialize the rotation of a matrix in an arbitrary direction, and returns true if it has been initialized correctly or false otherwise when no rotations have occurred at all. It also provides some useful information about how this operation works for vectors that are not vector-based; see Vector initialization methods below. The"}
{"id": 2165, "code": "func NewSurface(s uintptr, needsRef bool) *Surface {\n\tsurface := WrapSurface(s)\n\tif needsRef {\n\t\tsurface.reference()\n\t}\n\truntime.SetFinalizer(surface, (*Surface).destroy)\n\treturn surface\n}", "reference": "// NewSurface creates a gotk3 cairo Surface from a pointer to a\n// C cairo_surface_t.  This is primarily designed for use with other\n// gotk3 packages and should be avoided by applications.", "generated": "// Create a new Surface object that implements the interface of the current Surfaces struct and returns an instance for it.\n // The initializers are provided by wrap_surf , which is used to create wrappers around existing interfaces in order not be exposed as garbage collection objects. This method will return an instance when no"}
{"id": 2167, "code": "func AddFont(fontPath string) {\n\tpath := (*C.uchar)(unsafe.Pointer(C.CString(fontPath)))\n\tC.addFont(path)\n}", "reference": "// AddFont adds the font to the configuration.", "generated": "Add Font is a wrapper around the C++ standard library's font class, which provides an interface to add fonts and other types of text files into your program (including those that are not part or all of the default file system). It can be used as a base for any type of application code you want; it does"}
{"id": 2168, "code": "func (v *Label) native() *C.GtkLabel {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkLabel(p)\n}", "reference": "// native returns a pointer to the underlying GtkLabel.", "generated": "This is a wrapper around the GdkMutableType interface, which provides an implementation of type-safe types for all classes and interfaces that implement this class's methods or functions as well in order to provide more flexibility when writing code with different implementations than what we currently have available on our own hardware devices such at runtime."}
{"id": 2182, "code": "func (v *ActionGroup) ChangeActionState(actionName string, value *Variant) {\n\tC.g_action_group_change_action_state(v.native(), (*C.gchar)(C.CString(actionName)), value.native())\n}", "reference": "// ChangeActionState is a wrapper around g_action_group_change_action_state", "generated": "Changes the action state of a group to change its name and type in ActionGroup . The changes are applied as if by calling g_changed() on an existing session or returning nil for no effect when called with new-type options such that they do not affect any other actions within this context. This is useful because it"}
{"id": 2186, "code": "func (v *GLArea) native() *C.GtkGLArea {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkGLArea(p)\n}", "reference": "// native returns a pointer to the underlying GtkGLArea.", "generated": "This function is a wrapper around the GdkGL Area class, which provides an interface to create and manipulate GLArea objects in order for them not only be accessible but also available as methods of other classes that implement it's own API or are used by others within its scope such as OpenGL ES 3D Rendering APIs like"}
{"id": 2188, "code": "func (v *TreeView) SetSearchEqualSubstringMatch() {\n\tC.gtk_tree_view_set_search_equal_func(\n\t\tv.native(),\n\t\t(C.GtkTreeViewSearchEqualFunc)(unsafe.Pointer(C.substring_match_equal_func)),\n\t\tnil,\n\t\tnil)\n}", "reference": "// SetSearchEqualSubstringMatch sets TreeView to search by substring match.", "generated": "// Sets the search match for a tree view to equal the string matched by the specified filter in the given context.\n // The default is nil if no matching matches are found and false otherwise."}
{"id": 2202, "code": "func (v *ShortcutsShortcut) native() *C.GtkShortcutsShortcut {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkShortcutsShortcut(p)\n}", "reference": "// native returns a pointer to the underlying GtkShortcutsShortcut.", "generated": "This is a short-cut implementation of the GKShortcode interface, which provides an easy way to create and manipulate Shortcuts objects in any language with builtin support for strings or other non-ASCII characters that are not supported by standard input formats such as UTF8/UTF16 . The method returns either true"}
{"id": 2203, "code": "func SimpleActionGroupNew() *SimpleActionGroup {\n\tc := C.g_simple_action_group_new()\n\tif c == nil {\n\t\treturn nil\n\t}\n\treturn wrapSimpleActionGroup(wrapObject(unsafe.Pointer(c)))\n}", "reference": "// SimpleActionGroupNew is a wrapper around g_simple_action_group_new", "generated": "This function is a wrapper around the simple action group, which provides an interface to create and delete actions from within it (using wrappers). It also allows for creating new groups of objects that are not currently in use by default; this can be useful when you want to add or remove items without having to explicitly specify them"}
{"id": 2208, "code": "func (v *Action) GetParameterType() *VariantType {\n\tc := C.g_action_get_parameter_type(v.native())\n\tif c == nil {\n\t\treturn nil\n\t}\n\treturn newVariantType((*C.GVariantType)(c))\n}", "reference": "// GetParameterType is a wrapper around g_action_get_parameter_type", "generated": "This method returns a string representation of the parameter type, which is used to determine whether or not an action should be performed on that object in order for it's value returned from this function call to return true if and only otherwise. The default behavior when performing actions with parameters other than those specified by their native values can cause"}
{"id": 2218, "code": "func (v *Bin) native() *C.GtkBin {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkBin(p)\n}", "reference": "// native returns a pointer to the underlying GtkBin.", "generated": "This function is a wrapper around the GdkContext and provides an interface to create new objects from existing ones, which can be used as bindings for other functions in this context or by calling gkcontext . The following example uses it with two different methods of creating newly created instances using both interfaces :\nfunc (c *"}
{"id": 2221, "code": "func (v *CellRendererSpinner) native() *C.GtkCellRendererSpinner {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkCellRendererSpinner(p)\n}", "reference": "// native returns a pointer to the underlying GtkCellRendererSpinner.", "generated": "This method is a wrapper around the GdkCellFrame class, which provides an interface for creating and manipulating cell frames in order to create new cells from existing ones using methods such as CellView , FrameLayout or ViewGroup . The frame can be created by calling this constructor with any of its parameters passed through it's own"}
{"id": 2247, "code": "func (v *FileChooserDialog) native() *C.GtkFileChooserDialog {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkFileChooserDialog(p)\n}", "reference": "// native returns a pointer to the underlying GtkFileChooserDialog.", "generated": "This is a wrapper for the Gdk.Options object, which provides options to specify how an application should handle certain types of dialogs and their associated data structures in order that they can be used as part or even all of its own objects within it's interface. The default implementation will use this method only if there are"}
{"id": 2267, "code": "func (v *Paned) native() *C.GtkPaned {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkPaned(p)\n}", "reference": "// native returns a pointer to the underlying GtkPaned.", "generated": "This function returns a Panized object that is an instance of Panizable . It can be used to create new instances, or it may return the same objects as previously created by calling panize().\nExample usage:\n\n```\n// Create two newly-created GtkParams and add them into one `pan"}
{"id": 2303, "code": "func (v *TreePath) GetIndices() []int {\n\tvar depth C.gint\n\tvar goindices []int\n\tvar ginthelp C.gint\n\tindices := uintptr(unsafe.Pointer(C.gtk_tree_path_get_indices_with_depth(v.native(), &depth)))\n\tsize := unsafe.Sizeof(ginthelp)\n\tfor i := 0; i < int(depth); i++ {\n\t\tgoind := int(*((*C.gint)(unsafe.Pointer(indices))))\n\t\tgoindices = append(goindices, goind)\n\t\tindices += size\n\t}\n\treturn goindices\n}", "reference": "// GetIndices is a wrapper around gtk_tree_path_get_indices_with_depth", "generated": "This function returns a list of indices for the tree path specified by the root node in the current directory and its descendants as well with all branches removed from it at once if any are found to be missing or incomplete nodes within that branch set up correctly without removing them altogether when traversing through those trees again using this method instead"}
{"id": 2313, "code": "func (v *Window) native() *C.GtkWindow {\n\tif v == nil || v.GObject == nil {\n\t\treturn nil\n\t}\n\tp := unsafe.Pointer(v.GObject)\n\treturn C.toGtkWindow(p)\n}", "reference": "// native returns a pointer to the underlying GtkWindow.", "generated": "This is a wrapper around the GdkWindow interface, which provides an API for creating and manipulating window objects in order to create new windows or add/remove existing ones from within it. The implementation of this method takes advantage that there are no special methods required by any other package; instead, all you need to do with"}
{"id": 2348, "code": "func hideConsoleWindowOnWindows() {\n\tpid, err := getCurrentProcessId()\n\tif err != nil {\n\t\t// Ignore errors because:\n\t\t// 1. It is not critical if the console can't be hid.\n\t\t// 2. There is nothing to do when errors happen.\n\t\treturn\n\t}\n\tw, err := getConsoleWindow()\n\tif err != nil {\n\t\t// Ignore errors\n\t\treturn\n\t}\n\t// Get the process ID of the console's creator.\n\tcpid, err := getWindowThreadProcessId(w)\n\tif err != nil {\n\t\t// Ignore errors\n\t\treturn\n\t}\n\tif pid == cpid {\n\t\t// The current process created its own console. Hide this.\n\t\tshowWindowAsync(w, windows.SW_HIDE)\n\t}\n}", "reference": "// hideConsoleWindowOnWindows will hide the console window that is showing when\n// compiling on Windows without specifying the '-ldflags \"-Hwindowsgui\"' flag.", "generated": "The hidden window handler for Windows uses a special method called \"hideWindowAsync\" which returns an error message that indicates whether or no such event occurred in any given time frame. This function will return false otherwise and only displays information about events occurring during those frames (e., messages from other processes). If there are multiple instances"}
{"id": 2349, "code": "func DepthMask(flag bool) {\n\tC.glowDepthMask(gpDepthMask, (C.GLboolean)(boolToInt(flag)))\n}", "reference": "// enable or disable writing into the depth buffer", "generated": "This function returns the depth mask of the current buffer and its associated flags if it is not set to false . If this value does not exist in a given context, then nil will be returned as an error message when no such flag exists or undefined otherwise. The default values are 0 , 1 : true for all buffers that"}
{"id": 2354, "code": "func scaleUpdater() {\n\tfor {\n\t\ts := getscale(0, 0)\n\t\tatomic.StoreUint64(&cachedScale, math.Float64bits(s))\n\t\ttime.Sleep(cacheUpdateWait)\n\t}\n}", "reference": "// run as goroutine. Will keep the desktop scale up to date.\n// This can be removed once the scale change event is implemented in GLFW 3.3", "generated": "// Scale up the data in a single-dimensional array using an atomic store for each element of this object. The storage is stored as uint32_t . // This can be used to create arrays with multiple elements and/or collections that are not contiguous or large enough (e., if you want).\n func main"}
{"id": 2359, "code": "func (b *Board) Draw(boardImage *ebiten.Image) {\n\tboardImage.Fill(frameColor)\n\tfor j := 0; j < b.size; j++ {\n\t\tfor i := 0; i < b.size; i++ {\n\t\t\tv := 0\n\t\t\top := &ebiten.DrawImageOptions{}\n\t\t\tx := i*tileSize + (i+1)*tileMargin\n\t\t\ty := j*tileSize + (j+1)*tileMargin\n\t\t\top.GeoM.Translate(float64(x), float64(y))\n\t\t\tr, g, b, a := colorToScale(tileBackgroundColor(v))\n\t\t\top.ColorM.Scale(r, g, b, a)\n\t\t\tboardImage.DrawImage(tileImage, op)\n\t\t}\n\t}\n\tanimatingTiles := map[*Tile]struct{}{}\n\tnonAnimatingTiles := map[*Tile]struct{}{}\n\tfor t := range b.tiles {\n\t\tif t.IsMoving() {\n\t\t\tanimatingTiles[t] = struct{}{}\n\t\t} else {\n\t\t\tnonAnimatingTiles[t] = struct{}{}\n\t\t}\n\t}\n\tfor t := range nonAnimatingTiles {\n\t\tt.Draw(boardImage)\n\t}\n\tfor t := range animatingTiles {\n\t\tt.Draw(boardImage)\n\t}\n}", "reference": "// Draw draws the board to the given boardImage.", "generated": "// Initializes the board image and draws it to the screen using draw(). // The drawing method is called when an animation has finished or stopped for each frame in time.\n func (a *Board ) Drawing () { if not initWithAnimationFinished { return } var frames []byte\n\u0013frames.AddFrame"}
{"id": 2441, "code": "func (i *Image) makeStale() {\n\ti.basePixels = nil\n\ti.drawTrianglesHistory = nil\n\ti.stale = true\n\n\t// Don't have to call makeStale recursively here.\n\t// Restoring is done after topological sorting is done.\n\t// If an image depends on another stale image, this means that\n\t// the former image can be restored from the latest state of the latter image.\n}", "reference": "// makeStale makes the image stale.", "generated": "This function creates a new instance for each element in the collection and returns it as its base pixel value when called with no arguments or any other methods available at runtime. It also provides some additional information about how images are stored within collections by providing them directly through their metadata properties such as \"image\" , which contains all associated"}
{"id": 2498, "code": "func (u *UserInterface) setScreenSize(width, height int, scale float64, fullscreen bool, vsync bool) bool {\n\tif u.width == width && u.height == height && u.scale == scale && u.isFullscreen() == fullscreen && u.vsync == vsync {\n\t\treturn false\n\t}\n\tu.forceSetScreenSize(width, height, scale, fullscreen, vsync)\n\treturn true\n}", "reference": "// setScreenSize must be called from the main thread.", "generated": "// Set screen size to the specified value for a user interface that is not an empty UI element or nil if no such implementation exists. // The default setting of this method will be used when creating new users and returning null on failure with error code `nil` .\n// Note : This function does not return any information"}
{"id": 2504, "code": "func (q *commandQueue) Flush() {\n\tif q.err != nil {\n\t\treturn\n\t}\n\n\tes := q.indices\n\tvs := q.vertices\n\tif recordLog() {\n\t\tfmt.Println(\"--\")\n\t}\n\n\ttheGraphicsDriver.Begin()\n\tfor len(q.commands) > 0 {\n\t\tnv := 0\n\t\tne := 0\n\t\tnc := 0\n\t\tfor _, c := range q.commands {\n\t\t\tif c.NumIndices() > graphics.IndicesNum {\n\t\t\t\tpanic(fmt.Sprintf(\"graphicscommand: c.NumIndices() must be <= graphics.IndicesNum but not at Flush: c.NumIndices(): %d, graphics.IndicesNum: %d\", c.NumIndices(), graphics.IndicesNum))\n\t\t\t}\n\t\t\tif ne+c.NumIndices() > graphics.IndicesNum {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tnv += c.NumVertices()\n\t\t\tne += c.NumIndices()\n\t\t\tnc++\n\t\t}\n\t\tif 0 < ne {\n\t\t\ttheGraphicsDriver.SetVertices(vs[:nv], es[:ne])\n\t\t\tes = es[ne:]\n\t\t\tvs = vs[nv:]\n\t\t}\n\t\tindexOffset := 0\n\t\tfor _, c := range q.commands[:nc] {\n\t\t\tif err := c.Exec(indexOffset); err != nil {\n\t\t\t\tq.err = err\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif recordLog() {\n\t\t\t\tfmt.Printf(\"%s\\n\", c)\n\t\t\t}\n\t\t\t// TODO: indexOffset should be reset if the command type is different\n\t\t\t// from the previous one. This fix is needed when another drawing command is\n\t\t\t// introduced than drawTrianglesCommand.\n\t\t\tindexOffset += c.NumIndices()\n\t\t}\n\t\tif 0 < nc {\n\t\t\t// Call glFlush to prevent black flicking (especially on Android (#226) and iOS).\n\t\t\ttheGraphicsDriver.Flush()\n\t\t}\n\t\tq.commands = q.commands[nc:]\n\t}\n\ttheGraphicsDriver.End()\n\tq.commands = nil\n\tq.nvertices = 0\n\tq.nindices = 0\n\tq.tmpNumIndices = 0\n\tq.nextIndex = 0\n}", "reference": "// Flush flushes the command queue.", "generated": "The following code snippet creates a new file called \"drawtriangle-cluster\" in order for it's vertex data to have an offset of zero or more bytes before being drawn into the buffer by calling fsync . The resulting output will then contain all vertice coordinates that are currently visible within this cluster as well with"}
{"id": 2534, "code": "func flattenClusterHostGroup(d *schema.ResourceData, obj *types.ClusterHostGroup) error {\n\tvar hostIDs []string\n\tfor _, v := range obj.Host {\n\t\thostIDs = append(hostIDs, v.Value)\n\t}\n\n\treturn structure.SetBatch(d, map[string]interface{}{\n\t\t\"host_system_ids\": hostIDs,\n\t})\n}", "reference": "// flattenClusterHostGroup saves a ClusterHostGroup into the supplied ResourceData.", "generated": "This function creates a cluster of hosts for the specified resource data type and returns an array of all clusters that are connected to it in this way. The returned list is then sorted by number (inclusive). Each node has its own unique identifier which can be used as a string or any other value from within their Cluster Host"}
{"id": 2535, "code": "func resourceVSphereComputeClusterHostGroupFlattenID(cluster *object.ClusterComputeResource, name string) (string, error) {\n\tclusterID := cluster.Reference().Value\n\treturn strings.Join([]string{clusterID, name}, \":\"), nil\n}", "reference": "// resourceVSphereComputeClusterHostGroupFlattenID makes an ID for the\n// vsphere_cluster_host_group resource.", "generated": "The Cluster Host Group Flattens the ID of a group that is in use by this VM and returns an object with all associated IDs for each member who has been added to it since its creation on May 1st 2015 at 10am PDT . The returned objects are then used as part or after-all information about any"}
{"id": 2590, "code": "func MoveToFolder(client *govmomi.Client, vm *object.VirtualMachine, relative string) error {\n\tlog.Printf(\"[DEBUG] Moving virtual %q to VM path %q\", vm.InventoryPath, relative)\n\tf, err := folder.VirtualMachineFolderFromObject(client, vm, relative)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn folder.MoveObjectTo(vm.Reference(), f)\n}", "reference": "// MoveToFolder moves a virtual machine to the specified folder.", "generated": "This function moves the current directory of a client object into an inventory file and returns it as its value in this case. The move operation is performed by calling os.move() . If no such item exists within that list, then return obj instead. Otherwise, if there is one already created for any given name or type"}
{"id": 2611, "code": "func FromPath(client *govmomi.Client, name string, dc *object.Datacenter) (*object.VirtualApp, error) {\n\tfinder := find.NewFinder(client.Client, false)\n\n\tctx, cancel := context.WithTimeout(context.Background(), provider.DefaultAPITimeout)\n\tdefer cancel()\n\tif dc != nil {\n\t\tfinder.SetDatacenter(dc)\n\t}\n\treturn finder.VirtualApp(ctx, name)\n}", "reference": "// FromPath returns a VirtualApp via its supplied path.", "generated": "This method returns a virtual app that is created by the client and passed to its constructor as an argument in order for it not be terminated with an exception thrown from within this call (see below). The default value of \"from\" will return null if no such instance exists or undefined otherwise. This implementation does NOT support termination"}
{"id": 2643, "code": "func resourceVSphereComputeClusterApplyCreate(d *schema.ResourceData, meta interface{}) (*object.ClusterComputeResource, error) {\n\tlog.Printf(\"[DEBUG] %s: Processing compute cluster creation\", resourceVSphereComputeClusterIDString(d))\n\tclient, err := resourceVSphereComputeClusterClient(meta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tdc, err := datacenterFromID(client, d.Get(\"datacenter_id\").(string))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot locate datacenter: %s\", err)\n\t}\n\n\t// Find the folder based off the path to the datacenter. This is where we\n\t// create the datastore cluster.\n\tf, err := folder.FromPath(client, d.Get(\"folder\").(string), folder.VSphereFolderTypeHost, dc)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot locate folder: %s\", err)\n\t}\n\n\t// Create the cluster. We use an empty config spec so that we can move the\n\t// necessary hosts into the cluster *before* we send the full configuration,\n\t// ensuring that any host-dependent configuration does not break.\n\tcluster, err := clustercomputeresource.Create(f, d.Get(\"name\").(string), types.ClusterConfigSpecEx{})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error creating cluster: %s\", err)\n\t}\n\n\t// Set the ID now before proceeding any further. Any other operation past\n\t// this point is recoverable.\n\td.SetId(cluster.Reference().Value)\n\n\treturn cluster, nil\n}", "reference": "// resourceVSphereComputeClusterApplyCreate processes the creation part of\n// resourceVSphereComputeClusterCreate.", "generated": "The Resource Data Cluster (RDBMS) provides a set of resources for each Datasource in its own namespace and allows us access from within it without having to specify which one or more instances are created by calling RDS::createDatasources() . The following example creates two clusters with different namespaces using D"}
{"id": 2650, "code": "func resourceVSphereComputeClusterSaveDatacenter(\n\td *schema.ResourceData,\n\tmeta interface{},\n\tcluster *object.ClusterComputeResource,\n) error {\n\tlog.Printf(\"[DEBUG] %s: Saving datacenter\", resourceVSphereComputeClusterIDString(d))\n\tclient, err := resourceVSphereComputeClusterClient(meta)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tp, err := folder.RootPathParticleHost.SplitDatacenter(cluster.InventoryPath)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error parsing datacenter path from cluster: %s\", err)\n\t}\n\n\tdc, err := getDatacenter(client, p)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error fetching datacenter for cluster: %s\", err)\n\t}\n\n\treturn d.Set(\"datacenter_id\", dc.Reference().Value)\n}", "reference": "// resourceVSphereComputeClusterSaveDatacenter saves the datacenter that the\n// cluster is a member of for correctness on imports.", "generated": "The DatasourceContext is a collection of objects that are used to store the data in an array or list format (see below). The object can be any type and it has no parameters; this allows you access to all types available on disk without having additional information about them being stored by other entities within the context."}
{"id": 2677, "code": "func expandClusterDrsConfigInfo(d *schema.ResourceData) *types.ClusterDrsConfigInfo {\n\tobj := &types.ClusterDrsConfigInfo{\n\t\tDefaultVmBehavior:         types.DrsBehavior(d.Get(\"drs_automation_level\").(string)),\n\t\tEnabled:                   structure.GetBool(d, \"drs_enabled\"),\n\t\tEnableVmBehaviorOverrides: structure.GetBool(d, \"drs_enable_vm_overrides\"),\n\t\tVmotionRate:               int32(d.Get(\"drs_migration_threshold\").(int)),\n\t\tOption:                    expandResourceVSphereComputeClusterDrsAdvancedOptions(d),\n\t}\n\n\treturn obj\n}", "reference": "// expandClusterDrsConfigInfo reads certain ResourceData keys and returns a\n// ClusterDrsConfigInfo.", "generated": "This module provides a set of configuration options for the cluster DRS (Configuration Manager). The default settings are used to configure and manage all clusters in an application that uses this toolkit as well; however if you want to use more than one config option at once or have multiple configurations configured on different machines then it is recommended"}
{"id": 2689, "code": "func Rename(pod *object.StoragePod, name string) error {\n\tlog.Printf(\"[DEBUG] Renaming storage pod %q to %s\", pod.InventoryPath, name)\n\tctx, cancel := context.WithTimeout(context.Background(), provider.DefaultAPITimeout)\n\tdefer cancel()\n\ttask, err := pod.Rename(ctx, name)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn task.Wait(ctx)\n}", "reference": "// Rename renames a StoragePod.", "generated": "This function returns a new instance of Storage Pod that is used by the Task Manager and provides an interface for creating tasks in which they are created using methods defined on this object's properties (e., // createTask). The default implementation uses only one method per class or namespace; it does not provide any additional functionality as such"}
{"id": 2727, "code": "func createHardDisk(client *govmomi.Client, size int, diskPath string, diskType string, adapterType string, dc string) error {\n\tvar vDiskType string\n\tswitch diskType {\n\tcase \"thin\":\n\t\tvDiskType = \"thin\"\n\tcase \"eagerZeroedThick\":\n\t\tvDiskType = \"eagerZeroedThick\"\n\tcase \"lazy\":\n\t\tvDiskType = \"preallocated\"\n\t}\n\n\tvirtualDiskManager := object.NewVirtualDiskManager(client.Client)\n\tspec := &types.FileBackedVirtualDiskSpec{\n\t\tVirtualDiskSpec: types.VirtualDiskSpec{\n\t\t\tAdapterType: adapterType,\n\t\t\tDiskType:    vDiskType,\n\t\t},\n\t\tCapacityKb: int64(1024 * 1024 * size),\n\t}\n\tdatacenter, err := getDatacenter(client, dc)\n\tif err != nil {\n\t\treturn err\n\t}\n\tlog.Printf(\"[DEBUG] Disk spec: %v\", spec)\n\n\ttask, err := virtualDiskManager.CreateVirtualDisk(context.TODO(), diskPath, datacenter, spec)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t_, err = task.WaitForResult(context.TODO(), nil)\n\tif err != nil {\n\t\tlog.Printf(\"[INFO] Failed to create disk:  %v\", err)\n\t\treturn err\n\t}\n\tlog.Printf(\"[INFO] Created disk.\")\n\n\treturn nil\n}", "reference": "// createHardDisk creates a new Hard Disk.", "generated": "// Create a harddisk with the following parameters and an optional storage type for it // in order of priority (default is 0):\n/* Initialize Hard Drive Specification */\n/** Set up all disks on this drive as well; if not set then no more data will be created at any given time by default or"}
{"id": 2729, "code": "func (p *nasDatastoreMountProcessor) processMountOperations() (*object.Datastore, error) {\n\thosts := p.diffNewOld()\n\tif len(hosts) < 1 {\n\t\t// Nothing to do\n\t\treturn p.ds, nil\n\t}\n\t// Validate we are vCenter if we are working with multiple hosts\n\tif len(hosts) > 1 {\n\t\tif err := viapi.ValidateVirtualCenter(p.client); err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"cannot mount on multiple hosts: %s\", err)\n\t\t}\n\t}\n\tfor _, hsID := range hosts {\n\t\tdss, err := hostDatastoreSystemFromHostSystemID(p.client, hsID)\n\t\tif err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\t\tdefer cancel()\n\t\tds, err := dss.CreateNasDatastore(ctx, *p.volSpec)\n\t\tif err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t\tif err := p.validateDatastore(ds); err != nil {\n\t\t\treturn p.ds, fmt.Errorf(\"datastore validation error on host %q: %s\", hostsystem.NameOrID(p.client, hsID), err)\n\t\t}\n\t}\n\treturn p.ds, nil\n}", "reference": "// processMountOperations processes all pending mount operations by diffing old\n// and new and adding any hosts that were not found in old. The datastore is\n// returned, along with any error.", "generated": "The nas datatype is a string representation of the Datastores in an array or list format that can be used as input for any command line interface and/and other commands within it. The name may also include spaces such like \"n\" where N represents number; e.,g.:\n\nA simple example"}
{"id": 2733, "code": "func tagByName(client *tags.RestClient, name, categoryID string) (string, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\ttags, err := client.GetTagByNameForCategory(ctx, name, categoryID)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"could not get tag for name %q: %s\", name, err)\n\t}\n\n\tif len(tags) < 1 {\n\t\treturn \"\", fmt.Errorf(\"tag name %q not found in category ID %q\", name, categoryID)\n\t}\n\tif len(tags) > 1 {\n\t\t// This situation is very similar to the one in tagCategoryByName. The API\n\t\t// docs even say that tags need to be unique in categories, yet\n\t\t// GetTagByNameForCategory still returns multiple results.\n\t\treturn \"\", fmt.Errorf(vSphereTagSearchErrMultiple, name)\n\t}\n\n\treturn tags[0].ID, nil\n}", "reference": "// tagByName locates a tag by it supplied name and category ID. Use\n// tagCategoryByName to get the tag category ID if require the category ID as\n// well.", "generated": "The following code snippet creates a new Tag by Name object and uses it as an identifier of its own with no additional parameters or attributes at all; this method does not return any information about what type of data was created from which source file descriptor used when creating such objects using NSObjectStorage . It also provides some useful methods"}
{"id": 2752, "code": "func expandVMwareDVSConfigSpec(d *schema.ResourceData) *types.VMwareDVSConfigSpec {\n\tobj := &types.VMwareDVSConfigSpec{\n\t\tDVSConfigSpec: types.DVSConfigSpec{\n\t\t\tName:                                d.Get(\"name\").(string),\n\t\t\tConfigVersion:                       d.Get(\"config_version\").(string),\n\t\t\tDefaultPortConfig:                   expandVMwareDVSPortSetting(d),\n\t\t\tHost:                                expandSliceOfDistributedVirtualSwitchHostMemberConfigSpec(d),\n\t\t\tDescription:                         d.Get(\"description\").(string),\n\t\t\tContact:                             expandDVSContactInfo(d),\n\t\t\tSwitchIpAddress:                     d.Get(\"ipv4_address\").(string),\n\t\t\tInfrastructureTrafficResourceConfig: expandSliceOfDvsHostInfrastructureTrafficResource(d),\n\t\t\tNetworkResourceControlVersion:       d.Get(\"network_resource_control_version\").(string),\n\t\t\tUplinkPortPolicy:                    expandDVSNameArrayUplinkPortPolicy(d),\n\t\t},\n\t\tMaxMtu:                      int32(d.Get(\"max_mtu\").(int)),\n\t\tLinkDiscoveryProtocolConfig: expandLinkDiscoveryProtocolConfig(d),\n\t\tIpfixConfig:                 expandVMwareIpfixConfig(d),\n\t\tLacpApiVersion:              d.Get(\"lacp_api_version\").(string),\n\t\tMulticastFilteringMode:      d.Get(\"multicast_filtering_mode\").(string),\n\t}\n\treturn obj\n}", "reference": "// expandVMwareDVSConfigSpec reads certain ResourceData keys and\n// returns a VMwareDVSConfigSpec.", "generated": "// This is a list of the VMware DDSs that are currently being used by this application, and their names should be separated from each other in order to avoid confusion with others // for example, if you want to use an existing VMs configuration file (for instance vms/etc ), then add them here"}
{"id": 2765, "code": "func expandVirtualMachineResourceAllocation(d *schema.ResourceData, key string) *types.ResourceAllocationInfo {\n\tshareLevelKey := fmt.Sprintf(\"%s_share_level\", key)\n\tshareCountKey := fmt.Sprintf(\"%s_share_count\", key)\n\tlimitKey := fmt.Sprintf(\"%s_limit\", key)\n\treservationKey := fmt.Sprintf(\"%s_reservation\", key)\n\n\tobj := &types.ResourceAllocationInfo{\n\t\tLimit:       structure.GetInt64PtrEmptyZero(d, limitKey),\n\t\tReservation: structure.GetInt64PtrEmptyZero(d, reservationKey),\n\t}\n\tshares := &types.SharesInfo{\n\t\tLevel:  types.SharesLevel(d.Get(shareLevelKey).(string)),\n\t\tShares: int32(d.Get(shareCountKey).(int)),\n\t}\n\tobj.Shares = shares\n\treturn obj\n}", "reference": "// expandVirtualMachineResourceAllocation reads the VM resource allocation\n// resource data keys for the type supplied by key and returns an appropriate\n// types.ResourceAllocationInfo reference.", "generated": "The virtual machine resource allocation function expands the allocated resources to a list of all available shared objects and returns an object with each share in its corresponding pool (or nil if no pools are found for that particular type or size): The returned value is then used as the initializer parameter when creating new instances of this class using alloc"}
{"id": 2781, "code": "func expandClusterDasVMConfigInfo(\n\td *schema.ResourceData,\n\tmeta interface{},\n\tvm *object.VirtualMachine,\n) (*types.ClusterDasVmConfigInfo, error) {\n\tclient, err := resourceVSphereHAVMOverrideClient(meta)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tversion := viapi.ParseVersionFromClient(client)\n\n\tobj := &types.ClusterDasVmConfigInfo{\n\t\tDasSettings: expandClusterDasVMSettings(d, version),\n\t\tKey:         vm.Reference(),\n\t}\n\n\t// Expand ha_vm_monitoring_use_cluster_defaults here as it's not included in\n\t// the base vsphere_compute_cluster resource.\n\tobj.DasSettings.VmToolsMonitoringSettings.ClusterSettings = structure.GetBool(d, \"ha_vm_monitoring_use_cluster_defaults\")\n\n\treturn obj, nil\n}", "reference": "// expandClusterDasVMConfigInfo reads certain ResourceData keys and returns a\n// ClusterDasVmConfigInfo.", "generated": "This module provides a new datastore for HAVM monitoring and configuration of cluster nodes using VMs (vsphere-based virtual machines). The default VM is used to monitor all clusters that are connected via an external host or network connection with no additional information about their status at any time during deployment/deployment"}
{"id": 2819, "code": "func expandVmwareUplinkPortTeamingPolicy(d *schema.ResourceData) *types.VmwareUplinkPortTeamingPolicy {\n\tobj := &types.VmwareUplinkPortTeamingPolicy{\n\t\tPolicy:          structure.GetStringPolicy(d, \"teaming_policy\"),\n\t\tNotifySwitches:  structure.GetBoolPolicy(d, \"notify_switches\"),\n\t\tRollingOrder:    structure.GetBoolPolicyReverse(d, \"failback\"),\n\t\tFailureCriteria: expandDVSFailureCriteria(d),\n\t\tUplinkPortOrder: expandVMwareUplinkPortOrderPolicy(d),\n\t}\n\n\tif structure.AllFieldsEmpty(obj) {\n\t\treturn nil\n\t}\n\treturn obj\n}", "reference": "// expandVmwareUplinkPortTeamingPolicy reads certain ResourceData keys and\n// returns a VmwareUplinkPortTeamingPolicy.", "generated": "The expanded VMWare UPLINK port forwarding policy allows the user to specify a specific protocol for sending and receiving packets from an external source (e-mail or other communication medium). The default is UDP/IPv6 with no additional parameters specified in this section. This option can be used by any of the following"}
{"id": 2824, "code": "func flattenVMwareUplinkLacpPolicy(d *schema.ResourceData, obj *types.VMwareUplinkLacpPolicy) error {\n\tif obj == nil {\n\t\treturn nil\n\t}\n\n\tstructure.SetBoolPolicy(d, \"lacp_enabled\", obj.Enable)\n\tstructure.SetStringPolicy(d, \"lacp_mode\", obj.Mode)\n\treturn nil\n}", "reference": "// flattenVMwareUplinkLacpPolicy reads various fields from a\n// VMwareUplinkLacpPolicy into the passed in ResourceData.", "generated": "This method is used to create a policy for the VMkernel that will allow userspace access on all of their machines (including those with no LACP enabled). The default value is lxcpolicy . This can be changed by setting it as follows: // Set this option if you want user-space use only or not"}
{"id": 2841, "code": "func (r *CdromSubresource) ValidateDiff() error {\n\tlog.Printf(\"[DEBUG] %s: Beginning CDROM configuration validation\", r)\n\tdsID := r.Get(\"datastore_id\").(string)\n\tpath := r.Get(\"path\").(string)\n\tclientDevice := r.Get(\"client_device\").(bool)\n\tswitch {\n\tcase clientDevice && (dsID != \"\" || path != \"\"):\n\t\treturn fmt.Errorf(\"Cannot have both client_device parameter and ISO file parameters (datastore_id, path) set\")\n\tcase !clientDevice && (dsID == \"\" || path == \"\"):\n\t\treturn fmt.Errorf(\"Either client_device or datastore_id and path must be set\")\n\t}\n\tlog.Printf(\"[DEBUG] %s: Config validation complete\", r)\n\treturn nil\n}", "reference": "// ValidateDiff performs any complex validation of an individual\n// cdrom sub-resource that can't be done in schema alone.", "generated": "The CmdromSubResource class provides a method to validate the MDM of an object by checking if it is in use at runtime with respect for its ID attribute value specified as \"MDMA\". The methods are defined using cdrmgr::validateDMM(). If no valid DMS has been provided then"}
{"id": 2848, "code": "func verifyVAppCdromIso(d *schema.ResourceData, device *types.VirtualCdrom, l object.VirtualDeviceList, c *govmomi.Client) (bool, error) {\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: Checking if CDROM is using a vApp ISO\")\n\t// If the CDROM is using VirtualCdromIsoBackingInfo and matches the ISO\n\t// naming pattern, it has been used as a vApp CDROM, and we can move on to\n\t// checking if the parent VM supports ISO transport.\n\tif backing, ok := device.Backing.(*types.VirtualCdromIsoBackingInfo); ok {\n\t\tdp := &object.DatastorePath{}\n\t\tif ok := dp.FromString(backing.FileName); !ok {\n\t\t\t// If the ISO path can not be read, we can't tell if a vApp ISO is\n\t\t\t// connected.\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: Cannot read ISO path, cannot determine if CDROM is used for vApp\")\n\t\t\treturn false, nil\n\t\t}\n\t\t// The pattern used for vApp ISO naming is\n\t\t// \"<vmname>/_ovfenv-<vmname>.iso\"\n\t\tre := regexp.MustCompile(\".*/_ovfenv-.*.iso\")\n\t\tif !re.MatchString(dp.Path) {\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: ISO is name does not match vApp ISO naming pattern (<vmname>/_ovfenv-<vmname>.iso): %s\", dp.Path)\n\t\t\treturn false, nil\n\t\t}\n\t} else {\n\t\t// vApp CDROMs must be backed by an ISO.\n\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: CDROM is not backed by an ISO\")\n\t\treturn false, nil\n\t}\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: CDROM has a vApp ISO inserted\")\n\t// Set the vApp transport methods\n\ttm := d.Get(\"vapp_transport\").([]interface{})\n\tfor _, t := range tm {\n\t\tif t.(string) == \"iso\" {\n\t\t\tlog.Printf(\"[DEBUG] IsVAppCdrom: vApp ISO transport is supported\")\n\t\t\treturn true, nil\n\t\t}\n\t}\n\tlog.Printf(\"[DEBUG] IsVAppCdrom: vApp ISO transport is not required\")\n\treturn false, nil\n}", "reference": "// verifyVAppCdromIso takes VirtualCdrom and determines if it is needed for\n// vApp ISO transport. It does this by first checking if it has an ISO inserted\n// that matches the vApp ISO naming pattern. If it does, then the next step is\n// to see if vApp ISO transport is supported on the VM. If both of those\n// conditions are met, then the CDROM is considered in use for vApp transport.", "generated": "The VDVM provides support of virtualization protocols that are compatible with Windows XP/7 operating systems including Microsoft Exchange Server 2003 SP1 or later versions; however, there may still exist issues when implementing these protocol implementations in other platforms such Asynchronous File Transfer Protocol's like Hypertext Markup Language 2+2+. This"}
{"id": 2853, "code": "func soapFault(err error) (*soap.Fault, bool) {\n\tif soap.IsSoapFault(err) {\n\t\treturn soap.ToSoapFault(err), true\n\t}\n\treturn nil, false\n}", "reference": "// soapFault extracts the SOAP fault from an error fault, if it exists. Check\n// the returned boolean value to see if you have a SoapFault.", "generated": "// This function is called when a new instance of the Soaps class has been created and it was not initialized with an initializer or initialization method that returns None .\n // The constructor must be invoked before any other methods are used to initialize this object (see below). It should return Nothing if no such call occurred in"}
{"id": 2860, "code": "func isConcurrentAccessError(err error) bool {\n\t// ConcurrentAccess comes from a task more than it usually does from a direct\n\t// SOAP call, so we need to handle both here.\n\tvar f types.AnyType\n\tvar ok bool\n\tf, ok = vimSoapFault(err)\n\tif !ok {\n\t\tf, ok = taskFault(err)\n\t}\n\tif ok {\n\t\tswitch f.(type) {\n\t\tcase types.ConcurrentAccess, *types.ConcurrentAccess:\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "reference": "// isConcurrentAccessError checks an error to see if it's of the\n// ConcurrentAccess type.", "generated": "This function returns the current state of an accessor in this context and provides information about whether or not that particular type was accessed by another caller (see below). It also checks if there are any exceptions thrown when accessing other contexts with different semantics for each exception encountered during execution. The return value should be nil otherwise. This"}
{"id": 2882, "code": "func validateCloneSnapshots(props *mo.VirtualMachine) error {\n\tif props.Snapshot == nil {\n\t\treturn fmt.Errorf(\"virtual machine or template %s must have a snapshot to be used as a linked clone\", props.Config.Uuid)\n\t}\n\t// Root snapshot list can only have a singular element\n\tif len(props.Snapshot.RootSnapshotList) != 1 {\n\t\treturn fmt.Errorf(\"virtual machine or template %s must have exactly one root snapshot (has: %d)\", props.Config.Uuid, len(props.Snapshot.RootSnapshotList))\n\t}\n\t// Check to make sure the root snapshot has no children\n\tif len(props.Snapshot.RootSnapshotList[0].ChildSnapshotList) > 0 {\n\t\treturn fmt.Errorf(\"virtual machine or template %s's root snapshot must not have children\", props.Config.Uuid)\n\t}\n\t// Current snapshot must match root snapshot (this should be the case anyway)\n\tif props.Snapshot.CurrentSnapshot.Value != props.Snapshot.RootSnapshotList[0].Snapshot.Value {\n\t\treturn fmt.Errorf(\"virtual machine or template %s's current snapshot must match root snapshot\", props.Config.Uuid)\n\t}\n\treturn nil\n}", "reference": "// validateCloneSnapshots checks a VM to make sure it has a single snapshot\n// with no children, to make sure there is no ambiguity when selecting a\n// snapshot for linked clones.", "generated": "The virtual machines and templates are created by creating an instance of Virtual Machine with all its child snapshots in it at once using SnapShotManager . The parent VM is then passed into this method for each new snapshot that needs updating from within any other instances on the same host running VMware vCenter Server Appliance , which will"}
{"id": 2893, "code": "func dvsProperties(dvs *object.VmwareDistributedVirtualSwitch) (*mo.VmwareDistributedVirtualSwitch, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\tvar props mo.VmwareDistributedVirtualSwitch\n\tif err := dvs.Properties(ctx, dvs.Reference(), nil, &props); err != nil {\n\t\treturn nil, err\n\t}\n\treturn &props, nil\n}", "reference": "// dvsProperties is a convenience method that wraps fetching the DVS MO from\n// its higher-level object.", "generated": "// DVS Properties provides a way to create and manage virtual switches that are not managed by the VM or its drivers (e., for example, if you have an existing switch in your system). The key is provided as a string with which all of these properties can be set using // `DvProcs`"}
{"id": 2907, "code": "func (r *Subresource) Hash() int {\n\thf := schema.HashResource(&schema.Resource{Schema: r.schema})\n\treturn hf(r.data)\n}", "reference": "// Hash calculates a set hash for the current data. If you want a hash for\n// error reporting a device address, it's probably a good idea to run this at\n// the beginning of a run as any set calls will change the value this\n// ultimately calculates.", "generated": "This method returns the hash of a subresource that contains an array of hashes, and optionally one or more fields for each field in its data structure to be returned by this function. The return value is passed as nil if no other parameters are provided; otherwise, it will contain all values from any given resource type except those"}
{"id": 2919, "code": "func createSCSIController(l *object.VirtualDeviceList, ct string, st string) ([]types.BaseVirtualDeviceConfigSpec, error) {\n\tnc, err := l.CreateSCSIController(ct)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnc.(types.BaseVirtualSCSIController).GetVirtualSCSIController().SharedBus = types.VirtualSCSISharing(st)\n\tcspec, err := object.VirtualDeviceList{nc}.ConfigSpec(types.VirtualDeviceConfigSpecOperationAdd)\n\t*l = applyDeviceChange(*l, cspec)\n\treturn cspec, err\n}", "reference": "// createSCSIController creates a new SCSI controller of the specified type and\n// sharing mode.", "generated": "// Create a virtual device for the specified type and specify its name as an alias to be used in creating SCSSC wrappers that can use this interface with other interfaces or methods of scsscsoccer() .\n // This is done by calling sscsocce::createScsiCopper(), which"}
{"id": 2933, "code": "func resourceVSphereComputeClusterVMDependencyRuleFetchObjects(\n\tmeta interface{},\n\tclusterID string,\n\tkey int32,\n) (*object.ClusterComputeResource, int32, error) {\n\tclient, err := resourceVSphereComputeClusterVMDependencyRuleClient(meta)\n\tif err != nil {\n\t\treturn nil, 0, err\n\t}\n\n\tcluster, err := clustercomputeresource.FromID(client, clusterID)\n\tif err != nil {\n\t\treturn nil, 0, fmt.Errorf(\"cannot locate cluster: %s\", err)\n\t}\n\n\treturn cluster, key, nil\n}", "reference": "// resourceVSphereComputeClusterVMDependencyRuleFetchObjects fetches the \"objects\"\n// for a cluster rule. This is currently just the cluster object as the rule\n// key a static value and a pass-through - this is to keep its workflow\n// consistent with other cluster-dependent resources that derive from\n// ArrayUpdateSpec that have managed object as keys, such as VM and host\n// overrides.", "generated": "The resources provided by the client are used to compute clusters of a given type and their associated dependencies (see Cluster Compute Resource). The clustered vmdire object is an instance of VMDependencies . It can be accessed from any node in the network using its ID as specified above or via RPC callbacks"}
{"id": 2938, "code": "func resourceVSphereDatastoreClusterReadCustomAttributes(d *schema.ResourceData, meta interface{}, pod *object.StoragePod) error {\n\tclient := meta.(*VSphereClient).vimClient\n\t// Read custom attributes\n\tif customattribute.IsSupported(client) {\n\t\tlog.Printf(\"[DEBUG] %s: Reading custom attributes\", resourceVSphereDatastoreClusterIDString(d))\n\t\tprops, err := storagepod.Properties(pod)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcustomattribute.ReadFromResource(client, props.Entity(), d)\n\t} else {\n\t\tlog.Printf(\"[DEBUG] %s: Custom attributes unsupported on this connection, skipping\", resourceVSphereDatastoreClusterIDString(d))\n\t}\n\n\treturn nil\n}", "reference": "// resourceVSphereDatastoreClusterReadCustomAttributes reads the custom\n// attributes for vsphere_datastore_cluster.", "generated": "The VCS Datasource provides a datatype for the data structure of an object that is used to store and retrieve information about its state in memory or disk space (or any other form), as well at runtime by calling vcsdatacenter . The schema can be accessed using either JSON-RPC API"}
{"id": 2958, "code": "func flattenStorageDrsOptionSpec(d *schema.ResourceData, opts []types.BaseOptionValue) error {\n\tm := make(map[string]interface{})\n\tfor _, opt := range opts {\n\t\tm[opt.GetOptionValue().Key] = opt.GetOptionValue().Value\n\t}\n\n\treturn d.Set(\"sdrs_advanced_options\", m)\n}", "reference": "// flattenStorageDrsOptionSpec saves a StorageDrsOptionSpec into the supplied\n// ResourceData.", "generated": "The interface provides a list of options that can be used to specify the storage option for an object in JSON format (see below). The default value is \"default\" . This method returns nil if no such item exists or null otherwise. It also allows you access from any other type with which it may have been defined by"}
{"id": 2965, "code": "func diskApplyOperationDelete(\n\tindex int,\n\toldData map[string]interface{},\n\tnewDataSet []interface{},\n\tc *govmomi.Client,\n\td *schema.ResourceData,\n\tl *object.VirtualDeviceList,\n\tspec *[]types.BaseVirtualDeviceConfigSpec,\n) error {\n\tdidx := -1\n\tfor ni, ne := range newDataSet {\n\t\tnewData := ne.(map[string]interface{})\n\t\tvar name string\n\t\tvar err error\n\t\tif name, err = diskLabelOrName(newData); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif (name == diskDeletedName || name == diskDetachedName) && oldData[\"uuid\"] == newData[\"uuid\"] {\n\t\t\tdidx = ni\n\t\t\tbreak\n\t\t}\n\t}\n\tif didx < 0 {\n\t\t// Deleted entry not found\n\t\treturn nil\n\t}\n\tr := NewDiskSubresource(c, d, oldData, nil, index)\n\tdspec, err := r.Delete(*l)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"%s: %s\", r.Addr(), err)\n\t}\n\t*l = applyDeviceChange(*l, dspec)\n\t*spec = append(*spec, dspec...)\n\treturn nil\n}", "reference": "// diskApplyOperationDelete is an inner-loop helper for disk deletion\n// operations.", "generated": "The Disk Utility provides a simple and efficient way to delete data from the hard drive without having any additional effort on your part. The following example shows how to do this using an existing file system that is already deleted by default in Windows XP or later versions of Microsoft's operating systems. This method does not require you install anything"}
{"id": 2974, "code": "func (r *DiskSubresource) Delete(l object.VirtualDeviceList) ([]types.BaseVirtualDeviceConfigSpec, error) {\n\tlog.Printf(\"[DEBUG] %s: Beginning delete\", r)\n\tdisk, err := r.findVirtualDisk(l, false)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"cannot find disk device: %s\", err)\n\t}\n\tdeleteSpec, err := object.VirtualDeviceList{disk}.ConfigSpec(types.VirtualDeviceConfigSpecOperationRemove)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(deleteSpec) != 1 {\n\t\treturn nil, fmt.Errorf(\"incorrect number of config spec items returned - expected 1, got %d\", len(deleteSpec))\n\t}\n\tif r.Get(\"keep_on_remove\").(bool) || r.Get(\"attach\").(bool) {\n\t\t// Clear file operation so that the disk is kept on remove.\n\t\tdeleteSpec[0].GetVirtualDeviceConfigSpec().FileOperation = \"\"\n\t}\n\tlog.Printf(\"[DEBUG] %s: Device config operations from update: %s\", r, DeviceChangeString(deleteSpec))\n\tlog.Printf(\"[DEBUG] %s: Delete completed\", r)\n\treturn deleteSpec, nil\n}", "reference": "// Delete deletes a vsphere_virtual_machine disk sub-resource.", "generated": "The Disk Subresource class provides a method to create and destroy virtual disks in an attempt at creating new or existing partitions for use with Windows Vista/7 operating systems using Microsoft's Virtual Machine Manager program . The methods are described below as follows:\nMethods Description CreateCreate() Creates all physical drives associated by this drive type"}
{"id": 2979, "code": "func (r *DiskSubresource) String() string {\n\tp := diskPathOrName(r.data)\n\tif p == \"\" {\n\t\tp = \"<unknown>\"\n\t}\n\treturn fmt.Sprintf(\"%s (%s)\", r.Subresource.String(), p)\n}", "reference": "// String prints out the disk sub-resource's information including the ID at\n// time of instantiation, the path of the disk, and the current device\n// key and address.", "generated": "This method returns a new instance of the DiskSubResource class, which implements Subsystem for all subdirectories in the filesystem and provides access to its data structures by default. It is intended as an alternative implementation of FileSystemInfo , but it can be used with other methods that implement this interface or without any additional information"}
{"id": 2993, "code": "func hostNetworkSystemFromHostSystem(hs *object.HostSystem) (*object.HostNetworkSystem, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), defaultAPITimeout)\n\tdefer cancel()\n\treturn hs.ConfigManager().NetworkSystem(ctx)\n}", "reference": "// hostNetworkSystemFromHostSystem locates a HostNetworkSystem from a specified\n// HostSystem.", "generated": "This method returns a network system from the specified HostSystem object that is connected to the server and can be used as an interface for other interfaces in this class (see below). The name of the service should match any given protocol or API key provided by your application's client-side services such AsyncIO , asyncio"}
{"id": 3011, "code": "func (b *EnvironmentBrowser) QueryConfigOptionDescriptor(ctx context.Context) ([]types.VirtualMachineConfigOptionDescriptor, error) {\n\treq := types.QueryConfigOptionDescriptor{\n\t\tThis: b.Reference(),\n\t}\n\tres, err := methods.QueryConfigOptionDescriptor(ctx, b.Client(), &req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn res.Returnval, nil\n}", "reference": "// QueryConfigOptionDescriptor returns a list the list of ConfigOption keys\n// available on the environment that this browser targets. The keys can be used\n// as query options for DefaultDevices and other functions, facilitating the\n// specification of results specific to a certain VM version.", "generated": "// This is a query option descriptor for the virtual machine config options that are available in this browser's configuration file and can be used to specify which VM configurations should not have been created by default when running on Windows Server 2008 R2 or later versions of Microsoft Visual Studio 2010 SP1/SP3 environments. The following fields"}
{"id": 3033, "code": "func lookupAddrs(svc *compute.Service, project, zone, tag string) ([]string, error) {\n\tvar addrs []string\n\tf := func(page *compute.InstanceList) error {\n\t\tfor _, v := range page.Items {\n\t\t\tif len(v.NetworkInterfaces) == 0 || v.NetworkInterfaces[0].NetworkIP == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor _, t := range v.Tags.Items {\n\t\t\t\tif t == tag {\n\t\t\t\t\taddrs = append(addrs, v.NetworkInterfaces[0].NetworkIP)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\tcall := svc.Instances.List(project, zone)\n\tif err := call.Pages(oauth2.NoContext, f); err != nil {\n\t\treturn nil, err\n\t}\n\treturn addrs, nil\n}", "reference": "// lookupAddrs retrieves the private ip addresses of all instances in a given\n// project and zone which have a matching tag value.", "generated": "The following example creates a new instance of the Service class and adds an entry to it with its name as \"service\". The service is created by adding two fields in each field that are unique for this application's namespace :name , which will be used when creating additional instances or returning them from other services . This method returns"}
{"id": 3055, "code": "func virtualMachinesForTag(ctx context.Context, client *vSphereClient, id string) ([]*object.VirtualMachine, error) {\n\tlogger.Printf(\"[DEBUG] Locating all virtual machines under tag ID %q\", id)\n\n\tvar vms []*object.VirtualMachine\n\n\tobjs, err := client.TagsClient.ListAttachedObjects(ctx, id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor i, obj := range objs {\n\t\tswitch {\n\t\tcase obj.Type == nil || obj.ID == nil:\n\t\t\tlogger.Printf(\"[WARN] Discovered object at index %d has either no ID or type\", i)\n\t\t\tcontinue\n\t\tcase *obj.Type != \"VirtualMachine\":\n\t\t\tlogger.Printf(\"[DEBUG] Discovered object ID %q is not a virutal machine\", *obj.ID)\n\t\t\tcontinue\n\t\t}\n\t\tvm, err := virtualMachineFromMOID(ctx, client.VimClient, *obj.ID)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error locating virtual machine with ID %q: %s\", *obj.ID, err)\n\t\t}\n\t\tvms = append(vms, vm)\n\t}\n\n\tlogger.Printf(\"[DEBUG] Discovered virtual machines: %s\", virtualMachineNames(vms))\n\treturn vms, nil\n}", "reference": "// virtualMachinesForTag discovers all of the virtual machines that match a\n// specific tag ID and returns their higher level helper objects.", "generated": "virtual Machines for Tag and Virtual Machine are used to create an interface that can be accessed by the VM's host OS in order of priority from one node on each side of the network stack. The interfaces created using this method will also have their own unique IDs which may change over time as they become available through new nodes within"}
{"id": 3071, "code": "func (ctx *Context) RemoteAddr() string {\n\taddr := ctx.Req.Header.Get(\"X-Real-IP\")\n\tif len(addr) == 0 {\n\t\taddr = ctx.Req.Header.Get(\"X-Forwarded-For\")\n\t\tif addr == \"\" {\n\t\t\taddr = ctx.Req.RemoteAddr\n\t\t\tif i := strings.LastIndex(addr, \":\"); i > -1 {\n\t\t\t\taddr = addr[:i]\n\t\t\t}\n\t\t}\n\t}\n\treturn addr\n}", "reference": "// RemoteAddr returns more real IP address.", "generated": "The remote addrs are sent to the server and forwarded by default on all incoming connections using a single send request from the client or an additional push response for each connection that is not already in use at this time. The return value of the returned address can be used as a way forward if you want to avoid sending any"}
{"id": 3085, "code": "func (ctx *Context) GetCookie(name string) string {\n\tcookie, err := ctx.Req.Cookie(name)\n\tif err != nil {\n\t\treturn \"\"\n\t}\n\tval, _ := url.QueryUnescape(cookie.Value)\n\treturn val\n}", "reference": "// GetCookie returns given cookie value from request header.", "generated": "This method returns a cookie object that contains the name of the given URL and its associated cookies in JSON format. The returned Cookie is an array containing all available Cookies for this session as well with their corresponding values set to None . If no value was provided by any other request or response type then it will be used instead if"}
{"id": 3090, "code": "func (ctx *Context) GetSecureCookie(key string) (string, bool) {\n\treturn ctx.GetSuperSecureCookie(defaultCookieSecret, key)\n}", "reference": "// GetSecureCookie returns given cookie value from request header with default secret string.", "generated": "This method returns a new Secure Cookie object that contains the keys and values of all encrypted cookies in use by this application for authentication purposes. The returned objects are stored as plain text files on disk or locally accessible from any computer running Windows XP/Vista operating system using an RSA public Key Exchange server certificate authority to be used"}
{"id": 3092, "code": "func (ctx *Context) GetSuperSecureCookie(secret, name string) (string, bool) {\n\tval := ctx.GetCookie(name)\n\tif val == \"\" {\n\t\treturn \"\", false\n\t}\n\n\ttext, err := hex.DecodeString(val)\n\tif err != nil {\n\t\treturn \"\", false\n\t}\n\n\tkey := pbkdf2.Key([]byte(secret), []byte(secret), 1000, 16, sha256.New)\n\ttext, err = com.AESGCMDecrypt(key, text)\n\treturn string(text), err == nil\n}", "reference": "// GetSuperSecureCookie returns given cookie value from request header with secret string.", "generated": "// This function is used to decrypt the key and return it as a byte array of bytes in order for us // to use AES-128 encryption on our keys if we have one or more cipher suites available at this time. The main purpose of these functions is not // intended only for security purposes but also because they are"}
{"id": 3127, "code": "func (app *App) ReloadConfig() error {\n\tapp.Lock()\n\tdefer app.Unlock()\n\n\tvar err error\n\tif err = app.configure(); err != nil {\n\t\treturn err\n\t}\n\n\truntime.GOMAXPROCS(app.Config.Common.MaxCPU)\n\n\tapp.Cache.SetMaxSize(app.Config.Cache.MaxSize)\n\tapp.Cache.SetWriteStrategy(app.Config.Cache.WriteStrategy)\n\tapp.Cache.SetTagsEnabled(app.Config.Tags.Enabled)\n\n\tif app.Persister != nil {\n\t\tapp.Persister.Stop()\n\t\tapp.Persister = nil\n\t}\n\n\tif app.Tags != nil {\n\t\tapp.Tags.Stop()\n\t\tapp.Tags = nil\n\t}\n\n\tapp.startPersister()\n\n\tif app.Collector != nil {\n\t\tapp.Collector.Stop()\n\t\tapp.Collector = nil\n\t}\n\n\tapp.Collector = NewCollector(app)\n\n\treturn nil\n}", "reference": "// ReloadConfig reloads some settings from config", "generated": "// Initializes the cache and writes a new config file to disk, which is then used as an initializer for all subsequent calls to App.\n // This method will be called once every 10 minutes or so in order not only to ensure that no errors are generated during runtime but also prevent any unnecessary garbage collection from occurring"}
{"id": 3133, "code": "func (d *Duration) UnmarshalText(text []byte) error {\n\tvar err error\n\td.Duration, err = time.ParseDuration(string(text))\n\treturn err\n}", "reference": "// UnmarshalText from TOML", "generated": "This method is used to determine the length of a string in milliseconds and returns an integer if it has been truncated or not returned by this function. The value must be at least one byte long before returning true . If no longer than two bytes are available for comparison with other strings then return false . This can also cause"}
{"id": 3147, "code": "func (p *Points) Eq(other *Points) bool {\n\tif other == nil {\n\t\treturn false\n\t}\n\tif p.Metric != other.Metric {\n\t\treturn false\n\t}\n\tif p.Data == nil && other.Data == nil {\n\t\treturn true\n\t}\n\tif (p.Data == nil || other.Data == nil) && (p.Data != nil || other.Data != nil) {\n\t\treturn false\n\t}\n\tif len(p.Data) != len(other.Data) {\n\t\treturn false\n\t}\n\tfor i := 0; i < len(p.Data); i++ {\n\t\tif p.Data[i].Value != other.Data[i].Value {\n\t\t\treturn false\n\t\t}\n\t\tif p.Data[i].Timestamp != other.Data[i].Timestamp {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}", "reference": "// Eq points check", "generated": "// This function returns the number of points in a given field, if any are missing or not present on an object's fields. // The return value is returned as either one-to -1 to all objects with at least two values and zero empty strings for each element that has no elements left over from previous attempts."}
{"id": 3152, "code": "func (app *App) Restore(storeFunc func(*points.Points), path string, rps int) {\n\tif rps > 0 {\n\t\tticker := persister.NewThrottleTicker(rps)\n\t\tdefer ticker.Stop()\n\n\t\tthrottledStoreFunc := func(p *points.Points) {\n\t\t\tfor i := 0; i < len(p.Data); i++ {\n\t\t\t\t<-ticker.C\n\t\t\t}\n\t\t\tstoreFunc(p)\n\t\t}\n\n\t\tapp.RestoreFromDir(path, throttledStoreFunc)\n\t} else {\n\t\tapp.RestoreFromDir(path, storeFunc)\n\t}\n}", "reference": "// Restore from dump.path", "generated": "This method restores the state of a stored procedure from its previous execution to an earlier one that is not affected by any changes made in this process or if it was previously executed on another thread with no change at all and has been restored successfully without affecting other threads within your application's stack trace pool for which you have access."}
{"id": 3183, "code": "func (client *Client) CreateComment(handle, message string) (*Comment, error) {\n\tvar out reqComment\n\tcomment := Comment{Message: String(message)}\n\tif len(handle) > 0 {\n\t\tcomment.Handle = String(handle)\n\t}\n\tif err := client.doJsonRequest(\"POST\", \"/v1/comments\", &comment, &out); err != nil {\n\t\treturn nil, err\n\t}\n\treturn out.Comment, nil\n}", "reference": "// CreateComment adds a new comment to the system.", "generated": "// This function creates a new comment for the specified user and sends it to an external server that accepts comments as input in response of request from clients or other applications using JSON format strings provided by JsonResponseWriter .\n // The callback is called when this method returns true if all requests are successful with success status code 200"}
{"id": 3185, "code": "func (client *Client) EditComment(id int, handle, message string) error {\n\tcomment := Comment{Message: String(message)}\n\tif len(handle) > 0 {\n\t\tcomment.Handle = String(handle)\n\t}\n\treturn client.doJsonRequest(\"PUT\", fmt.Sprintf(\"/v1/comments/%d\", id),\n\t\t&comment, nil)\n}", "reference": "// EditComment changes the message and possibly handle of a particular comment.", "generated": "This method returns a new comment object that contains the following information about an existing user's comments and messages in JSON format:\nThe name of the current thread or process to which this action is applied; its status as logged into it by default; whether any other actions are performed on such threads within their scope ; The number"}
{"id": 3254, "code": "func (c *Check) GetTimestampOk() (string, bool) {\n\tif c == nil || c.Timestamp == nil {\n\t\treturn \"\", false\n\t}\n\treturn *c.Timestamp, true\n}", "reference": "// GetTimestampOk returns a tuple with the Timestamp field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Check if the timestamp is correct and return it to check for errors in a future call.\n // This function returns an error object that contains information about what happened when this time was not set up correctly or failed with no exceptions thrown from\n# include \"timestampok_check.h\" # }"}
{"id": 3256, "code": "func (c *Comment) GetRelatedId() int {\n\tif c == nil || c.RelatedId == nil {\n\t\treturn 0\n\t}\n\treturn *c.RelatedId\n}", "reference": "// GetRelatedId returns the RelatedId field if non-nil, zero value otherwise.", "generated": "This function returns the number of related id's that have been found in a given context, and if any are missing from this list, it will return an error message indicating whether or not these IDs were present at all during their search for matching Ids with other contexts within which they may be located. The returned ID is"}
{"id": 3292, "code": "func (d *Downtime) GetRecurrence() Recurrence {\n\tif d == nil || d.Recurrence == nil {\n\t\treturn Recurrence{}\n\t}\n\treturn *d.Recurrence\n}", "reference": "// GetRecurrence returns the Recurrence field if non-nil, zero value otherwise.", "generated": "// Returns a recurrences list of all occurrences in the specified time period, and returns an array containing each occurrence for that interval if it is not already present or absent from the collection. The returned value may be null .\n\n\n// Return None to indicate no current events are occurring at any given moment; otherwise return"}
{"id": 3293, "code": "func (d *Downtime) GetRecurrenceOk() (Recurrence, bool) {\n\tif d == nil || d.Recurrence == nil {\n\t\treturn Recurrence{}, false\n\t}\n\treturn *d.Recurrence, true\n}", "reference": "// GetRecurrenceOk returns a tuple with the Recurrence field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns the number of occurrences in a given period that are not recurred by any other time-based method or function returning an error if no such occurrence occurred during this interval.\n // This is useful for debugging purposes only and should be used with caution when using recursive methods to avoid repeating errors on subsequent intervals."}
{"id": 3310, "code": "func (g *Graph) GetDefinition() GraphDefinition {\n\tif g == nil || g.Definition == nil {\n\t\treturn GraphDefinition{}\n\t}\n\treturn *g.Definition\n}", "reference": "// GetDefinition returns the Definition field if non-nil, zero value otherwise.", "generated": "This function returns a graph definition that contains the following information about its contents: The name of the node, and an optional string containing all nodes in this list as well As described above, it also provides access to any other attributes on the tree or collection by calling GNode::GetName(). If no attribute is provided for"}
{"id": 3320, "code": "func (g *GraphDefinitionMarker) GetValOk() (json.Number, bool) {\n\tif g == nil || g.Val == nil {\n\t\treturn \"\", false\n\t}\n\treturn *g.Val, true\n}", "reference": "// GetValOk returns a tuple with the Val field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// This function returns a GraphDefinitionMarkers object that contains the values of all valid JSON objects in this graph and provides an error if any are not found or returned by this method.\n // The value is passed to this function as its first argument when it's called with no arguments set up for future use. If"}
{"id": 3325, "code": "func (g *GraphDefinitionRequest) GetStacked() bool {\n\tif g == nil || g.Stacked == nil {\n\t\treturn false\n\t}\n\treturn *g.Stacked\n}", "reference": "// GetStacked returns the Stacked field if non-nil, zero value otherwise.", "generated": "// Returns the stack of all available options for a given graph definition request, if any.\n // The default is to return true or false depending on whether it's an error in either case and how many times this requested option has been rejected. If no response was received from GDB before returning,\n\u00c3\u00c2\u00c3\u00c2t returns"}
{"id": 3343, "code": "func (h *HostActionMute) GetEndTime() string {\n\tif h == nil || h.EndTime == nil {\n\t\treturn \"\"\n\t}\n\treturn *h.EndTime\n}", "reference": "// GetEndTime returns the EndTime field if non-nil, zero value otherwise.", "generated": "// This method returns the time in milliseconds, or 0 if no end-time is specified and 1 otherwise.\n // The default value of this function will be returned when a new host action has been performed on an existing one.\n\n\n/*** Returns true for all hosts that have not yet started their service with `"}
{"id": 3366, "code": "func (i *IntegrationGCPCreateRequest) GetClientX509CertURL() string {\n\tif i == nil || i.ClientX509CertURL == nil {\n\t\treturn \"\"\n\t}\n\treturn *i.ClientX509CertURL\n}", "reference": "// GetClientX509CertURL returns the ClientX509CertURL field if non-nil, zero value otherwise.", "generated": "// Initializes the client certificate URL and returns a new Client X-509Certificate object with an initialization of TLSv1, which is used to authenticate against clients in order for them accesses from within this application.\n // This method can be called multiple times by passing it as one parameter or returning None"}
{"id": 3375, "code": "func (i *IntegrationGCPCreateRequest) HasPrivateKeyID() bool {\n\tif i != nil && i.PrivateKeyID != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasPrivateKeyID returns a boolean if a field has been set.", "generated": "// Initializes the private key ID for integration. This is a reference to an implementation-defined public KeyId that can be used by any GC client, including those using it as its own identifier or in conjunction with other implementations of this protocol such and so forth. // The initializer must return either None if no associated"}
{"id": 3394, "code": "func (m *MetricMetadata) HasStatsdInterval() bool {\n\tif m != nil && m.StatsdInterval != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasStatsdInterval returns a boolean if a field has been set.", "generated": "// Returns the number of stats in a metric, or 0 if no stat is specified and 1 otherwise.\n // The default value for this function should be zero to avoid confusion with other functions that return an error message when they fail. This returns either one-to -1 as well; it's not guaranteed by any"}
{"id": 3423, "code": "func (o *Options) GetLockedOk() (bool, bool) {\n\tif o == nil || o.Locked == nil {\n\t\treturn false, false\n\t}\n\treturn *o.Locked, true\n}", "reference": "// GetLockedOk returns a tuple with the Locked field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns the lock state of the current object if it is locked or not.\n // The default value for this method will be set to null when no locks are available in the future and returned as a result from\n#{\n\u00c3\u00c2\u00c3\u00c2 \"lock\" : LockState.LockState(o), #}, {}"}
{"id": 3431, "code": "func (o *Options) GetQueryConfig() QueryConfig {\n\tif o == nil || o.QueryConfig == nil {\n\t\treturn QueryConfig{}\n\t}\n\treturn *o.QueryConfig\n}", "reference": "// GetQueryConfig returns the QueryConfig field if non-nil, zero value otherwise.", "generated": "// This method returns the query config for a given database, and optionally provides an optional default value if it is not provided by any of its methods. The returned values are passed to all queries as parameters in order from most to least restrictive when possible.\n// Note that this function does not return null or undefined . If"}
{"id": 3444, "code": "func (o *Options) GetThresholdWindowsOk() (ThresholdWindows, bool) {\n\tif o == nil || o.ThresholdWindows == nil {\n\t\treturn ThresholdWindows{}, false\n\t}\n\treturn *o.ThresholdWindows, true\n}", "reference": "// GetThresholdWindowsOk returns a tuple with the ThresholdWindows field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// This function returns the threshold Windows value for a given window if it is not specified in an option list or otherwise set to None .\n // The default values are used when setting options and will be returned as soon after they have been selected by `GetWindowOption` , which can take several iterations depending on how many"}
{"id": 3465, "code": "func (r *Recurrence) GetUntilDateOk() (int, bool) {\n\tif r == nil || r.UntilDate == nil {\n\t\treturn 0, false\n\t}\n\treturn *r.UntilDate, true\n}", "reference": "// GetUntilDateOk returns a tuple with the UntilDate field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns the date of the occurrence in a string that is not an integer or non-negative number and returns None if no occurrences occurred within this range.\n // This function takes two arguments to specify which dates are returned by recursively searching for any matching strings with one exception being ignored when returning from Recursion::"}
{"id": 3475, "code": "func (r *reqComment) HasComment() bool {\n\tif r != nil && r.Comment != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasComment returns a boolean if a field has been set.", "generated": ""}
{"id": 3483, "code": "func (r *reqGetTags) GetTagsOk() (TagMap, bool) {\n\tif r == nil || r.Tags == nil {\n\t\treturn TagMap{}, false\n\t}\n\treturn *r.Tags, true\n}", "reference": "// GetTagsOk returns a tuple with the Tags field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// This method returns a tag that is not tagged by the user or any other tags in this context. It does not return an error if it has been used for anything else and no further information about its status will be returned until either of these conditions are met.\n// Note that there may be some exceptions to all"}
{"id": 3485, "code": "func (r *Rule) GetThreshold() json.Number {\n\tif r == nil || r.Threshold == nil {\n\t\treturn \"\"\n\t}\n\treturn *r.Threshold\n}", "reference": "// GetThreshold returns the Threshold field if non-nil, zero value otherwise.", "generated": "// This method returns the number of times a rule has been applied to an object, and if it is not specified in any way by this function or its return value, then that string will be returned as undefined .\n\n // Returns true for all rules with no parameters set; false otherwise.\n// Example:\n//"}
{"id": 3492, "code": "func (s *Screenboard) GetSharedOk() (bool, bool) {\n\tif s == nil || s.Shared == nil {\n\t\treturn false, false\n\t}\n\treturn *s.Shared, true\n}", "reference": "// GetSharedOk returns a tuple with the Shared field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns the shared ok value of a screenboard if it is not already set tonil or has been initialized with an error message and no other errors have occurred since this call.\n // This function returns all values that are currently in use by any user onscreen for which there was one prior to calling getShshared"}
{"id": 3495, "code": "func (s *Series) GetAggrOk() (string, bool) {\n\tif s == nil || s.Aggr == nil {\n\t\treturn \"\", false\n\t}\n\treturn *s.Aggr, true\n}", "reference": "// GetAggrOk returns a tuple with the Aggr field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns the number of elements in a series that are not null or undefined .\n // The first element is an array containing all possible values for this value and its associated type.\n#[inline] using namespace std;\n\n\n// Return one if no other options exist to return from any given Series object with respect"}
{"id": 3518, "code": "func (s *SyntheticsDevice) GetIsMobileOk() (bool, bool) {\n\tif s == nil || s.IsMobile == nil {\n\t\treturn false, false\n\t}\n\treturn *s.IsMobile, true\n}", "reference": "// GetIsMobileOk returns a tuple with the IsMobile field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns the mobile device ID of a SYNTHESIS Device if it is not currently available in an app or has been removed from one by another method call to getIsMobileOk().\n\n // This function returns True for all devices that are already present on this system and can be used as part-of-"}
{"id": 3522, "code": "func (s *SyntheticsDevice) HasUserAgent() bool {\n\tif s != nil && s.UserAgent != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasUserAgent returns a boolean if a field has been set.", "generated": "// This function returns the user agent for this device if it is not already present in a remote system, or otherwise has been created by an attacker with intent to cause havoc on that computer's network and/or other systems within its reach.\n// The default value of False means no action will be taken against any target"}
{"id": 3534, "code": "func (s *SyntheticsOptions) HasMinLocationFailed() bool {\n\tif s != nil && s.MinLocationFailed != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasMinLocationFailed returns a boolean if a field has been set.", "generated": "// Returns the minimum location for a SyntheticOption to be used in an application that does not have any options available, or if it is already specified as such by one of its default settings.\n // This option can only occur when using multiple Options and has no effect on all other Option types except those provided with `"}
{"id": 3541, "code": "func (s *SyntheticsRequest) GetMethod() string {\n\tif s == nil || s.Method == nil {\n\t\treturn \"\"\n\t}\n\treturn *s.Method\n}", "reference": "// GetMethod returns the Method field if non-nil, zero value otherwise.", "generated": "// This method returns a list of methods that are called by the SyntheticRequest interface, and return an array containing all available options for each one in this request's scope. The returned arrays can be used to create new instances or modify existing ones using any other syntaxes provided on-the fly with no additional parameters required"}
{"id": 3548, "code": "func (s *SyntheticsTest) GetConfigOk() (SyntheticsConfig, bool) {\n\tif s == nil || s.Config == nil {\n\t\treturn SyntheticsConfig{}, false\n\t}\n\treturn *s.Config, true\n}", "reference": "// GetConfigOk returns a tuple with the Config field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// This method returns the config value of the specified synthetic interface and sets it to a boolean if not set otherwise.\n // The default is False .\n// If this does not return an error message then no further configuration can be created or modified by calling\n#define LOGIC_CONFIGURATION(config)"}
{"id": 3551, "code": "func (s *SyntheticsTest) GetDeletedAtOk() (string, bool) {\n\tif s == nil || s.DeletedAt == nil {\n\t\treturn \"\", false\n\t}\n\treturn *s.DeletedAt, true\n}", "reference": "// GetDeletedAtOk returns a tuple with the DeletedAt field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// Returns a list of all the deleted items in the tree at the specified time and its size if no item is found or an error occurs while searching for it.\n // This function returns only one value per iteration; this does not return any other values as long as there are enough to be returned from each operation before"}
{"id": 3577, "code": "func (t *ThresholdCount) GetTimeAggregator() string {\n\tif t == nil || t.TimeAggregator == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.TimeAggregator\n}", "reference": "// GetTimeAggregator returns the TimeAggregator field if non-nil, zero value otherwise.", "generated": "// This method returns the time of a threshold for which it is not possible to determine if an entry has been entered in this list or otherwise ignored.\n // The default value is 0, and any entries that are already considered \"un-countable\" will be skipped by this method."}
{"id": 3579, "code": "func (t *ThresholdCount) HasTimeAggregator() bool {\n\tif t != nil && t.TimeAggregator != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasTimeAggregator returns a boolean if a field has been set.", "generated": "// This method is used to determine the time interval between a given threshold and an arbitrary value of zero, or 0 if no thresholds are reached in any order; otherwise it returns False for all values that exceed this range by at least one minute per tick.\n// The default behavior when using TimeAggregate::Duration("}
{"id": 3582, "code": "func (t *ThresholdCount) HasUnknown() bool {\n\tif t != nil && t.Unknown != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasUnknown returns a boolean if a field has been set.", "generated": "// This function returns the number of ticks that have been ticked in a given time interval, and if it is not zero then no further actions are taken on this value until all other values returned by ThreshReturnTicks().\n // The default behavior for non-zero or more than one threshold count has two possible"}
{"id": 3583, "code": "func (t *ThresholdCount) GetWarning() json.Number {\n\tif t == nil || t.Warning == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.Warning\n}", "reference": "// GetWarning returns the Warning field if non-nil, zero value otherwise.", "generated": "// This method returns a list of warnings for the specified threshold. The warning is an array containing all known errors, and contains information about what to do if any are encountered in this case.\n// Note that it does not return true or false when no error has been detected by Throws :\n// Warning = None"}
{"id": 3589, "code": "func (t *ThresholdWindows) GetRecoveryWindow() string {\n\tif t == nil || t.RecoveryWindow == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.RecoveryWindow\n}", "reference": "// GetRecoveryWindow returns the RecoveryWindow field if non-nil, zero value otherwise.", "generated": "// This method returns a list of windows that are currently recovering from the Windows recovery process, and optionally an error message if there is one or more errors in them during this time frame.\n// The returned value should be either None , which means no window was recovered by any other methods for at least two consecutive days,"}
{"id": 3597, "code": "func (t *TileDefRequest) HasQueryType() bool {\n\tif t != nil && t.QueryType != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasQueryType returns a boolean if a field has been set.", "generated": "// This method returns the QueryType of the TileDefRequest object, if it is not a valid query type or an error has occurred in this connection. // The returned value should be null otherwise return false.\n func (T*TileRefResponseContext ) QueryTypes(queryType string , responseInfo []interface{"}
{"id": 3598, "code": "func (t *TileDefRequest) GetTextFilter() string {\n\tif t == nil || t.TextFilter == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.TextFilter\n}", "reference": "// GetTextFilter returns the TextFilter field if non-nil, zero value otherwise.", "generated": "// This method returns a text filter that will return the specified value of T if it is not found in an existing tile list or has been removed from one, and may be used to remove tiles with no previous matching entries for any given Tile object type.\n// Note that this function does not provide accessor methods on"}
{"id": 3604, "code": "func (t *TimeRange) GetLive() bool {\n\tif t == nil || t.Live == nil {\n\t\treturn false\n\t}\n\treturn *t.Live\n}", "reference": "// GetLive returns the Live field if non-nil, zero value otherwise.", "generated": "// Returns the live time range for a given interval, or null if no such value exists in this context.\n // This is useful when using an array of strings to represent intervals that are not currently available on disk and/or unavailable from other sources."}
{"id": 3606, "code": "func (t *TimeRange) HasLive() bool {\n\tif t != nil && t.Live != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasLive returns a boolean if a field has been set.", "generated": "// Returns the live time range for a given date and hour, if it is not already known to be in use by an application or has been updated with new information about that location // from its current status as of this writing.\n// This function returns True when no changes have occurred since last call on T , False"}
{"id": 3613, "code": "func (t *TimeseriesRequestStyle) GetLineType() string {\n\tif t == nil || t.LineType == nil {\n\t\treturn \"\"\n\t}\n\treturn *t.LineType\n}", "reference": "// GetLineType returns the LineType field if non-nil, zero value otherwise.", "generated": "// Returns the line type of a request, or null if it is not provided by this method.\n // This can be used to check for errors in an existing response and return false otherwise.\n\n\n/*** Return true when all lines are returned from requests with no error messages attached. */ func (ts *T"}
{"id": 3626, "code": "func (t *TraceServiceDefinition) GetShowBreakdownOk() (bool, bool) {\n\tif t == nil || t.ShowBreakdown == nil {\n\t\treturn false, false\n\t}\n\treturn *t.ShowBreakdown, true\n}", "reference": "// GetShowBreakdownOk returns a tuple with the ShowBreakdown field if it's non-nil, zero value otherwise\n// and a boolean to check if the value has been set.", "generated": "// This method returns the break down status of a trace service if it is not present in an existing context or has been removed from one by another call to Traceroute::GetBreakdown.\n/**\n* The callback function should return True for success and False otherwise.\n*/ // Called when tracing services are no"}
{"id": 3631, "code": "func (t *TraceServiceDefinition) GetShowErrors() bool {\n\tif t == nil || t.ShowErrors == nil {\n\t\treturn false\n\t}\n\treturn *t.ShowErrors\n}", "reference": "// GetShowErrors returns the ShowErrors field if non-nil, zero value otherwise.", "generated": "// This function returns a list of errors that should be reported to the Tracert service for each error encountered by the user, and optionally an errno if any are found in this collection.\n// The returned value is either None or one of these values; it defaults not being zero as described above. If no"}
{"id": 3702, "code": "func (w *Widget) HasMustShowHits() bool {\n\tif w != nil && w.MustShowHits != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasMustShowHits returns a boolean if a field has been set.", "generated": "// Returns the number of hits that must be displayed in a widget if it is not currently displaying an error message or has been disabled by default.\n // This function returns True for all widgets, False otherwise.\n// The following code snippet shows how to use this method with any non-nil value as its return type"}
{"id": 3703, "code": "func (w *Widget) GetMustShowLatency() bool {\n\tif w == nil || w.MustShowLatency == nil {\n\t\treturn false\n\t}\n\treturn *w.MustShowLatency\n}", "reference": "// GetMustShowLatency returns the MustShowLatency field if non-nil, zero value otherwise.", "generated": "// Returns the latency of a widget if it is not currently displayed in an applet or otherwise unavailable to users, and returns true for all widgets that are available on iOS devices with Latency set by default.\n/**\n* This method should only be called when there's no other way to display this information than via"}
{"id": 3726, "code": "func (w *Widget) HasTileDef() bool {\n\tif w != nil && w.TileDef != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasTileDef returns a boolean if a field has been set.", "generated": "// This method returns the tile def if it is not a TileDef object, otherwise returns None .\n // The default value of this function should be null , or an empty string for non-null tiles in case they are no longer needed by other methods.\n// Note that these functions do not return any information about"}
{"id": 3747, "code": "func (w *WidgetConditionalFormat) HasImageUrl() bool {\n\tif w != nil && w.ImageUrl != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}", "reference": "// HasImageUrl returns a boolean if a field has been set.", "generated": "// This function returns the image url of the widget if it is not a valid URL, otherwise return null.\n // The default value for this method should be None .\n// If no images are found in the list then we will use an ImageLoader to load them from disk and store their contents on disk as well"}
{"id": 3762, "code": "func (t *templateData) addArrayType(x *ast.ArrayType, receiverType, fieldName string) {\n\t// TODO: should we make this dynamic? Could handle more cases than string only\n\tvar eltType string\n\tswitch elt := x.Elt.(type) {\n\tcase *ast.Ident:\n\t\teltType = elt.String()\n\tdefault:\n\t\tlogf(\"addArrayType: type %q, field %q: unknown element type: %T %+v; skipping.\", receiverType, fieldName, elt, elt)\n\t\treturn\n\t}\n\n\tt.Accessors = append(t.Accessors, newAccessor(receiverType, fieldName, \"[]\"+eltType, \"nil\"))\n}", "reference": "// addArrayType adds an accessor for a array type for a given receiver and field", "generated": "This function adds an array of types to the template data structure and returns a list containing all elements in that set as strings or arrays with no fields specified by default. The returned lists are then passed through the callbacks for each method on which they were added using `append` . This is useful when you want to return"}
{"id": 3764, "code": "func (client *Client) UpdateDowntime(downtime *Downtime) error {\n\treturn client.doJsonRequest(\"PUT\", fmt.Sprintf(\"/v1/downtime/%d\", *downtime.Id),\n\t\tdowntime, nil)\n}", "reference": "// UpdateDowntime takes a downtime that was previously retrieved through some method\n// and sends it back to the server.", "generated": "This method updates the time of a request to reflect changes in server status and returns an updated dt-time for that date or datetime if no change has occurred since then; otherwise, it will return null . The default is 0 , which means this function does not update any records at all unless they have been changed"}
{"id": 3768, "code": "func (k *APIKey) UnmarshalJSON(data []byte) error {\n\ttype Alias APIKey\n\taux := &struct {\n\t\tCreated *string `json:\"created,omitempty\"`\n\t\t*Alias\n\t}{\n\t\tAlias: (*Alias)(k),\n\t}\n\tif err := json.Unmarshal(data, &aux); err != nil {\n\t\treturn err\n\t}\n\n\tif created, err := time.Parse(createdTimeLayout, *aux.Created); err != nil {\n\t\treturn err\n\t} else {\n\t\tk.Created = &created\n\t}\n\n\treturn nil\n}", "reference": "// UnmarshalJSON is a custom method for handling datetime unmarshalling", "generated": "The unmapped JSON object is a string that contains the name of the key to be unmasked by calling mswap() . The returned value will contain an array containing all keys and values in this mapping as well with their associated aliases for each field within it's dictionary entry set up correctly before being sent back"}
{"id": 3770, "code": "func (client *Client) GetAPIKey(key string) (*APIKey, error) {\n\tvar out reqAPIKey\n\tif err := client.doJsonRequest(\"GET\", fmt.Sprintf(\"/v1/api_key/%s\", key), nil, &out); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn out.APIKey, nil\n}", "reference": "// GetAPIKey returns a single API key or error on failure", "generated": "// This method returns the API Key of the requested request object if it is not provided by a JsonResponse or an Error . The returned JSON representation will be used to create and retrieve responses from clients using this protocol as described in RFC 6455 , which was implemented for use with Java 8's javaxx-"}
{"id": 3791, "code": "func (t *bufferedObjectStream) WriteObject(obj interface{}) error {\n\tt.mu.Lock()\n\tdefer t.mu.Unlock()\n\tif err := t.codec.WriteObject(t.w, obj); err != nil {\n\t\treturn err\n\t}\n\treturn t.w.Flush()\n}", "reference": "// WriteObject implements ObjectStream.", "generated": "This function is a wrapper around the write-to-write operation of BufferingContext . It provides an implementation for writing to and writing from buffers using buffered objects in order that they can be read by other programs or written into memory without having to worry about buffer overflows when reading them back out again later on."}
{"id": 3794, "code": "func (r *Request) SetMeta(v interface{}) error {\n\tb, err := json.Marshal(v)\n\tif err != nil {\n\t\treturn err\n\t}\n\tr.Meta = (*json.RawMessage)(&b)\n\treturn nil\n}", "reference": "// SetMeta sets r.Meta to the JSON representation of v. If JSON\n// marshaling fails, it returns an error.", "generated": "// This method is used to set the meta of a request and return it if any errors occurred in that response.\n // The returned value will be an array containing all messages from this call which are sent back as JSON data for subsequent calls.\n\n\n/*** Returns `nil` when no message was received by '"}
{"id": 3795, "code": "func (r *Response) SetResult(v interface{}) error {\n\tb, err := json.Marshal(v)\n\tif err != nil {\n\t\treturn err\n\t}\n\tr.Result = (*json.RawMessage)(&b)\n\treturn nil\n}", "reference": "// SetResult sets r.Result to the JSON representation of v. If JSON\n// marshaling fails, it returns an error.", "generated": "// Initializes a JSON response object and returns the result of calling setResult() on it to return an empty string if no value is returned or null otherwise.\n// Returns true for success in case any errors were encountered while processing this request. If false , all exceptions will be ignored by default.\n\n // Returned"}
{"id": 3804, "code": "func PickID(id ID) CallOption {\n\treturn callOptionFunc(func(r *Request) error {\n\t\tr.ID = id\n\t\treturn nil\n\t})\n}", "reference": "// PickID returns a call option which sets the ID on a request. Care must be\n// taken to ensure there are no conflicts with any previously picked ID, nor\n// with the default sequence ID.", "generated": "This method returns an Option object that contains the name of the requested option, and a list containing all options for this user (including any associated fields). The returned value is then passed to the callback function as follows :\n\npackage com .googleapis.android.* ; import java.util;\nimport android._ val"}
{"id": 3863, "code": "func (c *Cursor) Backspace() {\n\ta := c.input\n\ti := c.Position\n\tif i == 0 {\n\t\t// Shrug\n\t\treturn\n\t}\n\tif i == len(a) {\n\t\tc.input = a[:i-1]\n\t} else {\n\t\tc.input = append(a[:i-1], a[i:]...)\n\t}\n\t// now it's pointing to the i+1th element\n\tc.Move(-1)\n}", "reference": "// Backspace removes the rune that precedes the cursor\n//\n// It handles being at the beginning or end of the row, and moves the cursor to\n// the appropriate position.", "generated": "This function is used for moving cursor over an object, and returning its position in space or time using backslash notation as described above. It returns nil if no such move has been made by this method since last call. The return value of func () []string{}, which can be any string that contains either \""}
{"id": 3870, "code": "func (p *Package) Type(name string) (t *Type) {\n\tt, _ = p.Members[name].(*Type)\n\treturn\n}", "reference": "// Type returns the package-level type of the specified name,\n// or nil if not found.\n//", "generated": "type is a type that can be used to represent any package name or class of the form \"package\". It has no special meaning for types other than those defined in packages and classes as well; it does not have an interface with interfaces such like structs nor methods which are implemented by standard library functions but rather only through"}
{"id": 3892, "code": "func (b *builder) switchStmt(fn *Function, s *ast.SwitchStmt, label *lblock) {\n\t// We treat SwitchStmt like a sequential if-else chain.\n\t// Multiway dispatch can be recovered later by ssautil.Switches()\n\t// to those cases that are free of side effects.\n\tif s.Init != nil {\n\t\tb.stmt(fn, s.Init)\n\t}\n\tvar tag Value = vTrue\n\tif s.Tag != nil {\n\t\ttag = b.expr(fn, s.Tag)\n\t}\n\tdone := fn.newBasicBlock(\"switch.done\")\n\tif label != nil {\n\t\tlabel._break = done\n\t}\n\t// We pull the default case (if present) down to the end.\n\t// But each fallthrough label must point to the next\n\t// body block in source order, so we preallocate a\n\t// body block (fallthru) for the next case.\n\t// Unfortunately this makes for a confusing block order.\n\tvar dfltBody *[]ast.Stmt\n\tvar dfltFallthrough *BasicBlock\n\tvar fallthru, dfltBlock *BasicBlock\n\tncases := len(s.Body.List)\n\tfor i, clause := range s.Body.List {\n\t\tbody := fallthru\n\t\tif body == nil {\n\t\t\tbody = fn.newBasicBlock(\"switch.body\") // first case only\n\t\t}\n\n\t\t// Preallocate body block for the next case.\n\t\tfallthru = done\n\t\tif i+1 < ncases {\n\t\t\tfallthru = fn.newBasicBlock(\"switch.body\")\n\t\t}\n\n\t\tcc := clause.(*ast.CaseClause)\n\t\tif cc.List == nil {\n\t\t\t// Default case.\n\t\t\tdfltBody = &cc.Body\n\t\t\tdfltFallthrough = fallthru\n\t\t\tdfltBlock = body\n\t\t\tcontinue\n\t\t}\n\n\t\tvar nextCond *BasicBlock\n\t\tfor _, cond := range cc.List {\n\t\t\tnextCond = fn.newBasicBlock(\"switch.next\")\n\t\t\t// TODO(adonovan): opt: when tag==vTrue, we'd\n\t\t\t// get better code if we use b.cond(cond)\n\t\t\t// instead of BinOp(EQL, tag, b.expr(cond))\n\t\t\t// followed by If.  Don't forget conversions\n\t\t\t// though.\n\t\t\tcond := emitCompare(fn, token.EQL, tag, b.expr(fn, cond), cond.Pos())\n\t\t\temitIf(fn, cond, body, nextCond)\n\t\t\tfn.currentBlock = nextCond\n\t\t}\n\t\tfn.currentBlock = body\n\t\tfn.targets = &targets{\n\t\t\ttail:         fn.targets,\n\t\t\t_break:       done,\n\t\t\t_fallthrough: fallthru,\n\t\t}\n\t\tb.stmtList(fn, cc.Body)\n\t\tfn.targets = fn.targets.tail\n\t\temitJump(fn, done)\n\t\tfn.currentBlock = nextCond\n\t}\n\tif dfltBlock != nil {\n\t\temitJump(fn, dfltBlock)\n\t\tfn.currentBlock = dfltBlock\n\t\tfn.targets = &targets{\n\t\t\ttail:         fn.targets,\n\t\t\t_break:       done,\n\t\t\t_fallthrough: dfltFallthrough,\n\t\t}\n\t\tb.stmtList(fn, *dfltBody)\n\t\tfn.targets = fn.targets.tail\n\t}\n\temitJump(fn, done)\n\tfn.currentBlock = done\n}", "reference": "// switchStmt emits to fn code for the switch statement s, optionally\n// labelled by label.\n//", "generated": "The following example creates an empty list with all its elements and returns it as one element without any additional information about what is contained within them or how they were created/removed from their original state; otherwise, there would be no way to know which items have been removed since then because none of these variables exist at runtime"}
{"id": 3913, "code": "func yaml_emitter_flush(emitter *yaml_emitter_t) bool {\n\tif emitter.write_handler == nil {\n\t\tpanic(\"write handler not set\")\n\t}\n\n\t// Check if the buffer is empty.\n\tif emitter.buffer_pos == 0 {\n\t\treturn true\n\t}\n\n\tif err := emitter.write_handler(emitter, emitter.buffer[:emitter.buffer_pos]); err != nil {\n\t\treturn yaml_emitter_set_writer_error(emitter, \"write error: \"+err.Error())\n\t}\n\temitter.buffer_pos = 0\n\treturn true\n}", "reference": "// Flush the output buffer.", "generated": "The YAML emitters are used to write messages from a file descriptor (elements of which can be read by other processes). The default value is false . This option has no effect on non-blocking operations such as reading or writing buffers and will only affect blocking operation when using an external process that does not support"}
{"id": 3930, "code": "func TCPDialCheck(addr string, timeout time.Duration) Check {\n\treturn func() error {\n\t\tconn, err := net.DialTimeout(\"tcp\", addr, timeout)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn conn.Close()\n\t}\n}", "reference": "// TCPDialCheck returns a Check that checks TCP connectivity to the provided\n// endpoint.", "generated": "TCP checks the connection status of a TCP socket and returns an object that contains information about whether or not it is open for use by any user on its own port (or if there are no users). The returned objects can be used to perform other operations such as checking connections in another process's system state; this method"}
{"id": 3934, "code": "func NewMetricsHandler(registry prometheus.Registerer, namespace string) Handler {\n\treturn &metricsHandler{\n\t\thandler:   NewHandler(),\n\t\tregistry:  registry,\n\t\tnamespace: namespace,\n\t}\n}", "reference": "// NewMetricsHandler returns a healthcheck Handler that also exposes metrics\n// into the provided Prometheus registry.", "generated": "New MetricHandler is a new handler for the metrics daemon that will be used to generate and display statistics on Prometheus's servers (and other services). It provides an interface which allows you access control over how your server handles requests from outside of its own cluster or network stack without having any additional configuration required by default. The"}
{"id": 3938, "code": "func (p *Pinger) AddIP(ipaddr string) error {\n\taddr := net.ParseIP(ipaddr)\n\tif addr == nil {\n\t\treturn fmt.Errorf(\"%s is not a valid textual representation of an IP address\", ipaddr)\n\t}\n\tp.mu.Lock()\n\tp.addrs[addr.String()] = &net.IPAddr{IP: addr}\n\tif isIPv4(addr) {\n\t\tp.hasIPv4 = true\n\t} else if isIPv6(addr) {\n\t\tp.hasIPv6 = true\n\t}\n\tp.mu.Unlock()\n\treturn nil\n}", "reference": "// AddIP adds an IP address to Pinger. ipaddr arg should be a string like\n// \"192.0.2.1\".", "generated": "// This function adds an IPv4-based interface to the Pinger protocol, which can be used for any number or multiple addresses in addition and without requiring additional configuration on each packet received by the client.\n // The implementation uses this method only when it's necessary; otherwise, use ptrace().unwrap(), as"}
{"id": 3943, "code": "func Substitute(s string, sub map[string]string) (buf string) {\n\tbuf = s\n\tvar keys []string\n\tfor k := range sub {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)\n\n\tfor _, key := range keys {\n\t\tbuf = strings.Replace(buf, key, sub[key], -1)\n\t}\n\treturn\n}", "reference": "// Substitute returns string with superseded all substrings from\n// provided substitution map. Substitution map will be applied in alphabetic\n// order. Many passes, on one substitution another one could apply.", "generated": "This function is a wrapper around the `sub` method of Sub . It returns an array containing all characters in each character sequence that are not part or after substring '.' and contains only those sequences with at least one non-zero length for which it can be used to substitute any other charset specified by this substitution"}
{"id": 3945, "code": "func Parse() error {\n\targs := os.Args\n\tif len(args) == 1 {\n\t\treturn nil\n\t}\n\n\t// Global flags.\n\tfset := flag.CommandLine\n\tfset.Usage = Usage\n\tout := fsetOutput(fset)\n\n\tif err := fset.Parse(args[1:]); err != nil {\n\t\treturn err\n\t}\n\n\t// Handle version request.\n\tif f := fset.Lookup(VersionBoolFlag); f != nil {\n\t\tif v, ok := f.Value.(flag.Getter); ok {\n\t\t\t// All values implemented by the flag package implement the flag.Getter interface.\n\t\t\tif b, ok := v.Get().(bool); ok && b {\n\t\t\t\t// The flag was defined as a bool and is set.\n\t\t\t\tprogram := programName(args[0])\n\t\t\t\tfmt.Fprintf(out, \"%s version %s %s/%s\\n\",\n\t\t\t\t\tprogram, buildinfo(),\n\t\t\t\t\truntime.GOOS, runtime.GOARCH)\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n\n\t// No cmdflag.\n\tif fset.NArg() == 0 {\n\t\treturn nil\n\t}\n\n\t// Subcommand.\n\tidx := len(args) - fset.NArg()\n\ts := args[idx]\n\targs = args[idx+1:]\n\tfor _, sub := range subs {\n\t\tif sub.name != s {\n\t\t\tcontinue\n\t\t}\n\n\t\tfs, handler := sub.init(out)\n\t\tif err := fs.Parse(args); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn handler(args[len(args)-fs.NArg():]...)\n\t}\n\n\treturn fmt.Errorf(\"%s is not a valid cmdflag\", s)\n}", "reference": "// Parse parses the command line arguments including the global flags and, if any, the cmdflag and its flags.\n//\n// If the VersionBoolFlag is defined as a global boolean flag, then the program version is displayed and the program stops.", "generated": "The command line argument to this function returns an array of strings representing all commands that are executed in one go (including any non-executable ones). It can be used for debugging purposes only if it contains no arguments or has been specified explicitly with --no-cmdflag . If you want to use multiple options on each"}
{"id": 3946, "code": "func (xxh XXHZero) Sum(b []byte) []byte {\n\th32 := xxh.Sum32()\n\treturn append(b, byte(h32), byte(h32>>8), byte(h32>>16), byte(h32>>24))\n}", "reference": "// Sum appends the current hash to b and returns the resulting slice.\n// It does not change the underlying hash state.", "generated": "This function returns a string containing the number of bytes to be returned by the specified hash algorithm for each element in the array and its corresponding value as an integer or floating point representation. The return values are then converted into integers using xor-hash . This is useful when you want to convert multiple elements from one input sequence"}
{"id": 3949, "code": "func (xxh *XXHZero) Sum32() uint32 {\n\th32 := uint32(xxh.totalLen)\n\tif h32 >= 16 {\n\t\th32 += rol1(xxh.v1) + rol7(xxh.v2) + rol12(xxh.v3) + rol18(xxh.v4)\n\t} else {\n\t\th32 += prime32_5\n\t}\n\n\tp := 0\n\tn := xxh.bufused\n\tbuf := xxh.buf\n\tfor n := n - 4; p <= n; p += 4 {\n\t\th32 += binary.LittleEndian.Uint32(buf[p:p+4]) * prime32_3\n\t\th32 = rol17(h32) * prime32_4\n\t}\n\tfor ; p < n; p++ {\n\t\th32 += uint32(buf[p]) * prime32_5\n\t\th32 = rol11(h32) * prime32_1\n\t}\n\n\th32 ^= h32 >> 15\n\th32 *= prime32_2\n\th32 ^= h32 >> 13\n\th32 *= prime32_3\n\th32 ^= h32 >> 16\n\n\treturn h32\n}", "reference": "// Sum32 returns the 32 bits Hash value.", "generated": "This function returns the number of bytes in the buffer, and then compares it against a string representation to determine if there is any difference between them or not at all. The result can be used as a comparison operator for other functions that return different values depending on whether they are called from within an array with no arguments suchas"}
{"id": 3956, "code": "func (z *Writer) Write(buf []byte) (int, error) {\n\tif !z.Header.done {\n\t\tif err := z.writeHeader(); err != nil {\n\t\t\treturn 0, err\n\t\t}\n\t}\n\tif debugFlag {\n\t\tdebug(\"input buffer len=%d index=%d\", len(buf), z.idx)\n\t}\n\n\tzn := len(z.data)\n\tvar n int\n\tfor len(buf) > 0 {\n\t\tif z.idx == 0 && len(buf) >= zn {\n\t\t\t// Avoid a copy as there is enough data for a block.\n\t\t\tif err := z.compressBlock(buf[:zn]); err != nil {\n\t\t\t\treturn n, err\n\t\t\t}\n\t\t\tn += zn\n\t\t\tbuf = buf[zn:]\n\t\t\tcontinue\n\t\t}\n\t\t// Accumulate the data to be compressed.\n\t\tm := copy(z.data[z.idx:], buf)\n\t\tn += m\n\t\tz.idx += m\n\t\tbuf = buf[m:]\n\t\tif debugFlag {\n\t\t\tdebug(\"%d bytes copied to buf, current index %d\", n, z.idx)\n\t\t}\n\n\t\tif z.idx < len(z.data) {\n\t\t\t// Buffer not filled.\n\t\t\tif debugFlag {\n\t\t\t\tdebug(\"need more data for compression\")\n\t\t\t}\n\t\t\treturn n, nil\n\t\t}\n\n\t\t// Buffer full.\n\t\tif err := z.compressBlock(z.data); err != nil {\n\t\t\treturn n, err\n\t\t}\n\t\tz.idx = 0\n\t}\n\n\treturn n, nil\n}", "reference": "// Write compresses data from the supplied buffer into the underlying io.Writer.\n// Write does not return until the data has been written.", "generated": "This function creates and compresses an array of byte arrays into one or more chunks that are then decompressed using write() . The resulting chunk can contain any number of elements in its original size which will eventually become uncompiled if it has been previously decrypted by another process before being stored on disk with read(). This method"}
{"id": 3959, "code": "func (z *Writer) Close() error {\n\tif !z.Header.done {\n\t\tif err := z.writeHeader(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := z.Flush(); err != nil {\n\t\treturn err\n\t}\n\n\tif debugFlag {\n\t\tdebug(\"writing last empty block\")\n\t}\n\tif err := z.writeUint32(0); err != nil {\n\t\treturn err\n\t}\n\tif !z.NoChecksum {\n\t\tchecksum := z.checksum.Sum32()\n\t\tif debugFlag {\n\t\t\tdebug(\"stream checksum %x\", checksum)\n\t\t}\n\t\tif err := z.writeUint32(checksum); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// Close closes the Writer, flushing any unwritten data to the underlying io.Writer, but does not close the underlying io.Writer.", "generated": "// This function is used to close the file descriptor of a buffer, and return it if no such entry exists in that buffer.\n // The default value for this method should be 0 or 1 depending on whether there are any entries missing from the stream at all. If so then we will use an unmodified version as"}
{"id": 4014, "code": "func (d *FileSelectDialog) detectPath() {\n\tp := d.currPath\n\tif p == \"\" {\n\t\td.currPath, _ = os.Getwd()\n\t\treturn\n\t}\n\n\tp = filepath.Clean(p)\n\tfor {\n\t\t_, err := os.Stat(p)\n\t\tif err == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tdirUp := filepath.Dir(p)\n\t\tif dirUp == p {\n\t\t\tp, _ = os.Getwd()\n\t\t\tbreak\n\t\t}\n\n\t\tp = dirUp\n\t}\n\td.currPath = p\n}", "reference": "// Tries to find the best fit for the given path.\n// It goes up until it gets into the existing directory.\n// If all fails it returns working directory.", "generated": "// Detects the path to a directory that is not in an existing list of directories and does not contain any files or folders within it. If there are no such paths then this function will return false if all other options have been set up correctly.\n func () bool { // Check for missing filenames from previous"}
{"id": 4018, "code": "func (d *dbCache) preload(firstRow, rowCount int) {\n\tif firstRow == d.firstRow && rowCount == d.rowCount {\n\t\t// fast path: view area is the same, return immediately\n\t\treturn\n\t}\n\n\t// slow path: refill cache\n\tfNames := []string{\"Jack\", \"Alisa\", \"Richard\", \"Paul\", \"Nicole\", \"Steven\", \"Jane\"}\n\tlNames := []string{\"Smith\", \"Catcher\", \"Stone\", \"White\", \"Black\"}\n\tposts := []string{\"Engineer\", \"Manager\", \"Janitor\", \"Driver\"}\n\tdeps := []string{\"IT\", \"Financial\", \"Support\"}\n\tsalary := []int{40000, 38000, 41000, 32000}\n\n\td.data = make([][]string, rowCount, rowCount)\n\tfor i := 0; i < rowCount; i++ {\n\t\tabsIndex := firstRow + i\n\t\td.data[i] = make([]string, columnInTable, columnInTable)\n\t\td.data[i][0] = fNames[absIndex%len(fNames)]\n\t\td.data[i][1] = lNames[absIndex%len(lNames)]\n\t\td.data[i][2] = fmt.Sprintf(\"%08d\", 100+absIndex)\n\t\td.data[i][3] = posts[absIndex%len(posts)]\n\t\td.data[i][4] = deps[absIndex%len(deps)]\n\t\td.data[i][5] = fmt.Sprintf(\"%d k/year\", salary[absIndex%len(salary)]/1000)\n\t}\n\n\t// do not forget to save the last values\n\td.firstRow = firstRow\n\td.rowCount = rowCount\n}", "reference": "// cache data from a new row span\n// It imitates a random data by selecting values from predefined arrays. Sizes\n// of all arrays should be different to make TableView data look more random", "generated": "This function takes a list of rows and returns an array containing all those records that are in this table's data structure at once. The returned arrays can be used as keys or strings for storing additional information about each record on the database stack such by using these functions from within your application code like so :"}
{"id": 4037, "code": "func PopClip() {\n\tif len(canvas.clipStack) == 0 {\n\t\treturn\n\t}\n\tc := canvas.clipStack[len(canvas.clipStack)-1]\n\tcanvas.clipStack = canvas.clipStack[:len(canvas.clipStack)-1]\n\tSetClipRect(c.x, c.y, c.w, c.h)\n}", "reference": "// PopClip restores saved with PushClip clipping window", "generated": "// Create a clip stack for the current frame of an image buffer and return it to its parent container if necessary.\n // This method is called when drawing from one or more frames in memory (i., `draw`). It returns nil otherwise unless there are no other buffers available at the time this call was made by"}
{"id": 4038, "code": "func InClipRect(x, y int) bool {\n\treturn x >= canvas.clipX && y >= canvas.clipY &&\n\t\tx < canvas.clipX+canvas.clipW &&\n\t\ty < canvas.clipY+canvas.clipH\n}", "reference": "// InClipRect returns true if x and y position is inside current clipping\n// rectangle", "generated": "// Creates a new rectangle with the same width and height as its parent (inclusive). The resulting rectangles are drawn to the specified dimensions by default in order of appearance. // This is useful for drawing rectangular shapes that have no borders or edges; it can be used when creating an edge-only shape if desired"}
{"id": 4049, "code": "func FillRect(x, y, w, h int, r rune) {\n\tx, y, w, h = clip(x, y, w, h)\n\tif w < 1 || y < -1 {\n\t\treturn\n\t}\n\n\tfor yy := y; yy < y+h; yy++ {\n\t\tfor xx := x; xx < x+w; xx++ {\n\t\t\tputCharUnsafe(xx, yy, r)\n\t\t}\n\t}\n}", "reference": "// FillRect paints the area with r character using the current colors", "generated": "The function fills the rectangle with a random number between 0 and 255. The resulting value is then converted to an integer by calling fillrect() . This method returns true if there are no more values in the rectangle at any given time (i.,e.: zero or one). If none of these conditions have been met"}
{"id": 4058, "code": "func (l *ListBox) SelectedItemText() string {\n\tif l.currSelection == -1 {\n\t\treturn \"\"\n\t}\n\n\treturn l.items[l.currSelection]\n}", "reference": "// SelectedItemText returns text of currently selected item or empty sting if nothing is\n// selected or ListBox is empty.", "generated": "// Selects a selected item from the list of items in the Listbox, and returns it to the user for further processing.\n // This method is called once every 10 seconds on an unselected or unexported object with no selection history at all. It does not return nil . func () []string{ if l"}
{"id": 4070, "code": "func ColorToString(attr term.Attribute) string {\n\tvar out string\n\n\trawClr := attr & 15\n\tif rawClr < 8 {\n\t\tfor k, v := range colorMap {\n\t\t\tif v == rawClr {\n\t\t\t\tout += k + \" \"\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tif attr&term.AttrBold != 0 {\n\t\tout += \"bold \"\n\t}\n\tif attr&term.AttrUnderline != 0 {\n\t\tout += \"underline \"\n\t}\n\tif attr&term.AttrReverse != 0 {\n\t\tout += \"reverse \"\n\t}\n\n\treturn strings.TrimSpace(out)\n}", "reference": "// ColorToString returns string representation of the attribute", "generated": "The following example uses the default attribute to convert a String into an Array of CharSequences and returns it as follows :"}
{"id": 4074, "code": "func DeactivateControls(parent Control) {\n\tfor _, ctrl := range parent.Children() {\n\t\tif ctrl.Active() {\n\t\t\tctrl.SetActive(false)\n\t\t\tctrl.ProcessEvent(Event{Type: EventActivate, X: 0})\n\t\t}\n\n\t\tDeactivateControls(ctrl)\n\t}\n}", "reference": "// DeactivateControls makes all children of parent inactive", "generated": "// This function is used to deactivate control handlers from the child controllers and return them back into their original state when they are no longer needed by a new controller or an existing one (e., if there is any). // The default behavior of this method will be undefined in some cases; see below for details on how"}
{"id": 4089, "code": "func (c *CheckBox) SetAllow3State(enable bool) {\n\tif !enable && c.state == 2 {\n\t\tc.state = 0\n\t}\n\tc.allow3state = enable\n}", "reference": "// SetAllow3State sets if ComboBox should use 3 states. If the current\n// state is unknown and one disables Allow3State option then the current\n// value resets to off", "generated": "// Checkbox is set to true if the state of the box should be enabled or false otherwise.\n // This checks whether a checkbox exists in the current system and returns an error message when it does not, as well for any errors that may occur during this process.\n\n\n/*** Checksboxes are created by"}
{"id": 4109, "code": "func (b *ProgressBar) SecondaryColors() (term.Attribute, term.Attribute) {\n\treturn b.emptyFg, b.emptyBg\n}", "reference": "// SecondaryColors returns text and background colors for empty\n// part of the ProgressBar", "generated": "// Initializes the secondary color scheme for a given user interface element and returns it as an array of primary colors in progressbar-mode with no additional information about its attributes or properties; this is done by calling `secondaryColor` on each new instance of Progress Bar .\n// The initializer will be called once every"}
{"id": 4219, "code": "func NewMemoryKeyCacher(maxKeyAge time.Duration, maxCacheSize int) KeyCacher {\n\treturn &memoryKeyCacher{\n\t\tentries:      map[string]keyCacherEntry{},\n\t\tmaxKeyAge:    maxKeyAge,\n\t\tmaxCacheSize: maxCacheSize,\n\t}\n}", "reference": "// NewMemoryKeyCacher creates a new Keycacher interface with option\n// to set max age of cached keys and max size of the cache.", "generated": "New Memory key cache is a new memory caching system that allows for the creation of cached keys and values in an arbitrary number (in this case 512). The default value is 0xFFFFFFF . This method can be used to create or delete stored data from any storage device using either NFS-based access control mechanisms"}
{"id": 4226, "code": "func validColor(c string) bool {\n\tvalid := false\n\tif validColors[c] {\n\t\tvalid = true\n\t}\n\treturn valid\n}", "reference": "// validColor will make sure the given color is actually allowed", "generated": "// This function is used to validate the color of a given c. It returns an error if it does not match any other values in the array, or nil otherwise.\n // The default value for this method will be \"nil\".\n// If there are no matching colors within that range, then return null and attempt"}
{"id": 4230, "code": "func (s *Spinner) Reverse() {\n\ts.lock.Lock()\n\tdefer s.lock.Unlock()\n\tfor i, j := 0, len(s.chars)-1; i < j; i, j = i+1, j-1 {\n\t\ts.chars[i], s.chars[j] = s.chars[j], s.chars[i]\n\t}\n}", "reference": "// Reverse will reverse the order of the slice assigned to the indicator", "generated": "// This function is used to reverse the lock of a string in order for it not being locked by another thread or other process on disk // and returning an error if no such locking was found when attempting this method with `reverse` looping through all strings that are currently held as keys from one end of the chain until"}
{"id": 4237, "code": "func NewMultiplex(con net.Conn, initiator bool) *Multiplex {\n\tmp := &Multiplex{\n\t\tcon:       con,\n\t\tinitiator: initiator,\n\t\tbuf:       bufio.NewReader(con),\n\t\tchannels:  make(map[streamID]*Stream),\n\t\tclosed:    make(chan struct{}),\n\t\tshutdown:  make(chan struct{}),\n\t\twrTkn:     make(chan struct{}, 1),\n\t\tnstreams:  make(chan *Stream, 16),\n\t}\n\n\tgo mp.handleIncoming()\n\n\tmp.wrTkn <- struct{}{}\n\n\treturn mp\n}", "reference": "// NewMultiplex creates a new multiplexer session.", "generated": "The new stream is a single-byte buffer containing the name of an existing Stream object and its channel ID (if any). The channels are specified in bytes as follows:\n//Channel Name Channel Id Description string[] int [] byte streams; //channel id number for each socket to be used by this method var channels"}
{"id": 4242, "code": "func (b Box) Round() (lat, lng float64) {\n\tx := maxDecimalPower(b.MaxLat - b.MinLat)\n\tlat = math.Ceil(b.MinLat/x) * x\n\tx = maxDecimalPower(b.MaxLng - b.MinLng)\n\tlng = math.Ceil(b.MinLng/x) * x\n\treturn\n}", "reference": "// Round returns a point inside the box, making an effort to round to minimal\n// precision.", "generated": "Round is a method that returns the number of degrees to be rounded in an integer range from 0-255 inclusive for each degree and zero or more digits within this value if there are no other values available at all times during rounding time. It also provides methods such as round_to_floor , which can return either 1"}
{"id": 4327, "code": "func (c *Client) DeleteCheckoutKey(account, repo, fingerprint string) error {\n\treturn c.request(\"DELETE\", fmt.Sprintf(\"project/%s/%s/checkout-key/%s\", account, repo, fingerprint), nil, nil, nil)\n}", "reference": "// DeleteCheckoutKey fetches the checkout key for the given project by fingerprint", "generated": "delete checks out key and returns a new checkouts list with the following properties :\nCursorPos := CursorPos + 1 if cursorpos > 0;\nCursorPath := Account.GetDir()\nif cursorpath == \"test\" && cursor path == \"/dev/\" || cursorsource"}
{"id": 4332, "code": "func (c *Client) Timing(bucket string, value interface{}) {\n\tif c.skip() {\n\t\treturn\n\t}\n\tc.conn.metric(c.prefix, bucket, value, \"ms\", c.rate, c.tags)\n}", "reference": "// Timing sends a timing value to a bucket.", "generated": "// This method is used to determine the time interval between a given tick and an event that occurs in milliseconds or seconds after it has occurred. The default for this example would be 0 ms .\n// If you want to use multiple ticks instead of one , add them as follows : // if elapsed > 1 m = new"}
{"id": 4333, "code": "func (t Timing) Send(bucket string) {\n\tt.c.Timing(bucket, int(t.Duration()/time.Millisecond))\n}", "reference": "// Send sends the time elapsed since the creation of the Timing.", "generated": "This method sends a message to the bucket and returns an object with time elapsed since receiving it from its destination address or if no such request was made by that host in question for any reason other than sending one of those messages on behalf only of itself as described above. The returned objects are then passed along to another thread which"}
{"id": 4348, "code": "func SpatialEntropy(match match.Match, turns int, shiftCount int) float64 {\n\tvar s, d float64\n\tif match.DictionaryName == \"qwerty\" || match.DictionaryName == \"dvorak\" {\n\t\t//todo: verify qwerty and dvorak have the same length and degree\n\t\ts = float64(len(adjacency.BuildQwerty().Graph))\n\t\td = adjacency.BuildQwerty().CalculateAvgDegree()\n\t} else {\n\t\ts = float64(keyPadStartingPositions)\n\t\td = keyPadAvgDegree\n\t}\n\n\tpossibilities := float64(0)\n\n\tlength := float64(len(match.Token))\n\n\t//TODO: Should this be <= or just < ?\n\t//Estimate the number of possible patterns w/ length L or less with t turns or less\n\tfor i := float64(2); i <= length+1; i++ {\n\t\tpossibleTurns := math.Min(float64(turns), i-1)\n\t\tfor j := float64(1); j <= possibleTurns+1; j++ {\n\t\t\tx := zxcvbnmath.NChoseK(i-1, j-1) * s * math.Pow(d, j)\n\t\t\tpossibilities += x\n\t\t}\n\t}\n\n\tentropy := math.Log2(possibilities)\n\t//add extra entropu for shifted keys. ( % instead of 5 A instead of a)\n\t//Math is similar to extra entropy for uppercase letters in dictionary matches.\n\n\tif S := float64(shiftCount); S > float64(0) {\n\t\tpossibilities = float64(0)\n\t\tU := length - S\n\n\t\tfor i := float64(0); i < math.Min(S, U)+1; i++ {\n\t\t\tpossibilities += zxcvbnmath.NChoseK(S+U, i)\n\t\t}\n\n\t\tentropy += math.Log2(possibilities)\n\t}\n\n\treturn entropy\n}", "reference": "// SpatialEntropy calculates the entropy for spatial matches", "generated": "The following example shows how to compute an average random seed from two different strings using one string as input by splitting it into multiple lines that are equal on each line before dividing them together again at runtime without any additional computation required when running through all three iterations until they reach zero size bytes after which time we can use our own"}
{"id": 4354, "code": "func Null(in []byte, pos int) (int, error) {\n\tswitch in[pos] {\n\tcase 'n':\n\t\treturn expect(in, pos, n...)\n\t\treturn pos + 4, nil\n\tdefault:\n\t\treturn 0, errUnexpectedValue\n\t}\n}", "reference": "// Null verifies the contents of bytes provided is a null starting as pos", "generated": "Null is a type that can be used to create null values. It has the following properties:\n\nA value of size N may not contain any non-null characters or numbers; it must have at least one character and no digits within its range from zero through 255 inclusive for this purpose. The default behavior when creating an"}
{"id": 4404, "code": "func (b *Base64) SetBSON(raw bson.Raw) error {\n\tvar m bson.M\n\tif err := raw.Unmarshal(&m); err != nil {\n\t\treturn err\n\t}\n\n\tif data, ok := m[\"data\"].(string); ok {\n\t\t*b = Base64(data)\n\t\treturn nil\n\t}\n\n\treturn errors.New(\"couldn't unmarshal bson raw value as Base64\")\n}", "reference": "// SetBSON sets the Base64 from raw bson data", "generated": "This method is used to set the base64 encoding of a string and return it if any other bytes are encoded in that format or otherwise not specified by this function. It returns an object with all possible values for each byte represented within its range from 0-255 inclusive using either \"0\", \"255\". The default setting"}
{"id": 4413, "code": "func (e *Email) UnmarshalEasyJSON(in *jlexer.Lexer) {\n\tif data := in.String(); in.Ok() {\n\t\t*e = Email(data)\n\t}\n}", "reference": "// UnmarshalEasyJSON sets the Email from a easyjson.Lexer", "generated": "This method is a wrapper around the JSON API, which provides an easy way to create and retrieve email addresses from any URL that you specify as part of your application's request body. It also allows for customizing how it handles requests with respect not only their content but its headers too. The following example shows what this can"}
{"id": 4422, "code": "func (u *IPv6) DeepCopy() *IPv6 {\n\tif u == nil {\n\t\treturn nil\n\t}\n\tout := new(IPv6)\n\tu.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new IPv6.", "generated": "// This function is a wrapper around the IPv4 deepcopy method, which returns an int64 encoded string that can be used to encode any number of bytes in memory at once for use with other functions and methods on UDP or TCP connections // as well; it also provides some additional functionality when using this interface against non"}
{"id": 4452, "code": "func (h *HexColor) DeepCopy() *HexColor {\n\tif h == nil {\n\t\treturn nil\n\t}\n\tout := new(HexColor)\n\th.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new HexColor.", "generated": "// This function is a wrapper around the HEX color scheme, which can be used to create an array of hexadecimal colors for use in other programs or as input into any program that uses it // by calling this method on its own instance of HexColor().\n// The implementation will return true if there are"}
{"id": 4466, "code": "func (t DateTime) MarshalJSON() ([]byte, error) {\n\tvar w jwriter.Writer\n\tt.MarshalEasyJSON(&w)\n\treturn w.BuildBytes()\n}", "reference": "// MarshalJSON returns the DateTime as JSON", "generated": "// This method returns a string representation of the JSON object returned by this function and is used to build bytes for serialization purposes. // The format parameter specifies how long it will take before we can use `json` as an encoding in our strings; if you want us not just return nil , then specify that value with"}
{"id": 4474, "code": "func (d *Duration) Scan(raw interface{}) error {\n\tswitch v := raw.(type) {\n\t// TODO: case []byte: // ?\n\tcase int64:\n\t\t*d = Duration(v)\n\tcase float64:\n\t\t*d = Duration(int64(v))\n\tcase nil:\n\t\t*d = Duration(0)\n\tdefault:\n\t\treturn fmt.Errorf(\"cannot sql.Scan() strfmt.Duration from: %#v\", v)\n\t}\n\n\treturn nil\n}", "reference": "// Scan reads a Duration value from database driver type.", "generated": "This method scans the string to determine if a given type is valid for an operation, and returns true or false depending on whether it has been performed successfully by that operator in any of its operands. The returned value can be either null , which means no operations were executed with this information available at all, or one of"}
{"id": 4491, "code": "func (d *Date) DeepCopy() *Date {\n\tif d == nil {\n\t\treturn nil\n\t}\n\tout := new(Date)\n\td.DeepCopyInto(out)\n\treturn out\n}", "reference": "// DeepCopy copies the receiver into a new Date.", "generated": "// This function is a wrapper around the DBCL, which provides an interface to create and delete objects from memory using deepcopy(). It also returns true if it has been created or deleted by another process in time for that operation. // The return value of this method should be either false , otherwise returned as null ."}
{"id": 4522, "code": "func GrepNot(r string) Filter {\n\tre, err := regexp.Compile(r)\n\tif err != nil {\n\t\treturn FilterFunc(func(Arg) error { return err })\n\t}\n\treturn If(func(s string) bool { return !re.MatchString(s) })\n}", "reference": "// GrepNot emits every input x that does not match the regular expression r.", "generated": "GprFilter is a filter that returns the results of an unary search for strings in r . It can be used to perform any sort or reverse lookup on all occurrences within it (including those from which no matching match was found). The default value is None , but you may specify more options by passing them as arguments"}
{"id": 4537, "code": "func FetchVersion(v discovery.ServerVersionInterface) (ret ServerVersion, err error) {\n\tversion, err := v.ServerVersion()\n\tif err != nil {\n\t\treturn ServerVersion{}, err\n\t}\n\treturn ParseVersion(version)\n}", "reference": "// FetchVersion fetches version information from discovery client, and parses", "generated": "Fuzzy version checking is performed on the server to ensure that it has been updated correctly and not corrupted by a malicious program or application running in its background with no known issues at all! This feature was introduced as part of Windows XP SP1 for compatibility reasons only when using an older operating system such ASLR-based"}
{"id": 4543, "code": "func (n ImageName) RegistryRepoName() string {\n\trepo := n.Repository\n\tif repo == \"\" {\n\t\trepo = \"library\"\n\t}\n\treturn fmt.Sprintf(\"%s/%s\", repo, n.Name)\n}", "reference": "// RegistryRepoName returns the \"repository\" as used in the registry URL", "generated": "This function returns a registry repos that contains the name of the repository to which it is stored and its associated metadata for use in subsequent queries or as an alias on other repositories using NTLM's default API methods such AsyncReleases . The returned value should be used with caution when querying multiple sources within one"}
{"id": 4556, "code": "func MarkdownHelper(body string, help HelperContext) (template.HTML, error) {\n\tvar err error\n\tif help.HasBlock() {\n\t\tbody, err = help.Block()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t}\n\tb := github_flavored_markdown.Markdown([]byte(body))\n\treturn template.HTML(b), err\n}", "reference": "// Markdown converts the string into HTML using GitHub flavored markdown.", "generated": "// This helper is a wrapper around the HTML helpers provided by markdown and provides an interface to generate markup for your code in plain text form. // The main purpose of this function is not to provide any additional functionality but rather simply allow you access directly from within source files or other sources that are available via `html`"}
{"id": 4565, "code": "func (t *Template) Exec(ctx hctx.Context) (string, error) {\n\terr := t.Parse()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tev := compiler{\n\t\tctx:     ctx,\n\t\tprogram: t.program,\n\t}\n\n\ts, err := ev.compile()\n\treturn s, err\n}", "reference": "// Exec the template using the content and return the results", "generated": "// Compiles a template to an executable string and returns the result of executing it in its current scope.\n // The runtime will return this if no such file exists or is not found by calling `cwd` with any arguments that are non-nil; otherwise, returning nil for all errors encountered during compilation. This"}
{"id": 4576, "code": "func hasPathPrefix(p string, s map[string]string) bool {\n\tfor prefix := range s {\n\t\tif strings.HasPrefix(p, prefix+\"/\") {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}", "reference": "// hasPathPrefix returns true if any of s is the prefix of p.", "generated": "// Returns the path to a file that contains all of its contents in one go (or nil if no files exist). If there are any missing or unneeded directories it returns an error message and is ignored by default.\n func getPath() []byte { return os.path.UnsafeFilePath(prefix +"}
{"id": 4588, "code": "func (a *Args) similar(r *Args, similar Similarity) bool {\n\tif a.Elided != r.Elided || len(a.Values) != len(r.Values) {\n\t\treturn false\n\t}\n\tif similar == AnyValue {\n\t\treturn true\n\t}\n\tfor i, l := range a.Values {\n\t\tswitch similar {\n\t\tcase ExactFlags, ExactLines:\n\t\t\tif l != r.Values[i] {\n\t\t\t\treturn false\n\t\t\t}\n\t\tdefault:\n\t\t\tif l.IsPtr() != r.Values[i].IsPtr() || (!l.IsPtr() && l != r.Values[i]) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\treturn true\n}", "reference": "// similar returns true if the two Args are equal or almost but not quite\n// equal.", "generated": ""}
{"id": 4597, "code": "func (s *Stack) merge(r *Stack) *Stack {\n\t// Assumes similar stacks have the same length.\n\tout := &Stack{\n\t\tCalls:  make([]Call, len(s.Calls)),\n\t\tElided: s.Elided,\n\t}\n\tfor i := range s.Calls {\n\t\tout.Calls[i] = s.Calls[i].merge(&r.Calls[i])\n\t}\n\treturn out\n}", "reference": "// merge merges two similar Stack, zapping out differences.", "generated": "This function merges a stack of two or more calls to an interface and returns one value for each call in that implementation's chain. The returned values are merged into their corresponding interfaces by calling this method on them as if they were identical objects with no differences between implementations' chains. This is useful when you want to use"}
{"id": 4624, "code": "func (b *base57) stringToNum(s string) (string, error) {\n\tn := big.NewInt(0)\n\n\tfor i := len(s) - 1; i >= 0; i-- {\n\t\tn.Mul(n, big.NewInt(b.alphabet.Length()))\n\n\t\tindex, err := b.alphabet.Index(string(s[i]))\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\n\t\tn.Add(n, big.NewInt(index))\n\t}\n\n\tx := fmt.Sprintf(\"%x\", n)\n\n\tif len(x) < 32 {\n\t\t// Pad the most significant bit (MSG) with 0 (zero) if the string is too short.\n\t\tx = strings.Repeat(\"0\", 32-len(x)) + x\n\t} else if len(x) > 32 {\n\t\treturn \"\", fmt.Errorf(\"UUID length overflow for %q\", s)\n\t}\n\n\treturn fmt.Sprintf(\"%s-%s-%s-%s-%s\", x[0:8], x[8:12], x[12:16], x[16:20], x[20:32]), nil\n}", "reference": "// stringToNum converts a string a number using the given alpabet.", "generated": "This function returns a new int representing the number of characters in the current buffer and an integer representation of its size that represents the total amount of bytes to be written by this character at once when writing it back into memory or after being read from disk using NTFE mode on Windows NT systems running Linux/Unix operating system"}
{"id": 4644, "code": "func (geoIndex *geoIndex) AddEntryAt(point Point) interface{} {\n\tsquare := cellOf(point, geoIndex.resolution)\n\n\tif _, ok := geoIndex.index[square]; !ok {\n\t\tgeoIndex.index[square] = geoIndex.newEntry()\n\t}\n\n\treturn geoIndex.index[square]\n}", "reference": "// AddEntryAt adds an entry if missing, returns the entry at specific position.", "generated": "Add entry at point to the map of geocodes and add a new node for each location in the list that contains it as an argument. The nodes are added by adding one or more entries into the array with their corresponding coordinates from within this mapping object's field data structure . This is done using GeoJSON::Map"}
{"id": 4662, "code": "func BearingTo(p1, p2 Point) float64 {\n\tdLon := toRadians(p2.Lon() - p1.Lon())\n\n\tlat1 := toRadians(p1.Lat())\n\tlat2 := toRadians(p2.Lat())\n\n\ty := math.Sin(dLon) * math.Cos(lat2)\n\tx := math.Cos(lat1)*math.Sin(lat2) -\n\t\tmath.Sin(lat1)*math.Cos(lat2)*math.Cos(dLon)\n\tbrng := toDegrees(math.Atan2(y, x))\n\n\treturn brng\n}", "reference": "// BearingTo returns the bearing from p1 to p2", "generated": "The bearing method is a simple and efficient way of calculating the angle between two points in an array using radian coordinates (or any other coordinate system). The following example shows how to use it for generating angles from one point on top-to bottom with radius 1/3 as its base value . It also demonstrates that this"}
{"id": 4720, "code": "func AddRelayTransport(ctx context.Context, h host.Host, upgrader *tptu.Upgrader, opts ...RelayOpt) error {\n\tn, ok := h.Network().(tpt.Network)\n\tif !ok {\n\t\treturn fmt.Errorf(\"%v is not a transport network\", h.Network())\n\t}\n\n\tr, err := NewRelay(ctx, h, upgrader, opts...)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// There's no nice way to handle these errors as we have no way to tear\n\t// down the relay.\n\t// TODO\n\tif err := n.AddTransport(r.Transport()); err != nil {\n\t\tlog.Error(\"failed to add relay transport:\", err)\n\t} else if err := n.Listen(r.Listener().Multiaddr()); err != nil {\n\t\tlog.Error(\"failed to listen on relay transport:\", err)\n\t}\n\treturn nil\n}", "reference": "// AddRelayTransport constructs a relay and adds it as a transport to the host network.", "generated": "The new Relays interface provides an easy-touse and fast method for handling UDP traffic between two or more hosts in one of three ways: by sending packets from either TCP/IP (or any other protocol), through HTTP using relaying protocols such AsyncRouting , OR via RPC . The following example shows how"}
{"id": 4731, "code": "func NewServer() http.Handler {\n\tr := mux.NewRouter()\n\tr.Path(\"/hello\").Methods(\"GET\").HandlerFunc(handleHello)\n\treturn r\n}", "reference": "// NewServer makes a new example server.", "generated": "This method returns a new server instance that implements the protocol described in RFC 6455, and provides access to all of its methods (including those defined by this interface). The client is responsible for creating an HTTP request with each connection made through it using RPC or GET . This implementation does not provide any additional functionality as such;"}
{"id": 4742, "code": "func StringFindBetween(s, start, stop string) (between, remainder string, found bool) {\n\tbegin := strings.Index(s, start)\n\tif begin == -1 {\n\t\treturn \"\", s, false\n\t}\n\tbetween = s[begin+len(start):]\n\tend := strings.Index(between, stop)\n\tif end == -1 {\n\t\treturn \"\", s, false\n\t}\n\treturn between[:end], s[begin+len(start)+end+len(stop):], true\n}", "reference": "// StringFindBetween returns the string between the first occurrences of the tokens start and stop.\n// The remainder of the string after the stop token will be returned if found.\n// If the tokens couldn't be found, then the whole string will be returned as remainder.", "generated": "This method returns a list of the elements in the given range that are not within an existing length or span . The returned array is then used to create new ranges for each element and return them as pairs if necessary. This can be useful when you want to iterate over multiple lists without having any additional information about which items"}
{"id": 4755, "code": "func HTTPPostJSON(url string, data interface{}) error {\n\tb, err := json.MarshalIndent(data, \"\", \"  \")\n\tif err != nil {\n\t\treturn err\n\t}\n\tresponse, err := http.Post(url, \"application/json\", bytes.NewBuffer(b))\n\tif err == nil && (response.StatusCode < 200 || response.StatusCode > 299) {\n\t\terr = errors.New(response.Status)\n\t}\n\treturn err\n}", "reference": "// HTTPPostJSON marshalles data as JSON\n// and sends it as HTTP POST request to url.\n// If the response status code is not 200 OK,\n// then the status is returned as an error.", "generated": "HTTP POST JSON is a simple and fast way to send an object of type `string` from one URL into another using the standard protocol for sending objects in different formats such as text or binary strings with no parameters at all. It also provides support for encoding arbitrary values by default which can be used when creating new URLs that"}
{"id": 4764, "code": "func FileSize(filename string) int64 {\r\n\tinfo, err := os.Stat(filename)\r\n\tif err != nil {\r\n\t\treturn 0\r\n\t}\r\n\treturn info.Size()\r\n}", "reference": "// FileSize returns the size of a file or zero in case of an error.", "generated": "This function returns the size of a file in bytes (in this case 32KB). The default is 64KB and can be changed to any number by calling fsck or fsync . Note that if you want to use an arbitrary length for your files then it's best to set them as long integers rather than byte arrays"}
{"id": 4781, "code": "func LoadTOMLBytes(conf interface{}, src []byte) error {\n\treturn loadConfigBytes(conf, src, nil, toml.Unmarshal)\n}", "reference": "// LoadTOMLBytes loads TOML bytes", "generated": "This function loads the byte[] from a config file and returns it as an array of bytes in binary format (binary-encoded). The returned string is then converted into ASCII by calling init() . This method can be used for any number or sequence that does not contain spaces at all; see Init(). Parameters : int"}
{"id": 4787, "code": "func Crop(img image.Image, c Config) (image.Image, error) {\n\tmaxBounds := c.maxBounds(img.Bounds())\n\tsize := c.computeSize(maxBounds, image.Point{c.Width, c.Height})\n\tcr := c.computedCropArea(img.Bounds(), size)\n\tcr = img.Bounds().Intersect(cr)\n\n\tif c.Options&Copy == Copy {\n\t\treturn cropWithCopy(img, cr)\n\t}\n\tif dImg, ok := img.(subImageSupported); ok {\n\t\treturn dImg.SubImage(cr), nil\n\t}\n\treturn cropWithCopy(img, cr)\n}", "reference": "// Crop retrieves an image that is a\n// cropped copy of the original img.\n//\n// The crop is made given the informations provided in config.", "generated": "// Create a new Image with the specified width and height as parameters to create an alternate cropped area for each pixel in the selected rectangle of the canvas that is not already included by this method. // This will be used when creating additional images from existing PNGs or other similar formats if necessary.\n// Returns: A newly"}
{"id": 4788, "code": "func (c Config) computeSize(bounds image.Rectangle, ratio image.Point) (p image.Point) {\n\tif c.Options&Ratio == Ratio {\n\t\t// Ratio option is on, so we take the biggest size available that fit the given ratio.\n\t\tif float64(ratio.X)/float64(bounds.Dx()) > float64(ratio.Y)/float64(bounds.Dy()) {\n\t\t\tp = image.Point{bounds.Dx(), (bounds.Dx() / ratio.X) * ratio.Y}\n\t\t} else {\n\t\t\tp = image.Point{(bounds.Dy() / ratio.Y) * ratio.X, bounds.Dy()}\n\t\t}\n\t} else {\n\t\tp = image.Point{ratio.X, ratio.Y}\n\t}\n\treturn\n}", "reference": "// computeSize retrieve the effective size of the cropped image.\n// It is defined by Height, Width, and Ratio option.", "generated": "The following example calculates a scaled-down version of an array with dimensions in pixels and widths as specified by bounds . The resulting result will be used to calculate scaling for all images within this range using BoundedImage , which can also include any other aspect ratios you specify such like height or depth :\n\nA scale"}
{"id": 4790, "code": "func NewThen(command string, args ...string) Then {\n\treturn &gitCmd{command: command, args: args}\n}", "reference": "// NewThen creates a new Then command.", "generated": "This function returns a new GitCommand object. It is used to create the commands and arguments of this script in order for it's execution process (and its dependencies). The default value is nil . This will be returned as an error message if no such file exists or fails with errors from other scripts that have not been created"}
{"id": 4792, "code": "func (g *gitCmd) Command() string {\n\treturn g.command + \" \" + strings.Join(g.args, \" \")\n}", "reference": "// Command returns the full command as configured in Caddyfile.", "generated": "This command is used to execute commands from the git repository and return a list of all files in that repo's directory with an optional argument --name . The default value for this option is nil , which means it will not be executed by Git when invoked on any other file or folder named `/`. This can also cause"}
{"id": 4812, "code": "func (r *Repo) pull() error {\n\n\t// if not pulled, perform clone\n\tif !r.pulled {\n\t\treturn r.clone()\n\t}\n\n\t// if latest tag config is set\n\tif r.Branch == latestTag {\n\t\treturn r.checkoutLatestTag()\n\t}\n\n\tparams := append([]string{\"pull\"}, append(r.PullArgs, \"origin\", r.Branch)...)\n\tvar err error\n\tif err = r.gitCmd(params, r.Path); err == nil {\n\t\tr.pulled = true\n\t\tr.lastPull = time.Now()\n\t\tLogger().Printf(\"%v pulled.\\n\", r.URL)\n\t\tr.lastCommit, err = r.mostRecentCommit()\n\t}\n\treturn err\n}", "reference": "// pull performs git pull, or git clone if repository does not exist.", "generated": "/// Returns the current branch of a repo that has been merged with another repository in this directory.\n# Examples include ```github.com/joshu-michaels/repo.git`` and `githubusercontent.*/*/***.git`. Note that these are branches which have already had their merge"}
{"id": 4815, "code": "func (r *Repo) Prepare() error {\n\t// check if directory exists or is empty\n\t// if not, create directory\n\tfs, err := gos.ReadDir(r.Path)\n\tif err != nil || len(fs) == 0 {\n\t\treturn gos.MkdirAll(r.Path, os.FileMode(0755))\n\t}\n\n\t// validate git repo\n\tisGit := false\n\tfor _, f := range fs {\n\t\tif f.IsDir() && f.Name() == \".git\" {\n\t\t\tisGit = true\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif isGit {\n\t\t// check if same repository\n\t\tvar repoURL string\n\t\tif repoURL, err = r.originURL(); err == nil {\n\t\t\tif strings.TrimSuffix(repoURL, \".git\") == strings.TrimSuffix(r.URL.Val(), \".git\") {\n\t\t\t\tr.pulled = true\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"cannot retrieve repo url for %v Error: %v\", r.Path, err)\n\t\t}\n\t\treturn fmt.Errorf(\"another git repo '%v' exists at %v\", repoURL, r.Path)\n\t}\n\treturn fmt.Errorf(\"cannot git clone into %v, directory not empty\", r.Path)\n}", "reference": "// Prepare prepares for a git pull\n// and validates the configured directory", "generated": "This function checks whether the given path contains a Git subdirectory and returns an output of that location in its current state when no such file has been created by this command line option specified with --no-gist . The default value is \"none\". If it does exist, then all files within those directories are considered to"}
{"id": 4819, "code": "func (g *gitCmd) Stdin(stdin io.Reader) {\n\tg.Cmd.Stdin = stdin\n}", "reference": "// Stdin sets the process's standard input.", "generated": "This function returns a string containing the current buffer and its contents, along with any errors that occurred during processing of this file or if it was not created by an external process before being called in GDB mode on Windows XP/Vista SP1+. The returned value is either nil , which means no error message has been"}
{"id": 4831, "code": "func (t TravisHook) handleSignature(r *http.Request, secret string) error {\n\tsignature := r.Header.Get(\"Authorization\")\n\tif signature == \"\" {\n\t\treturn errors.New(\"request sent no authorization signature\")\n\t}\n\tif secret == \"\" {\n\t\tLogger().Print(\"Unable to verify request signature. Secret not set in caddyfile!\\n\")\n\t\treturn nil\n\t}\n\n\tcontent := r.Header.Get(\"Travis-Repo-Slug\") + secret\n\thash := sha256.Sum256([]byte(content))\n\texpectedMac := hex.EncodeToString(hash[:])\n\tif signature != expectedMac {\n\t\tfmt.Println(signature, expectedMac)\n\t\treturn errors.New(\"Invalid authorization header\")\n\t}\n\treturn nil\n}", "reference": "// Check for an authorization signature in the request. Reject if not present. If validation required, check the sha", "generated": "// Handle the signing of a signed certificate using an authorized key and optionally its hash as input for each step on the chain. This is done by adding additional checks that are performed before any other steps can be completed or executed; this method does not require authentication from users who have already authenticated themselves with their certificates via TLS/"}
{"id": 4833, "code": "func hookName(h hookHandler) string {\n\tfor name, handler := range handlers {\n\t\tif handler == h {\n\t\t\treturn name\n\t\t}\n\t}\n\treturn \"\"\n}", "reference": "// hookName returns the name of the hookHanlder h.", "generated": "hookName() returns a list of strings that can be used to create an alias for the given hostname. The names are passed in as arguments and returned by hook . Hooks also return aliases when they have been created or modified with hooks , which is useful if you want to use multiple hosts at once without having all"}
{"id": 4861, "code": "func (u *URL) Short() string {\n\tif u.Scheme == \"\" {\n\t\treturn \"\"\n\t}\n\n\ts := schemeMap[u.Scheme].Aliases[0]\n\n\tif u.Scheme == \"odbc\" || u.Scheme == \"oleodbc\" {\n\t\tn := u.Proto\n\t\tif v, ok := schemeMap[n]; ok {\n\t\t\tn = v.Aliases[0]\n\t\t}\n\t\ts += \"+\" + n\n\t} else if u.Proto != \"tcp\" {\n\t\ts += \"+\" + u.Proto\n\t}\n\n\ts += \":\"\n\n\tif u.User != nil {\n\t\tif un := u.User.Username(); un != \"\" {\n\t\t\ts += un + \"@\"\n\t\t}\n\t}\n\n\tif u.Host != \"\" {\n\t\ts += u.Host\n\t}\n\n\tif u.Path != \"\" && u.Path != \"/\" {\n\t\ts += u.Path\n\t}\n\n\tif u.Opaque != \"\" {\n\t\ts += u.Opaque\n\t}\n\n\treturn s\n}", "reference": "// Short provides a short description of the user, host, and database.", "generated": "// This function returns a list of strings that are the same as their names in this case. The first two bytes should be empty and must not contain any characters other than whitespace or capitalization letters; otherwise they will return an error message for each character on the line containing them. // If there is no matching sequence"}
{"id": 4873, "code": "func (e *hdbError) Error() string {\n\tif e.stmtNo != -1 {\n\t\treturn fmt.Sprintf(\"SQL %s %d - %s (statement no: %d)\", e.errorLevel, e.errorCode, e.errorText, e.stmtNo)\n\t}\n\treturn fmt.Sprintf(\"SQL %s %d - %s\", e.errorLevel, e.errorCode, e.errorText)\n}", "reference": "// Error implements the Error interface.", "generated": "This function returns a SQL statement that contains the error message and an exception status code for the specified statements in the database table or column of interest to be returned by the user agent when performing any operations on it using sqlite3 . The result is then passed as an argument to this method which can either return null if there"}
{"id": 4883, "code": "func StringSize(s string) int {\n\tn := 0\n\tfor _, r := range s {\n\t\tn += RuneLen(r)\n\t}\n\treturn n\n}", "reference": "// StringSize is like Size with a string as parameter.", "generated": "This method returns the number of bytes in a given length. The default is 1 for strings that are longer than or equal to 255 characters long. This can be used as an alternative if you want to use more complex lengths (e., e..=255). Note however this does not guarantee accuracy; it only guarantees success"}
{"id": 4887, "code": "func On() bool {\n\ttracer.mu.RLock()\n\ton := tracer.on\n\ttracer.mu.RUnlock()\n\treturn on\n}", "reference": "// On returns if tracing methods output is active.", "generated": "// This method is called when the lock has been unlocked and no other locks are available to perform a task, such as calling an unlock operation or performing another action in progress. // The callback function will be invoked once every 10 seconds for each locked state of this object (i., if there are any).\nMethods:"}
{"id": 4913, "code": "func (r *Reader) ReadUint32() uint32 {\n\tif r.err != nil {\n\t\treturn 0\n\t}\n\tvar n int\n\tn, r.err = io.ReadFull(r.rd, r.b[:4])\n\tr.cnt += n\n\tif r.err != nil {\n\t\treturn 0\n\t}\n\treturn binary.LittleEndian.Uint32(r.b[:4])\n}", "reference": "// ReadUint32 reads and returns an uint32.", "generated": "// This function reads the full string from a buffer and returns an unsigned integer representation of that byte in bytes or bits if it is not found by calling read(). If there is no such result then return zero as well.\n// Returns true for all characters except those which are non-zero; false otherwise.\n//"}
{"id": 4918, "code": "func (r *Reader) ReadCesu8(size int) []byte {\n\tif r.err != nil {\n\t\treturn nil\n\t}\n\tp := make([]byte, size)\n\tvar n int\n\tn, r.err = io.ReadFull(r.rd, p)\n\tr.cnt += n\n\tif r.err != nil {\n\t\treturn nil\n\t}\n\tr.tr.Reset()\n\tif n, _, r.err = r.tr.Transform(p, p, true); r.err != nil { // inplace transformation\n\t\treturn nil\n\t}\n\treturn p[:n]\n}", "reference": "// ReadCesu8 reads a size CESU-8 encoded byte sequence and returns an UTF-8 byte slice.", "generated": "// This function is used to create a new buffer and store the contents of the current file into it for later use by calling this method on an existing one if necessary. The return value will be returned as soon after returning from read(). func main () {\n\u0019 var ctx string\nrawdownloadfor i , j :"}
{"id": 4923, "code": "func (w *Writer) Write(p []byte) {\n\tif w.err != nil {\n\t\treturn\n\t}\n\tw.wr.Write(p)\n}", "reference": "// Write writes the contents of p.", "generated": "// This function is used to write a string of bytes, and returns the result if it succeeds. It also checks for errors in its output before returning.\n // The return value should be an integer or float that represents how many times this process has failed with no error message returned by `write`.\n func main()"}
{"id": 4938, "code": "func (c *Connector) Locale() string {\n\tc.mu.RLock()\n\tdefer c.mu.RUnlock()\n\treturn c.locale\n}", "reference": "// Locale returns the locale of the connector.", "generated": "This method is used to lock the connection of a given module or class, and returns an error if it does not exist in that context for any reason other than failure on subsequent attempts at locking down its own instance with this function. The returned value will be passed as nil when no attempt has been made by another thread within"}
{"id": 4942, "code": "func (c *Connector) SetTLSConfig(tlsConfig *tls.Config) error {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\tc.tlsConfig = tlsConfig\n\treturn nil\n}", "reference": "// SetTLSConfig sets the TLS configuration of the connector.", "generated": "This method sets the TLS configuration to a single-byte string, which is used for authentication purposes only and does not affect any other methods of encryption or decryption that are defined in this specification. The default value will be set by calling ssl_setTCPConfiguration(). This function can also optionally return an optional hash"}
{"id": 4958, "code": "func Slice(arr []byte, count int) [][]byte {\n\n\tsliceCount := len(arr) / count\n\tresult := make([][]byte, sliceCount)\n\n\tfor i := 0; i < sliceCount; i++ {\n\t\tstart := i * count\n\t\tend := i*count + count\n\n\t\tresult[i] = arr[start:end]\n\t}\n\n\treturn result\n}", "reference": "// Slice is splitting input byte array into slice of subarrays. Each of count length.", "generated": "Slices are a type of Array. The following example creates an array with the same length as its first element and returns it to the caller for each iteration in which this is done (as opposed \"slice\"):"}
{"id": 4965, "code": "func Decode(data string) ([]byte,error) {\n\tdata = strings.Replace(data, \"-\", \"+\", -1) // 62nd char of encoding\n\tdata = strings.Replace(data, \"_\", \"/\", -1) // 63rd char of encoding\n\t\n\tswitch(len(data) % 4) { // Pad with trailing '='s\n\t\tcase 0:             // no padding\n\t\tcase 2: data+=\"==\"  // 2 pad chars\n\t\tcase 3:\tdata+=\"=\"   // 1 pad char\t\t\n\t}\n\t\t\n\treturn base64.StdEncoding.DecodeString(data)\n}", "reference": "// Decode decodes base64url string to byte array", "generated": "This function decodes a byte array containing the encoded text and returns an error if it fails to decode or not at all in case of failure on decoding errors due either to insufficient space for characters that are missing from character set bytes , lack thereof as well . The result is returned by default when there's only one possible way"}
{"id": 4969, "code": "func DerivePBKDF2(password, salt []byte, iterationCount, keyBitLength int, h hash.Hash) []byte {\n\n\tprf := hmac.New(func() hash.Hash { return h }, password)\n\thLen := prf.Size()\n\tdkLen := keyBitLength >> 3 //size of derived key in bytes\n\n\tl := int(math.Ceil(float64(dkLen) / float64(hLen))) // l = CEIL (dkLen / hLen)\n\tr := dkLen - (l-1)*hLen\n\n\t// 1. If dkLen > (2^32 - 1) * hLen, output \"derived key too long\" and stop.\n\tif dkLen > MaxInt {\n\t\tpanic(fmt.Sprintf(\"kdf.DerivePBKDF2: expects derived key size to be not more that (2^32-1) bits, but was requested %v bits.\", keyBitLength))\n\t}\n\n\tdk := make([]byte, 0, dkLen)\n\n\tfor i := 0; i < l; i++ {\n\n\t\tt := f(salt, iterationCount, i+1, prf) // T_l = F (P, S, c, l)\n\n\t\tif i == (l - 1) {\n\t\t\tt = t[:r]\n\t\t} // truncate last block to r bits\n\n\t\tdk = append(dk, t...) // DK = T_1 || T_2 ||  ...  || T_l<0..r-1>\n\t}\n\n\treturn dk\n}", "reference": "// DerivePBKDF2 implements Password Based Key Derivation Function 2, RFC 2898. Derives key of keyBitLength size, given password, salt, iteration count and hash function", "generated": "The derivation function is a simple wrapper around the PBKDF2 implementation provided by Cryptographic Digestion Services for use with Bitcoin Cash transactions using SHA256 hashes as inputs or outputs from an anonymous wallet service called Bitmain . The main purpose here is simply to provide cryptographic verification against any changes made on behalf at least one"}
{"id": 4970, "code": "func ReadPrivate(raw []byte) (key *ecdsa.PrivateKey,err error) {\n\tvar encoded *pem.Block\n\n\tif encoded, _ = pem.Decode(raw); encoded == nil {\n\t\treturn nil, errors.New(\"Ecc.ReadPrivate(): Key must be PEM encoded PKCS1 or PKCS8 EC private key\")\n\t}\n\n\tvar parsedKey interface{}\n\n\tif parsedKey,err=x509.ParseECPrivateKey(encoded.Bytes);err!=nil {\n\t\tif parsedKey, err = x509.ParsePKCS8PrivateKey(encoded.Bytes);err!=nil {\n\t\t\treturn nil,err\n\t\t}\n\t}\n\n\tvar ok bool\n\t\t\n\tif key,ok=parsedKey.(*ecdsa.PrivateKey);!ok {\n\t\treturn nil, errors.New(\"Ecc.ReadPrivate(): Key is not valid *ecdsa.PrivateKey\")\n\t}\n\t\n\treturn key,nil\n}", "reference": "// ReadPrivate loads ecdsa.PrivateKey from given PKCS1 or PKCS8 blobs", "generated": "// This function reads the public keys of a given encrypted file and returns an array of bytes that can then be used to decrypt it using AES-256 encryption for each byte in this string // provided by decryptedEncryption() .\n func readPublicKeys () (*ecdrsb. EncryptFile , req :"}
{"id": 4978, "code": "func (c *Consumer) TailingLogs(appGuid, authToken string) (<-chan *events.LogMessage, <-chan error) {\n\treturn c.tailingLogs(appGuid, authToken, true)\n}", "reference": "// TailingLogs listens indefinitely for log messages only; other event types\n// are dropped.\n// Whenever an error is encountered, the error will be sent down the error\n// channel and TailingLogs will attempt to reconnect up to 5 times.  After\n// five failed reconnection attempts, TailingLogs will give up and close the\n// error and LogMessage channels.\n//\n// If c is closed, the returned channels will both be closed.\n//\n// Errors must be drained from the returned error channel for it to continue\n// retrying; if they are not drained, the connection attempts will hang.", "generated": "Tails logs a log message to the specified user's account and returns an event that is logged on by default for each of those users in connection with this logging service or if no authentication has been provided at all it will return nil . The following example shows how you can use tailslog messages from your own app as"}
{"id": 4980, "code": "func (c *Consumer) Stream(appGuid string, authToken string) (outputChan <-chan *events.Envelope, errorChan <-chan error) {\n\treturn c.runStream(appGuid, authToken, true)\n}", "reference": "// Stream listens indefinitely for all log and event messages.\n//\n// Messages are presented in the order received from the loggregator server.\n// Chronological or other ordering is not guaranteed. It is the responsibility\n// of the consumer of these channels to provide any desired sorting mechanism.\n//\n// Whenever an error is encountered, the error will be sent down the error\n// channel and Stream will attempt to reconnect indefinitely.", "generated": "This stream is a wrapper around the consumer interface of Consumer . It provides an API for creating and receiving streams from user-defined APIs that are not provided by any other type or class in this specification. The following example creates two concurrent users with different credentials using one method to create their own streaming service on each request :"}
{"id": 5001, "code": "func (d *Dataset) Snapshot(name string, recursive bool) (*Dataset, error) {\n\targs := make([]string, 1, 4)\n\targs[0] = \"snapshot\"\n\tif recursive {\n\t\targs = append(args, \"-r\")\n\t}\n\tsnapName := fmt.Sprintf(\"%s@%s\", d.Name, name)\n\targs = append(args, snapName)\n\t_, err := zfs(args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn GetDataset(snapName)\n}", "reference": "// Snapshot creates a new ZFS snapshot of the receiving dataset, using the\n// specified name.  Optionally, the snapshot can be taken recursively, creating\n// snapshots of all descendent filesystems in a single, atomic operation.", "generated": "// This function returns a datastructure that is used to store the data in an array of named tuples and lists for each tuple or list element as described above. The default value will be returned if no such collection exists at all. // Note that this method does not return any information about collections; it only stores"}
{"id": 5017, "code": "func DialWithTimeout(url string, timeout time.Duration) (*Session, error) {\n\tinfo, err := ParseURL(url)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tinfo.Timeout = timeout\n\treturn DialWithInfo(info)\n}", "reference": "// DialWithTimeout works like Dial, but uses timeout as the amount of time to\n// wait for a server to respond when first connecting and also on follow up\n// operations in the session. If timeout is zero, the call may block\n// forever waiting for a connection to be made.\n//\n// See SetSyncTimeout for customizing the timeout for the session.", "generated": "// This function returns a new instance of the Session object and provides an interface to get started with it. It is used for creating sessions that are not currently in use by default.\n // The session will be created when this method has been called from within its own context (see below). If no other methods have been"}
{"id": 5025, "code": "func (s *Session) LogoutAll() {\n\ts.m.Lock()\n\tfor _, cred := range s.creds {\n\t\tif s.masterSocket != nil {\n\t\t\ts.masterSocket.Logout(cred.Source)\n\t\t}\n\t\tif s.slaveSocket != nil {\n\t\t\ts.slaveSocket.Logout(cred.Source)\n\t\t}\n\t}\n\ts.creds = s.creds[0:0]\n\ts.m.Unlock()\n}", "reference": "// LogoutAll removes all established authentication credentials for the session.", "generated": "// This method is used to log out all sessions from the specified session and lock them in a locked state for each of their associated credentials if they are not already logged out by default.\n/*** The following example logs an authenticated user into our server using this API with no authentication required; it will be executed when we"}
{"id": 5048, "code": "func (q *Query) LogReplay() *Query {\n\tq.m.Lock()\n\tq.op.flags |= flagLogReplay\n\tq.m.Unlock()\n\treturn q\n}", "reference": "// LogReplay enables an option that optimizes queries that are typically\n// made on the MongoDB oplog for replaying it. This is an internal\n// implementation aspect and most likely uninteresting for other uses.\n// It has seen at least one use case, though, so it's exposed via the API.", "generated": "// This function is used to lock the replay server and allow it access to all of its data in a single call, without requiring any additional parameters or calling log(Q). // The callback must be called with no arguments other than Q's own key-value pairs; otherwise this will return nil ."}
{"id": 5071, "code": "func tokenFor(t *transaction) token {\n\tnonce := t.Nonce\n\tif nonce == \"\" {\n\t\tnonce = newNonce()\n\t}\n\treturn token(t.Id.Hex() + \"_\" + nonce)\n}", "reference": "// tokenFor returns a unique transaction token that\n// is composed by t's id and a nonce. If t already has\n// a nonce assigned to it, it will be used, otherwise\n// a new nonce will be generated.", "generated": "token for isTransactions, tokens are a collection of strings that can be used to store and retrieve information about transactions in the blockchain (see Token). Tokens have no special meaning when they're passed as an argument or returned from a function call; instead it's just called with one parameter which will return all data associated by"}
{"id": 5073, "code": "func (r *Runner) Run(ops []Op, id bson.ObjectId, info interface{}) (err error) {\n\tconst efmt = \"error in transaction op %d: %s\"\n\tfor i := range ops {\n\t\top := &ops[i]\n\t\tif op.C == \"\" || op.Id == nil {\n\t\t\treturn fmt.Errorf(efmt, i, \"C or Id missing\")\n\t\t}\n\t\tchanges := 0\n\t\tif op.Insert != nil {\n\t\t\tchanges++\n\t\t}\n\t\tif op.Update != nil {\n\t\t\tchanges++\n\t\t}\n\t\tif op.Remove {\n\t\t\tchanges++\n\t\t}\n\t\tif changes > 1 {\n\t\t\treturn fmt.Errorf(efmt, i, \"more than one of Insert/Update/Remove set\")\n\t\t}\n\t\tif changes == 0 && op.Assert == nil {\n\t\t\treturn fmt.Errorf(efmt, i, \"none of Assert/Insert/Update/Remove set\")\n\t\t}\n\t}\n\tif id == \"\" {\n\t\tid = bson.NewObjectId()\n\t}\n\n\t// Insert transaction sooner rather than later, to stay on the safer side.\n\tt := transaction{\n\t\tId:    id,\n\t\tOps:   ops,\n\t\tState: tpreparing,\n\t\tInfo:  info,\n\t}\n\tif err = r.tc.Insert(&t); err != nil {\n\t\treturn err\n\t}\n\tif err = flush(r, &t); err != nil {\n\t\treturn err\n\t}\n\tif t.State == taborted {\n\t\treturn ErrAborted\n\t} else if t.State != tapplied {\n\t\tpanic(fmt.Errorf(\"invalid state for %s after flush: %q\", &t, t.State))\n\t}\n\treturn nil\n}", "reference": "// Run creates a new transaction with ops and runs it immediately.\n// The id parameter specifies the transaction id, and may be written\n// down ahead of time to later verify the success of the change and\n// resume it, when the procedure is interrupted for any reason. If\n// empty, a random id will be generated.\n// The info parameter, if not nil, is included under the \"i\"\n// field of the transaction document.\n//\n// Operations across documents are not atomically applied, but are\n// guaranteed to be eventually all applied in the order provided or\n// all aborted, as long as the affected documents are only modified\n// through transactions. If documents are simultaneously modified\n// by transactions and out of transactions the behavior is undefined.\n//\n// If Run returns no errors, all operations were applied successfully.\n// If it returns ErrAborted, one or more operations can't be applied\n// and the transaction was entirely aborted with no changes performed.\n// Otherwise, if the transaction is interrupted while running for any\n// reason, it may be resumed explicitly or by attempting to apply\n// another transaction on any of the documents targeted by ops, as\n// long as the interruption was made after the transaction document\n// itself was inserted. Run Resume with the obtained transaction id\n// to confirm whether the transaction was applied or not.\n//\n// Any number of transactions may be run concurrently, with one\n// runner or many.", "generated": "The Transaction ID is a string that contains all transactions from which an operation was performed and its associated data type as well any other information about it such like name, date, time, etc., but also includes details regarding how many txns were involved with each action being executed by this node's nodes when they are not yet"}
{"id": 5076, "code": "func SetChaos(c Chaos) {\n\tchaosSetting = c\n\tchaosEnabled = c.KillChance > 0 || c.SlowdownChance > 0\n}", "reference": "// SetChaos sets the failure injection parameters to c.", "generated": "Set ch chaos setting to the current state of the game, and set it as a value for each player in turn (if any). This will cause all players within range on their next attack to be affected by Chaos at once if they are not already hit with that effect or have no other effects left over from previous attacks"}
{"id": 5099, "code": "func NewObjectIdWithTime(t time.Time) ObjectId {\n\tvar b [12]byte\n\tbinary.BigEndian.PutUint32(b[:4], uint32(t.Unix()))\n\treturn ObjectId(string(b[:]))\n}", "reference": "// NewObjectIdWithTime returns a dummy ObjectId with the timestamp part filled\n// with the provided number of seconds from epoch UTC, and all other parts\n// filled with zeroes. It's not safe to insert a document with an id generated\n// by this method, it is useful only for queries to find documents with ids\n// generated before or after the specified timestamp.", "generated": "New objects are created by calling the new object method on a Time class, and returning an instance of that Class with its own unique ID (see below). The methods return all instances in this subclass as well; they do not need to be called from outside any other classes or functions within it itself. This is useful for"}
{"id": 5102, "code": "func (id ObjectId) Time() time.Time {\n\t// First 4 bytes of ObjectId is 32-bit big-endian seconds from epoch.\n\tsecs := int64(binary.BigEndian.Uint32(id.byteSlice(0, 4)))\n\treturn time.Unix(secs, 0)\n}", "reference": "// Time returns the timestamp part of the id.\n// It's a runtime error to call this method with an invalid id.", "generated": "This method returns the number and length in milliseconds for a given object ID or byte slice that has been passed to this function as an argument through its constructor methods on each iteration. The returned value can be used by any other type class with which it may have access; see also Methods .\nMethods are implemented using two types"}
{"id": 5107, "code": "func hasMinOf(top interface{}, current interface{}, field interface{}, param string) bool {\n\n\treturn isGte(top, current, field, param)\n}", "reference": "// min tests whether a variable value is larger or equal to a given\n// number. For number types, it's a simple lesser-than test; for\n// strings it tests the number of characters whereas for maps\n// and slices it tests the number of items.", "generated": "This method returns true if the top of a list contains an element with at least one value. If no elements are found in that range, then this function will return false . The returned values can be any number or multiple strings (see below). Parameters : top , current and fields Optional parameters to use for all methods Returns"}
{"id": 5109, "code": "func Connect() {\n\turi := os.Getenv(\"MONGODB_URL\")\n\n\tif len(uri) == 0 {\n\t\turi = MongoDBUrl\n\t}\n\n\tmongo, err := mgo.ParseURL(uri)\n\ts, err := mgo.Dial(uri)\n\tif err != nil {\n\t\tfmt.Printf(\"Can't connect to mongo, go error %v\\n\", err)\n\t\tpanic(err.Error())\n\t}\n\ts.SetSafe(&mgo.Safe{})\n\tfmt.Println(\"Connected to\", uri)\n\tSession = s\n\tMongo = mongo\n}", "reference": "// Connect connects to mongodb", "generated": "// This is a simple wrapper around the Mongodb API and provides some basic functionality for connecting with other applications using it // in conjunction of its own interface methods (e-mailing/signup). The main purpose of this implementation // will be to provide an easy way into any application that uses `http`"}
{"id": 5112, "code": "func (file *GridFile) SetChunkSize(bytes int) {\n\tfile.assertMode(gfsWriting)\n\tdebugf(\"GridFile %p: setting chunk size to %d\", file, bytes)\n\tfile.m.Lock()\n\tfile.doc.ChunkSize = bytes\n\tfile.m.Unlock()\n}", "reference": "// SetChunkSize sets size of saved chunks.  Once the file is written to, it\n// will be split in blocks of that size and each block saved into an\n// independent chunk document.  The default chunk size is 256kb.\n//\n// It is a runtime error to call this function once the file has started\n// being written to.", "generated": "// Sets the chunksize of a buffer in GBFS using gfsWrite(). This is used for writing and locking buffers on disk or by calling fsRead(), which will write data from one byte at time into another if necessary.\n // Note that this method does not lock any existing files; it only locks new ones"}
{"id": 5120, "code": "func (file *GridFile) Read(b []byte) (n int, err error) {\n\tfile.assertMode(gfsReading)\n\tfile.m.Lock()\n\tdebugf(\"GridFile %p: reading at offset %d into buffer of length %d\", file, file.offset, len(b))\n\tdefer file.m.Unlock()\n\tif file.offset == file.doc.Length {\n\t\treturn 0, io.EOF\n\t}\n\tfor err == nil {\n\t\ti := copy(b, file.rbuf)\n\t\tn += i\n\t\tfile.offset += int64(i)\n\t\tfile.rbuf = file.rbuf[i:]\n\t\tif i == len(b) || file.offset == file.doc.Length {\n\t\t\tbreak\n\t\t}\n\t\tb = b[i:]\n\t\tfile.rbuf, err = file.getChunk()\n\t}\n\treturn n, err\n}", "reference": "// Read reads into b the next available data from the file and\n// returns the number of bytes written and an error in case\n// something wrong happened.  At the end of the file, n will\n// be zero and err will be set to os.EOF.\n//\n// The parameters and behavior of this function turn the file\n// into an io.Reader.", "generated": "grpc_readdirs is a wrapper around the grpc-write command to read and write files from disk using GrPC's fsReadDir . It provides an interface for writing data directly in memory without having any additional overhead or performance issues associated with it; this can be used as part that other commands like g"}
{"id": 5123, "code": "func invertAttributes(windowsMode uint16) uint16 {\n\treturn (COMMON_LVB_MASK & windowsMode) | ((FOREGROUND_MASK & windowsMode) << 4) | ((BACKGROUND_MASK & windowsMode) >> 4)\n}", "reference": "// invertAttributes inverts the foreground and background colors of a Windows attributes value", "generated": "This function returns the value of the underlying Windows mode. The default is to return a string containing all attributes that are specified by this method, and no other information about any attribute values or properties will be returned for it. This can also occur if you want an additional parameter which may not have been provided as part thereof;"}
{"id": 5157, "code": "func (s *SegmentStack) Peek() int64 {\n\tif s.Len() == 0 {\n\t\treturn rootSegment\n\t}\n\treturn s.s[s.Len()-1]\n}", "reference": "// Peek returns id from the top of the stack. It returns rootSegment if the stack is empty.", "generated": "// This method is used to peek at the current segment of the stack, and return a new one if it's not found or otherwise removed from memory by an operation that returns nullptr .\n// The following example uses this technique for checking whether any existing segments are in use; see Section 4 below. // Note that"}
{"id": 5171, "code": "func (t *tx) StartExternal(host, name string) error {\n\tt.mtx.Lock()\n\tdefer t.mtx.Unlock()\n\n\tid, err := t.Tracer.BeginExternalSegment(t.id, t.ss.Peek(), host, name)\n\tif err != nil {\n\t\treturn err\n\t}\n\tt.ss.Push(id)\n\treturn nil\n}", "reference": "// StartExternal starts an external segment.", "generated": "// Initializes the external segment of a node and returns an internal token for that element in its context.\n // This is used to initialize all nodes on the network as well; it can be useful when you want to use multiple instances or if your own instance-specific tokens are not available at once. The default value"}
{"id": 5186, "code": "func NewClusterWithHost(hosts ...*URI) *Cluster {\n\tcluster := DefaultCluster()\n\tfor _, host := range hosts {\n\t\tcluster.AddHost(host)\n\t}\n\treturn cluster\n}", "reference": "// NewClusterWithHost returns a cluster with the given URIs.", "generated": "This is a new Cluster with Host and ServerName set to the same name as default clusters in this example (defaulting \"DefaultClustering\"). It will be used for all of the following purposes only if you want it to work on your own servers or other applications that use Cluster . The server names are"}
{"id": 5206, "code": "func (idx *Index) BatchQuery(queries ...PQLQuery) *PQLBatchQuery {\n\tstringQueries := make([]string, 0, len(queries))\n\thasKeys := false\n\tfor _, query := range queries {\n\t\tserializedQuery := query.Serialize()\n\t\thasKeys = hasKeys || serializedQuery.HasWriteKeys()\n\t\tstringQueries = append(stringQueries, serializedQuery.String())\n\t}\n\treturn &PQLBatchQuery{\n\t\tindex:   idx,\n\t\tqueries: stringQueries,\n\t\thasKeys: hasKeys,\n\t}\n}", "reference": "// BatchQuery creates a batch query with the given queries.", "generated": "The PQLSession provides a simple and easy way to retrieve the keys of an SQLite database using JSON data structures such as strings. The key-value pairs are stored in indexes that can be queried by any user or other entity within your application's schema for further processing purposes. This is useful when you need"}
{"id": 5218, "code": "func OptFieldTypeMutex(cacheType CacheType, cacheSize int) FieldOption {\n\treturn func(options *FieldOptions) {\n\t\toptions.fieldType = FieldTypeMutex\n\t\toptions.cacheType = cacheType\n\t\toptions.cacheSize = cacheSize\n\t}\n}", "reference": "// OptFieldTypeMutex adds a mutex field.", "generated": "This method returns a field type mutable with the following fields and methods that are available to all of its members in this context:\n\nA Type Mutate is an instance of Option , which provides access for any value within it (including those provided by other types). A Value can be either None or Either . The default"}
{"id": 5230, "code": "func (f *Field) Rows() *PQLRowsQuery {\n\ttext := fmt.Sprintf(\"Rows(field='%s')\", f.name)\n\treturn NewPQLRowsQuery(text, f.index, nil)\n}", "reference": "// Rows creates a Rows query with defaults", "generated": "This method returns a PLS query object that contains the fields of the given field and its indexes in order to retrieve information about each row or column from the database using SQLite's QueryBuilder interface. The returned data is then passed through to an SqlStatement which will be used for subsequent queries on this table as well"}
{"id": 5261, "code": "func OptClientConnectTimeout(timeout time.Duration) ClientOption {\n\treturn func(options *ClientOptions) error {\n\t\toptions.ConnectTimeout = timeout\n\t\treturn nil\n\t}\n}", "reference": "// OptClientConnectTimeout is the maximum time to connect in nanoseconds.", "generated": "This method is used to connect a client with the specified protocol and wait for it to complete before sending an HTTP request, or if no connection has been established by that server (e., not in any way connected), return false . The default value of this option will be returned when all connections have completed successfully; however you"}
{"id": 5271, "code": "func OptImportThreadCount(count int) ImportOption {\n\treturn func(options *ImportOptions) error {\n\t\toptions.threadCount = count\n\t\treturn nil\n\t}\n}", "reference": "// OptImportThreadCount is the number of goroutines allocated for import.", "generated": "This method imports a thread from the specified options list and returns an Option object that contains all of its arguments, including any additional information about how to use it in your program. The default value is None . This option can be used with other methods such as import , or by calling optimport() on one of those threads"}
{"id": 5282, "code": "func NewValueIterator(format Format, reader io.Reader) *Iterator {\n\treturn NewIterator(reader, FieldValueUnmarshaller(format))\n}", "reference": "// NewValueIterator creates a new iterator for value data.", "generated": "This method returns a new iterator that implements the format specifier and provides an interface for implementing it in its own way. It is intended to be used with any of the following methods (see below):\nMethods Description stringFormat Returns a formatted representation of the value returned by formatting . The default encoding will not work on Windows"}
{"id": 5287, "code": "func elementsFromLine(config *Config, line string) []interface{} {\n\tseparated := strings.Split(line, config.Delim)\n\telements := make([]interface{}, len(separated))\n\tfor i, field := range separated {\n\t\tvalue := field\n\t\tif !config.NoTrim {\n\t\t\tvalue = strings.TrimSpace(field)\n\t\t}\n\n\t\t// Apply the empty value, if configured.\n\t\tif value == \"\" && config.Empty != \"\" {\n\t\t\tvalue = config.Empty\n\t\t}\n\t\telements[i] = value\n\t}\n\treturn elements\n}", "reference": "// elementsFromLine returns a list of elements, each representing a single\n// item which will belong to a column of output.", "generated": "The interface provides a list of lines to be split into segments and an optional delimiter for each segment that is not in the specified order (see below). The separator specifies which sections are included within the given section or sub-section; it defaults on all other parts. If no part of the provided array contains any"}
{"id": 5306, "code": "func postEOFCheck(c *Cmp, r io.Reader, buf []byte) bool {\n\ttmpLR, isLR := r.(*io.LimitedReader)\n\tif isLR {\n\t\t// If the limit wasn't reached, then we don't need to check for\n\t\t// more data after the EOF\n\t\tif tmpLR.N > 0 {\n\t\t\treturn true\n\t\t}\n\n\t\t// Use the internal Reader for checking for more data\n\t\tr = tmpLR.R\n\t} else {\n\t\tc.debugf(\"compareReader: A type assertion of LimitedReader unexpectedly failed\\n\")\n\t}\n\n\t// Attempt to read more bytes from the original readers, to determine\n\t// if we should return an error for exceeding the MaxSize read limit.\n\tn, _ := readPartial(c, r, buf, 0, len(buf))\n\treturn n == 0\n}", "reference": "// postEOFCheck returns false if there is more data in a LimitedReader after\n// hitting EOF", "generated": "This function checks whether a given buffer contains at least one byte in length and returns false otherwise (see below). The returned value is either null or nil . It can be used as a way around some non-zero size limits on large buffers that are not guaranteed to contain any information about their contents before they reach zero sizes"}
{"id": 5311, "code": "func exist(file string) (bool, error) {\n\t_, err := os.Stat(file)\n\tif err != nil {\n\t\tif err == os.ErrNotExist {\n\t\t\treturn false, nil\n\t\t}\n\t\treturn false, err\n\t}\n\treturn true, nil\n}", "reference": "// exist checks if the file exists.", "generated": "// Create a new file with the name of the current directory and its contents in it.\n // This is called create() .\n func createdFile () (name string ) (err error , * File ) { if err = fs::createFile(name), err && errors.New(\"failed to open\", \""}
{"id": 5340, "code": "func (e *edit) Comment(reLine []string) error {\n\tallReSearch := make([]*regexp.Regexp, len(reLine))\n\n\tfor i, v := range reLine {\n\t\tif re, err := regexp.Compile(v); err != nil {\n\t\t\treturn err\n\t\t} else {\n\t\t\tallReSearch[i] = re\n\t\t}\n\t}\n\n\tif _, err := e.file.Seek(0, os.SEEK_SET); err != nil {\n\t\treturn err\n\t}\n\n\tchar := []byte(e.CommentChar + \" \")\n\tisNew := false\n\tbuf := new(bytes.Buffer)\n\n\t// Check every line.\n\tfor {\n\t\tline, err := e.buf.ReadBytes('\\n')\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\n\t\tfor _, v := range allReSearch {\n\t\t\tif v.Match(line) {\n\t\t\t\tline = append(char, line...)\n\n\t\t\t\tif !isNew {\n\t\t\t\t\tisNew = true\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif _, err = buf.Write(line); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif isNew {\n\t\treturn e.rewrite(buf.Bytes())\n\t}\n\treturn nil\n}", "reference": "// Comment inserts the comment character in lines that mach any regular expression\n// in reLine.", "generated": "This function returns a string that contains the text of the current comment in an input buffer and its contents if it matches any other characters or not. The output will be returned as JSON with no additional information about what was written to this file before being processed by editing mode on Windows XP/Vista machines running Win32 operating"}
{"id": 5384, "code": "func Run(command string) (output []byte, err error) {\n\toutput, _, err = RunWithMatch(command)\n\treturn\n}", "reference": "// Run executes external commands just like RunWithMatch, but does not return\n// the boolean `match`.", "generated": "This function runs the command specified in output. It returns a list of strings that are matched against an input buffer and then prints out all matches for each match to stdout or stderr . The result is returned as JSON with no errors if any were encountered during execution. If there was one such occurrence it will be"}
{"id": 5387, "code": "func (i *info) GroupHas(p ...perm) bool {\n\tmode := i.fi.Mode()\n\n\tfor _, v := range p {\n\t\tswitch v {\n\t\tcase R:\n\t\t\tif mode&modeRGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase W:\n\t\t\tif mode&modeWGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase X:\n\t\t\tif mode&modeXGroup == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\treturn true\n}", "reference": "// GroupHas reports whether the group has all given permissions.", "generated": "groups is a group of integers that can be used to represent any number in the world and optionally arbitrary numbers as well; it's not intended for use with strings or arrays but may also contain other types of information such like an integer value which could include values from multiple groups including memberships within each membergroup . It has"}
{"id": 5393, "code": "func ChPasswd(user string, key []byte) error {\n\tshadow, err := LookupShadow(user)\n\tif err != nil {\n\t\treturn err\n\t}\n\tshadow.Passwd(key)\n\n\treturn edit(user, shadow)\n}", "reference": "// == Change passwd\n// ChPasswd updates passwd.\n// The passwd must be supplied in clear-text.", "generated": "This function checks if the user has a passphrase and returns it to be used in an anonymous shell script that is executed by chpasswd . It also performs some other actions such as checking for changes made on disk or changing passwords from one account to another using ssh keys provided with this command line tool (see below)."}
{"id": 5399, "code": "func parseGroup(row string) (*Group, error) {\n\tfields := strings.Split(row, \":\")\n\tif len(fields) != 4 {\n\t\treturn nil, rowError{_GROUP_FILE, row}\n\t}\n\n\tgid, err := strconv.Atoi(fields[2])\n\tif err != nil {\n\t\treturn nil, atoiError{_GROUP_FILE, row, \"GID\"}\n\t}\n\n\treturn &Group{\n\t\tName:     fields[0],\n\t\tpassword: fields[1],\n\t\tGID:      gid,\n\t\tUserList: strings.Split(fields[3], \",\"),\n\t}, nil\n}", "reference": "// parseGroup parses the row of a group.", "generated": "// This function returns a list of all the groups in the group and its members (in this case, each member is an array). The returned values are sorted by their number from 0 to 1 inclusive.\n // If there were no more than one or two entries for any given field, it will return None if none"}
{"id": 5450, "code": "func (c *CallService) Create(ctx context.Context, data url.Values) (*Call, error) {\n\tcall := new(Call)\n\terr := c.client.CreateResource(ctx, callsPathPart, data, call)\n\treturn call, err\n}", "reference": "// Initiate a new Call.", "generated": "This method creates a Call service and returns an instance of the Service object that implements its methods as described in this section. The returned resource is created by calling C#::create() . This function will return nil if no resources are available for creation or destruction at runtime. If there is one such Resource , it must be"}
{"id": 5453, "code": "func (c *CallService) GetNextCallsInRange(start time.Time, end time.Time, nextPageURI string) CallPageIterator {\n\tif nextPageURI == \"\" {\n\t\tpanic(\"nextpageuri is empty\")\n\t}\n\titer := NewNextPageIterator(c.client, callsPathPart)\n\titer.SetNextPageURI(types.NullString{Valid: true, String: nextPageURI})\n\treturn &callDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetNextCallsInRange retrieves the page at the nextPageURI and continues\n// retrieving pages until any results are found in the range given by start or\n// end, or we determine there are no more records to be found in that range.\n//\n// If CallPage is non-nil, it will have at least one result.", "generated": "This method returns a new call to the callback function that will be called when an element of this array has been created or updated by calling its methods in range() . The returned value should not contain any special characters and may only refer back directly at runtime if it contains no character sequences other than those specified for each field name"}
{"id": 5455, "code": "func (c *CallService) GetRecordingsIterator(callSid string, data url.Values) *RecordingPageIterator {\n\tif data == nil {\n\t\tdata = url.Values{}\n\t}\n\t// Cheat - hit the Recordings list view with a filter instead of\n\t// GET /calls/CA123/Recordings. The former is probably more reliable\n\tdata.Set(\"CallSid\", callSid)\n\treturn c.client.Recordings.GetPageIterator(data)\n}", "reference": "// GetRecordings returns an iterator of recording pages for this Call.\n// Note there may be more than one Page of results.", "generated": "This method returns an iterator that iterates over all records in the Call service and compares them against each other to determine if they match or not. It also checks for duplicate calls from within this collection by checking whether there are any duplicates on record as well; otherwise, it will return null . Note that when calling C"}
{"id": 5461, "code": "func (r *KeyService) Delete(ctx context.Context, sid string) error {\n\treturn r.client.DeleteResource(ctx, keyPathPart, sid)\n}", "reference": "// Delete the Key with the given sid. If the Key has already been\n// deleted, or does not exist, Delete returns nil. If another error or a\n// timeout occurs, the error is returned.", "generated": "delete returns a new resource that is deleted from the client's cache and returned to the server for further processing by calling delete . The return value of delete will be null if no other resources were found in the session or nil otherwise used as an argument when returning. It also provides access back to any existing cached objects created with"}
{"id": 5462, "code": "func (a *AlertService) GetAlertsInRange(start time.Time, end time.Time, data url.Values) AlertPageIterator {\n\tif start.After(end) {\n\t\tpanic(\"start date is after end date\")\n\t}\n\td := url.Values{}\n\tif data != nil {\n\t\tfor k, v := range data {\n\t\t\td[k] = v\n\t\t}\n\t}\n\td.Del(\"Page\") // just in case\n\tif start != Epoch {\n\t\tstartFormat := start.UTC().Format(time.RFC3339)\n\t\td.Set(\"StartDate\", startFormat)\n\t}\n\tif end != HeatDeath {\n\t\t// If you specify \"StartTime<=YYYY-MM-DD\", the *latest* result returned\n\t\t// will be midnight (the earliest possible second) on DD. We want all\n\t\t// of the results for DD so we need to specify DD+1 in the API.\n\t\t//\n\t\t// TODO validate midnight-instant math more closely, since I don't think\n\t\t// Twilio returns the correct results for that instant.\n\t\tendFormat := end.UTC().Format(time.RFC3339)\n\t\td.Set(\"EndDate\", endFormat)\n\t}\n\titer := NewPageIterator(a.client, d, alertPathPart)\n\treturn &alertDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetAlertsInRange gets an Iterator containing conferences in the range\n// [start, end), optionally further filtered by data. GetAlertsInRange\n// panics if start is not before end. Any date filters provided in data will\n// be ignored. If you have an end, but don't want to specify a start, use\n// twilio.Epoch for start. If you have a start, but don't want to specify an\n// end, use twilio.HeatDeath for end.\n//\n// Assumes that Twilio returns resources in chronological order, latest\n// first. If this assumption is incorrect, your results will not be correct.\n//\n// Returned AlertPages will have at most PageSize results, but may have fewer,\n// based on filtering.", "generated": "The following example creates a new page with an updated timestamp and some information about its status as well AsyncResponse :\nfunc (b *Alert Service ) CreateNewPage() { var err errorMsg string, response []string{\"Error\"}\n\u0011 if b == null || !err && errors.ExpectedErrors"}
{"id": 5466, "code": "func (d Direction) Friendly() string {\n\tswitch d {\n\tcase DirectionOutboundReply:\n\t\treturn \"Reply\"\n\tcase DirectionOutboundCall:\n\t\treturn \"Outgoing (from call)\"\n\tcase DirectionOutboundAPI:\n\t\treturn \"Outgoing (from API)\"\n\tcase DirectionInbound:\n\t\treturn \"Incoming\"\n\tcase DirectionOutboundDial:\n\t\treturn \"Outgoing (via Dial)\"\n\tcase DirectionTrunkingTerminating:\n\t\treturn \"Trunking (terminating)\"\n\tcase DirectionTrunkingOriginating:\n\t\treturn \"Trunking (originating)\"\n\tdefault:\n\t\treturn string(d)\n\t}\n}", "reference": "// Friendly prints out a friendly version of the Direction, following the\n// example shown in the Twilio Dashboard.", "generated": "// This function is used to send a message from the client. It returns nil if it doesn't exist, or an error code of 0 otherwise // and return nil for any errors encountered by the server in this case; see below on how to handle exceptions that are thrown when sending messages via UDP/HTTP status codes #"}
{"id": 5468, "code": "func (m *MessageService) GetPage(ctx context.Context, data url.Values) (*MessagePage, error) {\n\titer := m.GetPageIterator(data)\n\treturn iter.Next(ctx)\n}", "reference": "// GetPage returns a single page of resources. To retrieve multiple pages, use\n// GetPageIterator.", "generated": "This method returns a new MessageService instance that implements the following methods and provides an interface to getPage() :\nMethods Description GET Page Return Response from message service for which this is not available or nil if no response was received by request body . POST Page Return Response returned as JSON string with status code 200 OK , otherwise"}
{"id": 5470, "code": "func (c *MessageService) GetNextMessagesInRange(start time.Time, end time.Time, nextPageURI string) MessagePageIterator {\n\tif nextPageURI == \"\" {\n\t\tpanic(\"nextpageuri is empty\")\n\t}\n\titer := NewNextPageIterator(c.client, messagesPathPart)\n\titer.SetNextPageURI(types.NullString{Valid: true, String: nextPageURI})\n\treturn &messageDateIterator{\n\t\tstart: start,\n\t\tend:   end,\n\t\tp:     iter,\n\t}\n}", "reference": "// GetNextMessagesInRange retrieves the page at the nextPageURI and continues\n// retrieving pages until any results are found in the range given by start or\n// end, or we determine there are no more records to be found in that range.\n//\n// If MessagePage is non-nil, it will have at least one result.", "generated": "// This method returns a new message for the current page URI and an iterator of all pages in range to return it if any are missing or not present.\n // The returned value should be nil otherwise this will fail with no response from client as well since there was already some pending data on that server's network connection being"}
{"id": 5486, "code": "func (r *ApplicationService) Delete(ctx context.Context, sid string) error {\n\treturn r.client.DeleteResource(ctx, applicationPathPart, sid)\n}", "reference": "// Delete the Application with the given sid. If the Application has already been\n// deleted, or does not exist, Delete returns nil. If another error or a\n// timeout occurs, the error is returned.", "generated": "delete returns a new Resource object that contains the specified resource and its associated ID number in hexadecimal format for use with applications running on Windows Server 2008 R2 or later operating systems as well Async operations are performed by calling delete() . The returned value is an instance of ApplicationServices , which implements RPC methods to"}
{"id": 5490, "code": "func (ipn *IncomingNumberService) BuyNumber(phoneNumber string) (*IncomingPhoneNumber, error) {\n\tdata := url.Values{\"PhoneNumber\": []string{phoneNumber}}\n\treturn ipn.NumberPurchasingService.Create(context.Background(), data)\n}", "reference": "// BuyNumber attempts to buy the provided phoneNumber and returns it if\n// successful.", "generated": ""}
{"id": 5517, "code": "func (m *Messenger) DeleteGetStartedButton() error {\n\tresult, err := m.changeThreadSettings(http.MethodDelete, &threadSettings{\n\t\tType:  settingTypeCallToActions,\n\t\tState: threadStateNew,\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\tif result.Result != \"Successfully deleted all new_thread's CTAs\" {\n\t\treturn fmt.Errorf(\"Error occured while deleting get started button, invalid result: %s\", result.Result)\n\t}\n\treturn nil\n}", "reference": "// DeleteGetStartedButton delets a button set by SetGetStartedButton", "generated": "// This method deletes the current queue of threads and returns a list of newly created ones that are not already in use by this user.\n // The delete operation is performed on each existing one before returning it to its caller for further processing.\n\n\n/**\n* Returns an array containing information about how many times these"}
{"id": 5523, "code": "func pushNumberValue(L *lua.State, a interface{}, t1, t2 reflect.Type) {\n\tv := reflect.ValueOf(a)\n\tisComplex := unsizedKind(v) == reflect.Complex128\n\tmt := cNumberMeta\n\tif isComplex {\n\t\tmt = cComplexMeta\n\t}\n\tif t1 == t2 || isPredeclaredType(t2) {\n\t\tmakeValueProxy(L, v.Convert(t1), mt)\n\t} else if isPredeclaredType(t1) {\n\t\tmakeValueProxy(L, v.Convert(t2), mt)\n\t} else if isComplex {\n\t\tcomplexType := reflect.TypeOf(0i)\n\t\tmakeValueProxy(L, v.Convert(complexType), cComplexMeta)\n\t} else {\n\t\tL.PushNumber(valueToNumber(L, v))\n\t}\n}", "reference": "// pushNumberValue pushes the number resulting from an arithmetic operation.\n//\n// At least one operand must be a proxy for this function to be called. See the\n// main documentation for the conversion rules.", "generated": "The Push Number Value Proxy function returns the number of elements in the string to be pushed into the buffer using an unary operator (or any other non-negative integer). The value returned by this method must not contain more than one element at a time and may only have two or more values per line depending on whether it"}
{"id": 5556, "code": "func (d *digest) Sum(in []byte) []byte {\n\ts := d.Sum64()\n\tin = append(in, byte(s))\n\tin = append(in, byte(s>>8))\n\tin = append(in, byte(s>>16))\n\tin = append(in, byte(s>>24))\n\tin = append(in, byte(s>>32))\n\tin = append(in, byte(s>>40))\n\tin = append(in, byte(s>>48))\n\tin = append(in, byte(s>>56))\n\treturn in\n}", "reference": "// Encode in little endian", "generated": "The sum function is a simple and efficient way to compute the number of bytes that are needed for an operation on a string or array using DigitMap . The result can be used as input into any operations such by calling digitsize , which returns either 0 if no data has been found at all times within this range"}
{"id": 5562, "code": "func FindPerformancePrice(productPackage datatypes.Product_Package, priceCategory string) (datatypes.Product_Item_Price, error) {\n\tfor _, item := range productPackage.Items {\n\t\tfor _, price := range item.Prices {\n\t\t\t// Only collect prices from valid location groups.\n\t\t\tif price.LocationGroupId != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif !hasCategory(price.Categories, priceCategory) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn price, nil\n\t\t}\n\t}\n\treturn datatypes.Product_Item_Price{}, bosherr.Error(\"Unable to find price for performance storage\")\n}", "reference": "// Find the price in the given package that has the specified category", "generated": "This function returns a list of all the available pricing information in an order that is consistent with its default value and provides some sort or other indication as to whether it should be used by any particular application on which this functionality may depend. The following example shows how one might use these functions if they were not provided explicitly at compile"}
{"id": 5571, "code": "func (o *OrderVMByFilterParams) WithBody(body *models.VMFilter) *OrderVMByFilterParams {\n\to.SetBody(body)\n\treturn o\n}", "reference": "// WithBody adds the body to the order Vm by filter params", "generated": "This method returns a new Order VM by filter parameters, which is used to create the order of all models in the model hierarchy and then return it as an object with its own setOf() methods that can be called from any other view or application using this API callbacks provided via Model::GetInstance(). The returned objects"}
{"id": 5572, "code": "func (c *FakeClient) Delete(instanceID string) error {\n\tc.DeleteCalled = true\n\treturn c.DeleteErr\n}", "reference": "// Delete deletes the instance settings for a given instance ID.", "generated": "This method deletes a client instance from the database and returns it to the caller for further processing, or if no such request is made by that user's server then calls delete() . The returned object will be deleted when called with an errno value of nil , which means any errors encountered during this call are not logged"}
{"id": 5599, "code": "func (o *UpdateVMWithStateParams) WithBody(body *models.VMState) *UpdateVMWithStateParams {\n\to.SetBody(body)\n\treturn o\n}", "reference": "// WithBody adds the body to the update Vm with state params", "generated": "This method is used to update the state of a model when it's created by using UpdateVMs() . It returns an object that contains all models in its current scope, and also provides methods for updating them with new states as needed or if they are not available at runtime. The following example shows how this can be"}
{"id": 5601, "code": "func (o *AddVMParams) WithTimeout(timeout time.Duration) *AddVMParams {\n\to.SetTimeout(timeout)\n\treturn o\n}", "reference": "// WithTimeout adds the timeout to the add Vm params", "generated": "// Add a new VMMapRequest object to the queue, and return an array of vmpars for each request that is received by this method // in order from start-to finish execution on all requests made with it until endof timeout .\n// This function returns nil if no response was returned or any errors"}
{"id": 5606, "code": "func (o *ListVMParams) WithContext(ctx context.Context) *ListVMParams {\n\to.SetContext(ctx)\n\treturn o\n}", "reference": "// WithContext adds the context to the list Vm params", "generated": "This method returns a list of VML parameters that are used to create the VM and return it as an object with all its properties set in one place, including any additional fields or methods defined by this class's constructor function callbacks . The returned objects will be passed along to other classes for further processing when they're created"}
{"id": 5626, "code": "func (pk PrivKeyLedgerSecp256k1) getPubKey() (key PubKey, err error) {\n\tdev, err := getLedger()\n\tif err != nil {\n\t\treturn key, fmt.Errorf(\"cannot connect to Ledger device - error: %v\", err)\n\t}\n\tkey, err = pubkeyLedgerSecp256k1(dev, pk.Path)\n\tif err != nil {\n\t\treturn key, fmt.Errorf(\"please open Cosmos app on the Ledger device - error: %v\", err)\n\t}\n\treturn key, err\n}", "reference": "// getPubKey reads the pubkey the ledger itself\n// since this involves IO, it may return an error, which is not exposed\n// in the PubKey interface, so this function allows better error handling", "generated": "// Create a new Key and create an encrypted private keyset for this session using CryptoNote's public API // This is used by all crypto-currencies that use it as their primary currency in order not be compromised or stolen from them; see https://githubusercontent/cryptonote/.\n#define KEY_KEY"}
{"id": 5656, "code": "func (kb dbKeybase) ImportPubKey(name string, armor string) (err error) {\n\tbz := kb.db.Get(infoKey(name))\n\tif len(bz) > 0 {\n\t\treturn errors.New(\"Cannot overwrite data for name \" + name)\n\t}\n\tpubBytes, err := unarmorPubKeyBytes(armor)\n\tif err != nil {\n\t\treturn\n\t}\n\tpubKey, err := crypto.PubKeyFromBytes(pubBytes)\n\tif err != nil {\n\t\treturn\n\t}\n\tkb.writeOfflineKey(pubKey, name)\n\treturn\n}", "reference": "// ImportPubKey imports ASCII-armored public keys.\n// Store a new Info object holding a public key only, i.e. it will\n// not be possible to sign with it as it lacks the secret key.", "generated": "// Create a new key base and store it in the database using an existing pubkey from this DB // with no additional information about its contents or any other details that might be needed to create one of these keys var bz = {}\n\n#Create two public bases on which we can use our own private Key Base if"}
{"id": 5660, "code": "func CompareHashAndPassword(hashedPassword, password []byte) error {\n\tp, err := newFromHash(hashedPassword)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\totherHash, err := bcrypt(password, p.cost, p.salt)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\totherP := &hashed{otherHash, p.salt, p.cost, p.major, p.minor}\n\tif subtle.ConstantTimeCompare(p.Hash(), otherP.Hash()) == 1 {\n\t\treturn nil\n\t}\n\n\treturn ErrMismatchedHashAndPassword\n}", "reference": "// CompareHashAndPassword compares a bcrypt hashed password with its possible\n// plaintext equivalent. Returns nil on success, or an error on failure.", "generated": "// Computes the hash of a given string and compares it against an existing Hash or Password that is available in both hashes (i..n).\n // The comparison can be performed on any input character as long *hashLength = 0xFFFFFFF . If no match exists for this value, then all characters are"}
{"id": 5696, "code": "func doDemangle(out *bufio.Writer, name string) {\n\tskip := 0\n\tif name[0] == '.' || name[0] == '$' {\n\t\tskip++\n\t}\n\tif *stripUnderscore && name[skip] == '_' {\n\t\tskip++\n\t}\n\tresult := demangle.Filter(name[skip:], options()...)\n\tif result == name[skip:] {\n\t\tout.WriteString(name)\n\t} else {\n\t\tif name[0] == '.' {\n\t\t\tout.WriteByte('.')\n\t\t}\n\t\tout.WriteString(result)\n\t}\n}", "reference": "// Demangle a string just as the GNU c++filt program does.", "generated": "// This function is used to filter out the characters that are not in a character set and return an error if they don't match any of the specified strings or nil otherwise // this will be called when no matching matches exist for all possible charsets (defaults). The default value is \"nil\".\n/**\n*"}
{"id": 5707, "code": "func (s *Sentinel) defaultPool(addr string) *redis.Pool {\n\treturn &redis.Pool{\n\t\tMaxIdle:     3,\n\t\tMaxActive:   10,\n\t\tWait:        true,\n\t\tIdleTimeout: 240 * time.Second,\n\t\tDial: func() (redis.Conn, error) {\n\t\t\treturn s.Dial(addr)\n\t\t},\n\t\tTestOnBorrow: func(c redis.Conn, t time.Time) error {\n\t\t\t_, err := c.Do(\"PING\")\n\t\t\treturn err\n\t\t},\n\t}\n}", "reference": "// defaultPool returns a connection pool to one Sentinel. This allows\n// us to call concurrent requests to Sentinel using connection Do method.", "generated": "default pools are used to store the pool's idlen and minidx of all transactions in a single transaction block for each txn that is sent or received by it. The IDL must be at least one byte long before any other data can get stored on them; this allows you not only access from within an"}
{"id": 5723, "code": "func (c *Client) CompareAndSwap(item *Item) error {\n\treturn c.populateOne(cmdSet, item, item.casid)\n}", "reference": "// CompareAndSwap writes the given item that was previously returned\n// by Get, if the value was neither modified or evicted between the\n// Get and the CompareAndSwap calls. The item's Key should not change\n// between calls but all other item fields may differ. ErrCASConflict\n// is returned if the value was modified in between the\n// calls. ErrNotStored is returned if the value was evicted in between\n// the calls.", "generated": "This method compares two items and swaps them for the same value in a swap operation using an array of strings to determine if they match or not. The returned result is either nil , which means that no matching element was found on any given string; otherwise it returns false . If both elements are matched then this function will return"}
{"id": 5736, "code": "func Ticker(ticker <-chan time.Time, procfunc gp.ProcessFunc) gp.Process {\n\treturn gp.Go(callOnTicker(ticker, procfunc))\n}", "reference": "// Ticker calls the given ProcessFunc every time the ticker fires.\n// This is sequentially rate limited, only one call will be in-flight at a time.", "generated": "This function is used to create a new tiddler that will be displayed when the user clicks on it and then displays an error message if there are any errors in this file or dialog box (if they exist). It also creates two additional fields for each of these field types which can contain information about what type of input was"}
{"id": 5746, "code": "func (a *API) FetchCheck(cid CIDType) (*Check, error) {\n\tif cid == nil || *cid == \"\" {\n\t\treturn nil, fmt.Errorf(\"Invalid check CID [none]\")\n\t}\n\n\tcheckCID := string(*cid)\n\n\tmatched, err := regexp.MatchString(config.CheckCIDRegex, checkCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !matched {\n\t\treturn nil, fmt.Errorf(\"Invalid check CID [%s]\", checkCID)\n\t}\n\n\tresult, err := a.Get(checkCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] fetch check, received JSON: %s\", string(result))\n\t}\n\n\tcheck := new(Check)\n\tif err := json.Unmarshal(result, check); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn check, nil\n}", "reference": "// FetchCheck retrieves check with passed cid.", "generated": "Fetch checks the specified API key for an object of type Check . The returned value is either None or one of two values depending on whether it was provided by this method in its initializer call to f() , if not supplied then return null and returns undefined otherwise. If no such request has been made with any given"}
{"id": 5747, "code": "func (a *API) FetchChecks() (*[]Check, error) {\n\tresult, err := a.Get(config.CheckPrefix)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar checks []Check\n\tif err := json.Unmarshal(result, &checks); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &checks, nil\n}", "reference": "// FetchChecks retrieves all checks available to the API Token.", "generated": "Fuzzy-checking is an API that allows you to check the status of your application's configuration file and provide it with information about its state before performing any action on this request or response in order for other requests to be processed by another process within their scope. It can also allow users to perform actions such as fetch"}
{"id": 5752, "code": "func (a *API) FetchGraph(cid CIDType) (*Graph, error) {\n\tif cid == nil || *cid == \"\" {\n\t\treturn nil, fmt.Errorf(\"Invalid graph CID [none]\")\n\t}\n\n\tgraphCID := string(*cid)\n\n\tmatched, err := regexp.MatchString(config.GraphCIDRegex, graphCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif !matched {\n\t\treturn nil, fmt.Errorf(\"Invalid graph CID [%s]\", graphCID)\n\t}\n\n\tresult, err := a.Get(graphCID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] fetch graph, received JSON: %s\", string(result))\n\t}\n\n\tgraph := new(Graph)\n\tif err := json.Unmarshal(result, graph); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn graph, nil\n}", "reference": "// FetchGraph retrieves graph with passed cid.", "generated": "Fuzzy Graph is an API that provides easy to use and fast way of querying the data in your application using SQLite3 or other database engines such as MongoDB/SQL Server for queries on multiple databases at once with no needlessly complex query parameters like \"SELECT id FROM user WHERE name = 'John Doe"}
{"id": 5786, "code": "func (a *API) FetchAnnotations() (*[]Annotation, error) {\n\tresult, err := a.Get(config.AnnotationPrefix)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar annotations []Annotation\n\tif err := json.Unmarshal(result, &annotations); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &annotations, nil\n}", "reference": "// FetchAnnotations retrieves all annotations available to the API Token.", "generated": "Fuzzy-matching is an important feature of the API and can be used to identify common errors in your code that may occur when using fuzzy matching for annotation information or other data types such as strings/strings etc.. The following examples show how this functionality works with JSON objects which are not supported by Swift's standard"}
{"id": 5815, "code": "func (m *CirconusMetrics) NewHistogram(metric string) *Histogram {\n\tm.hm.Lock()\n\tdefer m.hm.Unlock()\n\n\tif hist, ok := m.histograms[metric]; ok {\n\t\treturn hist\n\t}\n\n\thist := &Histogram{\n\t\tname: metric,\n\t\thist: circonusllhist.New(),\n\t}\n\n\tm.histograms[metric] = hist\n\n\treturn hist\n}", "reference": "// NewHistogram returns a histogram instance.", "generated": "This function returns a new histogram of the current time and an array containing all known historical events that occurred in this period or any other event during which it was recorded as such by CIRCONUS MetadataManager .\nThe returned list is then sorted into ascending order based on its length; for example, if there"}
{"id": 5847, "code": "func (a *API) CreateRuleSet(cfg *RuleSet) (*RuleSet, error) {\n\tif cfg == nil {\n\t\treturn nil, fmt.Errorf(\"Invalid rule set config [nil]\")\n\t}\n\n\tjsonCfg, err := json.Marshal(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] create rule set, sending JSON: %s\", string(jsonCfg))\n\t}\n\n\tresp, err := a.Post(config.RuleSetPrefix, jsonCfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\truleset := &RuleSet{}\n\tif err := json.Unmarshal(resp, ruleset); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn ruleset, nil\n}", "reference": "// CreateRuleSet creates a new rule set.", "generated": "// This is an implementation-defined interface for creating and managing Rule Sets in the API. It provides methods to manage Rulesets that are created by calling `CreateRuleSet` with no parameters or returning null if they were not specified as arguments. // The default value of this method will be used when setting up new policies"}
{"id": 5860, "code": "func (a *API) DeleteWorksheet(cfg *Worksheet) (bool, error) {\n\tif cfg == nil {\n\t\treturn false, fmt.Errorf(\"Invalid worksheet config [nil]\")\n\t}\n\treturn a.DeleteWorksheetByCID(CIDType(&cfg.CID))\n}", "reference": "// DeleteWorksheet deletes passed worksheet.", "generated": "// Create an API for deleting the specified files from the Worksheets and returning them as JSON objects to be used in future calls.\n // This method is called when creating new APIs or updating existing ones using `delete`.\n// The default behavior of this function will return true if no changes have been made since creation"}
{"id": 5865, "code": "func (a *API) CreateContactGroup(cfg *ContactGroup) (*ContactGroup, error) {\n\tif cfg == nil {\n\t\treturn nil, fmt.Errorf(\"Invalid contact group config [nil]\")\n\t}\n\n\tjsonCfg, err := json.Marshal(cfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif a.Debug {\n\t\ta.Log.Printf(\"[DEBUG] create contact group, sending JSON: %s\", string(jsonCfg))\n\t}\n\n\tresult, err := a.Post(config.ContactGroupPrefix, jsonCfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tgroup := &ContactGroup{}\n\tif err := json.Unmarshal(result, group); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn group, nil\n}", "reference": "// CreateContactGroup creates a new contact group.", "generated": "// Initializes the Contact Group and sends an initial message to all contacts in the list of selected groups for each profile that is created by this method. This will be used as part \"Initialize\" if no profiles are found within it or any other settings have been set up before calling func() { // Set some default"}
{"id": 5890, "code": "func NewEllipticSigner(alg Algorithm, curve elliptic.Curve) func(Store, crypto.Hash) (Signer, error) {\n\tcurveBitSize := curve.Params().BitSize\n\n\t// precompute curve key len\n\tkeyLen := curveBitSize / 8\n\tif curveBitSize%8 > 0 {\n\t\tkeyLen++\n\t}\n\n\treturn func(store Store, hash crypto.Hash) (Signer, error) {\n\t\tvar ok bool\n\t\tvar privRaw, pubRaw interface{}\n\t\tvar priv *ecdsa.PrivateKey\n\t\tvar pub *ecdsa.PublicKey\n\n\t\t// check private key\n\t\tif privRaw, ok = store.PrivateKey(); ok {\n\t\t\tif priv, ok = privRaw.(*ecdsa.PrivateKey); !ok {\n\t\t\t\treturn nil, ErrInvalidPrivateKey\n\t\t\t}\n\n\t\t\t// check curve type matches private key curve type\n\t\t\tif curveBitSize != priv.Curve.Params().BitSize {\n\t\t\t\treturn nil, ErrInvalidPrivateKeySize\n\t\t\t}\n\t\t}\n\n\t\t// check public key\n\t\tif pubRaw, ok = store.PublicKey(); ok {\n\t\t\tif pub, ok = pubRaw.(*ecdsa.PublicKey); !ok {\n\t\t\t\treturn nil, ErrInvalidPublicKey\n\t\t\t}\n\t\t}\n\n\t\t// check that either a private or public key has been provided\n\t\tif priv == nil && pub == nil {\n\t\t\treturn nil, ErrMissingPrivateOrPublicKey\n\t\t}\n\n\t\treturn &EccSigner{\n\t\t\talg:    alg,\n\t\t\tcurve:  curve,\n\t\t\thash:   hash,\n\t\t\tpriv:   priv,\n\t\t\tpub:    pub,\n\t\t\tkeyLen: keyLen,\n\t\t}, nil\n\t}\n}", "reference": "// NewEllipticSigner creates an Elliptic Curve Signer for the specified curve.", "generated": "This function checks the SHA256 and RSA keys of an encrypted file using AES-128 bit operations on each byte in its length to determine if it is valid for signing with this encryption algorithm as well; otherwise, returns false . The signature must be signed by both parties before being sent back through their respective servers via TLS/"}
{"id": 5907, "code": "func FromFile(path string, opts ...Option) (*GServiceAccount, error) {\n\tbuf, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn FromJSON(buf, opts...)\n}", "reference": "// FromFile loads Google service account credentials from a reader.", "generated": "This method returns a JSON object that contains the information about an account's name and password (in this case GServicesAccount). The following fields are optional; if omitted, it will be returned as null . If you omit them or want to return something more specific, use gserviceaccount-name instead of path , which"}
{"id": 5932, "code": "func PostEZCountTime(statName, ezkey string, count int, timestamp int64) error {\n\treturn DefaultReporter.PostEZCountTime(statName, ezkey, count, timestamp)\n}", "reference": "// Using the EZ API, posts a count to a stat at a specific time using DefaultReporter.", "generated": "This method returns the time of a post-mortem for each epoch in which it was recorded by an observer (e., if there is one). It also provides information about when and where to record this event on disk or memory devices that are not connected via serial communication with other observers; see below . The following example shows"}
{"id": 5952, "code": "func (s Scan) AddHosts(hosts ...string) Scan {\n\ts.configHosts = append(s.configHosts, hosts...)\n\treturn s\n}", "reference": "// AddHosts adds a list of hosts to the list of hosts to be scanned", "generated": "This method adds a host to the list of available Host objects and returns an array containing all known names for that object in addition any aliases or other information about it such as its name/value pair etc. The returned Array is then passed back through this function which will be called when we run our program again with new entries"}
{"id": 5955, "code": "func (s Scan) SetPorts(ports ...uint16) Scan {\n\ts.configPorts = ports\n\treturn s\n}", "reference": "// SetPorts sets the ports that wil be used", "generated": "This method sets the port to be used for scanning purposes, and returns a list of all available options that can then be passed as arguments in an array or string format using SscanOptions . The default is nil , which means no scan will take place if there are any errors encountered during this operation. This function also checks"}
{"id": 5964, "code": "func (otp HOTP) Counter() uint64 {\n\tcounter := binary.BigEndian.Uint64(otp.counter[:])\n\treturn counter\n}", "reference": "// Counter returns the HOTP's 8-byte counter as an unsigned 64-bit\n// integer.", "generated": "This function returns the number of bytes in the hash table, and compares it against a string representation that is not an integer or floating point value to determine if there are any differences between them. The result will be returned as 0xFFFFFFF . If no difference exists then this method does not return true , but instead"}
{"id": 5967, "code": "func (otp *HOTP) URL(label string) string {\n\tsecret := base32.StdEncoding.EncodeToString(otp.Key)\n\tu := url.URL{}\n\tv := url.Values{}\n\tu.Scheme = \"otpauth\"\n\tu.Host = \"hotp\"\n\tu.Path = label\n\tv.Add(\"secret\", secret)\n\tv.Add(\"counter\", fmt.Sprintf(\"%d\", otp.Counter()))\n\tu.RawQuery = v.Encode()\n\treturn u.String()\n}", "reference": "// URL returns a suitable URL, such as for the Google Authenticator\n// app. The label is used by these apps to identify the service to\n// which this OTP belongs. The digits value is ignored by the Google\n// authenticator app, and is therefore elided in the resulting URL.", "generated": "OAUTH2QLServer is a TLS server that provides authenticated access to the web interface of an OAuth 2 client and allows for authentication using any key-value pair, including those provided by other protocols such as RSA or ECDSA . The protocol uses two keys in order from most common values (\"key\") to"}
{"id": 5975, "code": "func Marshal(otp *HOTP) ([]byte, error) {\n\tvar asnHOTP struct {\n\t\tKey     []byte\n\t\tCounter *big.Int\n\t\tDigits  int\n\t}\n\tasnHOTP.Key = otp.Key[:]\n\tasnHOTP.Counter = new(big.Int).SetUint64(otp.Counter())\n\tasnHOTP.Digits = otp.Digits\n\treturn asn1.Marshal(asnHOTP)\n}", "reference": "// Marshal serialises an HOTP key value as a DER-encoded byte slice.", "generated": "This function returns a string representation of the hash table for an HASHTABLE object that contains all keys and values in the key-value pair specified by this HashTable . The returned value is then used to store data on subsequent calls with other functions or methods from within it's implementation using its own method call interface which can"}
{"id": 5981, "code": "func (pool *ReaderPool) Get(r io.Reader) (reader io.Reader, release func()) {\n\t// don't export a ThrottlerReader to prevent users changing the rate\n\t// and expecting their change to be respected, since we might modify\n\t// the rate under their feet\n\n\t// make the initial rate be 0, the actual rate is\n\t// set in the call to `setSharedRates`.\n\trd := ThrottledReader(r, 0, pool.maxBurst)\n\n\tpool.mu.Lock()\n\tpool.givenOut[rd] = struct{}{}\n\tpool.setSharedRates()\n\tpool.mu.Unlock()\n\n\treturn rd, func() {\n\t\tpool.mu.Lock()\n\t\tdelete(pool.givenOut, rd)\n\t\tpool.setSharedRates()\n\t\tpool.mu.Unlock()\n\t}\n}", "reference": "// Get a throttled reader that wraps r.", "generated": "The following example creates an anonymous stream of bytes that can only contain one byte at time when it's read from disk or written out by another process on port 8080 using this method. The resulting output will not have any errors because no error messages are generated for each operation performed with these methods until all operations were completed successfully"}
{"id": 6002, "code": "func JsonFile(path string) (Typed, error) {\n\tdata, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn Json(data)\n}", "reference": "// Create a Typed helper from the JSON within a file", "generated": "JSONFile is a file system program that provides the following features to Java applications and other programs written in C++ or Objective-C languages such as Go/JavaScript. It supports both standard input files for writing code using native bytecode objects like strings , arrays of bytes , etc., but also includes support for custom"}
{"id": 6018, "code": "func (t Typed) TimeMust(key string) time.Time {\n\ttt, exists := t.TimeIf(key)\n\tif exists == false {\n\t\tpanic(\"expected time.Time value for \" + key)\n\t}\n\treturn tt\n}", "reference": "// Returns a time.Time or panics", "generated": "// This function returns the current date and times of a given type in milliseconds or seconds depending on whether it is an integer representation or not. It also provides some information about how long to wait before returning if there are any errors encountered during processing such as missing data from memory due backtrace etc.. // The default behavior when"}
{"id": 6025, "code": "func (t Typed) BoolsOr(key string, d []bool) []bool {\n\tn, ok := t.BoolsIf(key)\n\tif ok {\n\t\treturn n\n\t}\n\treturn d\n}", "reference": "// Returns an slice of boolean, or the specified slice", "generated": "This function returns a list of strings that are either true or false if the key is not found in any given dictionary and return nil otherwise. The returned value will be an array containing all keys from each pair to which it was added by calling bool() . If no pairs were specified for this method, then only one"}
{"id": 6037, "code": "func NewWorker(logger log.Logger, db *reform.DB, ethBack eth.Backend,\n\tgasConc *GasConf, pscAddr common.Address, payAddr string,\n\tpwdGetter data.PWDGetter, countryConf *country.Config,\n\tdecryptKeyFunc data.ToPrivateKeyFunc, eptConf *ept.Config,\n\ttorHostname string, somcClientBuilder somc.ClientBuilderInterface) (*Worker, error) {\n\n\tl := logger.Add(\"type\", \"proc/worker.Worker\")\n\n\tabi, err := abi.JSON(\n\t\tstrings.NewReader(contract.PrivatixServiceContractABI))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\teptService, err := ept.New(db, logger, payAddr, eptConf.Timeout)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &Worker{\n\t\tabi:               abi,\n\t\tlogger:            l,\n\t\tdb:                db,\n\t\tdecryptKeyFunc:    decryptKeyFunc,\n\t\tgasConf:           gasConc,\n\t\tept:               eptService,\n\t\tethBack:           ethBack,\n\t\tpscAddr:           pscAddr,\n\t\tpwdGetter:         pwdGetter,\n\t\tcountryConfig:     countryConf,\n\t\ttorHostName:       data.FromBytes([]byte(torHostname)),\n\t\tsomcClientBuilder: somcClientBuilder,\n\t}, nil\n}", "reference": "// NewWorker returns new instance of worker.", "generated": "// Create a new worker for the specified type of work. This is used to create an instance of Worker and return it as its first argument in // this method call. The default value will be `new`. Parameters :type , id , name ) Description Example:\nvar bb = require('branch'); var"}
{"id": 6089, "code": "func AddWithDelay(q Queue, tx *reform.TX,\n\tjobType, relatedType, relatedID, creator string,\n\tdelay time.Duration) error {\n\treturn AddWithDataAndDelay(q, tx,\n\t\tjobType, relatedType, relatedID, creator, &struct{}{}, delay)\n}", "reference": "// AddWithDelay is convenience method to add a job with given data delay.", "generated": "Adds a new queue to the specified timeline and returns an updated list of queued events for that event type (see below). The following example creates two queues with different IDs in order from oldest one to newest; each has its own unique ID which is used as part thereof by other threads when creating them on their respective timelines"}
{"id": 6115, "code": "func NewFileLogger(conf *FileConfig) (Logger, io.Closer, error) {\n\tnow := time.Now()\n\tif conf.UTC {\n\t\tnow = now.UTC()\n\t}\n\n\tfile, err := os.OpenFile(\n\t\ttimeutil.Strftime(&now, conf.Filename),\n\t\tos.O_APPEND|os.O_CREATE|os.O_WRONLY, conf.FileMode)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tlogger, err := NewWriterLogger(conf.WriterConfig, file)\n\tif err != nil {\n\t\tfile.Close()\n\t\treturn nil, nil, err\n\t}\n\n\treturn logger, file, nil\n}", "reference": "// NewFileLogger creates a new file logger.", "generated": "New File Logging provides a new logging mechanism for the loggers that are used to create and manage files in Windows Vista/7 operating systems using Microsoft's System Information Management Service or SIS-based services such as MSI Services . The following sections describe how this functionality is implemented by default on all of these platforms;"}
{"id": 6138, "code": "func (b *backendInstance) EthBalanceAt(ctx context.Context,\n\towner common.Address) (*big.Int, error) {\n\tctx2, cancel := b.addTimeout(ctx)\n\tdefer cancel()\n\n\treturn b.conn.ethClient().BalanceAt(ctx2, owner, nil)\n}", "reference": "// EthBalanceAt returns the wei balance of the given account.", "generated": "This method returns a new instance of the eth balance at which to store and exchange funds in an address space that is not currently available for use by any other user or entity on this network interface. The ether balances are stored as uint256-encoded strings with no padding required; they can be used only when using public"}
{"id": 6147, "code": "func (w *Worker) keyFromChannelData(logger log.Logger,\n\tchannel string) (data.Base64String, error) {\n\tch, err := w.channel(logger, channel)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\toffering, err := w.offering(logger, ch.Offering)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tkey, err := data.ChannelKey(ch.Client, ch.Agent,\n\t\tch.Block, offering.Hash)\n\t// internal\n\tif err != nil {\n\t\tlogger.Add(\"channel\", ch, \"offering\", offering).Error(err.Error())\n\t\treturn \"\", ErrInternal\n\t}\n\treturn data.FromBytes(key), nil\n}", "reference": "// keyFromChannelData returns the unique channel identifier\n// used in a Privatix Service Contract.", "generated": "This function returns a new instance of the Worker class that implements Key from Channel Data . The returned object is an array containing all channels and their associated keys in order to be used as input for this method. This implementation does not support any other methods or functions which return objects with no parameters at runtime such like Keys , Returns"}
{"id": 6157, "code": "func (w *Worker) AgentAfterOfferingDelete(job *data.Job) error {\n\tlogger := w.logger.Add(\n\t\t\"method\", \"AgentAfterOfferingDelete\", \"job\", job)\n\n\toffering, err := w.relatedOffering(\n\t\tlogger, job, data.JobAgentAfterOfferingDelete)\n\tif err != nil {\n\t\treturn err\n\t}\n\toffering.Status = data.OfferRemoved\n\n\tif err := w.saveRecord(logger, w.db.Querier, offering); err != nil {\n\t\treturn err\n\t}\n\n\tagent, err := w.account(logger, offering.Agent)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn w.addJob(logger, nil,\n\t\tdata.JobAccountUpdateBalances, data.JobAccount, agent.ID)\n}", "reference": "// AgentAfterOfferingDelete set offering status to `remove`", "generated": "// This method is used to update the account balance of an existing Job object and return a new instance of that Worker .\n // The callback function returns all instances in this worker's database for which it has been called; if any are not available they will be deleted from the current thread or removed by default. func main"}
{"id": 6177, "code": "func (m *Monitor) VerifyChannelsForInactivity() error {\n\tquery := `\n              SELECT channels.id::text\n\t\tFROM channels\n                     LEFT JOIN sessions ses\n                     ON channels.id = ses.channel\n                     LEFT JOIN offerings offer\n                     ON channels.offering = offer.id\n                     INNER JOIN accounts acc\n                     ON channels.agent = acc.eth_addr\n               WHERE channels.service_status IN ('pending', 'active', 'suspended')\n                 AND channels.channel_status NOT IN ('pending')\n                 AND acc.in_use\n               GROUP BY channels.id, offer.max_inactive_time_sec\n              HAVING GREATEST(MAX(ses.last_usage_time), channels.service_changed_time) +\n\t      (offer.max_inactive_time_sec * INTERVAL '1 second') < now();`\n\n\treturn m.processEachChannel(query, m.terminateService)\n}", "reference": "// VerifyChannelsForInactivity scans all channels, that are not terminated,\n// and terminates those of them, who are staying inactive too long.", "generated": "This function checks if the channel is active and returns true or false for each service status in a list of available services that are currently running on an account with no current user privileges to verify their availability as well As described above it will also check whether any other users have been added by this method since they were created using these"}
{"id": 6235, "code": "func New(db *reform.DB, logger log.Logger, payAddr string,\n\ttimeout uint) (*Service, error) {\n\treturn &Service{\n\t\tdb:      db,\n\t\tmsgChan: make(chan *req),\n\t\tpayAddr: payAddr,\n\t\ttimeout: time.Duration(timeout) * time.Millisecond,\n\t\tlogger:  logger.Add(\"type\", \"messages/ept.Service\"),\n\t}, nil\n}", "reference": "// New function for initialize the service for generating\n// the Endpoint Message.", "generated": "New(new Service(), new PayAddrs(), callback() {})\n\n/**\n* Returns a service object that implements the interface of an existing API and returns its type or null if no such instance exists for any reason.\n*/ // This method is deprecated in favor to use `service` instead. func main"}
{"id": 6244, "code": "func BytesToUint32(b []byte) (uint32, error) {\n\tif len(b) != 4 {\n\t\treturn 0, fmt.Errorf(\"wrong len\")\n\t}\n\treturn binary.BigEndian.Uint32(b), nil\n}", "reference": "// BytesToUint32 using big endian.", "generated": "This method returns a byte array of bytes representing the number and length of an unsigned integer in UINT64 format using uint32 as its input value. The resulting string is then converted to int16 by calling ByteStringBuilder . If no such conversion occurs, it will be returned with zero or more bits for each bit"}
{"id": 6251, "code": "func ChannelKey(client, agent HexString, block uint32,\n\tofferingHash HexString) ([]byte, error) {\n\tclientAddr, err := HexToAddress(client)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tagentAddr, err := HexToAddress(agent)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\thash, err := base64.URLEncoding.DecodeString(\n\t\tstrings.TrimSpace(string(offeringHash)))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tblockBytes := Uint32ToBytes(block)\n\n\treturn crypto.Keccak256(clientAddr.Bytes(),\n\t\tagentAddr.Bytes(), blockBytes[:],\n\t\tcommon.BytesToHash(hash).Bytes()), nil\n}", "reference": "// ChannelKey returns the unique channel identifier\n// used in a Privatix Service Contract.", "generated": "// This function is used to create a new channel key for the client and an address of that account in order notify it when receiving messages from clients using this method. // The following example uses two different channels with one being sent by each user on both sides; if there are no other users at all then they will"}
{"id": 6280, "code": "func PanicHunter() {\n\tif panicIgnore {\n\t\treturn\n\t}\n\n\tif err := recover(); err != nil {\n\t\tif enable && notifier != nil {\n\t\t\tnotifier.NotifySync(\n\t\t\t\terrors.New(err, 3), true,\n\t\t\t\tmetadata([]data.HexString{defaultAccEth}))\n\t\t}\n\t\tpanic(err)\n\t}\n}", "reference": "// PanicHunter catches panic, in case of an enabled reporter.", "generated": "// This function is used to notify the user if a specific event has occurred or failed in an attempt at logging on and/or receiving messages from their computer system (e., logon).\n // The default behavior of this method will be undefined when invoked with no error message received by any other process running under it;"}
{"id": 6291, "code": "func (m *Marshaller) MarshalRaw(bs []byte) {\n\tif m.Error != nil {\n\t\treturn\n\t}\n\tif len(m.Data) < m.offset+len(bs) {\n\t\tm.Error = io.ErrShortBuffer\n\t\treturn\n\t}\n\n\tm.offset += copy(m.Data[m.offset:], bs)\n}", "reference": "// MarshalRaw copies the raw bytes to the buffer, without a size prefix or\n// padding. This is suitable for appending data already in XDR format from\n// another source.", "generated": "// This method returns a string representation of the buffer that was used to store data in the marshal function, and is called when an error occurs while processing or writing bytes from it. The returned value will be stored as byte[] . // Note that this implementation does not support using raw buffers for read-only operations on"}
{"id": 6293, "code": "func (m *Marshaller) MarshalBytes(bs []byte) {\n\tif m.Error != nil {\n\t\treturn\n\t}\n\tif len(m.Data) < m.offset+4+len(bs)+Padding(len(bs)) {\n\t\tm.Error = io.ErrShortBuffer\n\t\treturn\n\t}\n\n\tm.MarshalUint32(uint32(len(bs)))\n\tm.offset += copy(m.Data[m.offset:], bs)\n\tm.offset += copy(m.Data[m.offset:], padBytes[:Padding(len(bs))])\n}", "reference": "// MarshalString appends the bytes to the buffer, with a size prefix and\n// correct padding.", "generated": "// This function returns a byte array of bytes that are the size and offset of the buffer in bytes, or an integer if no such length is specified by M.MutableByteArray.\n // The returned value should be either 0xFFFFFFF00 , which indicates zero-length buffers for this operation, as"}
{"id": 6308, "code": "func Prefix(prefix string, p AssetPipeline) AssetPipeline {\n\tif prefix == \"\" {\n\t\treturn p\n\t}\n\n\treturn &prefixPipeline{\n\t\tprefix:        prefix,\n\t\tAssetPipeline: p,\n\t}\n}", "reference": "// Prefix returns an AssetPipeline that prefixes URLs with the\n// given string", "generated": "// Initialize the pre-existing asset pipeline. This is a wrapper around `Prefix` and returns an array of all assets that are currently in use by this script.\n // The initializer will be called when it receives any new data from its parent node (i = 0).\n/**\n* A list"}
{"id": 6327, "code": "func Map(ss []string, callback func(string) string) []string {\n\tnewStrings := make([]string, len(ss))\n\tfor i, s := range ss {\n\t\tnewStrings[i] = callback(s)\n\t}\n\n\treturn newStrings\n}", "reference": "// Map returns a slice containing all the elements of ss\n// after applying the callback function to each one", "generated": "Map is a map with the following properties. It can be used to create an array of strings or arrays that contain any number and length values (e., nil ). The mapping method returns all elements in the given list as well if they are empty; otherwise, it will return null . This function takes two arguments:"}
{"id": 6383, "code": "func SelectMany(subject Enumerable, toMany Unfolder) Enumerable {\n\treturn selectManyer{\n\t\toriginal: subject,\n\t\ttoMany:   toMany,\n\t}\n}", "reference": "// SelectMany allows for unfolding of values.", "generated": "SelectMany is a method that returns an enumeration of all the objects in this collection. It can be used as follows:\n\n```selectManyer` creates and stores each object from its list into one or more collections with no additional information about it (e., `objectName`, `name`.). The returned"}
{"id": 6400, "code": "func (stack *Stack) IsEmpty() bool {\n\tstack.key.RLock()\n\tdefer stack.key.RUnlock()\n\treturn stack.underlyer == nil || stack.underlyer.IsEmpty()\n}", "reference": "// IsEmpty tests the Stack to determine if it is populate or not.", "generated": "This function is called when the value of the key in the Stack object has been removed from the heap, and if it does not return true , then returns false . If this fails, or a new instance of the KeySet was created with that name as its first argument, an error will be thrown on failure to create"}
{"id": 6407, "code": "func (list *LinkedList) Enumerate(cancel <-chan struct{}) Enumerator {\n\tretval := make(chan interface{})\n\n\tgo func() {\n\t\tlist.key.RLock()\n\t\tdefer list.key.RUnlock()\n\t\tdefer close(retval)\n\n\t\tcurrent := list.first\n\t\tfor current != nil {\n\t\t\tselect {\n\t\t\tcase retval <- current.payload:\n\t\t\t\tbreak\n\t\t\tcase <-cancel:\n\t\t\t\treturn\n\t\t\t}\n\t\t\tcurrent = current.next\n\t\t}\n\t}()\n\n\treturn retval\n}", "reference": "// Enumerate creates a new instance of Enumerable which can be executed on.", "generated": "The enumeration of the Linkable List is a simple, non-blocking operation that returns an iterator over all elements in the linked list and then iterates through them to find their corresponding element's key or value pair at any given time using either C++11::Key , Java#C++14::Value , OR"}
{"id": 6415, "code": "func (list *LinkedList) Sort(comparator Comparator) error {\n\tlist.key.Lock()\n\tdefer list.key.Unlock()\n\tvar err error\n\tlist.first, err = mergeSort(list.first, comparator)\n\tif err != nil {\n\t\treturn err\n\t}\n\tlist.last = findLast(list.first)\n\treturn err\n}", "reference": "// Sort rearranges the positions of the entries in this list so that they are\n// ascending.", "generated": "The MergeSort method returns a sorted List that contains all the elements of the given LinkedList . The returned items are then merged into one or more lists and each element is assigned an index to its corresponding Index in order from most to least significant for comparison purposes. This operation can be used with any number between 0-"}
{"id": 6420, "code": "func merge(left, right *llNode, comparator Comparator) (first *llNode, err error) {\n\tcurLeft := left\n\tcurRight := right\n\n\tvar last *llNode\n\n\tappendResults := func(updated *llNode) {\n\t\tif last == nil {\n\t\t\tlast = updated\n\t\t} else {\n\t\t\tlast.next = updated\n\t\t\tlast = last.next\n\t\t}\n\t\tif first == nil {\n\t\t\tfirst = last\n\t\t}\n\t}\n\n\tfor curLeft != nil && curRight != nil {\n\t\tvar res int\n\t\tif res, err = comparator(curLeft.payload, curRight.payload); nil != err {\n\t\t\tbreak // Don't return, stitch the remaining elements back on.\n\t\t} else if res < 0 {\n\t\t\tappendResults(curLeft)\n\t\t\tcurLeft = curLeft.next\n\t\t} else {\n\t\t\tappendResults(curRight)\n\t\t\tcurRight = curRight.next\n\t\t}\n\t}\n\n\tif curLeft != nil {\n\t\tappendResults(curLeft)\n\t}\n\tif curRight != nil {\n\t\tappendResults(curRight)\n\t}\n\treturn\n}", "reference": "// merge takes two sorted lists and merges them into one sorted list.\n// Behavior is undefined when you pass a non-sorted list as `left` or `right`", "generated": "// Merge a node into an array of nodes and append them to the resulting list.\n/**\n* Returns true or false for all non-node arrays that are not in any order at all when merged with\n*/\npackage llNode\nimport os.path.join(\"/\") as ln;\n/**"}
{"id": 6439, "code": "func (l *List) Remove(pos uint) (interface{}, bool) {\n\tl.key.Lock()\n\tdefer l.key.Unlock()\n\n\tif pos > uint(len(l.underlyer)) {\n\t\treturn nil, false\n\t}\n\tretval := l.underlyer[pos]\n\tl.underlyer = append(l.underlyer[:pos], l.underlyer[pos+1:]...)\n\treturn retval, true\n}", "reference": "// Remove retreives a value from this List and shifts all other values.", "generated": "// This function removes the key from a list of strings and returns it to the caller if no string is found in its place.\n // The return value will be returned as an error message when there are any remaining keys left over after this call. If none exists, then all other values must have been removed by calling"}
{"id": 6484, "code": "func (h *Handler) Rule(r rule.Rule) *Handler {\n\tif r == nil {\n\t\t// if nothing passed then use the allow-everyting rule\n\t\tr = rule.Satisfied()\n\t}\n\th.rule = r\n\n\treturn h\n}", "reference": "// Rule sets the ruleset for this handler.\n//\n// returns itself.", "generated": "This function is used to check whether a given handler has been allowed by an existing ruleset, and returns true or false for any of its arguments. It also checks that all handlers have not yet met their requirements in order from most to least restrictive; otherwise it will return False . The default value returned depends on how many"}
{"id": 6515, "code": "func (c Client) CreateUser(email string, password string) (*user, error) {\n\tparams := map[string]interface{}{\n\t\t\"user[email]\":    email,\n\t\t\"user[password]\": password,\n\t}\n\tholder := userHolder{}\n\tif err := c.Post(\"users\", params, &holder); err != nil {\n\t\treturn nil, err\n\t}\n\tif err := checkApiErrors(holder.response, \"CreateUser\"); err != nil {\n\t\treturn nil, err\n\t}\n\treturn &holder.User, nil\n}", "reference": "// CreateUser creates a new user given an email and password", "generated": "// Creates a new User object with the given credentials and passwords for each of its users in `create`. The parameters are optional but can be used to specify additional options or defaults if desired.\n // This method is called when creating an existing instance using create() .\n func (d *ClientContext ) CreateNew"}
{"id": 6523, "code": "func (c Client) GetTransfers(page int) (*transfers, error) {\n\tparams := map[string]int{\n\t\t\"page\": page,\n\t}\n\tholder := transfersHolder{}\n\tif err := c.Get(\"transfers\", params, &holder); err != nil {\n\t\treturn nil, err\n\t}\n\ttransfers := transfers{\n\t\tpaginationStats: holder.paginationStats,\n\t}\n\t// Remove one layer of nesting\n\tfor _, t := range holder.Transfers {\n\t\ttransfers.Transfers = append(transfers.Transfers, t.Transfer)\n\t}\n\treturn &transfers, nil\n}", "reference": "// GetTransfers get transfers associated with an account", "generated": "The transfer function returns a list containing the transferred data and an iterator that iterates over it to remove all layers of nested information from its stack. The returned value is then passed as an argument back to the client for further processing in order not requiring any additional work on this side of the chain. This method can be used"}
{"id": 6531, "code": "func (d *SerialDispatcher) DispatchOptional(cmd interface{}) (err error) {\n\td.mutex.RLock()\n\tdefer d.mutex.RUnlock()\n\n\terr = d.Dispatch(cmd)\n\tswitch err.(type) {\n\tcase *NoHandlerFoundError:\n\t\treturn nil\n\tdefault:\n\t\treturn err\n\t}\n}", "reference": "// DispatchOptional implements `Dispatcher.DispatchOptional`", "generated": "// This method is called when the dispatcher receives an optional message from the client, and returns a value if it does not return any of its options or otherwise fails to dispatch all available messages for that protocol type specified by this call.\n// The default implementation will use only one option at most once per request; in other"}
{"id": 6532, "code": "func NewParallelDispatcher(handlers []Handler) Dispatcher {\n\treturn &ParallelDispatcher{\n\t\thandlers: handlers,\n\t\tmutex:    sync.RWMutex{},\n\t}\n}", "reference": "// NewParallelDispatcher creates a new PrallelDispatcher with the given handlers", "generated": "// This is a wrapper around the new Paralecatcher() function that was introduced in version 1 of this library. It provides an interface to all existing wrappers for handling asynchronous operations on data and events from within your application's context. The implementation uses synchronous dispatch as its primary mechanism by default; it will be"}
{"id": 6537, "code": "func (l *listener) Accept() (transport.Conn, error) {\n\tif c, ok := <-l.incoming; ok {\n\t\treturn c.conn, c.err\n\t}\n\treturn nil, fmt.Errorf(\"listener is closed\")\n}", "reference": "// Accept waits for and returns the next connection to the listener.", "generated": "Listeners accept incoming and outgoing messages from the same port as a list of peers in an existing connection or to another peer on that network interface using Conn . The message can be sent by any protocol other than TCP/IP , but it must not contain information about its destination address which may cause problems for some clients who are"}
{"id": 6557, "code": "func NewCommand(name string, args ...string) *Command {\n\treturn &Command{\n\t\tname: name,\n\t\targs: args,\n\t}\n}", "reference": "// NewCommand creates a new Livestatus command instance.", "generated": "This command is a new Command object. It contains the following fields and methods that are used to create it (see below):\n\n\nName Description String The first character of the given field Name Returns an array of strings containing all characters in the specified range from 0-9 inclusive for each line within this list; if no"}
{"id": 6564, "code": "func (r Record) GetSlice(column string) ([]interface{}, error) {\n\tv, err := r.getKey(reflect.Slice, column)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trv := reflect.ValueOf(v)\n\tn := rv.Len()\n\tout := make([]interface{}, n)\n\n\tfor i := 0; i < n; i++ {\n\t\tout[i] = rv.Index(i).Interface()\n\t}\n\n\treturn out, nil\n}", "reference": "// GetSlice returns a slice of interface value for a specific column.", "generated": "// Returns a slice of the key-value pairs from an interface that implements Slices and returns them as keys in return values for each element within this struct or its substructs with no other information about their type than what is provided by reference to it // if any are missing at all before returning value types suchas"}
{"id": 6588, "code": "func RemoveSvcAcknowledgement(\n\thost_name string,\n\tservice_description string,\n) *livestatus.Command {\n\treturn livestatus.NewCommand(\n\t\t\"REMOVE_SVC_ACKNOWLEDGEMENT\",\n\t\tstringifyArg(\"host_name\", \"string\", host_name),\n\t\tstringifyArg(\"service_description\", \"string\", service_description),\n\t)\n}", "reference": "// RemoveSvcAcknowledgement creates a new \"REMOVE_SVC_ACKNOWLEDGEMENT\" Nagios command.\n//\n// This removes the problem acknowledgement for a particular service.\n//\n// Once the acknowledgement has been removed, notifications can once again be sent out for the given service.", "generated": "// Removes the SSC acknowledgement from a command that is not yet in use.\n // This can be done by calling removeSsc() or deleteSrc() .\n\n#define DEFAULT-DEVICE 0x00800000\n Description : Returns the name of the specified user agent for removal of SCS"}
{"id": 6615, "code": "func NewCmdWithRunner(cmdName string, runner func()) (*CmdWithRunner, error) {\n\tif cmdName == \"\" {\n\t\treturn nil, errors.New(\"cmdName cannot be blank\")\n\t}\n\n\tfor _, r := range cmdName {\n\t\tif unicode.IsSpace(r) {\n\t\t\treturn nil, errors.Errorf(\"cmdName cannot contain whitespace: %q\", cmdName)\n\t\t}\n\t}\n\n\treturn &CmdWithRunner{\n\t\tcmdName: cmdName,\n\t\trunner:  runner,\n\t}, nil\n}", "reference": "// NewCmdWithRunner creates a new CmdWithRunner for the provided name and runner. Returns an error if the provided name\n// is not a legal command name.", "generated": "// This command creates a new Runnable object that will run the specified commands and return an instance of this class for each one executed by it. The default is to use `newCmd` as its name when creating objects from existing ones (see below).\n // Note : If you want to create multiple instances with"}
{"id": 6617, "code": "func importBreakPaths(file *ast.File) []string {\n\tvar output []string\n\n\tfor _, decl := range file.Decls {\n\t\tif gen, ok := decl.(*ast.GenDecl); ok && gen.Tok == token.IMPORT {\n\t\t\tfor srcIndex, currSpec := range gen.Specs {\n\t\t\t\tif srcIndex > 0 {\n\t\t\t\t\t// if there was a previous element, check if the group has changed\n\t\t\t\t\tcurrGroup := importGroup(importPath(currSpec))\n\t\t\t\t\tprevGroup := importGroup(importPath(gen.Specs[srcIndex-1]))\n\t\t\t\t\tif currGroup != prevGroup {\n\t\t\t\t\t\t// if group has changed, add path to the output\n\t\t\t\t\t\toutput = append(output, importPath(gen.Specs[srcIndex]))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// assume that only one import token block exists\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn output\n}", "reference": "// importBreakPaths returns a slice that contains the import paths before which a line breaks should be inserted.", "generated": "This module imports and exports an AST of strings as input data for use in parsing or encoding text files (including JSON). It is intended primarily for usage with Python 2.7+ libraries such AsyncIO , asyncio , etc., but may be used by other programming languages including C++11 . The following examples are"}
{"id": 6619, "code": "func SupplierWithPrependedArgs(s CmderSupplier, argsFunc func(cmd Cmd) []string) CmderSupplier {\n\treturn func(cmd Cmd) (Cmder, error) {\n\t\tr, err := s(cmd)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn CmderWithPrependedArgs(r, argsFunc(cmd)...), nil\n\t}\n}", "reference": "// SupplierWithPrependedArgs returns a new Supplier that invokes the provided supplier and returns the result of calling\n// RunnerWithPrependedArgs on the returned runner with the result of applying the provided \"argsFunc\" function to the\n// provided command.", "generated": "This function provides a wrapper for the supplied arguments. It returns an optional string containing all of the required information and optionally one or more additional parameters to be passed in as argument by cmd . The returned value is then used when returning from this method if it does not exist yet on any given command line invocation with no options provided"}
{"id": 6633, "code": "func (t *Timer) ServeHTTP(w http.ResponseWriter, req *http.Request) {\n\n\treq.ParseForm()\n\tsortBy := req.Form.Get(\"sort\")\n\n\tstats := &Stats{}\n\tstats.SortBy = strings.ToLower(sortBy)\n\tstats.Generated = time.Now()\n\tstats.UpTime = fmt.Sprintf(\"%s\", stats.Generated.Sub(t.Since))\n\t// Read access OK for map?\n\tstats.Result = make([]*Stat, 0, len(t.routes))\n\tfor k, v := range t.routes {\n\t\tstat := &Stat{}\n\t\tstat.Route = k\n\t\tstat.Count = v.Count\n\t\tstat.Tot = v.Tot\n\t\tstat.Avg = time.Duration(int64(v.Tot) / v.Count)\n\t\tstat.AvgAfter = time.Duration(int64(v.AfterTot) / v.Count)\n\t\tstat.AvgBefore = time.Duration(int64(v.BeforeTot) / v.Count)\n\t\tstat.Max = v.Max\n\t\tstat.Min = v.Min\n\t\tstats.Result = append(stats.Result, stat)\n\t}\n\tsort.Sort(sort.Reverse(stats))\n\tjsonData, _ := json.Marshal(stats)\n\tw.Write(jsonData)\n}", "reference": "// For serving statistics", "generated": "The JSON data returned by the server is a collection of string values that are sorted according to their length and value in ascending order from most recently retrieved items into descending orders based on current status or previous state as specified above. The results can be used with any number between 1 and 100 inclusive if desired but may not exceed this"}
{"id": 6638, "code": "func RectFromSphere(c Vec3, r float32) Rectangle {\n\treturn RectWHD(c[0]-r, c[1]-r, c[2]-r, 2*r, 2*r, 2*r)\n}", "reference": "// RectFromSphere returns the minimum rectangle that contains the circle of\n// center c and radius r.", "generated": "RectFromSphere is a vector of coordinates. It can be used to create an array or as the basis for any other type of vectors (e., Vector). The following example shows how to use it in C# and Visual Basic using its methods from above code snippet :\n\n\n// Create arrays with rectangles // Use"}
{"id": 6640, "code": "func (r Rectangle) Size() Vec3 {\n\treturn Vec3{\n\t\tr.Max[0] - r.Min[0],\n\t\tr.Max[1] - r.Min[1],\n\t\tr.Max[2] - r.Min[2],\n\t}\n}", "reference": "// Size returns r's width, height and depth.", "generated": "This method returns a new Vector4 that is the size of the rectangle, and contains all its elements in an array with zero or more dimensions to store it into. The returned value will be used as part for calculating how many pixels are needed on each side when creating this vector from scratch using Racket's built-in"}
{"id": 6645, "code": "func (r Rectangle) In(s Rectangle) bool {\n\tif r.Empty() {\n\t\treturn true\n\t}\n\t// Note that r.Max is an exclusive bound for r, so that r.In(s)\n\t// does not require that r.Max.In(s).\n\treturn s.Min[0] <= r.Min[0] && r.Max[0] <= s.Max[0] &&\n\t\ts.Min[1] <= r.Min[1] && r.Max[1] <= s.Max[1]\n}", "reference": "// In reports whether Rectangle r is contained in s.", "generated": "This method returns a new instance of the class RoundedRectangle . The returned object will be used to initialize and update its properties in order as needed by this implementation. This constructor can also optionally return null if no methods are provided or nil otherwise. Parameters :a , b int A string representing number representation from which to"}
{"id": 6647, "code": "func ApproxEpsilon(x, y float64, eps float64) bool {\n\treturn math.Abs(x-y) < eps*(1.0+math.Max(math.Abs(x), math.Abs(y)))\n}", "reference": "// ApproxEpsilon returns true if x ~= y, using provided epsilon value.", "generated": "Approximately approximates the Eulerian approximation of a given value in terms that is less than or equal to x and greater then y . The resulting result can be computed using either an integer (elements with no digits are assumed by default); integers may also have values larger than zero; for example if there were two"}
{"id": 6650, "code": "func (v Vec3) Copy(dst Vec3) {\n\tdst[0] = v[0]\n\tdst[1] = v[1]\n\tdst[2] = v[2]\n}", "reference": "// Vec3 methods\n// Copy copies the 3 vector components into dst.", "generated": "copy() copies the contents of a vector to an array. The copy method is called when two vectors are copied, and then returns one or more values for each element in that collection as well; it does not return any other value if there were no elements left over from previous operations on this object before copying was performed."}
{"id": 6703, "code": "func (c *Client) LoadBalancer(identifier string) (*LoadBalancer, error) {\n\tlb := new(LoadBalancer)\n\t_, err := c.MakeApiRequest(\"GET\", \"/1.0/load_balancers/\"+identifier, nil, lb)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn lb, err\n}", "reference": "// LoadBalancer retrieves a detailed view of one load balancer", "generated": "// Initializes a load balancing request to the specified identifier and returns an object with all of its attributes set up for loading in progress by calling init() .\n // This method is used when creating or updating loads from existing clients using C# code as described above.\n// The initializer will be called upon initialization"}
{"id": 6730, "code": "func FromURL(src *url.URL, w io.Writer, options Options) error {\n\thttpClient := getHTTPClient(options)\n\tvar (\n\t\terr  error\n\t\tresp *http.Response\n\t)\n\tdownloader := func() error {\n\t\tresp, err = httpClient.Get(src.String())\n\t\tif err != nil {\n\t\t\treturn &retriableError{errors.Wrap(err, \"Temporary download error\")}\n\t\t}\n\t\tif resp.StatusCode != http.StatusOK {\n\t\t\tdefer func() { _ = resp.Body.Close() }() // #nosec\n\t\t\treturn errors.Errorf(\"received invalid status code: %d (expected %d)\", resp.StatusCode, http.StatusOK)\n\t\t}\n\t\treturn nil\n\t}\n\tretries := options.Retries\n\tif retries == 0 {\n\t\tretries = 5\n\t}\n\tif err = retryAfter(retries, downloader, options.RetryInterval); err != nil {\n\t\treturn errors.Wrap(err, \"download failed\")\n\t}\n\tdefer func() { _ = resp.Body.Close() }() // #nosec\n\n\tvar (\n\t\tvalidator checksumValidator\n\n\t\treader io.Reader = resp.Body\n\t)\n\n\tif options.ProgressBars != nil && resp.ContentLength > 0 {\n\t\tbar := newProgressBar(resp.ContentLength, options.ProgressBars.MaxWidth, options.ProgressBars.Writer)\n\t\tbar.Start()\n\t\treader = bar.NewProxyReader(reader)\n\t\tdefer func() {\n\t\t\t<-time.After(bar.RefreshRate)\n\t\t\tfmt.Println()\n\t\t}()\n\t}\n\n\tvalidator, reader, err = createValidatorReader(reader, options.ChecksumHash, httpClient, options.Checksum, path.Base(src.Path))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif _, err = io.Copy(w, reader); err != nil {\n\t\treturn errors.Wrap(err, \"failed to copy contents\")\n\t}\n\n\tif !validator.validate() {\n\t\treturn errors.New(\"checksum validation failed\")\n\t}\n\n\treturn nil\n}", "reference": "// FromURL downloads the specified `src` URL to `w` writer using\n// the specified `Options`.", "generated": "The following example creates a validating HTTP client and downloads the content of the request from the server using curl . The URL is provided as an argument for this method in order that it can be used by other applications or services on their own servers without having access control over its execution process itself. This implementation uses two methods which"}
{"id": 6733, "code": "func RandomSecret(length int, rnd *rand.Rand) string {\n\tif 0 <= length {\n\t\tlength = 10\n\t}\n\tsecret := make([]byte, length)\n\tfor i, _ := range secret {\n\t\tsecret[i] = byte(rnd.Int31() % 256)\n\t}\n\treturn base32.StdEncoding.EncodeToString(secret)\n}", "reference": "// Generate a Random secret encoded as a b32 string\n// If the length is <= 0, a default length of 10 bytes will\n// be used, which will generate a secret of length 16.", "generated": "Random Secret is a random number generator that generates an encrypted message with the given key and value for each of its keys in hexadecimal format (hex digits). It can be used to generate plaintext messages or as part-of any cipher text file such by using it's own encryption algorithm which uses AES256 ."}
{"id": 6758, "code": "func (a *AddrBook) RemoveAddress(addr *NetAddress) {\n\ta.mtx.Lock()\n\tdefer a.mtx.Unlock()\n\tka := a.addrLookup[addr.String()]\n\tif ka == nil {\n\t\treturn\n\t}\n\tlog.Info(\"Remove address from book\", \"addr\", addr)\n\ta.removeFromAllBuckets(ka)\n}", "reference": "// RemoveAddress removes the address from the book.", "generated": "This function removes all addresses in the list of books that are currently available for deletion, and returns an array containing only those records which have been deleted or removed by this method. The delete operation is performed on any record whose name contains no characters except one character at most once per page; if there were more than two such"}
{"id": 6767, "code": "func (na *NetAddress) Dial() (net.Conn, error) {\n\tconn, err := net.Dial(\"tcp\", na.String())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn conn, nil\n}", "reference": "// Dial calls net.Dial on the address.", "generated": "// This function returns a string that contains the address of the server to which it is sent and an optional message for each connection received from this client // in order notifying clients when they receive messages with different addresses or if there are no connections at all within range(0).\n// The default value will be \"nil"}
{"id": 6778, "code": "func LogOnPanic(id int64, err interface{}, stacktrace []string, _ *http.Request) {\n\tlogMutex.Lock()\n\tdefer logMutex.Unlock()\n\n\tlog.Printf(\"panic=%016x message=%v\\n\", id, err)\n\tfor _, line := range stacktrace {\n\t\tlog.Printf(\"panic=%016x %s\", id, line)\n\t}\n}", "reference": "// LogOnPanic logs the given panic and its stacktrace, prefixing each line with\n// the panic ID.", "generated": "Logon Panics is a method that logs messages to the console when an error occurs in the process of logging or debugging information about any program running on your system (including those you are using). It can be used as a way for users and developers alike not only debug errors but also help them understand what's going wrong"}
{"id": 6791, "code": "func (hub *hub) getChannel(name string) *channel {\n\thub.Lock()\n\tdefer hub.Unlock()\n\tcn, ok := hub.channels[name]\n\tif ok {\n\t\treturn cn\n\t}\n\tcn = makeChannel(hub, name)\n\thub.channels[name] = cn\n\tgo cn.start()\n\treturn cn\n}", "reference": "// GetChannel gets or creates new pubsub channel.", "generated": "// Create a channel for the specified namespace and create an instance of it using channels from that class to be used as its default ChannelHandler .\n // This is done by calling channels with no arguments or returning nil if there are any bindings available in this context.\n// The following example creates two new instances named \""}
{"id": 6814, "code": "func (c *Client) Push(value interface{}, params map[string]string) (*Client, error) {\n\tbody, err := json.Marshal(value)\n\tif err != nil {\n\t\tlog.Printf(\"%v\\n\", err)\n\t\treturn nil, err\n\t}\n\n\tres, err := c.api.Call(\"POST\", c.Url, c.Auth, body, params)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar r map[string]string\n\n\terr = json.Unmarshal(res, &r)\n\tif err != nil {\n\t\tlog.Printf(\"%v\\n\", err)\n\t\treturn nil, err\n\t}\n\n\tret := &Client{\n\t\tapi:   c.api,\n\t\tAuth:  c.Auth,\n\t\tUrl:   c.Url + \"/\" + r[\"name\"],\n\t\tvalue: value}\n\n\treturn ret, nil\n}", "reference": "// Push creates a new value under the current root url.\n// A populated pointer with that value is also returned.", "generated": "// This method is used to create a new client and request the credentials of an existing one using JSON API // from within it. The callback function returns true if this connection has been established or false otherwise.\n func () Client { log \"Connection opened with {}\".format(client.Id) }() -> bool {"}
{"id": 6821, "code": "func (t *trace) Finish() {\n\tif t.err {\n\t\tincrError(t)\n\t}\n\tincr(t)\n\tduration(t)\n\tif t.err {\n\t\tincrError(t)\n\t}\n\tt.trace.Finish()\n}", "reference": "// Finish declares that this trace is complete.\n// The trace should not be used after calling this method.", "generated": "// This function is called when the trace finishes, and returns a status code indicating whether the process has finished or not.\n // The following example shows how to use this method in an application that does not have any traces at all."}
{"id": 6843, "code": "func (c *Client) PushLinkToChannel(tag, title, u, body string) error {\n\tdata := Link{\n\t\tTag:   tag,\n\t\tType:  \"link\",\n\t\tTitle: title,\n\t\tURL:   u,\n\t\tBody:  body,\n\t}\n\treturn c.Push(\"/pushes\", data)\n}", "reference": "// PushLinkToChannel pushes a link with a title and url to a specific PushBullet device.", "generated": "// This method is used to push a link from the channel into the client's local storage and return it as an object with no parameters or methods that are not provided by this class. // The following example uses `http://localhost` for sending links back in time using http-proxy instead of https::port . func"}
{"id": 6852, "code": "func (c *cachedLoader) MustGetString(key string) string {\n\tb, err := c.Get(key)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"Could not fetch config (%s) %v\", key, err))\n\t}\n\n\tvar s string\n\terr = json.Unmarshal(b, &s)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"Could not unmarshal config (%s) %v\", key, err))\n\t}\n\n\treturn s\n}", "reference": "// MustGetString fetches the config and parses it into a string.  Panics on failure.", "generated": "The cache is a collection of strings that are returned by the CacheManager . The following code snippet retrieves and returns an array containing all available configuration options for each user in this application's database using CachingCacheOptions :"}
{"id": 6870, "code": "func (e *execStreamerBuilder) Exe(exe string) ExecStreamerBuilder {\n\te.d.Exe = exe\n\treturn e\n}", "reference": "//Exe sets the Exe", "generated": "This function returns an instance of the EXE class, which is a wrapper around the existing API provided by Microsoft's Visual Studio IDE and provides some useful functionality to developers using it in their applications or for debugging purposes as well.[1] The following code snippet demonstrates how this works:[2][3]:\n\n[4]("}
{"id": 6884, "code": "func (w *Window) setCell(x, y int, c Cell) {\n\tc.dirty = true\n\tpos := x + (y * w.x)\n\tif pos < len(w.backingStore) {\n\t\tw.backingStore[pos] = c\n\t}\n}", "reference": "// setCell sets the content of the window cell at the x and y coordinate.\n// setCell shall be called from queue context.", "generated": "// Set the cell to a new location in the window's backing store for each row of cells that are not already there. This is called setting up an initial state and then returning it when no more rows have been created or returned from the storage pool by this method. // The default value will be nil if nothing"}
{"id": 6896, "code": "func Deinit() {\n\twait := make(chan interface{})\n\tQueue(func() {\n\t\ttermbox.Close()\n\t\tfocus = nil\n\t\tprevFocus = nil\n\t\twindows = make(map[int]*Window) // toss all windows\n\n\t\trawMtx.Lock()\n\t\ttermRaw = false\n\t\trawMtx.Unlock()\n\n\t\twait <- true\n\t})\n\t<-wait\n}", "reference": "// Deinit switches the terminal back to cooked mode and it terminates managed\n// window mode.  Init must be called again if a switch is required again.\n// Deinit shall be called on application exit; failing to do so may leave the\n// terminal corrupted.  If that does happen typing \"reset\" on the shell usually\n// fixes this problem.", "generated": "// This function is called when the buffer has been closed and a new window was opened, or if no current frame exists in that context (i.,e.: it's not possible to open an existing one). It returns null for nonce errors as well; otherwise, this will return undefined .\n// The default behavior"}
{"id": 6933, "code": "func (d *Derive) Update(v float64) {\n\tp := atomic.SwapUint64(&d.value, math.Float64bits(v))\n\td.rate.Update(v - math.Float64frombits(p))\n}", "reference": "// Update update rate value based on the stored previous value.", "generated": "This method updates the value of a Derivative object to its original state and returns it as an AtomicReference . The update() function is called when all values are updated with new information about their respective states or if no changes have been made in any way by this call without updating at least one element from within that reference"}
{"id": 6934, "code": "func (r *Reservoir) Snapshot() Distribution {\n\th := newHistogram(defaultHistogramSize)\n\tr.m.Lock()\n\th = r.hist.Copy(h)\n\tr.m.Unlock()\n\treturn h\n}", "reference": "// Snapshot returns a Distribution", "generated": "This function is a wrapper around the Resolver class, which provides an interface to collect and store data about collections in memory using serialization of strings as keys or values for collection operations on objects that are not enumerated by this method. The returned value can be used with any number between 0-9 inclusive; it will"}
{"id": 6957, "code": "func (s *Set) RemoveAll(values ...interface{}) {\n\ts.Lock()\n\tdefer s.Unlock()\n\tfor _, value := range values {\n\t\tdelete(s.m, value)\n\t}\n}", "reference": "// RemoveAll removes all values from the set if they exist in the set.", "generated": "// This method removes all of the items from a set and returns them as an array with no additional information about their contents or status.\n // The methods are defined in Set .\nMethods:"}
{"id": 6980, "code": "func (s *Server) SendRequest(connID string, method string, params interface{}, resHandler func(ctx *ResCtx) error) (reqID string, err error) {\n\tif !s.running.Load().(bool) {\n\t\treturn \"\", errors.New(\"use of closed server\")\n\t}\n\n\tif conn, ok := s.conns.GetOk(connID); ok {\n\t\treqID, err = conn.(*Conn).SendRequest(method, params, resHandler)\n\t\t// todo: only log in debug mode?\n\t\tlog.Printf(\"server: send-request: connID: %v, reqID: %v, method: %v, params: %#v, err (if any): %v\", connID, reqID, method, params, err)\n\t\treturn\n\t}\n\n\treturn \"\", fmt.Errorf(\"connection with requested ID: %v does not exist\", connID)\n}", "reference": "// SendRequest sends a JSON-RPC request through the connection denoted by the connection ID with an auto generated request ID.\n// resHandler is called when a response is returned.", "generated": "This function sends a request and returns an object that contains the following information about its status:\nThe response is sent asynchronously by calling this callback on each connection received from it or if no such call was made before receiving one; otherwise nil . The returned objects are passed along to other functions which will be called when"}
{"id": 6996, "code": "func (r *Router) Request(route string, handler func(ctx *neptulon.ReqCtx) error) {\n\tr.routes[route] = handler\n}", "reference": "// Request adds a new request route registry.", "generated": "Request is a request to the router for routes that are not specified in route or nil . The default value of route will be returned if no routing information was provided by this function and any other options were used as parameters when calling it with an empty list. If there is none available then return None , otherwise returns"}
{"id": 7042, "code": "func (c *Conn) setConn(ws *websocket.Conn) error {\n\tc.ws.Store(ws)\n\tc.connected.Store(true)\n\tif err := ws.SetDeadline(time.Now().Add(c.deadline)); err != nil {\n\t\treturn fmt.Errorf(\"conn: error while setting websocket connection deadline: %v\", err)\n\t}\n\treturn nil\n}", "reference": "// Reuse an established websocket.Conn.", "generated": "// Set the timeout for a socket to be opened by calling Conn() . This is used when an incoming message arrives from another server, or if it's not received yet and there are no other connections available at that time in your application.\n// Returns: true , false , or None depending on whether this method was"}
{"id": 7046, "code": "func (r *MockReadWriteCloser) Read(p []byte) (n int, err error) {\n\n\tif err = r.ReadErr; err == nil {\n\t\tr.BytesRead = p\n\t\tn = len(p)\n\t}\n\treturn\n}", "reference": "//Read - satisfies reader interface", "generated": "This method reads and writes a byte to the buffer specified by the mockserver's read() function in order for itto be able access its contents from within that particular block of data if necessary. The following example is an implementation-defined interface which implements this functionality using MockingDB::read(). It uses two methods"}
{"id": 7078, "code": "func (m *MACMaskArg) MarshalBinary() ([]byte, error) {\n\t// Must indicate correct number of directives\n\tif int(m.DirCount) != len(m.Directives) {\n\t\treturn nil, ErrorBadArgumentParameter\n\t}\n\n\t// Allocate byte slice for argument and all directives\n\tb := make([]byte, macMaskArgLen+(directiveLen*m.DirCount))\n\n\t// 1 byte reserved\n\n\tb[1] = uint8(m.Command)\n\tb[2] = uint8(m.Error)\n\tb[3] = m.DirCount\n\n\t// Marshal each directive into binary and copy into byte slice\n\t// after argument\n\tn := 4\n\tfor _, d := range m.Directives {\n\t\tdb, err := d.MarshalBinary()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tcopy(b[n:n+directiveLen], db)\n\t\tn += directiveLen\n\t}\n\n\treturn b, nil\n}", "reference": "// MarshalBinary allocates a byte slice containing the data from a MACMaskArg.\n//\n// If m.DirCount does not indicate the actual length of m.Directives, or\n// a Directive is malformed, ErrorBadArgumentParameter is returned.", "generated": "This function is a wrapper around the MACM_MASK macro to create an alias that can be used in conjunction with other macros such as MIRROR or MASTER . The name must match any given command line string which will appear on your Mac when you run it from within Windows Explorer using MS-Windows Shell Command"}
{"id": 7086, "code": "func (s *CORSHandler) CreatePreflight(routes Routes) Routes {\n\tlist := make(Routes, 0, len(routes))\n\thList := make(map[string]*CORSPreflight, len(routes))\n\tfor _, v := range routes {\n\t\tpreflight, ok := hList[v.Path]\n\t\tif !ok {\n\t\t\tpreflight = &CORSPreflight{\n\t\t\t\t*s,\n\t\t\t\tmake([]string, 0, 1),\n\t\t\t\tv.MustAuth,\n\t\t\t}\n\t\t\thList[v.Path] = preflight\n\t\t}\n\n\t\tpreflight.Methods = append(preflight.Methods, v.Method)\n\t\tif v.MustAuth {\n\t\t\tpreflight.UseCredentials = true\n\t\t}\n\t}\n\n\tfor k, v := range hList {\n\t\tlist = append(list, Route{\n\t\t\tName:       \"\",\n\t\t\tMethod:     DEFAULT_CORS_PREFLIGHT_METHOD,\n\t\t\tPath:       k,\n\t\t\tMustAuth:   v.UseCredentials,\n\t\t\tActionFunc: v.ServeHTTP,\n\t\t})\n\t}\n\treturn list\n}", "reference": "// CreatePreflight creates HTTP routes that handles pre-flight requests.", "generated": "// Initializes a new route with the specified name and path to be used for initialization of an existing one.\n // This method is called when all other methods are invoked on that same instance. It returns nil if no such request was made or any error occurred in this case;\n/**\n** A single-"}
{"id": 7097, "code": "func (b *RefCountBox) Alloc() (DB, error) {\n\tb.Lock()\n\tdefer b.Unlock()\n\n\tif b.db.DB == nil {\n\t\tif b.DataPath == nil {\n\t\t\treturn DB{}, errorsp.WithStacks(ErrBoxDataPathNotSpecified)\n\t\t}\n\t\tvar db DB\n\t\tvar err error\n\t\tif b.OpenFunc == nil {\n\t\t\tdb, err = Open(b.DataPath(), 0644, nil)\n\t\t} else {\n\t\t\tdb, err = b.OpenFunc(b.DataPath())\n\t\t}\n\t\tif err != nil {\n\t\t\treturn DB{}, errorsp.WithStacks(err)\n\t\t}\n\t\tb.db, b.count = db, 0\n\t}\n\tb.count++\n\treturn b.db, nil\n}", "reference": "// Alloc opens a DB if not openned yet. It adds a reference if already openned.", "generated": "// This function is used to lock the data in a buffer and return it if there are no more entries or not found at all within that file descriptor range for any reason other than an exception thrown by this method // from some database entry handler which may be encountered during processing of new files on disk with respect ToString()."}
{"id": 7105, "code": "func ToSSN(theString, delimiter string) (string, error) {\n\tf := New(theString)\n\tf.removeNonDigits()\n\n\tif f.length != 9 {\n\t\treturn \"\", errors.New(\"string needs to be 9 digits for Social Security Numbers\")\n\t}\n\n\tvar buffer bytes.Buffer\n\tcount := 0\n\n\tfor _, i := range f.theString {\n\t\tcount++\n\n\t\tbuffer.WriteString(string(i))\n\n\t\tif count == 3 || count == 5 {\n\t\t\tbuffer.WriteString(delimiter)\n\t\t}\n\t}\n\treturn buffer.String(), nil\n}", "reference": "// ToSSN will format the provided string as a SSN.", "generated": "The method is a wrapper around the new StringBuilder interface and provides an optional `to` parameter that can optionally contain any number of strings or numbers in addition from 1 to 10 inclusive. The returned value will return either one of two values - true if there are no characters left on the screen at all while false otherwise."}
{"id": 7113, "code": "func (c *Config) OptionMap(section string) map[string]string {\n\toptions := make(map[string]string)\n\tfor _, sect := range c.sections {\n\t\tif sect.name == section {\n\t\t\tfor _, opt := range sect.options {\n\t\t\t\toptions[opt.name] = opt.value\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t}\n\treturn options\n}", "reference": "// OptionMap returns the map option => value for a given section.", "generated": "Option maps a list of strings to the specified sections and returns an array containing all available values for that element in each row or column within this mapping . The default value is nil if no matching elements are found on any given page; otherwise it will return None , which means there's nothing left over from previous iterations with only"}
{"id": 7121, "code": "func Convert(val interface{}, targetType reflect.Type) reflect.Value {\n\tvalue := reflect.ValueOf(val)\n\tif !value.IsValid() {\n\t\treturn reflect.Zero(targetType)\n\t}\n\n\tvalType := value.Type()\n\tif valType.ConvertibleTo(targetType) {\n\t\treturn value.Convert(targetType)\n\t}\n\n\t//fmt.Printf(\"Value type is %v, emptyInterfaceType is %v, equals %v\\n\", valType, emptyInterfaceType, valType == emptyInterfaceType)\n\tinterfaceVal := value.Interface()\n\n\tswitch realVal := interfaceVal.(type) {\n\tcase float64:\n\t\treturn reflect.ValueOf(realVal).Convert(targetType)\n\tcase []interface{}:\n\t\t// val is of type []interface{}, try to convert to typ\n\t\tsliceSize := len(realVal)\n\t\ttargetSlice := reflect.MakeSlice(targetType, 0, sliceSize)\n\t\telemType := targetType.Elem()\n\t\tfor i := 0; i < sliceSize; i++ {\n\t\t\ttargetSlice = reflect.Append(targetSlice, Convert(value.Index(i), elemType))\n\t\t}\n\t\treturn targetSlice\n\t}\n\n\tpanic(fmt.Errorf(\"convert from type %v to %v failed: %v\", valType, targetType, value))\n}", "reference": "// try to convert value to target type, panic if fail", "generated": "The conversion function converts a string representation of an object into the form of a struct or enum with no fields and returns its corresponding values as follows : int[]int[]string{\"name\": \"Name\", \"description\":\"Description\"} . The return types are enumerated in this way by default for all objects that have not"}
{"id": 7123, "code": "func Filter(l LogBackend, r Ruler) LogBackend {\n\treturn &filter{\n\t\tLogBackend: l,\n\t\tr:          r,\n\t}\n}", "reference": "// Filter creates a new filter with rules r for l backend.", "generated": "// This function filters the logbackends of a logger. It returns an error if no logging is available for any given path or destination (i.,e.: nil).\n // The default value is false .\n func filter() { return L }\n\n Description : Returns a list containing all logs that have been filtered by"}
{"id": 7139, "code": "func (cn *ContentNegotiator) getEncoder(req *http.Request) Encoder {\n\tvar result = cn.DefaultEncoder\n\taccept := req.Header.Get(\"Accept\")\n\n\tfor k, v := range cn.encoderMap {\n\t\tif strings.Contains(accept, k) {\n\t\t\tresult = v\n\t\t\tbreak\n\t\t}\n\t}\n\treturn result\n}", "reference": "// getEncoder parses the Accept header an returns the appropriate encoder to use", "generated": "// Get the encoding of a Content Negotiation object and return it as an array with all encodings in order from most to least encoded for each request type // provided by http.Request . The default is \"UTF-8\".\n// This method returns only one value if no other options exist or nil otherwise returned"}
{"id": 7148, "code": "func DefaultServiceConfig() ServiceConfig {\n\treturn ServiceConfig{\n\t\t// Dependencies.\n\t\tBackoffFactory: func() Backoff {\n\t\t\treturn &backoff.StopBackOff{}\n\t\t},\n\t\tRandFactory: rand.Int,\n\n\t\t// Settings.\n\t\tRandReader: rand.Reader,\n\t\tTimeout:    1 * time.Second,\n\t}\n}", "reference": "// DefaultServiceConfig provides a default configuration to create a new random\n// service by best effort.", "generated": "This service configures the default settings for a specific application and provides an interface to manage them in real-time using custom configuration files (defaults to nil ). The defaults are used by all services that use this API as well; they can be changed at any point during runtime or when needed from within their own codebase"}
{"id": 7222, "code": "func (logger *Logger) Log(level Level, a ...interface{}) {\n\tlogger.log(level, \"\", a...)\n}", "reference": "// Log logs provided message.", "generated": "This function returns the log level of the logger and its associated interface . The logging levels are specified in an array with each entry as follows :\n\n\nLevel Description string String A list containing all logs that have been logged by this user or any other account on your system for at least one day since last login to LOG_"}
{"id": 7234, "code": "func (e *Entry) getChildEntry(pat string) *Entry {\n\tfor _, entry := range e.entries {\n\t\tif pat == entry.Pattern() {\n\t\t\treturn entry\n\t\t}\n\t}\n\treturn nil\n}", "reference": "// getChildEntry returns a child Entry that matches the given pattern string.", "generated": "// Returns a list of entries that are the same as an Entry object and return it if they match any criteria for matching in this case // or otherwise fail to do so with no exceptions thrown by default.\n// Example:\n// Get all children from each child's parent tree using `getChildren` method on Ent"}
{"id": 7263, "code": "func routeSplitFunc(data []byte, atEOF bool) (int, []byte, error) {\n\tif atEOF || data == nil {\n\t\treturn 0, nil, io.EOF\n\t}\n\n\tr, _ := utf8.DecodeRune(data)\n\n\t// matcher\n\tif r == '<' {\n\t\ti := bytes.IndexRune(data, '>')\n\t\tif i == -1 {\n\t\t\treturn 0, nil, NoClosingBracket\n\t\t}\n\t\treturn (i + 1), data[:(i + 1)], nil\n\t}\n\n\t// one char\n\tif len(data) == 1 {\n\t\treturn 1, data, nil\n\t}\n\n\t// should ignore first '/'\n\tslashIndex := bytes.IndexRune(data[1:], '/')\n\tif slashIndex != -1 {\n\t\tslashIndex++\n\t}\n\n\tmatchIndex := bytes.IndexRune(data, '<')\n\n\t// remaining string would be a static entry\n\tif slashIndex == -1 && matchIndex == -1 {\n\t\treturn len(data), data, nil\n\t}\n\n\t// split by '<'\n\t// return data before '<'\n\tif matchIndex != -1 && (slashIndex == -1 || slashIndex > matchIndex) {\n\t\treturn matchIndex, data[:matchIndex], nil\n\t}\n\n\t// split by '/'\n\t// return data before '/' including '/'\n\treturn slashIndex + 1, data[:(slashIndex + 1)], nil\n}", "reference": "// routeSplitFunc is the SplitFunc to scan url pattern.", "generated": "The method routes splits the strings of an array into two parts and returns them as single-character arrays with no trailing whitespace or spaces in between each element. The resulting sequence is then passed to another function that will perform all necessary operations on it's elements until they are returned from its callback using either `split` or"}
{"id": 7282, "code": "func (s *Image) Run(cfg *RunConfig) (*Container, error) {\n\targs := make([]string, 0, len(cfg.Options)+len(cfg.Args)+1)\n\targs = append(args, cfg.Options...)\n\targs = append(args, s.name)\n\targs = append(args, cfg.Args...)\n\n\tout, err := s.docker.Run(\"run\", args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcontainer := &Container{\n\t\tdocker: s.docker,\n\t\tid:     strings.TrimSpace(out),\n\t}\n\tif container.id == \"\" {\n\t\treturn nil, UnexpectedOutputError(\n\t\t\t\"Unexpected empty output when running docker container\")\n\t}\n\n\treturn container, nil\n}", "reference": "// Run creates a new Docker container as defined by current image and container\n// template.\n//\n// Returns ExternalCmdError or UnexpectedOutputError on error.", "generated": "The Docker daemon creates a new Container object and returns it to the user for execution by calling its init() method on that instance of the application specified in config.json . The default value is \"true\". This function will return an array containing all containers created with this name as well any instances which have been added or removed"}
{"id": 7285, "code": "func (s NetworkSettings) PortAt(index int) (string, *HostPublish) {\n\tcounter := 0\n\tfor k, v := range s.Ports {\n\t\tif counter != index {\n\t\t\tcounter++\n\t\t\tcontinue\n\t\t}\n\n\t\treturn k, v\n\t}\n\n\treturn \"\", nil\n}", "reference": "// PortAt returns expose and publish port information at especified index.", "generated": "// This method is used to create a new TCP connection for the specified port at which it will be sent and received by all clients on that network interface. The default value of this function should not be changed unless explicitly set in an application configuration file or otherwise overridden with // `netstat -d '` ."}
{"id": 7297, "code": "func (tx Tx) ForEachGob(folders [][]byte, f func(Bucket, bytesp.Slice, interface{}) error) error {\n\treturn tx.ForEach(folders, func(b Bucket, k, bs bytesp.Slice) error {\n\t\tvar v interface{}\n\t\tif err := gob.NewDecoder(&bs).Decode(&v); err != nil {\n\t\t\treturn errorsp.WithStacksAndMessage(err, \"decoding %d bytes value for key %q failed\", len(bs), string(k))\n\t\t}\n\t\treturn errorsp.WithStacks(f(b, k, v))\n\t})\n}", "reference": "// ForEach iterates over all key values of a folder, decode non-nil values using gob.", "generated": "This function creates a new byte[] chunk from the given bucket and returns it as an array of chunks with all keys in that block's slice at once. The resulting hash is then used to create two additional buckets which are returned by this method each time they're created using cobblenumber . This can be useful when"}
{"id": 7310, "code": "func (handler *WriteHandler) Handle(record *Record) error {\n\t_, err := handler.Writer.Write([]byte(handler.Formatter.Format(record) + \"\\n\"))\n\treturn err\n}", "reference": "// Handle writes all provided log records to writer provided during creation.", "generated": "This function handles errors in the form of a string or an array containing information about record types and methods that are not available to write handlers for this type of event. The format is specified by default as \"string\", but can be changed with `write` . This method will return nil if no data was found on any"}
